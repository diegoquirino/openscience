Item Title,Publication Title,Book Series Title,Journal Volume,Journal Issue,Item DOI,Authors,Publication Year,URL,Content Type,Keywords,Pages,Abstract
Efficient Dynamic Model Based Testing,"Formal Techniques for Distributed Objects, Components, and Systems",,,,10.1007/978-3-031-35355-0_11,P. H. M. van Spaendonck,2023,http://link.springer.com/chapter/10.1007/978-3-031-35355-0_11,Chapter,"efficient testing, model based testing, test case selection",10,"Model-based testing (MBT) provides an automated approach for finding discrepancies between software models and their implementation. If we want to incorporate MBT into the fast and iterative software development process that is Continuous Integration Continuous Deployment, then MBT must be able to test the entire model in as little time as possible. However, current academic MBT tools either traverse models at random, which we show to be ineffective for this purpose, or use precalculated optimal paths which can not be efficiently calculated for large industrial models. We provide a new traversal strategy that provides an improvement in error-detection rate comparable to using precalculated paths. We show that the new strategy is able to be applied efficiently to large models. The benchmarks are performed on a mix of real-world and pseudo-randomly generated models. We observe no significant difference between these two types of models."
Compositionality in Model-Based Testing,Testing Software and Systems,,,,10.1007/978-3-031-43240-8_13,Gijs van CuyckLars van ArragonJan Tretmans,2023,http://link.springer.com/chapter/10.1007/978-3-031-43240-8_13,Chapter,"component-based testing, compositional testing, labelled transition systems, model-based testing, uioco",10,"Model-based testing (MBT) promises a scalable solution to testing large systems, if a model is available. Creating these models for large systems, however, has proven to be difficult. Composing larger models from smaller ones could solve this, but our current MBT conformance relation $$\mathrel {{\textbf {uioco}}}$$ uioco is not compositional, i.e. correctly tested components, when composed into a system, can still lead to a faulty system. To catch these integration problems, we introduce a new relation over component models called mutual acceptance . Mutually accepting components are guaranteed to communicate correctly, which makes MBT compositional. In addition to providing compositionality, mutual acceptance has benefits when retesting systems with updated components, and when diagnosing systems consisting of components."
Model-based Player Experience Testing with Emotion Pattern Verification,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-031-30826-0_9,Saba Gholizadeh AnsariI. S. W. B. PrasetyaDavide PrandiFitsum Meshesha KifetewMehdi DastaniFrank DignumGabriele Keller,2023,http://link.springer.com/chapter/10.1007/978-3-031-30826-0_9,Chapter,"agent-based testing, automated player experience testing, model-based testing, models of emotion",10,"Player eXperience (PX) testing has attracted attention in the game industry as video games become more complex and widespread. Understanding players’ desires and their experience are key elements to guarantee the success of a game in the highly competitive market. Although a number of techniques have been introduced to measure the emotional aspect of the experience, automated testing of player experience still needs to be explored. This paper presents a framework for automated player experience testing by formulating emotion patterns’ requirements and utilizing a computational model of players’ emotions developed based on a psychological theory of emotions along with a model-based testing approach for test suite generation. We evaluate the strength of our framework by performing mutation test. The paper also evaluates the performance of a search-based generated test suite and LTL model checking-based test suite in revealing various variations of temporal and spatial emotion patterns. Results show the contribution of both algorithms in generating complementary test cases for revealing various emotions in different locations of a game level."
Towards a Dynamic Testing Approach for Checking the Correctness of Ethereum Smart Contracts,Risks and Security of Internet and Systems,,,,10.1007/978-3-031-31108-6_7,Mohamed Amin HammamiMariam LahamiAfef Jmal Maâlej,2023,http://link.springer.com/chapter/10.1007/978-3-031-31108-6_7,Chapter,"Blockchain, Dynamic Testing, Ethereum, Model-based testing, Smart contracts, UPPAAL Timed automata, Validation, Verification",10,"One of the most essential concepts related to the development of Blockchain oriented software is smart contracts. Once deployed on the blockchain, these pieces of code cannot be altered due to the immutability feature of the blockchain technology. Therefore, it is necessary to verify and validate smart contracts before their deployment. This paper presents a model-based testing approach for validating and checking the correctness of Ethereum smart contracts. The adopted process comprises essentially four steps: (1) modelling the smart contract and its blockchain environment as UPPAAL Timed Automata, (2) generating abstract test cases by UPPAAL CO $$\surd $$ √ ER tool, (3) executing in a dynamic manner the generated test cases, and finally (4) analyzing the obtained test results and generating test reports. To illustrate our proposal, we apply it on Ethereum Blockchain and especially on the electronic voting case study."
Towards Online Testing Under Uncertainty Using Model-Based Reinforcement Learning,Software Architecture. ECSA 2022 Tracks and Workshops,,,,10.1007/978-3-031-36889-9_17,Matteo CamilliRaffaela MirandolaPatrizia ScandurraCatia Trubiani,2023,http://link.springer.com/chapter/10.1007/978-3-031-36889-9_17,Chapter,"Bayesian Reinforcement Learning, Markov Decision Processes, Model-based Testing, Uncertainty quantification",10,"Modern software operates in complex ecosystems and is exposed to multiple sources of uncertainty that emerge in different phases of the development lifecycle, such as early requirement analysis or late testing and in-field monitoring. This paper envisions a novel methodology to deal with uncertainty in online model-based testing. We make use of model-based reinforcement learning to gather runtime evidence, spot and quantify existing uncertainties of the system under test. Preliminary experiments show that our novel testing approach has the potential of overcoming the major weaknesses of existing online testing techniques tailored to uncertainty quantification."
Conformance in the Railway Industry: Single-Input-Change Testing a EULYNX Controller,Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-031-43681-9_14,Djurre van der WalMarcus GerholdMariëlle Stoelinga,2023,http://link.springer.com/chapter/10.1007/978-3-031-43681-9_14,Chapter,"Conformance testing, Model-based testing, Programmable logic controllers, Railways, Safety-critical systems, Single-Input-Change",10,"We propose a novel framework for model-based testing against specifications from EULYNX , a SysML-based standard from the railway industry for the controllers of systems such as points, signals, sensors, and crossings. The main challenge here is the sheer complexity: with state spaces exceeding $$10^{10}$$ states, it is hard to derive test suites that achieve a meaningful type of coverage. We tackle this problem by moving away from the traditional interleaving semantics for SysML. Instead, we propose a synchronous semantics in terms of Finite State Machines (FSMs), leveraging the fact that EULYNX is implemented on Programmable Logic Controllers (PLCs). Then, we deploy Single-Input-Change Deterministic Finite State Machines (SIC-DFSMs), which ensures fully deterministic tests thus minimizing scalability issues. Our focus lies on the EULYNX specification for point controllers . The generated test suite achieves maximal transition coverage, but test execution time remains substantial. We introduce an additional test suite that achieves maximal transition label coverage. Remarkably, this smaller suite successfully identifies the same four faults as the larger suite."
Towards Automated Load Testing Through the User Interface,Human-Computer Interaction – INTERACT 2023,,,,10.1007/978-3-031-42283-6_28,Bruno TeixeiraJosé Creissac Campos,2023,http://link.springer.com/chapter/10.1007/978-3-031-42283-6_28,Chapter,"capture and replay, load testing, Model-based testing",10,"Slight variations in user interface response times can significantly impact the user experience provided by an interface. Load testing is used to evaluate how an application behaves under increasing loads. For interactive applications, load testing can be done by directly calling services at the business logic or through the user interface. In modern web applications, there is a considerable amount of control logic on the browser side. The impact of this logic on applications’ behaviour is only fully considered if the tests are done through the user interface. Capture reply tools are used for this, but their use can become costly. Leveraging an existing model-based testing tool, we propose an approach to automate load testing done through the user interface."
A Systematic Literature Review on Prioritizing Software Test Cases Using Markov Chains,Testing Software and Systems,,,,10.1007/978-3-031-43240-8_20,G. BarbosaÉ. SouzaL. RebeloM. SilvaJ. BaleraN. Vijaykumar,2023,http://link.springer.com/chapter/10.1007/978-3-031-43240-8_20,Chapter,,10,"Software Testing is a costly activity since the size of the test case set tends to increase as the construction of the software evolves. Test Case Prioritization (TCP) can reduce the effort and cost of software testing. TCP is an activity where a subset of the existing test cases is selected in order to maximize the possibility of finding defects. On the other hand, Markov chains representing a system, when solved, can present the occupation time of each of their states. The idea is to use such information and associate priority to those test cases that consist of states with the highest probabilities. This journal-first paper provides an overview of a systematic survey of the state-of-the-art to identify and understand key initiatives for using Markov chains in TCP."
Using GUI Change Detection for Delta Testing,Research Challenges in Information Science: Information Science and the Connected World,,,,10.1007/978-3-031-33080-3_32,Fernando Pastor RicósRick NeeftBeatriz MarínTanja E. J. VosPekka Aho,2023,http://link.springer.com/chapter/10.1007/978-3-031-33080-3_32,Chapter,"Delta testing, GUI change detection, Scriptless testing, State-model inference",10,"Current software development processes in the industry are designed to respond to rapid modification or changes in software features. Delta testing is a technique used to check that the identified changes are deliberate and neither compromise existing functionality nor result in introducing new defects. This paper proposes a technique for delta testing at the Graphical User Interface (GUI) level. We employ scriptless testing and state-model inference to automatically detect and visualize GUI changes between different versions of the same application. Our proposed offline change detection algorithm compares two existing GUI state models to detect changes. We present a proof of concept experiment with the open-source application Notepad ++ , which allows automatic inference and highlights GUI changes. The results show that our technique is a valuable amplification of scriptless testing tools for delta testing."
Protocol Conformance with Choreographic PlusCal,Theoretical Aspects of Software Engineering,,,,10.1007/978-3-031-35257-7_8,Darius FooAndreea CosteaWei-Ngan Chin,2023,http://link.springer.com/chapter/10.1007/978-3-031-35257-7_8,Chapter,,10,"Distributed protocols, an essential part of modern computing infrastructure, are well-known to be difficult to implement correctly. While lightweight formal methods such as TLA $$^{+}$$ +  can be effectively used to verify abstract protocols, end-to-end validation of real-world protocol implementations remains challenging due to their complexity. To address this problem, we extend the TLA $$^{+}$$ +  toolset along two fronts. We propose several extensions to PlusCal – an algorithm language which compiles to TLA $$^{+}$$ +  – to allow writing distributed protocols as choreographies. This enables more structured and succinct specifications for role-based protocols. We also provide a methodology and toolchain for compiling TLA $$^{+}$$ +  models into monitors, allowing them to be used to test existing systems for conformance. The result is a lightweight testing method that bridges specification and implementation. We demonstrate its benefits with case studies of both classic and recent protocols and show it to be readily applicable to existing systems with low runtime overhead."
A Modulatory Elongated Model for Delineating Retinal Microvasculature in OCTA Images,Medical Image Computing and Computer Assisted Intervention – MICCAI 2023,,,,10.1007/978-3-031-43990-2_67,Mohsin ChalloobYongsheng GaoAndrew BuschWeichuan Zhang,2023,http://link.springer.com/chapter/10.1007/978-3-031-43990-2_67,Chapter,"Contextual information, Elongated responses, Modulatory influences, OCTA, Retinal vasculature, Vessel features",10,"Robust delineation of retinal microvasculature in optical coherence tomography angiography (OCTA) images remains a challenging task, particularly in handling the weak continuity of vessels, low visibility of capillaries, and significant noise interferences. This paper introduces a modulatory elongated model to overcome these difficulties by exploiting the facilitatory and inhibitory interactions exhibited by the contextual influences for neurons in the primary visual cortex. We construct the receptive field of the neurons by an elongated representation, which encodes the underlying profile of vasculature structures, elongated-like patterns, in an anisotropic neighborhood. An annular function is formed to capture the contextual influences presented in the surrounding region outside the neuron support and provide an automatic tuning of contextual information. The proposed modulatory method incorporates the elongated responses with the contextual influences to produce spatial coherent responses for delineating microvasculature features more distinctively from their background regions. Experimental evaluation on clinical retinal OCTA images shows the effectiveness of the proposed model in attaining a promising performance, outperforming the state-of-the-art vessel delineation methods."
Performance Evaluation of Global Trust Management in MANETs Routing Protocols,Computer Performance Engineering and Stochastic Modelling,,,,10.1007/978-3-031-43185-2_26,Hassan JariNigel Thomas,2023,http://link.springer.com/chapter/10.1007/978-3-031-43185-2_26,Chapter,"AODV, Direct trust, Global trust, Indirect trust, MANETs, NS-3, Routing protocol",10,"This paper presents a comprehensive trust management strategy for MANETs, concentrating on developing, assessing, and comparing global trust management mechanisms for the Ad-hoc On-demand Distance Vector (AODV) routing protocol. The research introduces a novel trust-based routing protocol called GTAODV, which builds upon the standard AODV protocol. GTAODV incorporates direct, indirect, and global trust mechanisms to evaluate the reliability of nodes when forwarding packets. This study aims to contribute to ongoing efforts in creating more secure, robust, and efficient ad-hoc networking solutions by focusing on the performance of MANET routing protocols when subjected to black hole attacks. Using Network Simulator 3 (NS-3), the performance of AODV and GTAODV is evaluated and compared. The experimental results demonstrate the effectiveness of the GTAODV protocol in countering black hole attacks, highlighting its potential to enhance the security and reliability of MANETs."
Verifying Open Data Portals Completeness in Compliance to a Grounding Framework,Electronic Government,,,,10.1007/978-3-031-41138-0_16,Flavia BernardiniCatherine Fortes Thedim CostaShaiana PereiraVictor Antunes VieiraDaniela TrevisanJosé Viterbo,2023,http://link.springer.com/chapter/10.1007/978-3-031-41138-0_16,Chapter,"Completeness Evaluation, Compliance Assessment, Open Data Reference Framework, Open Government Data",10,"Open Government Data Portals (OGDPs) are a way of keeping up the information about government’s actions, including how the collected taxes are used in favor of its citizens. However, one difficult in some of these portals is guaranteeing accountability on OGDP completeness according to different instruments specifying legal requirements and good practices, especially when they may reinforce some requirements or may be even contradictory. This problem leads to the need for a comprehensive methodology to assess completeness of OGDPs related to data and information availability. This work presents a process for constructing a reference guide, aiming to help analyzing completeness of an OGDP content, in compliance to legal requirements and good practices, presented by textual instruments. We conducted an experimental analysis for evaluating the completeness of Transparency OGDPs (TOGDPs) requirements using our process. We evaluated, as (T)OGDP experts, the constructed reference guide on three different TOGDPs. We also used the output guide to interview managers and users of the Niterói TOGDP, in order to both evaluate the quality of the guide and the Niterói TOGDP completeness. We could observe which items of our guide were well understood and which need to be improved. These results are of interest to the OGD research community as they provide a tool for constructing a reference guide that facilitates the systematic assessment of OGDPs completeness, in compliance to a given legal framework. Future research includes testing our approach on different contexts for various OGDP types and exploring automation possibilities."
"Relating Reversible Petri Nets and Reversible Event Structures, Categorically","Formal Techniques for Distributed Objects, Components, and Systems",,,,10.1007/978-3-031-35355-0_13,Hernán MelgrattiClaudio Antares MezzinaG. Michele Pinna,2023,http://link.springer.com/chapter/10.1007/978-3-031-35355-0_13,Chapter,,10,"Causal nets (CNs) are Petri nets where causal dependencies are modelled via inhibitor arcs. They play the role of occurrence nets when representing the behaviour of a concurrent and distributed system, even when reversibility is considered. In this paper we extend CNs to account also for asymmetric conflicts and study (i) how this kind of nets, and their reversible versions, can be turned into a category; and (ii) their relation with the categories of reversible asymmetric event structures."
Research on Feature Picking of Domestic Waste Sorting Based on Neural Network Training,"Application of Big Data, Blockchain, and Internet of Things for Education Informatization",,,,10.1007/978-3-031-23944-1_52,Yufei HuangZhengjie LuJixin SunBo WangShude Liao,2023,http://link.springer.com/chapter/10.1007/978-3-031-23944-1_52,Chapter,"Domestic waste, GUI, MATLAB, Neural network",10,"Through the analysis of the status quo of domestic waste treatment, three common and recyclable domestic wastes of plastic bottles, cardboard and cans are selected as the classification samples to study the classification of the overall domestic waste. Based on MATLAB, a nerve that can be used for domestic waste sorting is designed. The network model realizes the effective classification of the domestic garbage images after real-time acquisition of the images by the camera, and borrows the MATLAB GUI toolbox to design a GUI that is easy to operate and has strong practicability. The research provides an implementation method for the effective sorting and treatment of domestic waste."
Spanning Trees with Few Branch Vertices in Graphs of Bounded Neighborhood Diversity,Structural Information and Communication Complexity,,,,10.1007/978-3-031-32733-9_22,Luisa GarganoAdele A. Rescigno,2023,http://link.springer.com/chapter/10.1007/978-3-031-32733-9_22,Chapter,"Fixed parameterized algorithms, Neighborhood diversity, Spanning tree",10,"A branch vertex in a tree is a vertex of degree at least three. We study the NP -hard problem of constructing spanning trees with as few branch vertices as possible. This problem generalizes the famous Hamiltonian Path problem which corresponds to the case of no vertices having degree three or more. It has been extensively studied in the literature and has important applications in network design and optimization. In this paper, we study the problem of finding a spanning tree with the minimum number of branch vertices in graphs of bounded neighborhood diversity. Neighborhood diversity, a generalization of vertex cover to dense graphs, plays an important role in the design of algorithms for such graphs."
Minimal Generating Sets for Semiflows,"Formal Techniques for Distributed Objects, Components, and Systems",,,,10.1007/978-3-031-35355-0_12,Gerard Memmi,2023,http://link.springer.com/chapter/10.1007/978-3-031-35355-0_12,Chapter,"Formal verification, generating set, invariant, linear algebra, Petri Nets, semiflow",10,"We discuss important characteristics of finite generating sets for $$\mathcal {F^{+}}$$ F + , the set of all semiflows with non-negative coordinates of a Petri Net. We endeavor to regroup a number of algebraic results dispersed throughout the Petri Nets literature and also to better position the results while considering semirings such as $$\mathbb {N}$$ N or $$\mathbb {Q^+}$$ Q + then fields such as $$\mathbb {Q}$$ Q . As accurately as possible, we provide a range of new algebraic results on minimal semiflows, minimal supports, and finite minimal generating sets for a given family of semiflows. Minimality of semiflows and of support are critical to develop effective analysis of invariants and behavioral properties of Petri Nets. Main results are concisely presented in a table and our contribution is highlighted. We conclude with the analysis of an example drawn from the telecommunication industry underlining the efficiency brought by using minimal semiflows of minimal supports."
Model-Based Testing of Internet of Things Protocols,Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-031-15008-1_12,Xavier Manuel van DommelenMachiel van der BijlAndy Pimentel,2022,http://link.springer.com/chapter/10.1007/978-3-031-15008-1_12,Chapter,"Bluetooth Low Energy, Communication Protocol, Embedded Systems, Internet of Things, Model-Based Testing",10,"Internet of Things (IoT) is a popular term to describe systems/devices that connect and interact with each other through a network, e.g., the Internet. These devices communicate with each other via a communication protocol, such as Zigbee or Bluetooth Low Energy (BLE), the subject of this paper. Communication protocols are notoriously hard to implement correctly and a large set of test-cases is needed to check for conformance to the standard. Many of us have encountered communication problems in practice, such as random mobile phone disconnects, difficulty obtaining a Bluetooth connection, etc. In this paper, we research the application of industry strength Model-Based Testing (MBT) within the IoT domain. This technique contributes to higher quality specifications and more efficient and more thorough conformance testing. We show how we can model part of the BLE protocol specification using the Axini Modeling Platform (AMP). Based on the model, AMP is then able to automatically test the conformance of a BLE device. With this approach, we found specification flaws in the official BLE specifications as well as conformance errors on a certified BLE system."
Investigating The Effectiveness of Model-Based Testing on Testing Skill Acquisition,The Practice of Enterprise Modeling,,,,10.1007/978-3-031-21488-2_1,Felix CammaertsCharlotte VerbruggenMonique Snoeck,2022,http://link.springer.com/chapter/10.1007/978-3-031-21488-2_1,Chapter,"Model-based testing, TesCaV, Testing skill acquisition",10,"Software does not only need to be developed but also needs to get tested. Testing of software reduces the development and maintenance costs and increases software quality. Unfortunately, few software development courses focus on good testing practices. Some prior work has nevertheless researched possible ways of teaching software testing techniques to students. Unfortunately, all these approaches are code-oriented approaches, implying that a strong technical background is needed to effectively use them. They are also mostly focused on improving students’ knowledge on basic testing techniques. In contrast, TesCaV, a software tool used for teaching testing skills to university students, focuses on teaching testing to novice users with limited technical skills by providing a model-based testing (MBT) approach. MBT is a black-box testing technique in which the tests are automatically generated from a software model. This automatic generation allows for easy maintenance of the test suite when the software changes. These tests can be automatically generated by using a.o. Finite State Machines (FSMs), Markov Chains and Logic Programming. TesCaV is mainly based on Finite State Machines. The effect of using TesCaV on testing coverage is quantitatively analysed in this research. The preliminary results of TesCaV show that it is a promising tool for the teaching of MBT."
libfsmtest An Open Source Library for FSM-Based Testing,Testing Software and Systems,,,,10.1007/978-3-031-04673-5_1,Moritz BergenthalNiklas KrafczykJan PeleskaRobert Sachtleben,2022,http://link.springer.com/chapter/10.1007/978-3-031-04673-5_1,Chapter,,10,"In this paper, the open source library libfsmtest is presented. It has been developed to support model-based testing with finite state machine (FSM) models. The library is provided as a collection of $$\mathtt{C}^{++}$$ C + + classes, each class supporting specific aspects of FSM creation and transformation, and test generation from FSM models. Additionally, the library provides main programs for test generation with the methods realised in the library and for testing ‘implementation FSMs’ with suites generated from ‘reference FSMs’. Moreover, a generic test harness is provided for running test suites against $$\mathtt{C}^{++}$$ C + + libraries. We explain the unique selling points of this library and compare it to competing approaches."
Towards Substructural Property-Based Testing,Logic-Based Program Synthesis and Transformation,,,,10.1007/978-3-030-98869-2_6,Marco MantovaniAlberto Momigliano,2022,http://link.springer.com/chapter/10.1007/978-3-030-98869-2_6,Chapter,"Focusing, Linear logic, Property-based testing, Semantics of programming languages",10,We propose to extend property-based testing to substructural logics to overcome the current lack of reasoning tools in the field. We take the first step by implementing a property-based testing system for specifications written in the linear logic programming language Lolli. We employ the foundational proof certificates architecture to model various data generation strategies. We validate our approach by encoding a model of a simple imperative programming language and its compilation and by testing its meta-theory via mutation analysis.
Towards Causal Model-Based Engineering in Automotive System Safety,Model-Based Safety and Assessment,,,,10.1007/978-3-031-15842-1_9,Robert MaierLisa GrabingerDavid UrlhartJürgen Mottok,2022,http://link.springer.com/chapter/10.1007/978-3-031-15842-1_9,Chapter,"Causality, Model-based engineering, Probabilistic reasoning, Scenario identification, SOTIF",10,"Engineering is based on the understanding of causes and effects. Thus, causality should also guide the safety assessment of complex systems such as autonomous driving cars. To ensure the safety of the intended functionality of these systems, normative regulations like ISO 21448 recommend scenario-based testing. An important task here is to identify critical scenarios, so-called edge and corner cases. Data-driven approaches to this task (e.g. based on machine learning) cannot adequately address a constantly changing operational design domain. Model-based approaches offer a remedy – they allow including different sources of knowledge (e.g. data, human experts) into safety considerations. With this paper, we outline a novel approach for ensuring automotive system safety. We propose to use structural causal models as a probabilistic modelling language to combine knowledge about an open-context environment from different sources. Based on these models, we investigate parameter configurations that are candidates for critical scenarios. In this paper, we first discuss some aspects of scenario-based testing. We then provide an informal introduction to causal models and relate their development lifecycle to the established V-model. Finally, we outline a generic workflow for using causal models to identify critical scenarios and highlight some challenges that arise in the process."
Locality-Based Test Selection for Autonomous Agents,Testing Software and Systems,,,,10.1007/978-3-031-04673-5_6,Sina EntekhabiWojciech MostowskiMohammad Reza MousaviThomas Arts,2022,http://link.springer.com/chapter/10.1007/978-3-031-04673-5_6,Chapter,"Autonomous agents, Domain specific languages, Model-based testing, Scenario-based testing, Test input generation, Test selection",10,"Automated random testing is useful in finding faulty corner cases that are difficult to find by using manually-defined fixed test suites. However, random test inputs can be inefficient in finding faults, particularly in systems where test execution is time- and resource-consuming. Hence, filtering out less-effective test cases by applying domain knowledge constraints can contribute to test effectiveness and efficiency. In this paper, we provide a domain specific language (DSL) for formalising locality-based test selection constraints for autonomous agents. We use this DSL for filtering randomly generated test inputs. To evaluate our approach, we use a simple case study of autonomous agents and evaluate our approach using the QuickCheck tool. The results of our experiments show that using domain knowledge and applying test selection filters significantly reduce the required number of potentially expensive test executions to discover still existing faults. We have also identified the need for applying filters earlier during the test data generation. This observation shows the need to make a more formal connection between the data generation and the DSL-based filtering, which will be addressed in future work."
Temporal Multi-view Contracts for Efficient Test Models,Digital Business and Intelligent Systems,,,,10.1007/978-3-031-09850-5_10,Jishu GuinJüri VainLeonidas TsiopoulosGert Valdek,2022,http://link.springer.com/chapter/10.1007/978-3-031-09850-5_10,Chapter,"Contract-based design, Model-based testing, Model-checking",10,"In this work we focus on practical aspects of test automation, namely reducing the model creation effort for model-based testing by exploiting the multi-view contract paradigm. We take into account explicitly the design views of the system and develop dedicated system test models by views in an incremental manner. The test models formalized as Uppaal Timed Automata refine the requirements of the views and are verified against the view contracts specified in Timed Computation Tree logic. As a novel theoretical contribution we extend the notion of assume/guarantee contracts by introducing temporal modalities. As a second contribution, we demonstrate the feasibility of the approach on an industrial climate control system testing case study. The improvement of testing process productivity is compared to that of developing a monolithic model empirically without extracting views. Finally, we discuss the usability aspects of the method in test development and outline the challenges."
Is NLP-based Test Automation Cheaper Than Programmable and Capture &Replay?,Quality of Information and Communications Technology,,,,10.1007/978-3-031-14179-9_6,Maurizio LeottaFilippo RiccaSimone StoppaAlessandro Marchetto,2022,http://link.springer.com/chapter/10.1007/978-3-031-14179-9_6,Chapter,"Artificial intelligence, NLP, Test automation, Web testing",10,"Nowadays, there is a growing interest in the use of Natural-Language Processing (NLP) for supporting software test automation. This paper investigates the adoption of NLP in web testing. To this aim, a case study has been conducted to compare the cost of the adoption of a NLP testing approach, with respect to more consolidated approaches, i.e., programmable testing and capture and replay testing, in two testing tasks: test cases development and test case evolution/maintenance. Even if preliminary, results show that NLP testing is quite competitive with respect to the more consolidated approaches since the cumulative testing effort of a NLP testing approach, computed considering both development and evolution efforts, is almost always lower than the one of programmable testing and capture &replay testing."
Testing Against Non-deterministic FSMs: A Probabilistic Approach for Test Suite Minimization,Testing Software and Systems,,,,10.1007/978-3-031-04673-5_4,Natalia KushikNina YevtushenkoJorge López,2022,http://link.springer.com/chapter/10.1007/978-3-031-04673-5_4,Chapter,"Guaranteed fault coverage, Model based testing, Non-deterministic finite state machines, Probabilistic approach",10,"The paper is devoted to model based testing against non-deterministic specifications. Such test derivation strategies are well developed, for example against non-deterministic Finite State Machines, however the length of the corresponding test suite can be exponential w.r.t. the number of specification states. We therefore discuss how a test suite can be minimized or reduced when certain level of guarantee concerning its fault coverage is still preserved. The main idea behind the approach is to augment the specification by assigning probabilities for the non-deterministic transitions and later on evaluate the probability of each test sequence to detect the relevant faulty implementation. Given a probability P which is user-defined, we propose an approach for minimizing a given exhaustive test suite TS such that, it stays exhaustive with the probability no less than P ."
Learning Deterministic One-Clock Timed Automata via Mutation Testing,Automated Technology for Verification and Analysis,,,,10.1007/978-3-031-19992-9_15,Xiaochen TangWei ShenMiaomiao ZhangJie AnBohua ZhanNaijun Zhan,2022,http://link.springer.com/chapter/10.1007/978-3-031-19992-9_15,Chapter,"Active learning, Model-based mutation testing, Timed automata",10,"In active learning, an equivalence oracle is supposed to answer whether a hypothesis model is equivalent to the system under learning. Its implementation in real applications is considered a major bottleneck for active automata learning. The problem is especially difficult in the context of learning timed automata due to the infinitely large state space involved. In this paper, following the framework of combining mutation analysis and random testing, we propose an implementation of equivalence oracle in the context of learning deterministic one-clock timed automata (DOTAs). This includes two learning-friendly mutation operators, a heuristic test-case generation method, and a score-based test-case selection method. We implemented a prototype applying our approach by extending an existing tool on active learning of DOTAs and conducted extensive experiments. The results indicate that our method improves upon existing methods on the rate of learning correct models, the number of test cases required, and accumulated delay time in test cases."
Towards Continuous Quality Control in the Context of Language-Driven Engineering,"Leveraging Applications of Formal Methods, Verification and Validation. Software Engineering",,,,10.1007/978-3-031-19756-7_22,Alexander BainczykSteve BoßelmannMarvin KrauseMarco KrumreyDominic WirknerBernhard Steffen,2022,http://link.springer.com/chapter/10.1007/978-3-031-19756-7_22,Chapter,"Active automata learning, Continuous quality control, Domain-specific languages, Generation, Language-driven engineering, Migration, Model/learning-based testing",10,"In this paper, we illustrate the role of quality assurance in Language-Driven Engineering (LDE) which exploits the observation that the more specific a programming/modeling language is, the better it can be controlled . In fact, well-tailored domain-specific languages (DSLs) allow one to (1) syntactically express a number of semantic properties with the effect that they can be verified during syntax analysis or using more involved static verification techniques like model checking, and (2), combined with a concept of design for testability, to automatically validate run-time properties using, in our case, learning-based testing technology. To ensure practicality and scalability, the LDE approach must be supported by language definition technology, powerful enough to ensure that corresponding Integrated Modeling Environments (IMEs) can be generated on demand. Our LDE ecosystem provides such means in a fashion where the dependencies between the various modeling environments and their corresponding meta-modeling environments are systematically addressed in a path-up/tree-down fashion: application-level requests are stepwise moved up to the meta hierarchy, far enough to fully address the issue at hand. The resulting meta-level changes are then propagated down the meta hierarchy to ensure the adequate migration of all involved IMEs and their corresponding modeled artifacts."
A Survey-driven Feature Model for Software Traceability Approaches,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-030-99429-7_2,Edouard Romari BatotSebastien GérardJordi Cabot,2022,http://link.springer.com/chapter/10.1007/978-3-030-99429-7_2,Chapter,,10,"Traceability is the capability to represent, understand and analyze the relationships between software artefacts. Traceability is at the core of many software engineering activities. This is a blessing in disguise as traceability research is scattered among various research subfields, which impairs a global view and integration of the different innovations around the recording, identification, evaluation and management of traces. This also limits the adoption of traceability solutions in industry. In this sense, the goal of this paper is to present a characterization of the traceability mechanism as a feature model depicting the shared and variable elements in any traceability proposal. The features in the model are derived from a survey of papers related to traceability published in the literature. We believe this feature model is useful to assess and compare different proposals and provide a common terminology and background. Beyond the feature model, the survey we conducted also help us to identify a number of challenges to be solved in order to move traceability forward, especially in a context where, due to the increasing importance of AI techniques in Software Engineering, traces are more important than ever in order to be able to reproduce and explain AI decisions."
Modeling and Model Transformation as a Service: Towards an Agile Approach to Model-Driven Development,Lean and Agile Software Development,,,,10.1007/978-3-030-94238-0_7,Adel VahdatiRaman Ramsin,2022,http://link.springer.com/chapter/10.1007/978-3-030-94238-0_7,Chapter,"Agile methods, Model-Driven Development, Service-oriented architecture",10,"Scalability has always been a challenge in software development, and agile methods have faced their own ordeal in this regard. The classic solution is to use modeling to manage the complexities of the system while facilitating intra-team and inter-team communication; however, agile methods tend to shy away from modeling to avoid its adverse effect on productivity. Model-driven development (MDD) has shown great potential for automatic code generation, thereby enhancing productivity, but the agile community seems unconvinced that this gain in productivity justifies the extra effort required for modeling. The challenge that the MDD community faces today is to incorporate MDD in agile development methodologies in such a way that agility is tangibly and convincingly preserved. In this paper, we address this challenge by using a service-oriented approach to modeling and model transformation that pays special attention to abiding by agile values and principles."
A New Approach for Active Automata Learning Based on Apartness,Tools and Algorithms for the Construction and Analysis of Systems,,,,10.1007/978-3-030-99524-9_12,Frits VaandragerBharat GarhewalJurriaan RotThorsten Wißmann,2022,http://link.springer.com/chapter/10.1007/978-3-030-99524-9_12,Chapter,"
                
                  
                
                $$L^{\#}$$
                
                  
                    L
                    #
                  
                
               algorithm, active automata learning, adaptive distinguishing sequence, apartness relation, conformance testing, Mealy machine, observation tree",10,"We present $$L^{\#}$$ L # , a new and simple approach to active automata learning. Instead of focusing on equivalence of observations, like the $$L^{*}$$ L ∗ algorithm and its descendants, $$L^{\#}$$ L # takes a different perspective: it tries to establish apartness , a constructive form of inequality. $$L^{\#}$$ L # does not require auxiliary notions such as observation tables or discrimination trees, but operates directly on tree-shaped automata. $$L^{\#}$$ L # has the same asymptotic query and symbol complexities as the best existing learning algorithms, but we show that adaptive distinguishing sequences can be naturally integrated to boost the performance of $$L^{\#}$$ L # in practice. Experiments with a prototype implementation, written in Rust, suggest that $$L^{\#}$$ L # is competitive with existing algorithms."
Algebraic Virtual Machine Project,ICTERI 2021 Workshops,,,,10.1007/978-3-031-14841-5_23,Oleksandr LetychevskyiVolodymyr PeschanenkoVladislav Volkov,2022,http://link.springer.com/chapter/10.1007/978-3-031-14841-5_23,Chapter,"Behavior algebra, Formal methods, Model-based testing, Symbolic modeling, Verification",10,"T his paper presents a program system called an algebraic virtual machine (AVM), which handles industrial hardware specifications, programs in different languages, and models in algebraic language. It uses the formal algebraic methods that were developed in the scope of behavior algebra and help to resolve the problems of verification, analysis, testing, and cybersecurity. It permits the possibility of creating your own methods and theories and trying them with industrial examples with minimal efforts. The machine learning technique is used for the definition of formal method efficiency, and the classification model is trained during algebraic processing. The formalization and checking for resistance of blockchain attack is considered."
Algebraic Virtual Machine and Its Applications,"Information and Communication Technologies in Education, Research, and Industrial Applications",,,,10.1007/978-3-031-20834-8_2,Oleksandr LetychevskyiVolodymyr PeschanenkoVlad Volkov,2022,http://link.springer.com/chapter/10.1007/978-3-031-20834-8_2,Chapter,"Behavior algebra, Formal methods, Model-based testing, Symbolic modeling, Verification",10,"This paper presents a software system called “Algebraic Virtual Machine (AVM), which handles industrial hardware specifications, programs in different languages, and models in algebraic language. It uses the formal algebraic methods that were developed in the scope of behavior algebra and help to resolve the problems of verification, analysis, testing, and cybersecurity. The new version of AVM will include the possibilities to formalize continuous process and significantly extends the usage of formal methods. It permits the possibility of creating your own methods and theories and trying them with industrial examples with minimal efforts. The machine learning technique is used for the definition of formal method efficiency, and the classification model is trained during algebraic processing. The formalization and checking for resistance of blockchain attack is considered as case study."
Digital Twin for IoT Environments: A Testing and Simulation Tool,Quality of Information and Communications Technology,,,,10.1007/978-3-031-14179-9_14,Luong NguyenMariana SegoviaWissam MallouliEdgardo Montes de OcaAna R. Cavalli,2022,http://link.springer.com/chapter/10.1007/978-3-031-14179-9_14,Chapter,"Actuators, Digital Twins, Gateway, IoT, Sensors, Simulation, Testing",10,"Digital Twin (DT) is one of the pillars of modern information technologies that plays an important role on industry’s digitalization. A DT is composed of a real physical object, a virtual abstraction of the object and a bidirectional data flow between the physical and virtual components. This paper presents a DT-based tool, called TaS, to easily test and simulate IoT environments. The objective is to improve the testing methodologies in IoT systems to evaluate the possible impact of it on the physical world. We provide the conditions to test, predict errors and stress application depending on hardware, software and real world physical process. The tool is based on the DT concept in order to detect and predict failures in evolving IoT environments. In particular, the way to prepare the DT to support fault injection and cybersecurity threats is analyzed. The TaS tool is tested through an industrial case study, the Intelligent Transport System (ITS) provided by the INDRA company. Results of experiments are presented that show that our DT is closely linked to the real world."
Safe and Secure Future AI-Driven Railway Technologies: Challenges for Formal Methods in Railway,"Leveraging Applications of Formal Methods, Verification and Validation. Practice",,,,10.1007/978-3-031-19762-8_20,Monika SeisenbergerMaurice H. ter BeekXiuyi FanAlessio FerrariAnne E. HaxthausenPhillip JamesAndrew LawrenceBas LuttikJaco van de PolSimon Wimmer,2022,http://link.springer.com/chapter/10.1007/978-3-031-19762-8_20,Chapter,,10,"In 2020, the EU launched its sustainable and smart mobility strategy, outlining how it plans to have a 90% reduction in transport emission by 2050. Central to achieving this goal will be the improvement of rail technology, with many new data-driven visionary systems being proposed. AI will be the enabling technology for many of those systems. However, safety and security guarantees will be key for wide-spread acceptance and uptake by Industry and Society. Therefore, suitable verification and validation techniques are needed. In this article, we argue how formal methods research can contribute to the development of modern Railway systems—which may or may not make use of AI techniques—and present several research problems and techniques worth to be further considered."
State Model Inference Through the GUI Using Run-Time Test Generation,Research Challenges in Information Science,,,,10.1007/978-3-031-05760-1_32,Ad MuldersOlivia Rodriguez ValdesFernando Pastor RicósPekka AhoBeatriz MarínTanja E. J. Vos,2022,http://link.springer.com/chapter/10.1007/978-3-031-05760-1_32,Chapter,"Automated GUI testing, Model inference, TESTAR tool",10,"Software testing is an important part of engineering trustworthy information systems. End-to-end testing through Graphical User Interface (GUI) can be done manually, but it is a very time consuming and costly process. There are tools to capture or manually define scripts for automating regression testing through a GUI, but the main challenge is the high maintenance cost of the scripts when the GUI changes. In addition, GUIs tend to have a large state space, so creating scripts to cover all the possible paths and defining test oracles to check all the elements of all the states would be an enormous effort. This paper presents an approach to automatically explore a GUI while inferring state models that are used for action selection in run-time GUI test generation, implemented as an extension to the open source TESTAR tool. As an initial validation, we experiment on the impact of using various state abstraction mechanisms on the model inference and the performance of the implemented action selection algorithm based on the inferred model. Later, we analyse the challenges and provide future research directions on model inference and scriptless GUI testing."
Visual Smart Contracts for DAML,Graph Transformation,,,,10.1007/978-3-031-09843-7_8,Reiko HeckelZobia ErumNitia RahmiAlbert Pul,2022,http://link.springer.com/chapter/10.1007/978-3-031-09843-7_8,Chapter,"DAML, graph transformation, Groove, model-based development, smart contracts, UML, visual contracts",10,"The Digital Asset Modelling Language (DAML) enables low-code development of smart contract applications. Starting from a high-level but textual notation, DAML thus implements the lower end of a model-driven development process, from a platform-specific level to implementations on a range of blockchain platforms. Existing approaches for modelling smart contracts support a domain-oriented, conceptual view but do not link to the same technology-specific level. We develop a notation based on class diagrams and visual contracts that map directly to DAML smart contracts. The approach is grounded in an operational semantics in terms of graph transformation that accounts for the more complex behavioural features of DAML, such as its role-based access control and the order of contract execution and archival. The models, with their mappings to DAML and their operational semantics, are introduced via the Doodle case study from a DAML tutorial and validated through testing the graph transformation system against the DAML code using the Groove model checker."
Scriptless Testing for Extended Reality Systems,Research Challenges in Information Science,,,,10.1007/978-3-031-05760-1_56,Fernando Pastor Ricós,2022,http://link.springer.com/chapter/10.1007/978-3-031-05760-1_56,Chapter,"Extended reality, Scriptless testing, State model inference",10,"Extended Reality ( XR ) systems are complex applications that have emerged in a wide variety of domains, such as computer games and medical practice. Testing XR software is mainly done manually by human testers, which implies a high cost in terms of time and money. Current automated testing approaches for XR systems consist of rudimentary capture and replay of scripts. However, this approach only works for simple test scenarios. Moreover, it is well-known that the scripts break easily each time the XR system is changed. There are research projects aimed at using autonomous agents that will follow scripted instructions to test XR functionalities. Nonetheless, using only scripted testing techniques, it is difficult and expensive to tackle the challenges of testing XR systems. This thesis is focus on the use of automated scriptless testing for XR systems. This way we help to reduce part of the manual testing effort and complement the scripted techniques."
Computational Discovery of Transaction-Based Financial Crime via Grammatical Evolution: The Case of Ponzi Schemes,"Coordination, Organizations, Institutions, Norms, and Ethics for Governance of Multi-Agent Systems XV",,,,10.1007/978-3-031-20845-4_7,Peter FratričGiovanni SilenoTom van EngersSander Klous,2022,http://link.springer.com/chapter/10.1007/978-3-031-20845-4_7,Chapter,,10,"The financial sector continues to experience wide digitalization; the resulting transactional activity creates large amounts of data, in principle enabling public and private actors to better understand the social domain they operate on, possibly facilitating the design of interventions to reduce illegal activity. However, the adversarial nature of frauds and the relatively low amount of observed instances make the problem especially challenging with standard statistical-based methods. To address such fundamental issues to non-compliance detection, this paper presents a proof-of-concept of a methodological framework based on automated discovery of instances of non-compliant behaviour in a simulation environment via grammatical evolution. We illustrate the methodology with an experiment capable of discovering two known types of Ponzi schemes from a modest set of assumptions."
Verified Security for the Morello Capability-enhanced Prototype Arm Architecture,Programming Languages and Systems,,,,10.1007/978-3-030-99336-8_7,Thomas BauereissBrian CampbellThomas SewellAlasdair ArmstrongLawrence EsswoodIan StarkGraeme BarnesRobert N. M. WatsonPeter Sewell,2022,http://link.springer.com/chapter/10.1007/978-3-030-99336-8_7,Chapter,,10,"Memory safety bugs continue to be a major source of security vulnerabilities in our critical infrastructure. The CHERI project has proposed extending conventional architectures with hardware-supported capabilities to enable fine-grained memory protection and scalable compartmentalisation, allowing historically memory-unsafe C and C++ to be adapted to deterministically mitigate large classes of vulnerabilities, while requiring only minor changes to existing system software sources. Arm is currently designing and building Morello, a CHERI-enabled prototype architecture, processor, SoC, and board, extending the high-performance Neoverse N1, to enable industrial evaluation of CHERI and pave the way for potential mass-market adoption. However, for such a major new security-oriented architecture feature, it is important to establish high confidence that it does provide the intended protections, and that cannot be done with conventional engineering techniques. In this paper we put the Morello architecture on a solid mathematical footing from the outset. We define the fundamental security property that Morello aims to provide, reachable capability monotonicity, and prove that the architecture definition satisfies it. This proof is mechanised in Isabelle/HOL, and applies to a translation of the official Arm specification of the Morello instruction-set architecture (ISA) into Isabelle. The main challenge is handling the complexity and scale of a production architecture: 62,000 lines of specification, translated to 210,000 lines of Isabelle. We do so by factoring the proof via a narrow abstraction capturing essential properties of arbitrary CHERI ISAs, expressed above a monadic intra-instruction semantics. We also develop a model-based test generator, which generates instruction-sequence tests that give good specification coverage, used in early testing of the Morello implementation and in Morello QEMU development, and we use Arm’s internal test suite to validate our model. This gives us machine-checked mathematical proofs of whole-ISA security properties of a full-scale industry architecture, at design-time. To the best of our knowledge, this is the first demonstration that that is feasible, and it significantly increases confidence in Morello."
Designing Functional Prototypes Combining BCI and AR for Home Automation,Virtual Reality and Mixed Reality,,,,10.1007/978-3-031-16234-3_1,Hakim Si-MohammedCoralie HaumontAlexandre SanchezCyril PlapousFoued BouchnakJean-Philippe JavaudinAnatole Lécuyer,2022,http://link.springer.com/chapter/10.1007/978-3-031-16234-3_1,Chapter,"Augmented Reality (AR), Brain-Computer Interface (BCI), Home automation, Smart home, Steady-State Visual Evoked Potentials (SSVEP)",10,"In this technology report we present how to design functional prototypes of smart home systems, based on Augmented Reality (AR) and Brain-Computer Interfaces (BCI). A prototype was designed and integrated into a home automation platform, aiming to illustrate the potential of combining EEG-based interaction with Augmented Reality interfaces for operating home appliances. Our proposed solution enables users to interact with different types of appliances from “on-off”-based objects like lamps, to multiple command objects like televisions. This technology report presents the different steps of the design and implementation of the system, and proposes general guidelines regarding the future development of such solutions. These guidelines start with the description of the functional and technical specifications that should be met, before the introduction of a generic and modular software architecture that can be maintained and adapted for different types of BCI, AR displays and connected objects. Overall this technology report paves the way to the development of a new generation of smart home systems, exploiting brain activity and Augmented Reality for direct interaction with multiple home appliances."
Bi-directional Contrastive Learning for Domain Adaptive Semantic Segmentation,Computer Vision – ECCV 2022,,,,10.1007/978-3-031-20056-4_3,Geon LeeChanho EomWonkyung LeeHyekang ParkBumsub Ham,2022,http://link.springer.com/chapter/10.1007/978-3-031-20056-4_3,Chapter,"Bi-directional contrastive learning, Domain adaptive semantic segmentation, Dynamic pseudo label",10,"We present a novel unsupervised domain adaptation method for semantic segmentation that generalizes a model trained with source images and corresponding ground-truth labels to a target domain. A key to domain adaptive semantic segmentation is to learn domain-invariant and discriminative features without target ground-truth labels. To this end, we propose a bi-directional pixel-prototype contrastive learning framework that minimizes intra-class variations of features for the same object class, while maximizing inter-class variations for different ones, regardless of domains. Specifically, our framework aligns pixel-level features and a prototype of the same object class in target and source images (i.e., positive pairs), respectively, sets them apart for different classes (i.e., negative pairs), and performs the alignment and separation processes toward the other direction with pixel-level features in the source image and a prototype in the target image. The cross-domain matching encourages domain-invariant feature representations, while the bidirectional pixel-prototype correspondences aggregate features for the same object class, providing discriminative features. To establish training pairs for contrastive learning, we propose to generate dynamic pseudo labels of target images using a non-parametric label transfer, that is, pixel-prototype correspondences across different domains. We also present a calibration method compensating class-wise domain biases of prototypes gradually during training. Experimental results on standard benchmarks including GTA5 $$\rightarrow $$ → Cityscapes and SYNTHIA $$\rightarrow $$ → Cityscapes demonstrate the effectiveness of our framework."
Learning Audio-Video Modalities from Image Captions,Computer Vision – ECCV 2022,,,,10.1007/978-3-031-19781-9_24,Arsha NagraniPaul Hongsuck SeoBryan SeyboldAnja HauthSantiago ManenChen SunCordelia Schmid,2022,http://link.springer.com/chapter/10.1007/978-3-031-19781-9_24,Chapter,"Captioning, Data mining, Video retrieval",10,"There has been a recent explosion of large-scale image-text datasets, as images with alt-text captions can be easily obtained online. Obtaining large-scale, high quality data for video in the form of text-video and text-audio pairs however, is more challenging. To close this gap we propose a new video mining pipeline which involves transferring captions from image captioning datasets to video clips with no additional manual effort. Using this pipeline, we create a new large-scale, weakly labelled audio-video captioning dataset consisting of millions of paired clips and captions. We show that training a multimodal transformer based model on this data achieves competitive performance on video retrieval and video captioning, matching or even outperforming HowTo100M pretraining with 20x fewer clips. We also show that our mined clips are suitable for text-audio pretraining, and achieve state of the art results for the task of audio retrieval."
"Specification and Verification with the TLA+ Trifecta: TLC, Apalache, and TLAPS","Leveraging Applications of Formal Methods, Verification and Validation. Verification Principles",,,,10.1007/978-3-031-19849-6_6,Igor KonnovMarkus KuppeStephan Merz,2022,http://link.springer.com/chapter/10.1007/978-3-031-19849-6_6,Chapter,"Model checking, Specification, Theorem proving, TLA+",10,"Using an algorithm due to Safra for distributed termination detection as a running example, we present the main tools for verifying specifications written in TLA + . Examining their complementary strengths and weaknesses, we suggest a workflow that supports different types of analysis and that can be adapted to the desired degree of confidence."
A Model-Based Approach for Quality Assessment of Insulin Infusion Pump Systems,ITNG 2022 19th International Conference on Information Technology-New Generations,,,,10.1007/978-3-030-97652-1_8,Tássio Fernandes CostaÁlvaro SobrinhoLenardo Chaves e SilvaLeandro Dias da SilvaAngelo Perkusich,2022,http://link.springer.com/chapter/10.1007/978-3-030-97652-1_8,Chapter,"Access/CPN, ASK-CTL, Coloured Petri Nets, Formal specifications, Modeling, Quality assessment, Simulation, Web-based application",10,"Insulin infusion pumps are safety-critical systems that require the approval of regulatory agencies before commercialization to prevent hazard situations. Nowadays, many recalls are reported for insulin infusion pump systems, motivating the usage of a formal model-based approach to improve quality. However, the usage of such approaches increases costs and development time. Thus, this study aims to assist the quality assessment of such systems cost-effectively and time-efficient. We defined a coloured Petri nets model-based approach and conducted a case study on the ACCU-CHEK Spirit system to verify and validate a reference model, describing quality assessment scenarios. We also conducted an empirical evaluation of the approach with 12 modelers to verify productivity and reusability. Using the approach, 66.7% of the modelers stated no effort, while 8.3%, stated low effort, 16.7% medium effort, and 8.3% considerable effort. Given such results, we developed a web-based application to assist modelers in re-using the proposed approach. The usage of the approach can decrease development time and thus costs, increasing confidence in quality attributes such as safety and effectiveness."
Exploring Fine-Grained Audiovisual Categorization with the SSW60 Dataset,Computer Vision – ECCV 2022,,,,10.1007/978-3-031-20074-8_16,Grant Van HornRui QianKimberly WilberHartwig AdamOisin Mac AodhaSerge Belongie,2022,http://link.springer.com/chapter/10.1007/978-3-031-20074-8_16,Chapter,"Audio, Fine-grained, Multi-modal learning, Video",10,"We present a new benchmark dataset, Sapsucker Woods 60 (SSW60), for advancing research on audiovisual fine-grained categorization. While our community has made great strides in fine-grained visual categorization on images, the counterparts in audio and video fine-grained categorization are relatively unexplored. To encourage advancements in this space, we have carefully constructed the SSW60 dataset to enable researchers to experiment with classifying the same set of categories in three different modalities: images, audio, and video. The dataset covers 60 species of birds and is comprised of images from existing datasets, and brand new, expert curated audio and video datasets. We thoroughly benchmark audiovisual classification performance and modality fusion experiments through the use of state-of-the-art transformer methods. Our findings show that performance of audiovisual fusion methods is better than using exclusively image or audio based methods for the task of video classification. We also present interesting modality transfer experiments, enabled by the unique construction of SSW60 to encompass three different modalities. We hope the SSW60 dataset and accompanying baselines spur research in this fascinating area."
Data Quality Model-Based Testing of Information Systems: Two-Level Testing of the Insurance System,Information Technology for Management: Towards Business Excellence,,,,10.1007/978-3-030-71846-6_2,Anastasija NikiforovaJanis BicevskisZane BicevskaIvo Oditis,2021,http://link.springer.com/chapter/10.1007/978-3-030-71846-6_2,Chapter,"Complete test set, Data quality model, Information system, Model-Based testing, Post-condition, Pre-condition",10,"In order to develop reliable software, its operating must be verified for all possible cases of use. This can be achieved, at least partly, by means of a model-based testing (MBT), by establishing tests that check all conditions covered by the model. This paper presents a Data Quality Model-based Testing (DQMBT) using the data quality model (DQ-model) as a testing model. The DQ-model contains definitions and conditions for data objects to consider the data object as correct. The proposed testing approach allows complete testing of the conformity of the data to be entered and the data already stored in the database. The data to be entered shall be verified by means of predefined pre-conditions, while post-conditions verify the allocation of the data into the database. The paper demonstrates the application of the proposed solution to the insurance system, concluding that it is able to identify previously undetected defects even after years of operating the IS. Therefore, the proposed solution can be considered as an effective complementary testing approach capable to improve the quality of an information system significantly. In the context of this study, we also address the MBT approach and the main factors affecting its popularity and identify the most popular ways of classifying MBT approaches."
Aspect-Oriented Model-Based Testing with UPPAAL Timed Automata,Model and Data Engineering,,,,10.1007/978-3-030-78428-7_10,Jüri VainLeonidas TsiopoulosGert Kanter,2021,http://link.springer.com/chapter/10.1007/978-3-030-78428-7_10,Chapter,"Aspect-Oriented Modeling, Model-Based Testing, Offline test generation, Test coverage, UPPAAL Timed Automata",10,This paper presents a method for offline test derivation from formal aspect-oriented models so that the tests provide coverage in terms of aspects related metrics. A test purpose specification method in temporal logic TCTL is proposed that enables referring to the attributes of aspect models symbolically. The method is exemplified on a health monitoring system and the quantitative evidence of the advantages provided by the method are evaluated in terms of work effort put into the test development and by analytical reasoning on the complexity.
Search-Based Automated Play Testing of Computer Games: A Model-Based Approach,Search-Based Software Engineering,,,,10.1007/978-3-030-88106-1_5,Raihana FerdousFitsum KifetewDavide PrandiI. S. W. B. PrasetyaSamira ShirzadehhajimahmoodAngelo Susi,2021,http://link.springer.com/chapter/10.1007/978-3-030-88106-1_5,Chapter,"Game play testing, Model-based testing, Search-based testing",10,"Computer game technology is increasingly more complex and applied in a wide variety of domains, beyond entertainment, such as training and educational scenarios. Testing games is a difficult task requiring a lot of manual effort since the interaction space in the game is very fine grained and requires a certain level of intelligence that cannot be easily automated. This makes testing a costly activity in the overall development of games. This paper presents a model-based formulation of game play testing in such a way that search-based testing can be applied for test generation. An abstraction of the desired game behaviour is captured in an extended finite state machine (EFSM) and search-based algorithms are used to derive abstract tests from the model, which are then concretised into action sequences that are executed on the game under test. The approach is implemented in a prototype tool EvoMBT . We carried out experiments on a 3D game to assess the suitability of the approach in general, and search-based test generation in particular. We applied 5 search algorithms for test generation on three different models of the game. Results show that search algorithms are able to achieve reasonable coverage on models: between 75% and 100% for the small and medium sized models, and between 29% and 56% for the bigger model. Mutation analysis shows that on the actual game application tests kill up to 99% of mutants. Tests have also revealed previously unknown faults."
Towards a Model-Based Approach to Support Physical Test Process of Aircraft Hydraulic Systems,Model and Data Engineering,,,,10.1007/978-3-030-78428-7_3,Ouissem Mesli-KesraouiYassine OuhammouOlga GoubaliPascal BerruetPatrick GirardEmmanuel Grolleau,2021,http://link.springer.com/chapter/10.1007/978-3-030-78428-7_3,Chapter,"Avionic test, DSML, Flushing, Hydraulic system, MBT",10,"The physical integration of an aircraft consists of the assembly of several complex subsystems (including hydraulic systems) developed by different stakeholders. The cleanliness of the developed hydraulic subsystems is ensured by performing several decontamination and flushing tests. This testing phase is very tedious as it is mainly performed by SCADA (Supervisory Control and Data Acquisition) systems and depends on chemical substances. However, as the design is mainly expressed in informal textual languages and synoptic diagrams, this testing is currently done manually and is determined by the experience of the testers. This makes it error-prone and time-consuming. In this paper, we propose to capitalize the effort for physical testing of hydraulic systems by proposing a model-based system engineering approach that allows: (i) to graphically specify the systems under test and (ii) to automatically generate the corresponding test cases. A proof of concept is proposed as well as a case study."
"A Proposal for the Classification of Methods for Verification and Validation of Safety, Cybersecurity, and Privacy of Automated Systems",Quality of Information and Communications Technology,,,,10.1007/978-3-030-85347-1_24,Jose Luis de la VaraThomas BauerBernhard FischerMustafa KaracaHenrique MadeiraMartin MatschnigSilvia MazziniGiann Spilere NandiFabio PatroneDavid PereiraJosé ProençaRupert SchlickStefano TonettaUgur YayanBehrooz Sangchoolie,2021,http://link.springer.com/chapter/10.1007/978-3-030-85347-1_24,Chapter,"Automated system, Classification, Cybersecurity, Method, Privacy, Safety, V&V, Verification and validation",10,"As our dependence on automated systems grows, so does the need for guaranteeing their safety, cybersecurity, and privacy (SCP). Dedicated methods for verification and validation (V&V) must be used to this end and it is necessary that the methods and their characteristics can be clearly differentiated. This can be achieved via method classifications. However, we have experienced that existing classifications are not suitable to categorise V&V methods for SCP of automated systems. They do not pay enough attention to the distinguishing characteristics of this system type and of these quality concerns. As a solution, we present a new classification developed in the scope of a large-scale industry-academia project. The classification considers both the method type, e.g., testing, and the concern addressed, e.g., safety. Over 70 people have successfully used the classification on 53 methods. We argue that the classification is a more suitable means to categorise V&V methods for SCP of automated systems and that it can help other researchers and practitioners."
An OWASP Top Ten Driven Survey on Web Application Protection Methods,Risks and Security of Internet and Systems,,,,10.1007/978-3-030-68887-5_14,Ouissem Ben FredjOmar CheikhrouhouMoez KrichenHabib HamamAbdelouahid Derhab,2021,http://link.springer.com/chapter/10.1007/978-3-030-68887-5_14,Chapter,"Attacks, Countermeasures, OWASP top ten, Security, Survey, Web",10,"Web applications (WAs) are constantly evolving and deployed at broad scale. However, they are exposed to a variety of attacks. The biggest challenge facing organizations is how to develop a WA that fulfills their requirements with respect to sensitive data exchange, E-commerce, and secure workflows. This paper identifies the most critical web vulnerabilities according to OWASP Top Ten, their corresponding attacks, and their countermeasures. The application of these countermeasures will guarantee the protection of the WAs against the most severe attacks and prevent several unknown exploits."
Relation Between Test Coverage and Timed Automata Model Structure,Tools and Methods of Program Analysis,,,,10.1007/978-3-030-71472-7_9,Lukáš KrejčíJan SobotkaJiří Novák,2021,http://link.springer.com/chapter/10.1007/978-3-030-71472-7_9,Chapter,"Automotive, Coverage, Hardware-in-the-Loop, HiL, Model-Based, Structure, Testing, Timed Automata",10,"This paper deals with problematics of structure of Timed Automata models suitable for Model-Based Testing of automotive systems. Previous experiments, primarily focused on the environmental models, have shown that their structure does not significantly affect the coverage speed of testing process. However, similar questions regarding the observer part of the system model remained open. This paper analyzes those remaining questions and focuses on uncovering possible relation between an observer model structure and the quality of generated test sequences according to multiple criteria. Goal of presented experiments is to compare multiple modeling approaches and discover which one is most suitable for automotive systems."
Realizing Digital Systems Engineering—Aerospace and Defence Use Case,Complex Systems Design & Management,,,,10.1007/978-3-030-73539-5_29,Eran Gery,2021,http://link.springer.com/chapter/10.1007/978-3-030-73539-5_29,Chapter,,10,The aerospace and defense industry have always been in the forefront of designing and developing complex systems. Mission challenges combined with technological advances are both contributing factors in how quickly the pace of complexity and sophistication is evolving in this industry. Being able to successfully navigate these challenges will define which companies are most competitive in this market.
Abstract Test Execution for Early Testing Activities in Model-Driven Scenarios,Model-Driven Engineering and Software Development,,,,10.1007/978-3-030-67445-8_12,Reinhard PröllNoël HagemannBernhard Bauer,2021,http://link.springer.com/chapter/10.1007/978-3-030-67445-8_12,Chapter,"Domain-specific modeling, Integrated model basis, Model-based testing, Model-driven software development, Test execution",10,"The continuous improvement of the performance of computing units makes it possible to cope with increasingly complex tasks. This results in more complex software systems. However, the development of such highly complex systems is difficult to achieve using traditional approaches. Concepts like model-driven software development can weaken this problem in these constructive phases. However, new challenges arise for the testing of development artifacts. In order to be able to perform a real shift left of verification and validation tasks towards early phases of development, we present a semi-formal approach that enables users to execute test cases against the system under development (SUD) on the model-level. Grounded on an Integrated Model Basis which is created and maintained during development, test reports are automatically derived. This opens up a wide range of possibilities for early and targeted troubleshooting."
30 Years of Automated GUI Testing: A Bibliometric Analysis,Quality of Information and Communications Technology,,,,10.1007/978-3-030-85347-1_34,Olivia Rodríguez-ValdésTanja E. J. VosPekka AhoBeatriz Marín,2021,http://link.springer.com/chapter/10.1007/978-3-030-85347-1_34,Chapter,"Automated testing, Bibliometric analysis, Graphical user interface, Secondary study",10,"Context: Over the last 30 years, GUIs have changed considerably, becoming everyday part of our lives through smart phones and other devices. More complex GUIs and multitude of platforms have increased the challenges when testing software through the GUI. Objective: To visualise how the field of automated GUI testing has evolved by studying the growth of the field; types of publications; influential events, papers and authors; collaboration among authors; and trends on GUI testing. Method: To conduct a bibliometric analysis of automated GUI testing by performing a systematic search of primary studies in Scopus from 1990 to 2020. Results: 744 publications were selected as primary studies. The majority of them were conference papers, the most cited paper was published on 2013, and the most published author has 53 papers. Conclusions: Automated GUI testing has continuously grown. Keywords show that testing applied to mobile interfaces will be the trend in next years, along with the integration of Artificial Intelligence and automated exploration techniques."
A Formalisation of SysML State Machines in mCRL2,"Formal Techniques for Distributed Objects, Components, and Systems",,,,10.1007/978-3-030-78089-0_3,Mark BouwmanBas LuttikDjurre van der Wal,2021,http://link.springer.com/chapter/10.1007/978-3-030-78089-0_3,Chapter,,10,"This paper reports on a formalisation of the semi-formal modelling language SysML in the formal language mCRL2, in order to unlock formal verification and model-based testing using the mCRL2 toolset for SysML models. The formalisation focuses on a fragment of SysML used in the railway standardisation project EULYNX. It comprises the semantics of state machines, communication between objects via ports, and an action language called ASAL. It turns out that the generic execution model of SysML state machines can be elegantly specified using the rich data and process languages of mCRL2. This is a big step towards an automated translation as the generic model can be configured with a formal description of a specific set of state machines in a straightforward manner."
Formal Analysis of the UNISIG Safety Application Intermediate Sub-layer,Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-030-85248-1_11,Davide BasileAlessandro FantechiIrene Rosadi,2021,http://link.springer.com/chapter/10.1007/978-3-030-85248-1_11,Chapter,,10,"The combined use of standard interfaces and formal methods is currently under investigation by Shift2Rail, a joint undertaking between railway stakeholders and the EU. Standard interfaces are useful to increase market competition and standardization whilst reducing long-term life cycle costs. Formal methods are needed to achieve interoperability and safety of standard interfaces and are one of the targets of the 4SECURail project funded by Shift2Rail. This paper presents the modelling and analysis of the selected case study of the 4SECURail project: the Safe Application Intermediate sub-layer of the UNISIG RBC/RBC Safe Communication Interface. The adopted formal method is Statistical Model Checking of a network of Stochastic Priced Timed Automata, as provided by the Uppaal SMC tool. The main contributions are: (i) rigorous complete and publicly available models of an official interface specification already in operation, (ii) identification of safety and interoperability issues in the original specification using Statistical Model Checking, (iii) quantification of costs for learning the adopted formal method and developing the carried out analysis."
Ontology-Driven Audit Using the REA-Ontology,Advanced Information Systems Engineering Workshops,,,,10.1007/978-3-030-79022-6_10,Graham GalMonique SnoeckWim Laurier,2021,http://link.springer.com/chapter/10.1007/978-3-030-79022-6_10,Chapter,"Model-driven engineering, Ontology, Smart contracts, Software audit",10,"While blockchains are not yet ubiquitous in business practice, they are expected to serve as a platform to handle an increasing number of business transactions in a not-too-distant future. Smart contracts can be used to code and to enforce agreements between business parties. A significant difference between traditional and smart contracts is that once the actual events of the smart contract become part of a block in the blockchain, they are almost impossible to undo. Therefore, it is important that critical validity aspects of these smart contracts are explicitly represented. As smart contracts are software products too, it is therefore also critical that the coding of these critical validity aspects guarantees a faithful implementation of the validity checks. This paper suggests applying a combination of two approaches (i.e., ontology engineering and model-driven engineering) to the design and the implementation of smart contracts, in order to facilitate their audit through a clear separation of concerns. More precisely, this paper discusses the example of the REA ontology to provide the ontological commitment of the critical validity aspects of a contract, while MDE provides a tool to unambiguously translate the REA ontology’s contracting terms into a well-designed Smart Contract. This paper suggests that the resulting Smart Contract can support auditors’ assertions regarding exchanges between business partners and support the audit process."
An Automated Modeling Method and Visualization Implementation of Smart Contracts,Blockchain and Trustworthy Systems,,,,10.1007/978-981-16-7993-3_30,Jie MengZheng LiRuiliang ZhaoYing Shang,2021,http://link.springer.com/chapter/10.1007/978-981-16-7993-3_30,Chapter,"Blockchain, EFSM, EFSMSolid, Formal definition, Smart contracts",10,"Smart contracts are one of the core components of the block-chain system and have been widely used across various fields. Since a smart contract cannot be easily changed or updated once instantiated, one has to be absolutely sure that the program code works as expected. However, there are no uniform definitions for smart contracts, and the programming of smart contracts requires professional developers with expert domain knowledge. This paper proposed a formal modeling method for start contracts. First, the formal definition of smart contracts is proposed. Second, we introduce an EFSM based modeling method for smart contracts. Finally, we design a visual modeling tool EFSMSolid for creating EFSM on an easy-to-use graphical platform. To verify the effectiveness of the method, we conduct experiments on smart contracts of five blockchain applications, and the experimental results show that the proposed method can automatically and effectively create smart contracts models."
Understanding Digital Twins for Cyber-Physical Systems: A Conceptual Model,"Leveraging Applications of Formal Methods, Verification and Validation: Tools and Trends",,,,10.1007/978-3-030-83723-5_5,Tao YuePaolo ArcainiShaukat Ali,2021,http://link.springer.com/chapter/10.1007/978-3-030-83723-5_5,Chapter,"Conceptual model, Cyber-physical systems, Digital twins",10,"Digital Twins (DTs) are revolutionizing Cyber-Physical Systems (CPSs) in many ways, including their development and operation. The significant interest of industry and academia in DTs has led to various definitions of DTs and related concepts, as seen in many recently published papers. Thus, there is a need for precisely defining different DT concepts and their relationships. To this end, we present a conceptual model that captures various DT concepts and their relationships, some of which are from the published literature, to provide a unified understanding of these concepts in the context of CPSs. The conceptual model is implemented as a set of Unified Modeling Language (UML) class diagrams and the concepts in the conceptual model are explained with a running example of an automated warehouse case study from published literature and based on the authors’ experience of working with the real CPS case study in previous projects."
On Education and Training in Formal Methods for Industrial Critical Systems,Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-030-85248-1_6,Bernd Westphal,2021,http://link.springer.com/chapter/10.1007/978-3-030-85248-1_6,Chapter,,10,"The 2020 expert survey on formal methods has put one topic into the focus of the formal methods for industrial critical systems community: education and training. Of three overall conclusions, the first one finds the survey to indicate “a consensus about the essential role of education”. At the same time, survey results and individual expert statements indicate largely open challenges. In this work, we analyse the 2020 expert survey results from an education and training perspective, and we discuss the proposal of an integrative approach with respect to these challenges. A central enabler for the integrated approach is the modern, inclusive interpretation of formal methods as put forth in the survey report and a differentiated understanding of roles (or stakeholders) in formal methods for industrial critical systems."
Privacy Design Strategies and the GDPR: A Systematic Literature Review,"HCI for Cybersecurity, Privacy and Trust",,,,10.1007/978-3-030-77392-2_16,Marco SaltarellaGiuseppe DesoldaRosa Lanzilotti,2021,http://link.springer.com/chapter/10.1007/978-3-030-77392-2_16,Chapter,"GDPR, Privacy by design, Usable privacy",10,"Article 25 of the GDPR states that data collection, processing and management measures should be implemented following tṇhe privacy by design and privacy by default paradigms. This paper presents a systematic literature review to identify useful guidelines to support the development of GDPR-compliant software. Selected papers are categorized under 8 different data-oriented and process-oriented strategies and their contributions are reported. Future activities will highlight the HCI community’s attitude towards these new technical and organizational approaches in order to bridge the identified gaps and shortcomings."
Testing Autogenerated OPC UA NodeSet Models for Product Variants in Industry,Software Quality: Future Perspectives on Software Engineering Quality,,,,10.1007/978-3-030-65854-0_2,Claus KlammerThomas WetzlmaierMichael PfeifferThomas SteinerMatthias Konnerth,2021,http://link.springer.com/chapter/10.1007/978-3-030-65854-0_2,Chapter,"Integration testing, Middleware, OPC UA, Test case generation",10,"Product line management activities have to ensure that offered product options are valid and compatible. With the arise of the Internet of Things (IoT) movement not only the own product compatibility has to be managed by the vendors anymore, but also the compliance and openness to standardized interfaces has to be supported as well. The Machine to Machine (M2M) communication protocol standard Open Platform Communications Unified Architecture (OPC UA) has received great attention in the field of mechanical engineering recently. In this industrial experience report we describe our approach how to support the testing of automatically generated models for OPC UA, by applying test case generation at the integration level. We show the feasibility of our approach and report about found issues, discuss some general findings and provide an outlook for future work."
Model-Based Testing Under Parametric Variability of Uncertain Beliefs,Software Engineering and Formal Methods,,,,10.1007/978-3-030-58768-0_10,Matteo CamilliBarbara Russo,2020,http://link.springer.com/chapter/10.1007/978-3-030-58768-0_10,Chapter,"Bayesian inference, Model-based Testing, Parametric Markov Decision Processes, Uncertainty analysis",10,"Modern software systems operate in complex and changing environments and are exposed to multiple sources of uncertainty. Considering uncertainty as a first-class concern in software testing is currently on an uptrend. This paper introduces a novel methodology to deal with testing under uncertainty. Our proposal combines the usage of parametric model checking at design-time and online model-based testing algorithms to gather runtime evidence and detect requirements violations. As modeling formalism, we adopt parametric Markov Decision Processes where transition probabilities are not fixed, but are possibly given as a set of uncertain parameters. The design-time phase aims at analyzing the parameter space to identify the constraints for requirements satisfaction. Then, the testing activity applies a Bayesian inference process to identify violations of pre-computed constraints. An extensive empirical evaluation shows that the proposed technique is effective in discovering violations and is cheaper than existing testing under uncertainty methods."
TesCaV: An Approach for Learning Model-Based Testing and Coverage in Practice,Research Challenges in Information Science,,,,10.1007/978-3-030-50316-1_18,Beatriz MarínSofía AlarcónGiovanni GiachettiMonique Snoeck,2020,http://link.springer.com/chapter/10.1007/978-3-030-50316-1_18,Chapter,"Coverage, Lessons learned, Model-Based Testing, Teaching/learning testing",10,"Academy and industry permanently remark the importance of software-testing techniques to improve software quality and to reduce development and maintenance costs. A testing method to be considered for this purpose is Model-Based Testing (MBT), which generates test cases from a model that represents the structure and the behavior of the system to be developed. The generated test suite is easier to maintain and adapt to changes in requirements or evolution of the developed system. However, teaching and learning MBT techniques are not easy tasks; students need to know the different testing techniques to assure that the requirements are fulfilled as well as to identify any failure in the software system modeled. In this work, we present TesCaV , an MBT teaching tool for university students, which is based on a model-driven technology for the automatic software generation from UML diagrams. TesCaV allows validating the test cases defined by students and graphically determines the level of testing coverage over the system modeled. Preliminary results show TesCaV as a promising approach for MBT teaching/learning processes."
Multi-path Coverage of All Final States for Model-Based Testing Theory Using Spark In-memory Design,Verification and Evaluation of Computer and Communication Systems,,,,10.1007/978-3-030-65955-4_14,Wilfried Yves Hamilton AdoniMoez KrichenTarik NahhalAbdeltif Elbyed,2020,http://link.springer.com/chapter/10.1007/978-3-030-65955-4_14,Chapter,"Apache hadoop, Apache spark, Big data, Big graphs, Coverage, Model-based testing, Parallel and distributed computing",10,"This paper deals with an efficient and robust distributed framework for finite state machine coverage in the field model based testing theory. All final states coverage in large-scale automaton is inherently computing-intensive and memory exhausting with impractical time complexity because of an explosion of the number of states. Thus, it is important to propose a faster solution that reduces the time complexity by exploiting big data concept based on Spark RDD computation. To cope with this situation, we propose a parallel and distributed approach based on Spark in-memory design which exploits A* algorithm for optimal coverage. The experiments performed on multi-node cluster prove that the proposed framework achieves significant gain of the computation time."
Giving a Model-Based Testing Language a Formal Semantics via Partial MAX-SAT,Testing Software and Systems,,,,10.1007/978-3-030-64881-7_3,Bernhard K. AichernigChristian Burghard,2020,http://link.springer.com/chapter/10.1007/978-3-030-64881-7_3,Chapter,"Consistency checking, Formal semantics, Frame problem, Model transformation, Partial MAX-SAT, Partial moore machines",10,"Domain-specific Languages (DSLs) are widely used in model-based testing to make the benefits of modeling available to test engineers while avoiding the problem of excessive learning effort. Complex DSLs benefit from a formal definition of their semantics for model processing as well as consistency checking. A formal semantics can be established by mapping the model domain to a well-known formalism. In this paper, we present an industrial use case which includes a mapping from domain-specific models to Moore Machines, based on a Partial MAX-SAT problem, encoding a predicative semantics for the model-to-model mapping. We show how Partial MAX-SAT solves the frame problem for a non-trivial DSL in which the non-effect on variables cannot be determined statically. We evaluated the performance of our model-transformation algorithm based on models from our industrial use case."
Model-Based Testing for MQTT Applications,Knowledge-Based Software Engineering: 2020,,,,10.1007/978-3-030-53949-8_5,Kotaro TanabeYoshinori TanabeMasami Hagiya,2020,http://link.springer.com/chapter/10.1007/978-3-030-53949-8_5,Chapter,,10,"Model-based testing is a widely-used vital technique for testing software running in a complex environment. In this paper, we propose extensions to existing model-based tools to apply this technique to software that employs the MQ Telemetry Transport (MQTT) protocol for transmitting messages, commonly used in the Internet of Things (IoT) environment. First, in the finite state machine used for generating test cases in a model-based testing framework, we introduce a type of transition that is triggered when receiving MQTT messages. Second, we extend the finite-state machine so that it produces test cases that reflect the characteristics of IoT software – a large number of relatively simple devices communicate with servers. Third, the concept of time is introduced into the finite state machine. Naturally, this is necessary for verifying the properties of software that runs for a long time. Moreover, to facilitate such verification, both real-time and virtual time are introduced. We implemented these extensions into a model-based testing tool, Modbat, and conducted a small experiment to confirm the feasibility, gaining positive results."
Automated Requirements-Based Testing of Black-Box Reactive Systems,NASA Formal Methods,,,,10.1007/978-3-030-55754-6_9,Massimo NarizzanoLuca PulinaArmando TacchellaSimone Vuotto,2020,http://link.springer.com/chapter/10.1007/978-3-030-55754-6_9,Chapter,"Automated testing and verification, Black-box conformance testing, Runtime verification",10,"We present a new approach to conformance testing of black-box reactive systems. We consider system specifications written as linear temporal logic formulas to generate tests as sequences of input/output pairs: inputs are extracted from the Büchi automata corresponding to the specifications, and outputs are obtained by feeding the inputs to the systems. Conformance is checked by comparing input/output sequences with automata traces to detect violations of the specifications. We consider several criteria for extracting tests and for stopping generation, and we compare them experimentally using both indicators of coverage and error-detection. The results show that our methodology can generate test suites with good system coverage and error-detection capability."
Interoperability and Integration Testing Methods for IoT Systems: A Systematic Mapping Study,Software Engineering and Formal Methods,,,,10.1007/978-3-030-58768-0_6,Miroslav BuresMatej KlimaVaclav RechtbergerXavier BellekensChristos TachtatzisRobert AtkinsonBestoun S. Ahmed,2020,http://link.springer.com/chapter/10.1007/978-3-030-58768-0_6,Chapter,"Automated testing, Integration, Internet of Things, Interoperability, Testing, Verification",10,"The recent active development of Internet of Things (IoT) solutions in various domains has led to an increased demand for security, safety, and reliability of these systems. Security and data privacy are currently the most frequently discussed topics; however, other reliability aspects also need to be focused on to maintain smooth and safe operation of IoT systems. Until now, there has been no systematic mapping study dedicated to the topic of interoperability and integration testing of IoT systems specifically; therefore, we present such an overview in this study. We analyze 803 papers from four major primary databases and perform detailed assessment and quality check to find 115 relevant papers. In addition, recently published testing techniques and approaches are analyzed and classified; the challenges and limitations in the field are also identified and discussed. Research trends related to publication time, active researchers, and publication media are presented in this study. The results suggest that studies mainly focus only on general testing methods, which can be applied to integration and interoperability testing of IoT systems; thus, there are research opportunities to develop additional testing methods focused specifically on IoT systems, so that they are more effective in the IoT context."
Improving and Optimizing Verification and Testing Techniques for Distributed Information Systems,Enterprise Information Systems,,,,10.1007/978-3-030-40783-4_22,Moez Krichen,2020,http://link.springer.com/chapter/10.1007/978-3-030-40783-4_22,Chapter,"Distributed, Formal verification, Information systems, Model based testing, Optimization, Test component placement",10,"In this paper, we deal with two validation techniques which may be adopted for improving the quality and ensuring the correctness of Distributed Information Systems. These two techniques are Formal Verification and Model Based Techniques. The first one consists in checking the correctness of a mathematical model used to describe the behavior of the considered system before its implementation. The second technique consists in deriving tests suites from the adopted model, executing them and finally deducing verdicts about the correctness of this system under test. In both cases, we need to tackle the explosion state challenge which corresponds to the fact of reaching a very large space of states and consuming a very long time during the validation process. To solve this problem we propose a set of appropriate techniques taken from the literature. We also identify a set of techniques which may be used for the optimization of the test component placement procedure."
On the Automation of Security Testing for IoT Constrained Scenarios,Information Security Applications,,,,10.1007/978-3-030-39303-8_22,Sara N. MatheuSalvador PérezJosé L. Hernández RamosAntonio Skarmeta,2020,http://link.springer.com/chapter/10.1007/978-3-030-39303-8_22,Chapter,"IoT, Model-Based Testing (MBT), Security risk assessment, Security testing",10,"Due to the high increase of IoT technologies and devices, analyzing their security is crucial for their acceptance. Towards this end, an automated security testing approach should be considered as a cornerstone to cope with the business interests and the high fragmentation of new approaches. In particular, this work analyses the use of the Model-Based Testing (MBT) approach and specific technologies and tools to automate the generation of security tests. Then, we provide a detailed description of its application to the Elliptic Curve Diffie-Hellman over COSE (EDHOC) protocol, which is being defined within the scope of the Internet Engineering Task Force (IETF)."
Teaching Software Testing to Industrial Practitioners Using Distance and Web-Based Learning,Frontiers in Software Engineering Education,,,,10.1007/978-3-030-57663-9_6,Eduard Paul Enoiu,2020,http://link.springer.com/chapter/10.1007/978-3-030-57663-9_6,Chapter,"Industrial practitioners, Online education, Software engineering education, Software testing education, Web-based learning",10,"Software testing is a business-critical process used by private and public organizations and an important source of market competitiveness. Employees of these organizations are facing tough competition and are required to be able to maintain and develop their skills and knowledge in software testing. In the education market, many commercial courses and certifications are available for industrial engineers who wish to improve their skills in software development. Nevertheless, there is a lack of access to world-leading research within the software testing field in these commercial courses that supports the companies’ innovation in software testing. As an alternative, universities are approaching this challenge by developing academic courses on software testing that can suit professionals who need to be able to combine work and studies. This study highlights several good approaches and challenges in developing and teaching three distance web-based software testing courses targeting test practitioners. The proposed approaches for enhancing teaching of software testing in an online setting for industrial practitioners are: active participation at the student’s pace, inclusion of software testing artifacts from the student’s organization as part of assignments, continuous access to online materials, the use of short video materials on testing theory, and setting clear expectations for performing online test design assignments. Finally, several challenges have been identified: poor feedback on assignments, distances between students and teachers, the use of non-realistic assignments and the difficulty for industrial practitioners to complete academic assignments each week. Future work is needed to explore these results in practice, for example on how to shorten distances between students and teachers, as well as how to enhance the inclusion of real-world testing artifacts in course assignments."
Benchmarking Combinations of Learning and Testing Algorithms for Active Automata Learning,Tests and Proofs,,,,10.1007/978-3-030-50995-8_1,Bernhard K. AichernigMartin TapplerFelix Wallner,2020,http://link.springer.com/chapter/10.1007/978-3-030-50995-8_1,Chapter,"Active automata learning, Conformance testing, LearnLib, Model learning, Model-based testing",10,"Active automata learning comprises techniques for learning automata models of black-box systems by testing such systems. While this form of learning enables model-based analysis and verification, it may also require a substantial amount of interactions with considered systems to learn adequate models, which capture the systems’ behaviour. The test cases executed during learning can be divided into two categories: (1) test cases to gain knowledge about a system and (2) test cases to falsify a learned hypothesis automaton. The former are selected by learning algorithms, whereas the latter are selected by conformance-testing algorithms. There exist various options for both types of algorithms and there are dependencies between them. In this paper, we investigate the performance of combinations of four different learning algorithms and seven different testing algorithms. For this purpose, we perform learning experiments using 39 benchmark models. Based on experimental results, we discuss insights regarding the performance of different configurations for various types of systems. These insights may serve as guidance for future users of active automata learning."
Flexible Formality Practical Experience with Agile Formal Methods,Trends in Functional Programming,,,,10.1007/978-3-030-57761-2_5,Philipp KantKevin HammondDuncan CouttsJames ChapmanNicholas ClarkeJared CorduanNeil DaviesJavier DíazMatthias GüdemannWolfgang JeltschMarcin SzamotulskiPolina Vinogradova,2020,http://link.springer.com/chapter/10.1007/978-3-030-57761-2_5,Chapter,,10,"Agile software development and Formal Methods are traditionally seen as being in conflict. From an Agile perspective, there is pressure to deliver quickly , building vertical prototypes and doing many iterations/sprints, refining the requirements; from a Formal Methods perspective, there is pressure to deliver correctly and any change in requirements often necessitates changes in the formal specification and might even impact all arguments of correctness. Over the years, the need to “be agile” has become a kind of mantra in software development management, and there is a prevalent prejudice that using formal methods was an impediment to being agile. In this paper, we contribute to the refutation of this stereotype, by providing a real-world example of using good practices from formal methods and agile software engineering to deliver software that is simultaneously reliable, effective, testable, and that can also be iterated and delivered rapidly. We thus present how a lightweight software engineering methodology, drawing from appropriate formal methods techniques and providing the benefits of agile software development, can look like. Our methodology is informed and motivated by practical experience. We have devised and adapted it in the light of experience in delivering a large-scale software system that needs to meet complex real-world requirements: the Cardano blockchain and its cryptocurrency ada. The cryptocurrency domain is a rather new application area for which no clear engineering habit exists, so it is fitting well for agile methods. At the same time, there is a lot of real monetary value at stake, making it a good fit for using formal methods to ensure high quality and correctness. This paper reports on the issues that have been faced and overcome, and provides a number of real-world lessons that can be used to leverage the benefits of both agile and formal methods in other situations."
From Requirements to Automated Acceptance Tests with the RSL Language,Evaluation of Novel Approaches to Software Engineering,,,,10.1007/978-3-030-40223-5_3,Ana C. R. PaivaDaniel MacielAlberto Rodrigues da Silva,2020,http://link.springer.com/chapter/10.1007/978-3-030-40223-5_3,Chapter,"Model-based Testing (MBT), Requirements Specification Language (RSL), Test case execution, Test case generation, Test case specification",10,"Software testing can promote software quality. However, this activity is often performed at the end of projects where failures are most difficult to correct. Combining requirements specification activities with test design at an early stage of the software development process can be beneficial. One way to do this is to use a more structured requirements specification language. This allow to reduce typical problems such as ambiguity, inconsistency, and incorrectness in requirements and may allow the automatic generation of (parts of) acceptance test cases reducing the test design effort. In this paper we discuss an approach that promotes the practice of requirements specification combined with testing specification. This is a model-based approach that promotes the alignment between requirements and tests, namely, test cases and also low-level automated test scripts. To show the applicability of this approach, we integrate two complementary languages: (i) the ITLingo RSL (Requirements Specification Language) that is specially designed to support both requirements and tests rigorously and consistently specified; and (ii) the Robot language, which is a low-level keyword-based language for specifying test scripts. This approach includes model-to-model transformation processes, namely a transformation process from requirements (defined in RSL) into test cases (defined in RSL), and a second transformation process from test cases (in RSL) into test scripts (defined according the Robot framework). This approach was applied in a fictitious online store that illustrates the various phases of the proposal."
From Passive to Active: Learning Timed Automata Efficiently,NASA Formal Methods,,,,10.1007/978-3-030-55754-6_1,Bernhard K. AichernigAndrea PferscherMartin Tappler,2020,http://link.springer.com/chapter/10.1007/978-3-030-55754-6_1,Chapter,"Active automata learning, Genetic programming, Model inference, Model learning, Timed automata",10,"Model-based testing is a promising technique for quality assurance. In practice, however, a model is not always present. Hence, model learning techniques attain increasing interest. Still, many learning approaches can only learn relatively simple types of models and advanced properties like time are ignored in many cases. In this paper we present an active model learning technique for timed automata. For this, we build upon an existing passive learning technique for real-timed systems. Our goal is to efficiently learn a timed system while simultaneously minimizing the set of training data. For evaluation we compared our active to the passive learning technique based on 43 timed systems with up to 20 locations and multiple clock variables. The results of $$18\,060$$ 18 060 experiments show that we require only 100 timed traces to adequately learn a timed system. The new approach is up to 755 times faster."
Aplib: Tactical Agents for Testing Computer Games,Engineering Multi-Agent Systems,,,,10.1007/978-3-030-66534-0_2,I. S. W. B. PrasetyaMehdi DastaniRui PradaTanja E. J. VosFrank DignumFitsum Kifetew,2020,http://link.springer.com/chapter/10.1007/978-3-030-66534-0_2,Chapter,"Agents tactical programming, AI for automated testing, Automated game testing, Intelligent agent programming, Intelligent agents for testing",10,"Modern interactive software, such as computer games, employ complex user interfaces. Although these user interfaces make the games attractive and powerful, unfortunately they also make them extremely difficult to test. Not only do we have to deal with their functional complexity, but also the fine grained interactivity of their user interface blows up their interaction space, so that traditional automated testing techniques have trouble handling it. An agent-based testing approach offers an alternative solution: agents’ goal driven planning, adaptivity, and reasoning ability can provide an extra edge towards effective navigation in complex interaction space. This paper presents aplib , a Java library for programming intelligent test agents, featuring novel tactical programming as an abstract way to exert control over agents’ underlying reasoning-based behavior. This type of control is suitable for programming testing tasks. Aplib is implemented in such a way to provide the fluency of a Domain Specific Language (DSL). Its embedded DSL approach also means that aplib programmers will get al.l the advantages that Java programmers get: rich language features and a whole array of development tools ."
Test Automation with the Gauge Framework: Experience and Best Practices,Computational Science and Its Applications – ICCSA 2020,,,,10.1007/978-3-030-58802-1_33,Vahid GarousiAlper Buğra KeleşYunus BalamanZeynep Özdemir Güler,2020,http://link.springer.com/chapter/10.1007/978-3-030-58802-1_33,Chapter,"Best practices, Gauge framework, Industrial experience, Software testing, Test automation",10,"While Behavior-driven development (BDD) tools such as Cucumber are powerful tools for automated testing, they have certain limitations. For example, they often enforce strict syntax for test cases, like the “Given-When-Then” format, which may not always be easy to write for a given test case. A new test automation framework named Gauge ( gauge.org ) addresses that limitation since it does not prescribe the BDD testing process with a strict syntax. In Gauge, writing a test case is as easy as writing down the flow of test cases in several itemized sentences in a natural language, like English. In the context of Testinium ( testinium.com ), a large software testing company which provides software testing services, tools and solutions to a large number of clients, we have actively used the Gauge framework since 2018 to develop large automated front-end test suites for several large web applications. In this paper/talk, the speakers will share several examples and best practices of developing automated tests in natural-language requirements using the Gauge framework. By learning from the ideas presented in the talk, readers (attendees) will be able to consider applying the Gauge framework in their own test automation projects."
"A Model-Based Approach to the Design, Verification and Deployment of Railway Interlocking System","Leveraging Applications of Formal Methods, Verification and Validation: Applications",,,,10.1007/978-3-030-61467-6_16,Arturo AmendolaAnna BecchiRoberto CavadaAlessandro CimattiAlberto GriggioGiuseppe ScaglioneAngelo SusiAlberto TacchellaMatteo Tessi,2020,http://link.springer.com/chapter/10.1007/978-3-030-61467-6_16,Chapter,"Code generation, Formal verification, Functional specifications, Interlocking Systems, Model-based design",10,"This paper describes a model-based flow for the development of Interlocking Systems. The flow starts from a set of specifications in Controlled Natural Language (CNL), that are close to the jargon adopted in by domain experts, but fully formal. From the CNL, a complete SysML specification is extracted, leveraging various forms of diagrams, and enabling automated code generation. Several formal verification methods are supported. A complementary part of the flow supports the extraction of formal properties from legacy Interlocking Systems designed as Relay circuits. The flow is implemented in a comprehensive toolset, and is currently used by railway experts."
Test4Enforcers: Test Case Generation for Software Enforcers,Runtime Verification,,,,10.1007/978-3-030-60508-7_15,Michell GuzmanOliviero RiganelliDaniela MicucciLeonardo Mariani,2020,http://link.springer.com/chapter/10.1007/978-3-030-60508-7_15,Chapter,"Android apps, Runtime enforcement, Test case generation, Testing enforcers",10,"Software enforcers can be used to modify the runtime behavior of software applications to guarantee that relevant correctness policies are satisfied. Indeed, the implementation of software enforcers can be tricky, due to the heterogeneity of the situations that they must be able to handle. Assessing their ability to steer the behavior of the target system without introducing any side effect is an important challenge to fully trust the resulting system. To address this challenge, this paper presents Test4Enforcers, the first approach to derive thorough test suites that can validate the impact of enforcers on a target system. The paper also shows how to implement the Test4Enforcers approach in the DroidBot test generator to validate enforcers for Android apps."
Trace Analysis Using an Event-Driven Interval Temporal Logic,Logic-Based Program Synthesis and Transformation,,,,10.1007/978-3-030-45260-5_11,María-del-Mar GallardoLaura Panizo,2020,http://link.springer.com/chapter/10.1007/978-3-030-45260-5_11,Chapter,,10,"Nowadays, many critical systems can be characterized as hybrid ones, combining continuous and discrete behaviours that are closely related. Changes in the continuous dynamics are usually fired by internal or external discrete events. Due to their inherent complexity, it is a crucial but not trivial task to ensure that these systems satisfy some desirable properties. An approach to analyze them consists of the combination of model-based testing and run-time verification techniques. In this paper, we present an interval logic to specify properties of event-driven hybrid systems and an automatic transformation of the logic formulae into networks of finite-state machines. Currently, we use Promela / Spin to implement the network of finite-state machines, and analyze non-functional properties of mobile applications. We use the TRIANGLE testbed, which implements a controllable network environment for testing, to obtain the application traces and monitor network parameters."
The 2020 Expert Survey on Formal Methods,Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-030-58298-2_1,Hubert GaravelMaurice H. ter BeekJaco van de Pol,2020,http://link.springer.com/chapter/10.1007/978-3-030-58298-2_1,Chapter,"Cybersecurity, Education, Formal method, Modelling, Safety, Software engineering, Software tool, Specification, Survey, Technology transfer, Verification",10,"Organised to celebrate the 25th anniversary of the FMICS international conference, the present survey addresses 30 questions on the past, present, and future of formal methods in research, industry, and education. Not less than 130 high-profile experts in formal methods (among whom three Turing award winners and many recipients of other prizes and distinctions) accepted to participate in this survey. We analyse their answers and comments, and present a collection of 111 position statements provided by these experts. The survey is both an exercise in collective thinking and a family picture of key actors in formal methods."
A General Framework for Decentralized Combinatorial Testing of Access Control Engine: Examples of Application,Information Systems Security and Privacy,,,,10.1007/978-3-030-49443-8_10,Said DaoudaghFrancesca LonettiEda Marchetti,2020,http://link.springer.com/chapter/10.1007/978-3-030-49443-8_10,Chapter,"Access control systems, Oracle, Testing, Web service, XACML",10,"Access control mechanisms aim to assure data protection in modern software systems. Testing of such mechanisms is a key activity to avoid security flaws and violations inside the systems or applications. In this paper, we introduce the general architecture of a new decentralized framework for testing of XACML-based access control engines. The proposed framework is composed of different web services and can be instantiated for different testing purposes: i) generation of test cases based on combinatorial testing strategies; ii) distributed test cases execution; iii) decentralized oracle derivation able to associate the expected authorization decision to a given XACML request. The effectiveness of the framework has been proven into two different experiments. The former addressed the evaluation of the distributed vs non distributed testing solution. The latter focused on the performance comparison of two distributed oracle approaches."
An Architecture for Automated Security Test Case Generation for MQTT Systems,Database and Expert Systems Applications,,,,10.1007/978-3-030-59028-4_5,Hannes SochorFlavio FerrarottiRudolf Ramler,2020,http://link.springer.com/chapter/10.1007/978-3-030-59028-4_5,Chapter,"Automated testing, IoT, MQTT, Security testing",10,"Message Queuing Telemetry Transport (MQTT) protocol is among the preferred publish/subscribe protocols used for Machine-to-Machine (M2M) communication and Internet of Things (IoT). Although the MQTT protocol itself is quite simple, the concurrent iteration of brokers and clients and its intrinsic non-determinism, coupled with the diversity of platforms and programming languages in which the protocol is implemented and run, makes the necessary task of security testing challenging. We address precisely this problem by proposing an architecture for security test generation for systems relying on the MQTT protocol. This architecture enables automated test case generation to reveal vulnerabilities and discrepancies between different implementations. As a desired consequence, when implemented, our architectural design can be used to uncover erroneous behaviours that entail latent security risks in MQTT broker and client implementations. In this paper we describe the key components of our architecture, our prototypical implementation using a random test case generator, core design decisions and the use of security attacks in testing. Moreover, we present first evaluations of the architectural design and the prototypical implementation with encouraging initial results."
"Uncertainty, Modeling and Safety Assurance: Towards a Unified Framework","Verified Software. Theories, Tools, and Experiments",,,,10.1007/978-3-030-41600-3_2,Marsha ChechikSahar KokalyMona RahimiRick SalayTorin Viger,2020,http://link.springer.com/chapter/10.1007/978-3-030-41600-3_2,Chapter,,10,"Uncertainty occurs naturally in software systems, including those that are model-based. When such systems are safety-critical, they need to be assured, e.g., by arguing that the system satisfies its safety goals. But how can we rigorously reason about assurance in the presence of uncertainty? In this paper, we propose a vision for a framework for managing uncertainty in assurance cases for software systems, and in particular, for model-based software systems, by systematically identifying , assessing and addressing it. We also discuss a set of challenges that need to be addressed to realize this framework."
Learning Abstracted Non-deterministic Finite State Machines,Testing Software and Systems,,,,10.1007/978-3-030-64881-7_4,Andrea PferscherBernhard K. Aichernig,2020,http://link.springer.com/chapter/10.1007/978-3-030-64881-7_4,Chapter,"Active automata learning, Model inference, MQTT, Non-deterministic finite state machines",10,"Active automata learning gains increasing interest since it gives an insight into the behavior of a black-box system. A crucial drawback of the frequently used learning algorithms based on Angluin’s $$L^*$$ L ∗ is that they become impractical if systems with a large input/output alphabet are learned. Previous work suggested to circumvent this problem by abstracting the input alphabet and the observed outputs. However, abstraction could introduce non-deterministic behavior. Already existing active automata learning algorithms for observable non-deterministic systems learn larger models if outputs are only observable after certain input/output sequences. In this paper, we introduce an abstraction scheme that merges akin states. Hence, we learn a more generic behavioral model of a black-box system. Furthermore, we evaluate our algorithm in a practical case study. In this case study, we learn the behavior of five different Message Queuing Telemetry Transport (mqtt) brokers interacting with multiple clients."
Language Inclusion for Finite Prime Event Structures,"Verification, Model Checking, and Abstract Interpretation",,,,10.1007/978-3-030-39322-9_15,Andreas FellnerThorsten TarrachGeorg Weissenbacher,2020,http://link.springer.com/chapter/10.1007/978-3-030-39322-9_15,Chapter,"Concurrency, Event structures, Language inclusion, Mutation-based test case generation",10,"We study the problem of language inclusion between finite, labeled prime event structures. Prime event structures are a formalism to compactly represent concurrent behavior of discrete systems. A labeled prime event structure induces a language of sequences of labels produced by the represented system. We study the problem of deciding inclusion and membership for languages encoded by finite prime event structures and provide complexity results for both problems. We provide a family of examples where prime event structures are exponentially more succinct than formalisms that do not take concurrency into account. We provide a decision algorithm for language inclusion that exploits this succinctness. Furthermore, we provide an implementation of the algorithm and an evaluation on a series of benchmarks. Finally, we demonstrate how our results can be applied to mutation-based test case generation."
Interrogating Virtual Agents: In Quest of Security Vulnerabilities,Testing Software and Systems,,,,10.1007/978-3-030-64881-7_2,Josip BozicFranz Wotawa,2020,http://link.springer.com/chapter/10.1007/978-3-030-64881-7_2,Chapter,"Chatbots, Model-based testing, Security testing, Web applications",10,"Chatbots, i.e., systems that communicate in natural language, have been of increasing importance over the last few years. These virtual agents provide specific services or products to clients on a 24/7 basis. Chatbots provide a simple and intuitive interface, i.e., natural language processing, which makes them increasingly attractive for various applications. In fact, chatbots are used as substitutes for repetitive tasks or user inquiries that can be automated. However, these advantages always are accompanied with concerns, e.g., whether security and privacy can be assured. These concerns become more and more important, because in contrast to simple requests, more sophisticated chatbots are able to utilize personalized services to users. In such cases, sensitive user data are processed and exchanged. Hence, such systems become natural targets for cyber-attacks with unforeseen consequences. For this reason, assuring information security of chatbots is an important challenge in practice. In this paper, we contribute to this challenge and introduce an automated security testing approach for chatbots. The presented framework is able to generate and run tests in order to detect intrinsic software weaknesses leading to the XSS vulnerability. We assume a vulnerability to be triggered when obtaining critical information from or crashing the virtual agent, regardless of its purpose. We discuss the underlying basic foundations and demonstrate the testing approach using several real-world chatbots."
A Modular SystemC RTOS Model for Uncertainty Analysis,Cyber Physical Systems. Model-Based Design,,,,10.1007/978-3-030-41131-2_1,Lorenzo LazzaraGiulio Mosé MancusoFabio CremonaAlessandro Ulisse,2020,http://link.springer.com/chapter/10.1007/978-3-030-41131-2_1,Chapter,"Real-time operating system model, Statistical model checking, SystemC, Uncertainty quantification",10,"Nowadays the complexity of embedded systems is constantly increasing and several different types of applications concurrently execute on the same computational platform. Hence these systems have to satisfy real-time constraints and support real-time communication. The design and verification of these systems is very complex, full formal verification is not always possible and the run-time verification is the only feasible path to follow. In this context, the possibility to simulate their behavior becomes a crucial aspect. This paper proposes a SystemC modular RTOS model to assist the design and the verification of real-time embedded systems. The model architecture has been designed to capture all the typical functionalities that every RTOS owns, in order to easily reproduce the behavior of a large class of RTOS. The RTOS model can support functional simulation for design space exploration to rapidly evaluate the impact of different RTOS configurations (such as scheduling policies) on the overall system performances. Moreover the model can be used for software verification by implementing specific RTOS APIs over the generic services provided by the model, allowing the simulation of a real application without changing any instruction. The proposed approach enables the user to model non-deterministic behaviors at architectural and application level by means of probabilistic distributions. This allows to assess system performances of complex embedded systems under uncertain behavior (e.g. execution time). A use case is proposed considering an instance of the model compliant with the ARINC 653 specification, which requires spatial and temporal segregation, and where typical RTOS performances are assessed given the probability distributions of execution time and aperiodic task activation."
Model-Driven Chatbot Development,Conceptual Modeling,,,,10.1007/978-3-030-62522-1_15,Sara Pérez-SolerEsther GuerraJuan de Lara,2020,http://link.springer.com/chapter/10.1007/978-3-030-62522-1_15,Chapter,"Chatbots, DSLs, Migration, Model-driven engineering",10,"Chatbots are software services accessed via conversation in natural language. They are increasingly used to help in all kinds of procedures like booking flights, querying visa information or assigning tasks to developers. They can be embedded in webs and social networks, and be used from mobile devices without installing dedicated apps. While many frameworks and platforms have emerged for their development, identifying the most appropriate one for building a particular chatbot requires a high investment of time. Moreover, some of them are closed – resulting in customer lock-in – or require deep technical knowledge. To tackle these issues, we propose a model-driven engineering approach to chatbot development. It comprises a neutral meta-model and a domain-specific language (DSL) for chatbot description; code generators and parsers for several chatbot platforms; and a platform recommender. Our approach supports forward and reverse engineering, and model-based analysis. We demonstrate its feasibility presenting a prototype tool and an evaluation based on migrating third party Dialogflow bots to Rasa."
Coverage Analysis of Net Inscriptions in Coloured Petri Net Models,Verification and Evaluation of Computer and Communication Systems,,,,10.1007/978-3-030-65955-4_6,Faustin AhishakiyeJosé Ignacio Requeno JaraboLars Michael KristensenVolker Stolz,2020,http://link.springer.com/chapter/10.1007/978-3-030-65955-4_6,Chapter,,10,"High-level Petri nets such as Coloured Petri Nets (CPNs) are characterised by the combination of Petri nets and a high-level programming language. In the context of CPNs and CPN Tools, the inscriptions (e.g., arc expressions and guards) are specified using Standard ML (SML). The application of simulation and state space exploration (SSE) for validating CPN models traditionally focusses on behavioural properties related to net structure, i.e., places and transitions. This means that the net inscriptions are only implicitly validated, and the extent to which their sub-expressions have been covered is not made explicit. The contribution of this paper is an approach that establishes a link between coverage analysis known from programming languages and net inscriptions of CPN models. Specifically, we consider Modified Condition/Decision Coverage (MC/DC) of Boolean SML decisions, which cannot be measured within CPN Tools neither through state space exploration nor model checking directly. We have implemented our approach in a library for CPN Tools comprised of an annotation and instrumentation mechanism that transparently intercepts and collects evaluation of boolean conditions, and a post-processing tool that, for a set of model executions (runs), determines whether each decision is MC/DC-covered. We evaluate our approach on four large publicly available CPN models."
Inspecting Code Churns to Prioritize Test Cases,Testing Software and Systems,,,,10.1007/978-3-030-64881-7_17,Francesco AltieroAnna CorazzaSergio Di MartinoAdriano PeronLuigi Libero Lucio Starace,2020,http://link.springer.com/chapter/10.1007/978-3-030-64881-7_17,Chapter,"Code churn., Regression testing, Test prioritization",10,"Within the context of software evolution, due to time-to-market pressure, it is not uncommon that a company has not enough time and/or resources to re-execute the whole test suite on the new software version, to check for non-regression. To face this issue, many Regression Test Prioritization techniques have been proposed, aimed at ranking test cases in a way that tests more likely to expose faults have higher priority. Some of these techniques exploit code churn metrics, i.e. some quantification of code changes between two subsequent versions of a software artifact, which have been proven to be effective indicators of defect-prone components. In this paper, we first present three new Regression Test Prioritization strategies, based on a novel code churn metric, that we empirically assessed on an open source software system. Results highlighted that the proposal is promising, but that it might be further improved by a more detailed analysis on the nature of the changes introduced between two subsequent code versions. To this aim, in this paper we also sketch a more refined approach we are currently investigating, that quantifies changes in a code base at a finer grained level. Intuitively, we seek to prioritize tests that stress more fault-prone changes (e.g., structural changes in the control flow), w.r.t. those that are less likely to introduce errors (e.g., the renaming of a variable). To do so, we propose the exploitation of the Abstract Syntax Tree (AST) representation of source code, and to quantify differences between ASTs by means of specifically designed Tree Kernel functions, a type of similarity measure for tree-based data structures, which have shown to be very effective in other domains, thanks to their customizability."
Continuous Optimization Benchmarks by Simulation,Parallel Problem Solving from Nature – PPSN XVI,,,,10.1007/978-3-030-58112-1_19,Martin ZaeffererFrederik Rehbach,2020,http://link.springer.com/chapter/10.1007/978-3-030-58112-1_19,Chapter,"Benchmarking, Continuous optimization, Gaussian process regression, Kriging, Simulation, Test function",10,"Benchmark experiments are required to test, compare, tune, and understand optimization algorithms. Ideally, benchmark problems closely reflect real-world problem behavior. Yet, real-world problems are not always readily available for benchmarking. For example, evaluation costs may be too high, or resources are unavailable (e.g., software or equipment). As a solution, data from previous evaluations can be used to train surrogate models which are then used for benchmarking. The goal is to generate test functions on which the performance of an algorithm is similar to that on the real-world objective function. However, predictions from data-driven models tend to be smoother than the ground-truth from which the training data is derived. This is especially problematic when the training data becomes sparse. The resulting benchmarks may not reflect the landscape features of the ground-truth, are too easy, and may lead to biased conclusions. To resolve this, we use simulation of Gaussian processes instead of estimation (or prediction). This retains the covariance properties estimated during model training. While previous research suggested a decomposition-based approach for a small-scale, discrete problem, we show that the spectral simulation method enables simulation for continuous optimization problems. In a set of experiments with an artificial ground-truth, we demonstrate that this yields more accurate benchmarks than simply predicting with the Gaussian process model."
Statistical Model Checking for Variability-Intensive Systems,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-030-45234-6_15,Maxime CordyMike PapadakisAxel Legay,2020,http://link.springer.com/chapter/10.1007/978-3-030-45234-6_15,Chapter,,10,"We propose a new Statistical Model Checking (SMC) method to discover bugs in variability-intensive systems (VIS). The state-space of such systems is exponential in the number of variants, which makes the verification problem harder than for classical systems. To reduce verification time, we sample executions from a featured transition system – a model that represents jointly the state spaces of all variants. The combination of this compact representation and the inherent efficiency of SMC allows us to find bugs much faster (up to 16 times according to our experiments) than other methods. As any simulation-based approach, however, the risk of Type-1 error exists. We provide a lower bound and an upper bound for the number of simulations to perform to achieve the desired level of confidence. Our empirical study involving 59 properties over three case studies reveals that our method manages to discover all variants violating 41 of the properties. This indicates that SMC can act as a low-cost-high-reward method for verifying VIS."
Safety Patterns for SysML: What Does OMG Specify?,Reuse in Emerging Software Engineering Practices,,,,10.1007/978-3-030-64694-3_2,Nan NiuLogan JohnsonChristopher Diltz,2020,http://link.springer.com/chapter/10.1007/978-3-030-64694-3_2,Chapter,"Grounded theory, Semantic roles, Specification patterns, Systems Modeling Language (SysML), Systems reuse, Temporal constraints",10,"The Systems Modeling Language (SysML) represents a significant and increasing segment of industrial support for building critical systems. The Object Management Group (OMG) has been releasing and revising the formal specification of SysML since 2007, with version 1.6 recently formalized in November 2019. However, little is known about what OMG specifies and how the official specification influences model-driven engineering (MDE). To fill the gap, we present a new way of analyzing the OMG SysML specification (version 1.6) to uncover reusable guidelines and constraints for safe MDE practice. We illustrate our approach with the discovery of the recurring “Asset Leakage” safety pattern and the development of a semantic-role-based theory to support practitioners’ identification, formulation, and verification of critical properties in their modeling contexts."
Systematic Approach to Engineer Decentralized Self-adaptive Systems,Software Architecture,,,,10.1007/978-3-030-59155-7_4,Federico Quin,2020,http://link.springer.com/chapter/10.1007/978-3-030-59155-7_4,Chapter,"Architecture-based adaptation, Decentralization, Formal techniques, Machine learning, Self-adaptation",10,"Self-adaptation is a widely accepted approach to deal with uncertainties that are difficult to anticipate before deployment. We focus on architecture-based adaptation that relies on a feedback loop that reasons over architectural models of the system at runtime to make adaptation decisions. In particular, we study decentralized self-adaptive systems where self-adaptation is realized through multiple coordinating feedback loops. Such decentralization is crucial for systems where adaptation decisions cannot be made in a centralized way, such as in large scale Internet of Things (IoT). State of the art in this area is limited to either conceptual ideas or solutions dedicated to particular settings. This paper outlines a research project targeting the research question: “how to model and realize decentralized feedback loops that are capable to guarantee compliance of system goals in an efficient way despite uncertainties the system faces?” We plan to answer this question in two stage. First, we study commonalities and variability of decentralized self-adaptive systems leveraging on patterns and coordination mechanisms, and reify our insights in a framework. Second, we study language support for the design and implementation of decentralized self-adaptation, capitalizing on the outcome of the first stage. To ensure guarantees for the qualities we will found our work on formal techniques. To ensure efficiency, we will combine statistical techniques with machine learning. We plan to validate the research results in two domains: IoT and multi-cloud systems."
Formal Verification of OIL Component Specifications using mCRL2,Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-030-58298-2_10,Olav BunteLouis C. M. van GoolTim A. C. Willemse,2020,http://link.springer.com/chapter/10.1007/978-3-030-58298-2_10,Chapter,,10,"To aid in making software bug-free, several high-tech companies are moving from coding to modelling. In some cases model checking techniques are explored or have already been adopted to get more value from these models. This also holds for Canon Production Printing, where the language OIL was developed for modelling control-software components. In this paper we present OIL and give its semantics. We define a translation from OIL to mCRL2 to enable the use of model checking techniques. Moreover, we discuss informal validity requirements on OIL component specifications and show how these can be formalised and verified using model checking. To test the feasibility of these techniques, we apply them to two models of systems used in production."
Continuous Formal Verification of Microservice-Based Process Flows,Software Architecture,,,,10.1007/978-3-030-59155-7_31,Matteo Camilli,2020,http://link.springer.com/chapter/10.1007/978-3-030-59155-7_31,Chapter,"DevOps, Formal verification, Microservices, Petri nets",10,"The microservice architectural style is often used to implement modern cloud, IoT, and large-scale distributed applications. Here software development processes are characterized by short incremental iterations, where several updates and new functionalities are continuously integrated many times a day in a agile fashion. Such a paradigm shift calls for new formal approaches to systematic (design-time and runtime) verification. This paper introduces a formal framework to apply continuous verification of microservice based applications built on top of Conductor , i.e., an open source orchestration engine of microservices workflows in use at Netflix, Inc. for their production environment. Our proposal adopts a model-driven paradigm and it leverages solid foundation from Petri nets to specify and verify the behavior of time-dependent workflows. This paper describes our approach, the current implementation, and evaluation activity conducted on a taxi-hailing application example."
Declarative Stream Runtime Verification (hLola),Programming Languages and Systems,,,,10.1007/978-3-030-64437-6_2,Martín CeresaFelipe GorostiagaCésar Sánchez,2020,http://link.springer.com/chapter/10.1007/978-3-030-64437-6_2,Chapter,,10,"Stream Runtime Verification (SRV) is a formal dynamic analysis technique that generalizes runtime verification algorithms from temporal logics like LTL to stream monitoring, allowing the computation of richer verdicts than Booleans (quantitative values or even arbitrary data). The core of SRV algorithms is a clean separation between temporal dependencies and data computations. In spite of this theoretical separation previous engines include ad-hoc implementations of just a few data types, requiring complex changes in the tools to incorporate new data types. In this paper we present a solution as a Haskell embedded domain specific language that is easily extensible to arbitrary data types. The solution is enabled by a technique, which we call lift deep embedding , that consists in borrowing general Haskell types and embedding them transparently into an eDSL. This allows for example the use of higher-order functions to implement static stream parametrization. We describe the Haskell implementation called hLola and illustrate simple extensions implemented using libraries, which would require long and error-prone additions in other ad-hoc SRV formalisms."
Quantifying the Similarity of Non-bisimilar Labelled Transition Systems,Software Engineering and Formal Methods,,,,10.1007/978-3-030-57506-9_16,Gwen Salaün,2020,http://link.springer.com/chapter/10.1007/978-3-030-57506-9_16,Chapter,,10,"Equivalence checking is an established technique for automatically verifying that two behavioural models (Labelled Transition Systems, LTSs) are equivalent from the point of view of an external observer. When these models are not equivalent, the checker returns a Boolean result with a counterexample, which is a sequence of actions leading to a state where the equivalence relation is not satisfied. However, this counterexample does not give any indication of how far the two LTSs are one from another. One can wonder whether they are almost identical or totally different, which is quite different from a design or debugging point of view. In this paper, we present an approach for measuring the similarity between two LTS models. The set of metrics is computed automatically using a tool we implemented. Beyond presenting the foundations of the proposed solution, we will show how it can be applied to a concrete application domain for supporting the construction of IoT applications by composition of existing devices."
Optimistic and Pessimistic On-the-fly Analysis for Metric Temporal Graph Logic,Graph Transformation,,,,10.1007/978-3-030-51372-6_16,Sven SchneiderLucas SakizloglouMaria MaximovaHolger Giese,2020,http://link.springer.com/chapter/10.1007/978-3-030-51372-6_16,Chapter,"Graph logic with binding, Nonpropositional metric temporal logic, Runtime monitoring, Three-valued logic",10,"The nonpropositional Metric Temporal Graph Logic (MTGL) specifies the behavior of timed dynamic systems given by timed graph sequences (TGSs), which contain typed attributed graphs representing system states and the elapsed time between states. MTGL satisfaction can be analyzed for finite TGSs by translating its satisfaction problem to the satisfaction problem of nested graph conditions using a folding operation (aggregating a TGS into a graph with history ) and a reduction operation (translating an MTGL condition into a nested graph condition). In this paper, we introduce an analysis procedure for MTGL to allow for an on-the-fly analysis of finite/infinite TGSs. To this end, we introduce a further (optimistic) reduction of MTGL conditions, which leads to violations during the on-the-fly analysis only when non-satisfaction is guaranteed in the future whereas the former (pessimistic) reduction leads to violations when satisfaction is not guaranteed in the future. We motivate the relevance of our analysis procedure, which uses both reduction operations, by means of a running example. Finally, we discuss prototypical support in the tool AutoGraph ."
On Testing Message-Passing Components,"Leveraging Applications of Formal Methods, Verification and Validation: Verification Principles",,,,10.1007/978-3-030-61362-4_2,Alex CotoRoberto GuancialeEmilio Tuosto,2020,http://link.springer.com/chapter/10.1007/978-3-030-61362-4_2,Chapter,,10,"We instantiate and apply a recently proposed abstract framework featuring an algorithm for the automatic generation of tests for component testing of message-passing systems. We demonstrate the application of a top-down mechanism for test generation. More precisely, we reduce the problem of generating tests for components of message-passing applications to the projection of global views of choreographies. The application of the framework to some examples gives us the pretext to make some considerations about our approach."
Modelling an Automotive Software-Intensive System with Adaptive Features Using ASMETA,Rigorous State-Based Methods,,,,10.1007/978-3-030-48077-6_25,Paolo ArcainiSilvia BonfantiAngelo GargantiniElvinia RiccobenePatrizia Scandurra,2020,http://link.springer.com/chapter/10.1007/978-3-030-48077-6_25,Chapter,,10,"In the context of automotive domain, modern control systems are software-intensive and have adaptive features to provide safety and comfort. These software-based features demand software engineering approaches and formal methods that are able to guarantee correct operation, since malfunctions may cause harm/damage. Adaptive Exterior Light and the Speed Control Systems are examples of software-intensive systems that equip modern cars. We have used the Abstract State Machines to model the behaviour of both control systems. Each model has been developed through model refinement, following the incremental way in which functional requirements are given. We used the ASMETA tool-set to support the simulation of the abstract models, their validation against the informal requirements, and the verification of behavioural properties. In this paper, we discuss our modelling, validation and verification strategies, and the results (in terms of features addressed and not) of our activities. In particular, we provide insights on how we addressed the adaptive features (the adaptive high beam headlights and the adaptive cruise control) by explicitly modelling their software control loops according to the MAPE-K (Monitor-Analyse-Plan-Execute over a shared Knowledge) reference control model for self-adaptive systems."
Tendermint Blockchain Synchronization: Formal Specification and Model Checking,"Leveraging Applications of Formal Methods, Verification and Validation: Verification Principles",,,,10.1007/978-3-030-61362-4_27,Sean BraithwaiteEthan BuchmanIgor KonnovZarko MilosevicIlina StoilkovskaJosef WidderAnca Zamfir,2020,http://link.springer.com/chapter/10.1007/978-3-030-61362-4_27,Chapter,,10,"Blockchain synchronization is one of the core protocols of Tendermint blockchains. We describe our recent efforts on formal specification of the protocol and its implementation, and present model checking results for small parameters. We demonstrate that the protocol quality and understanding can be improved by writing specifications and applying model checking to verify their properties."
Towards a Formally Verified Implementation of the MimbleWimble Cryptocurrency Protocol,Applied Cryptography and Network Security Workshops,,,,10.1007/978-3-030-61638-0_1,Gustavo BetarteMaximiliano CristiáCarlos LunaAdrián SilveiraDante Zanarini,2020,http://link.springer.com/chapter/10.1007/978-3-030-61638-0_1,Chapter,"Cryptocurrency, Formal verification, Idealized model, MimbleWimble, Security",10,MimbleWimble is a privacy-oriented cryptocurrency technology which provides security and scalability properties that distinguish it from other protocols of its kind. We present and briefly discuss those properties and outline the basis of a model-driven verification approach to address the certification of the correctness of an implementation of the protocol.
Using Model Learning for the Generation of Mock Components,Testing Software and Systems,,,,10.1007/978-3-030-64881-7_1,Sébastien SalvaElliott Blot,2020,http://link.springer.com/chapter/10.1007/978-3-030-64881-7_1,Chapter,"Communicating systems, Mock, Model learning, Quality metrics",10,"Mocking objects is a common technique that substitutes parts of a program to simplify the test case development, to increase test coverage or to speed up performance. Today, mocks are almost exclusively used with object oriented programs. But mocks could offer the same benefits with communicating systems to make them more reliable. This paper proposes a model-based approach to help developers generate mocks for this kind of system, i.e. systems made up of components interacting with each other by data networks and whose communications can be monitored. The approach combines model learning to infer models from event logs, quality metric measurements to help chose the components that may be replaced by mocks, and mock generation and execution algorithms to reduce the mock development time. The approach has been implemented as a tool chain with which we performed experimentations to evaluate its benefits in terms of usability and efficiency."
"The Impact of Social-Support, Self-efficacy and APP on MBI","Cross-Cultural Design. Applications in Health, Learning, Communication, and Creativity",,,,10.1007/978-3-030-49913-6_12,Shu-Mei LinLiang-Ming LoChia-Yi LiuChao LiuWen-Ko Chiou,2020,http://link.springer.com/chapter/10.1007/978-3-030-49913-6_12,Chapter,"APP, MBI, Self-efficacy, Social-support",10,"Social-support, self-efficacy and APP were one of the advanced MBI. This article presents a structured literature review of 44 articles to elucidate the impacts of social support, self-efficacy, APP. We discuss (1) the MBIs in which social-support, self-efficacy, and APP operate; (2) social-support, self-efficacy, and APP as MBI design choices and (3) the implycations of MBI design choices on MBI performance output. The structure of this article is based on the MBI-PPD-APP model. Results of our literature review revealed that, social-support, self-efficacy, and APP are employed in a variety of applications. We also found that MBI design involves choices pertaining to MBI configurations, MBI relationship, social-support, self-efficacy, and the APP process. The MBI performance outputs which were found to be most influenced by social-support, self-efficacy, and APP included PPD (reduce), MBI phenomena (reduced), and MBI responsiveness (improved). We used the findings of our literature review to develop a conceptual framework, which includes 18 propositions and an agenda for research. Specifically, the goal of this research agenda is to existing knowledge about how social-support, self-efficacy, and APP impact MBI design. We expect that social-support and self-efficacy and APP will eventually lead to improve."
Initial Pose Estimation of 3D Object with Severe Occlusion Using Deep Learning,Advanced Concepts for Intelligent Vision Systems,,,,10.1007/978-3-030-40605-9_28,Jean-Pierre LomalizaHanhoon Park,2020,http://link.springer.com/chapter/10.1007/978-3-030-40605-9_28,Chapter,"Deep learning, Initial camera pose estimation, Mobile augmented reality, Model-based tracking, Partially visible object, Severe occlusion, Subpart detection",10,"During the last decade, augmented reality (AR) has gained explosive attention and demonstrated high potential on educational and training applications. As a core technique, AR requires a tracking method to get 3D poses of a camera or an object. Hence, providing fast, accurate, robust, and consistent tracking methods have been a main research topic in the AR field. Fortunately, tracking the camera pose using a relatively small and less-textured known object placed on the scene has been successfully mastered through various types of model-based tracking (MBT) methods. However, MBT methods requires a good initial camera pose estimator and estimating an initial camera pose from partially visible objects remains an open problem. Moreover, severe occlusions are also challenging problems for initial camera pose estimation. Thus, in this paper, we propose a deep learning method to estimate an initial camera pose from a partially visible object that may also be severely occluded. The proposed method handles such challenging scenarios by relying on the information of detected subparts of a target object to be tracked. Specifically, we first detect subparts of the target object using a state-of-the-art convolutional neural networks (CNN). The object detector returns two dimensional bounding boxes, associated classes, and confidence scores. We then use the bounding boxes and classes information to train a deep neural network (DNN) that regresses to camera’s 6-DoF pose. After initial pose estimation, we attempt to use a tweaked version of an existing MBT method to keep tracking the target object in real time on mobile platform. Experimental results demonstrate that the proposed method can estimate accurately initial camera poses from objects that are partially visible or/and severely occluded. Finally, we analyze the performance of the proposed method in more detail by comparing the estimation errors when different number of subparts are detected."
STAMP S&S: Layered Modeling for the Complexed System in the Society of AI/IoT,Knowledge-Based Software Engineering: 2020,,,,10.1007/978-3-030-53949-8_11,Tomoko KanekoNobukazu Yoshioka,2020,http://link.springer.com/chapter/10.1007/978-3-030-53949-8_11,Chapter,"ISO15288, ISO21207, Layered modeling, Risk analysis, Safety, Security, Socio-technical system, STAMP",10,"Systems, including AI/IoT, have complex relationships. It is necessary to analyze risks from various perspectives to build a system that can be used safely and securely throughout society, including people and organizations. Object modeling is desirable for risk analysis from multiple viewpoints. An accident model based on system theory called STAMP and its hazard analysis method STPA has attracted attention recently. The basis of this theory is the Control Structure diagram (CS) that captures the entire system. The authors use CS as a structural diagram that captures the requirements of the whole system, including humans and society, and clarifies the relationship by the software lifecycle process standard and the system-life cycle process standard. Therefore, it is proposed to explain the specifications hierarchically for each software, system, service, and stakeholder, and to standardize it for the social layer. In order to model a complex system hierarchically, we propose to model the control structure diagram of STAMP into five layers according to the life cycle of software and system requirements. In addition, we present a case study of safety and security analysis based on the above-mentioned model, considering the case of level 3 autonomous driving."
The First Twenty-Five Years of Industrial Use of the B-Method,Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-030-58298-2_8,Michael ButlerPhilipp KörnerSebastian KringsThierry LecomteMichael LeuschelLuis-Fernando MejiaLaurent Voisin,2020,http://link.springer.com/chapter/10.1007/978-3-030-58298-2_8,Chapter,,10,"The B-Method has an interesting history, where language and tools have evolved over the years. This not only led to considerable research and progress in the area of formal methods, but also to numerous industrial applications, in particular in the railway domain. We present a survey of the industrial usage of the B-Method since the first toolset in 1993 and the inauguration of the driverless metro line 14 in Paris in 1999. We discuss the various areas of applications, from software development to data validation and on to systems modelling. The evolution of the tooling landscape is also analysed, and we present an assessment of the current situation, lessons learned and possible new directions."
Families of Monotonic Trees: Combinatorial Enumeration and Asymptotics,Computer Science – Theory and Applications,,,,10.1007/978-3-030-50026-9_11,Olivier BodiniAntoine GenitriniMehdi NaimaAlexandros Singh,2020,http://link.springer.com/chapter/10.1007/978-3-030-50026-9_11,Chapter,"Analytic Combinatorics, Asymptotic enumeration, Borel transform, Evolution process, Increasing trees, Monotonic trees",10,"There exists a wealth of literature concerning families of increasing trees, particularly suitable for representing the evolution of either data structures in computer science, or probabilistic urns in mathematics, but are also adapted to model evolutionary trees in biology. The classical notion of increasing trees corresponds to labeled trees such that, along paths from the root to any leaf, node labels are strictly increasing; in addition nodes have distinct labels. In this paper we introduce new families of increasingly labeled trees relaxing the constraint of unicity of each label. Such models are especially useful to characterize processes evolving in discrete time whose nodes evolve simultaneously. In particular, we obtain growth processes for biology much more adequate than the previous increasing models. The families of monotonic trees we introduce are much more delicate to deal with, since they are not decomposable in the sense of Analytic Combinatorics. New tools are required to study the quantitative statistics of such families. In this paper, we first present a way to combinatorially specify such families through evolution processes, then, we study the tree enumerations."
A Study of Mechanism Design for C2C Service Based on Multi-agent Simulation,Knowledge-Based Software Engineering: 2020,,,,10.1007/978-3-030-53949-8_6,Takuya IzumisawaYuki KatsumataAkira Yamada,2020,http://link.springer.com/chapter/10.1007/978-3-030-53949-8_6,Chapter,"Evolutionary game, Mechanism design, Multi-agent simulation",10,"In Consumer-to-Consumer (C2C) services where individuals provide their own idle assets to other individuals, the number of trouble incidents between individuals is increasing. These incidents arise because individuals act inappropriately (defection strategy) when providing or using assets against the will of the counterpart. One goal for C2C services is to activate the market by increasing the number of individuals who take appropriate action (cooperation strategy). Toward this end, we propose a mechanism that achieves the desired cooperation rate. The number of individuals who follow the cooperation strategy will increase as incentives are increased, and there is a trade-off between the achievable cooperation rate and incentives. The purpose of this study is to clarify the conditions that achieve the desired cooperation rate with fewer incentives. Simulation results show that the proposed mechanism increases the number of individuals who follow the cooperation strategy and that incentives contribute to achieving the desired cooperation rate rather than penalties."
Quantitative Analysis of Goal Oriented Requirements Models,Knowledge-Based Software Engineering: 2020,,,,10.1007/978-3-030-53949-8_1,Haruhiko Kaiya,2020,http://link.springer.com/chapter/10.1007/978-3-030-53949-8_1,Chapter,"Goal Oriented Requirements Analysis, Metrics, Quality requirements",10,"An information system is developed and embedded into a dairy activity to satisfy requirements of people in the activity. Because the system is expected to improve the activity, we have to predict the extent of such improvement. Goal oriented requirements models are useful to represent the relationships among systems and people in a business or life activity. We have been proposed extended goal oriented requirements models to predict how well the system improves the activity of the people. In this talk, we briefly introduce typical goal oriented requirements models, and their extensions suitable for quantitative analysis. Finally, we show several issues of future challenges."
Revisiting Principles and Challenges in Natural Language Programming,Knowledge-Based Software Engineering: 2020,,,,10.1007/978-3-030-53949-8_2,Juliano Efson SalesAndré FreitasDouglas OliveiraAdamantios KoumpisSiegfried Handschuh,2020,http://link.springer.com/chapter/10.1007/978-3-030-53949-8_2,Chapter,"Natural language interfaces, Natural language programming, Very high-level languages",10,"Automation has faced the risk of reducing its pace due to the shortage of information technology professionals. Although part of the programming demand can be addressed by simple compositions of high-level functions and data flows, non-technical professionals are still unable to build their own software given the intrinsic complexity of coding. Among other types of end-user development, natural language programming has emerged as a strong candidate to fill this gap by developing methods and tools to allow end users to program. The paper revisits some principles of evaluation of traditional programming languages and analyses the new challenges to deliver an effective end-user development platform based on aspects of natural language processing, human-computer interaction, software engineering, and programming education. We advocate that an effective end-user platform is essentially hybrid, combining features from different branches of the end-user development research, having, however, a search mechanism with semantic capabilities at its centre ."
Experimental Evaluation of Traceability Checking Tool for Goal Dependency Modeling,Knowledge-Based Software Engineering: 2020,,,,10.1007/978-3-030-53949-8_7,Haruhiko KaiyaWataru FujitaRyotaro YamadaAtsuo HazeyamaShinpei OgataTakao OkuboNobukazu YoshiokaHironori Washizaki,2020,http://link.springer.com/chapter/10.1007/978-3-030-53949-8_7,Chapter,"Experimental evaluation, Goal oriented requirements analysis, Istar, Modeling tool, Traceability",10,"In a complex socio-technical system, a human’s goal is delegated to many actors such as human and machines. Because the delegated goal can be decomposed into several sub-goals by each actor, goals are delegated recursively until an actor provides the means to achieve each sub-goal. We have already proposed a notation and a method called GDMA to represent and analyze the issues above. Because GDMA can be represented in a class diagram, software engineers do not have to use specific tools of GDMA models. To confirm whether a goal is properly achieved by suitable means, we have to trace such delegation and decomposition relationships. However, it is not easy to confirm it in a real-world system because of the system’s complexity. In this paper, we present a tool to check such traceability. The tool is implemented as a plugin of an existing UML modeling editor, and goal dependencies and decompositions are depicted using color. We also evaluate the tool through a comparative experiment. As a result, the tool enables an analyst to check the traceability without omission although it does not improve efficiency of the traceability checking task."
State Identification for Labeled Transition Systems with Inputs and Outputs,Formal Aspects of Component Software,,,,10.1007/978-3-030-40914-2_10,Petra van den BosFrits Vaandrager,2020,http://link.springer.com/chapter/10.1007/978-3-030-40914-2_10,Chapter,,10,"For Finite State Machines (FSMs) a rich testing theory has been developed to discover aspects of their behavior and ensure their correct functioning. Although this theory is widely used, e.g., to check conformance of protocol implementations, its applicability is limited by restrictions of the FSM framework: the fact that inputs and outputs alternate in an FSM, and outputs are fully determined by the previous input and state. Labeled Transition Systems with inputs and outputs (LTSs), as studied in ioco testing theory, provide a richer framework for testing component oriented systems, but lack the algorithms for test generation from FSM theory. In this article, we propose an algorithm for the fundamental problem of state identification during testing of LTSs. Our algorithm is a direct generalization of the well-known algorithm for computing adaptive distinguishing sequences for FSMs proposed by Lee & Yannakakis. Our algorithm has to deal with so-called compatible states, states that cannot be distinguished in case of an adversarial system-under-test. Analogous to the result of Lee & Yannakakis, we prove that if an (adaptive) test exists that distinguishes all pairs of incompatible states of an LTS, our algorithm will find one. In practice, such adaptive tests typically do not exist. However, in experiments with an implementation of our algorithm on an industrial benchmark, we find that tests produced by our algorithm still distinguish more than 99% of the incompatible state pairs."
How the Apriori Algorithm Can Help to Find Semantic Duplicates in Ontology,Knowledge-Based Software Engineering: 2020,,,,10.1007/978-3-030-53949-8_16,Irina AstrovaArne KoschelSu Ling Lee,2020,http://link.springer.com/chapter/10.1007/978-3-030-53949-8_16,Chapter,"Apriori algorithm, Market basket analysis, Ontolgy, OntoLife, Semantic heterogeneity, Similar attributes",10,"Ontology-based data integration attempts to overcome the semantic heterogeneity problem in data integration. Semantic heterogeneity refers to an ambiguous interpretation of terms that describes the meaning of data in heterogeneous resources. However, the presence of semantic duplicates such as similar attributes in the integrated ontologies can lead to incomplete query results. This paper proposes to use the Apriori algorithm from market basket analysis to find similar attributes in an ontology."
Learning-Based Testing of an Industrial Measurement Device,NASA Formal Methods,,,,10.1007/978-3-030-20652-9_1,Bernhard K. AichernigChristian BurghardRobert Korošec,2019,http://link.springer.com/chapter/10.1007/978-3-030-20652-9_1,Chapter,"Active learning, Automata learning, Automotive case study, Model inference, Mutation analysis, Testbed, Testing",10,"Active automata learning algorithms have gained increasing importance in the field of model-based system verification. For some classes of systems - especially deterministic systems, like Mealy machines, a variety of learning algorithm implementations is readily available. In this paper, we apply this technique to a measurement device from the automotive industry in order to systematically test its behaviour. However, our system under learning shows sparse non-deterministic behaviour, preventing the direct application of the available learning tools. We propose an implementation of the active automata learning framework which masks this non-determinism. We repeat a previous model-based testing experiment with faulty devices and show that we can detect all injected faults. Most importantly, our technique was also able to find unknown bugs."
A Model-Driven Approach for Simplified Cluster Based Test Suite Optimization of Industrial Systems – An Introduction to UMLTSO,Computer Information Systems and Industrial Management,,,,10.1007/978-3-030-28957-7_14,Ayesha KiranFarooque AzamMuhammad Waseem AnwarIqra QasimHanny Tufail,2019,http://link.springer.com/chapter/10.1007/978-3-030-28957-7_14,Chapter,"Clustering, Model-based optimization, Optimization, Test case, Testing",10,"Software testing is a significant but costly activity of software development life cycle, because it accounts for more than fifty-two percent (>52%) of entire development cost. Testing requires the execution of all possible test cases in order to find defects in software. However, the selection and implementation of right test cases is always challenging for large scale industrial systems. In this context, clustering is a renowned approach for achieving optimization. However, it is difficult to optimize test cases through clustering due to its implementation complexity and time-consuming nature. Hence, a model based simple mechanism is strongly needed for optimization of generated test cases while preserving the coverage criterion. In this paper, a Unified Modeling Language profile for Test Suite Optimization (UMLTSO) is presented that models the optimization process for test case generated from java source code. Particularly, UMLTSO is capable of modeling test case generation, coverage criteria application and optimization using clustering approaches. This offers the rationale for converting the UMLTSO source code into target test cases for optimization based on different coverage criteria e.g. code coverage. The applicability of UMLTSO is validated through two industrial case studies."
"Challenges for Automated, Model-Based Test Scenario Generation",Information and Software Technologies,,,,10.1007/978-3-030-30275-7_15,Alexander KolchinStepan PotiyenkoThomas Weigert,2019,http://link.springer.com/chapter/10.1007/978-3-030-30275-7_15,Chapter,"Data flow, Model-based testing, Tests quality",10,"This paper focuses on challenges to automatic test suite generation from formal models of software systems. Popular tools and methods and their limitations are discussed. Data cohesion, meaningfulness of derived behavior, usefulness for debugging, coverage evenness, coverage overlap, fault detection ability, and size of the generated test suite are considered as quality indicators for generated tests. A novel composite weight-based heuristic method for improving the quality of automatically generated test scenarios is proposed."
Visualization and Abstractions for Execution Paths in Model-Based Software Testing,Integrated Formal Methods,,,,10.1007/978-3-030-34968-4_26,Rui WangCyrille ArthoLars Michael KristensenVolker Stolz,2019,http://link.springer.com/chapter/10.1007/978-3-030-34968-4_26,Chapter,,10,"This paper presents a technique to measure and visualize execution-path coverage of test cases in the context of model-based software systems testing. Our technique provides visual feedback of the tests, their coverage, and their diversity. We provide two types of visualizations for path coverage based on so-called state-based graphs and path-based graphs. Our approach is implemented by extending the Modbat tool for model-based testing and experimentally evaluated on a collection of examples, including the ZooKeeper distributed coordination service. Our experimental results show that the state-based visualization is good at relating the tests to the model structure, while the path-based visualization shows distinct paths well, in particular linearly independent paths. Furthermore, our graph abstractions retain the characteristics of distinct execution paths, while removing some of the complexity of the graph."
Automatic Generation of Test Oracles from Component Based Software Architectures,Testing Software and Systems,,,,10.1007/978-3-030-31280-0_16,Maxime SamsonThomas Vergnaud,2019,http://link.springer.com/chapter/10.1007/978-3-030-31280-0_16,Chapter,"Component Based Software Engineering, Model based testing, UCM",10,"In a software development process, the integration and verification of the different parts of the application under development often require a lot of effort. Component Based Software Engineering (CBSE) approaches help cut software integration costs by enabling the automatic generation of data types, method signatures and middleware configuration from a model of the application structure. Model Based Testing (MBT) techniques help cut software verification costs by enabling the automatic generation of test oracles from a model of the expected application behaviour. Models for CBSE and MBT are usually separate. This may result in discrepancies between them, especially when the application architecture is updated, which always happens. In this paper, we describe how to rely on a single CBSE model to produce both code generation and oracles for some tests, thus ensuring consistency between them. Our work is based on existing OMG standards, mainly UCM and UML."
VERCORS: Hardware and Software Complex for Intelligent Round-Trip Formalized Verification of Dependable Cyber-Physical Systems in a Digital Twin Environment (Position Paper),Software Technology: Methods and Tools,,,,10.1007/978-3-030-29852-4_30,Alexandr NaumchevAndrey SadovykhVladimir Ivanov,2019,http://link.springer.com/chapter/10.1007/978-3-030-29852-4_30,Chapter,"Co-simulation, Cyber-physical systems (CPS), Digital twin, Formal specification, Language processing, Model-based testing, Multi-modelling, Natural, Traceability, Verification",10,"Formal specification, model checking and model-based testing are recommended techniques for engineering of mission-critical systems. In the meantime, those techniques struggle to obtain wide adoption due to inherent learning barrier, i.e. it is considered difficult to use those methods. There is also a common difficulty in translating the specifications in natural language, a common practice nowadays, to formal specifications. In this position paper we discuss the concept of an end-to-end methodology that helps identify specifications from various sources, automatically create formal specifications and apply them to verification of cyber-physical systems. Thus, we intent to address the challenges of creation of formal specifications in an efficient automated and tool-supported manner. The novelty of the approach is analyzed through a survey of state of the art. It is currently planned to implement this concept and evaluate it with industrial case studies."
Formal Modelling and Verification of an Interlocking Using mCRL2,Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-030-27008-7_2,Mark BouwmanBob JanssenBas Luttik,2019,http://link.springer.com/chapter/10.1007/978-3-030-27008-7_2,Chapter,,10,"This paper presents an application of the formal modelling and model checking toolkit mCRL2 and the model-based testing tool JTorX in the signalling domain. The mCRL2 toolkit is used to formally model the behaviour of a system at the core of signalling solutions: the interlocking. The model of the interlocking is validated through model-based testing. We use the mCRL2 toolkit to verify high-level safety properties of the interlocking software. The suitability of mCRL2, JTorX and our modelling approach is evaluated and suggestions are given for future research to improve the applicability of mCRL2 in the signalling domain."
A Search-Based Approach to Generate MC/DC Test Data for OCL Constraints,Search-Based Software Engineering,,,,10.1007/978-3-030-27455-9_8,Hassan SartajMuhammad Zohaib IqbalAtif Aftab Ahmed JilaniMuhammad Uzair Khan,2019,http://link.springer.com/chapter/10.1007/978-3-030-27455-9_8,Chapter,"MC/DC, Model-based testing, OCL, SBSE, Test data generation",10,"Automated generation of test data is an important and challenging activity in Model-based Testing. This typically requires solving of constraints, written in Object Constraint Language (OCL), specified on models in order to obtain solutions that can be used as test data. Test data generation techniques in the literature discuss various coverage criteria for test generation to achieve a sufficient level of coverage. One of the recommended criteria is modified condition/decision coverage (MC/DC) that is a requirement of different safety standards, such as DO-178C. In this paper, we propose a search-based strategy that utilizes case-based reasoning (CBR) to reuse the already generated test data and generate new test data that provides MC/DC coverage of OCL constraints. To evaluate the performance of the proposed approach in solving MC/DC constraints, we perform an empirical evaluation using AVM without CBR, AVM with CBR, and use Random Search (RS) as a baseline for comparison. We use 84 OCL constraints from four case studies belonging to different domains with varying size and complexity. The experimental results show that our proposed strategy of reusing already generated test data is better as compared to generating test data without using previous test data."
"A Test Specification Language for Information Systems Based on Data Entities, Use Cases and State Machines",Model-Driven Engineering and Software Development,,,,10.1007/978-3-030-11030-7_20,Alberto Rodrigues da SilvaAna C. R. PaivaValter E. R. da Silva,2019,http://link.springer.com/chapter/10.1007/978-3-030-11030-7_20,Chapter,"Model based Testing (MBT), Test case generation, Test case specification, Test Specification Language (TSL)",10,"Testing is one of the most important activities to ensure the quality of a software system. This paper proposes and discusses the TSL (Test Specification Language) that adopts a model-based testing approach for both human-readable and computer-executable specifications of test cases. TSL is strongly inspired on the grammar, nomenclature and writing style as defined by the RSLingo RSL, which is a rigorous requirements specification language. Both RSL and TSL are controlled natural languages that share common concepts such as data entities, use cases and state machines. However, by applying black-box functional testing design techniques, TSL includes and supports four complementary testing strategies, namely: domain analysis testing; use case tests; state machine testing; and acceptance criteria. This paper focuses on the first three testing strategies of TSL. Finally, a simple but effective case study illustrates the overall approach and supports the discussion."
Component-aware Input-Output Conformance,"Formal Techniques for Distributed Objects, Components, and Systems",,,,10.1007/978-3-030-21759-4_7,Alexander Graf-BrillHolger Hermanns,2019,http://link.springer.com/chapter/10.1007/978-3-030-21759-4_7,Chapter,"Compositionality, Input-output conformance, Model-based testing",10,"Black-box conformance testing based on a compositional model of the intended behaviour is a very attractive approach to validate the correctness of an implementation. In this context, input-output conformance is a scientifically well-established formalisation of the testing process. This paper discusses peculiar problems arising in situations where the implementation is a monolithic black box, for instance for reasons of intellectual property restrictions, while the specification is compositional. In essence, tests need to be enabled to observe progress in individual specification-level components. For that, we will reconsider input-output conformance so that it can faithfully deal with such situations. Refined notions of quiescence play a central role in a proper treatment of the problem. We focus on the scenario of parallel components with fully asynchronous communication covering very many notorious practical examples. We finally illustrate the practical implications of component-aware conformance testing in the context of a prominent example, namely networked embedded software."
Property-Based Test Case Generators for Free,Tests and Proofs,,,,10.1007/978-3-030-31157-5_12,Emanuele De AngelisFabio FioravantiAdrián PalaciosAlberto PettorossiMaurizio Proietti,2019,http://link.springer.com/chapter/10.1007/978-3-030-31157-5_12,Chapter,,10,"Property-Based Testing requires the programmer to write suitable generators , i.e., programs that generate (possibly in a random way) input values for which the program under test should be run. However, the process of writing generators is quite a costly, error-prone activity. In the context of Property-Based Testing of Erlang programs, we propose an approach to relieve the programmer from the task of writing generators. Our approach allows the automatic, efficient generation of input test values that satisfy a given specification. In particular, we have considered the case when the input values are data structures satisfying complex constraints. That generation is performed via the symbolic execution of the specification using constraint logic programming."
Testing Real-Time Systems Using Determinization Techniques for Automata over Timed Domains,Theoretical Aspects of Computing – ICTAC 2019,,,,10.1007/978-3-030-32505-3_8,Moez Krichen,2019,http://link.springer.com/chapter/10.1007/978-3-030-32505-3_8,Chapter,"Automaton over timed domains, Conformance relation, Correctness, Determinization, Model-Based Testing, Real-time systems",10,"In this work, we are interested in Model-Based Testing for Real-Time Systems. The proposed approach is based on the use of the model of Automata over Timed Domains (ATD) which corresponds to an extension of the classical Timed Automaton Model. First, we explain the main advantages of adopting this new formalism. Then, we propose a testing framework based on ATD and which is an extension of our initial framework presented in previous contributions. We extend the notion of correctness requirements (soundness and completeness) along with the notion of timed input-output conformance relation (tioco) used to compare between implementations and specifications. Moreover we propose a determinization technique used to generate test cases. Finally, several possible extensions of the present work are proposed."
Directed Multi-target Search Based Unit Tests Generation,Information and Software Technologies,,,,10.1007/978-3-030-30275-7_8,Greta RudžionienėŠarūnas PackevičiusEduardas Bareiša,2019,http://link.springer.com/chapter/10.1007/978-3-030-30275-7_8,Chapter,"Search based software testing, Unit testing, Unit tests generation",10,"Software testing costs are reduced by employing test automation. One of the automation activities is tests generation. The goal of tests generation is to generate tests with large code coverage with the efficient faults detection ability. Search-based tests generation methods are analysed and their experimental comparison is provided in this paper. The novel search-based unit tests generation approach directed by multiple search targets to generate unit tests is presented. Introduced method allows generating test data and oracles using static code analysis and code instrumentation. Oracles are created as assertions based on system state after tests execution phase, thus making tests suitable for regression testing. The method was implemented as an experimental tool. It was evaluated and compared against other search-based tests generation tools/methods by using code coverage and mutation score metrics. The experimental evaluation was performed on 124 classes from 3 open source libraries."
Generating Test Data for Blackbox Testing from UML-Based Web Engineering Content and Presentation Models,Industrial Networks and Intelligent Systems,,,,10.1007/978-3-030-30149-1_17,Quyet-Thang HuynhDinh-Dien TranDuc-Man NguyenNhu-Hang HaThi-Mai-Anh BuiPhi-Le Nguyen,2019,http://link.springer.com/chapter/10.1007/978-3-030-30149-1_17,Chapter,"Model-based testing, Test case generation, UML-based Web Engineering, Web application testing",10,"Software testing is a process that produces and consumes huge amounts of data. Thus, the test data is usually either gathered manually by the testers or randomly generated by tools. The manual method consumes lot of time and highly depends on the testers’ experience while the random approach faces the problem of redundant test data caused by identical use cases. By leveraging the concept of Model-based testing, this paper provides a novel method of testing to save the cost of manual testing and to increase the reliability of the testing processes. In Model-based testing, test cases and test data can be derived from different models. In this paper, we present a technique to generate test data from UML-based Web Engineering (UWE) presentation model for web application testing by using formal specification and Z3 SMT solver. We also build a model-based testing Eclipse Plug-in tool called TESTGER-UWE that generates test data based on the model of UWE for the web application. We evaluate the proposed methods by applying them to generate test data for an Address Book project of UWE. Experimental results show that our proposed methods can reduce the time significantly when generating test data for automation test tools such as Selenium, Katalon, Unit test, etc."
Multi-objective Search for Effective Testing of Cyber-Physical Systems,Software Engineering and Formal Methods,,,,10.1007/978-3-030-30446-1_10,Hugo AraujoGustavo CarvalhoMohammad Reza MousaviAugusto Sampaio,2019,http://link.springer.com/chapter/10.1007/978-3-030-30446-1_10,Chapter,"Cyber-Physical Systems, Input selection, Search based",10,"We propose a multi-objective strategy for finding effective inputs for fault detection in Cyber Physical Systems (CPSs). The main goal is to provide input signals for a system in such a way that they maximise the distance between the system’s output and an ideal target, thus leading the system towards a fault; this is based on Genetic Algorithm and Simulated Annealing heuristics. Additionally, we take into consideration the discrete locations (of hybrid system models) and a notion of input diversity to increase coverage. We implement our strategy and present an empirical analysis to estimate its effectiveness."
A Methodology for Generating Tests for Evaluating User-Centric Performance of Mobile Streaming Applications,Model-Driven Engineering and Software Development,,,,10.1007/978-3-030-11030-7_18,Mustafa Al-tekreetiKshirasagar NaikAtef AbdrabouMarzia ZamanPradeep Srivastava,2019,http://link.springer.com/chapter/10.1007/978-3-030-11030-7_18,Chapter,"Coverage criteria, Performance, Software, Testing",10,"Compared to other platforms, mobile apps’ quality assurance is more challenging, since their functionality is affected by the surrounding environment. In literature, a considerable volume of research has been devoted to develop frameworks that facilitate conducting performance analysis during the development life cycle. However, less attention has been given to test generation and test selection criteria for performance evaluation. In this work, a model based test generation methodology is proposed to evaluate the impact of the interaction of the environment, the wireless network, and the app configurations on the performance of a mobile streaming app and thereby on the experience of the end user. The methodology steps, inputs, and outputs are explained using an app example. The methodology assumes that the app has a network access through a WiFi access point. We evaluate the effectiveness of the methodology by comparing the time cost to design a test suite with random testing. The obtained results are very promising."
Does Diversity Improve the Test Suite Generation for Mobile Applications?,Search-Based Software Engineering,,,,10.1007/978-3-030-27455-9_5,Thomas VogelChinh TranLars Grunske,2019,http://link.springer.com/chapter/10.1007/978-3-030-27455-9_5,Chapter,"Diversity, Fitness landscape analysis, Test generation",10,"In search-based software engineering we often use popular heuristics with default configurations, which typically lead to suboptimal results, or we perform experiments to identify configurations on a trial-and-error basis, which may lead to better results for a specific problem. To obtain better results while avoiding trial-and-error experiments, a fitness landscape analysis is helpful in understanding the search problem, and making an informed decision about the heuristics. In this paper, we investigate the search problem of test suite generation for mobile applications (apps) using Sapienz whose heuristic is a default NSGA-II. We analyze the fitness landscape of Sapienz with respect to genotypic diversity and use the gained insights to adapt the heuristic of Sapienz . These adaptations result in Sapienz $$^{div}$$ that aims for preserving the diversity of test suites during the search. To evaluate Sapienz $$^{div}$$ , we perform a head-to-head comparison with Sapienz on 76 open-source apps."
Research Review on Web Service Composition Testing,Structured Object-Oriented Formal Language and Method,,,,10.1007/978-3-030-13651-2_3,Zhoujie DuHuaikou Miao,2019,http://link.springer.com/chapter/10.1007/978-3-030-13651-2_3,Chapter,"Testing methods, Testing techniques, Web service, Web service combination",10,"Web services composition is designed to achieve a more powerful and large-grained services with organic synthesis of different Web services. In order to guarantee the quality of the Web services composition, comprehensive and adequate testing of the Web services composition is required. However, the dynamic and distributed characteristics of Web services combination make its testing technology and method have big difference with the traditional software testing and bring a large of challenges. In this paper, we summarize and analyze the definition, architecture, testing methods and testing techniques of Web service composition. In addition, we also analyze and prospect the progress of Web services combination testing."
Conformance Testing of Schedulers for DSL-based Model Checking,Model Checking Software,,,,10.1007/978-3-030-30923-7_12,Nhat-Hoa TranToshiaki Aoki,2019,http://link.springer.com/chapter/10.1007/978-3-030-30923-7_12,Chapter,"Conformance testing, Domain-specific language, Model checking, Model-based testing, Scheduling policy, Test generation",10,"When we verify concurrent systems executed under a real operating system (OS), we should take the scheduling policy of the OS into account. However, with a specific implementation of an OS, the description of the scheduling policy does not exist or not clear to describe the behaviors of the real scheduler. In this case, we need to make assumptions in the specification by ourselves. Therefore, checking the correctness of the specification of the scheduling policy is important because it affects the verification result. In this paper, we propose a method to validate the correspondence between the specification of the scheduling policy and the implementation of the scheduler using testing techniques. The overall approach can be regarded as conformance testing. As a result, we can find the inconsistency between the implementation and the specification. That indicates the incorrectness of the specification. To deal with testing, we propose a domain-specific language (DSL) to specify the test generation with the scheduling policy. A search algorithm is introduced to determine the executions of the processes. The tests are generated automatically and exhaustively by applying model-based testing (MBT) techniques. Based on this method, we develop a tool for generating the tests. We demonstrate our method with Linux FIFO scheduling policy. The experiments show that we can facilitate the test generation and check the specification of the scheduling policy easily."
Mutation Testing with Hyperproperties,Software Engineering and Formal Methods,,,,10.1007/978-3-030-30446-1_11,Andreas FellnerMitra Tabaei BefroueiGeorg Weissenbacher,2019,http://link.springer.com/chapter/10.1007/978-3-030-30446-1_11,Chapter,,10,"We present a new method for model-based mutation-driven test case generation. Mutants are generated by making small syntactical modifications to the model or source code of the system under test. A test case kills a mutant if the behavior of the mutant deviates from the original system when running the test. In this work, we use hyperproperties—which allow to express relations between multiple executions—to formalize different notions of killing for both deterministic as well as non-deterministic models. The resulting hyperproperties are universal in the sense that they apply to arbitrary reactive models and mutants. Moreover, an off-the-shelf model checking tool for hyperproperties can be used to generate test cases. We evaluate our approach on a number of models expressed in two different modeling languages by generating tests using a state-of-the-art mutation testing tool."
Mutation-Based Web Test Case Generation,Quality of Information and Communications Technology,,,,10.1007/978-3-030-29238-6_25,Sérgio AlmeidaAna C. R. PaivaAndré Restivo,2019,http://link.springer.com/chapter/10.1007/978-3-030-29238-6_25,Chapter,"Mutation testing, Software testing, Test case generation, Web testing",10,"Regression testing is of paramount importance to ensure that the quality of software does not suffer when code changes are implemented. However, having a large set of tests is mostly done by hand and is time-consuming. Regression tests are written to test functionality that is already implemented and thus are a prime target for automatic test generation. Mutation testing is a technique that evaluates the quality of tests by applying simple changes to source code and checking if any test detects those changes. This paper presents an approach focused on GUI Testing that takes the idea behind mutation testing and applies it, not to the source code, but the actual tests. Generated tests are then analyzed, and those that generate different outcomes are chosen. The set of initial test cases is obtained from the interactions of the actual users of the service under analysis. In the end, an evaluation of the approach is presented."
A Lightweight Multilevel Markup Language for Connecting Software Requirements and Simulations,Requirements Engineering: Foundation for Software Quality,,,,10.1007/978-3-030-15538-4_11,Florian PudlitzAndreas VogelsangFlorian Brokhausen,2019,http://link.springer.com/chapter/10.1007/978-3-030-15538-4_11,Chapter,"Markup language, Requirements modeling, Simulation, Test evaluation",10,"[ Context ] Simulation is a powerful tool to validate specified requirements especially for complex systems that constantly monitor and react to characteristics of their environment. The simulators for such systems are complex themselves as they simulate multiple actors with multiple interacting functions in a number of different scenarios. To validate requirements in such simulations, the requirements must be related to the simulation runs. [ Problem ] In practice, engineers are reluctant to state their requirements in terms of structured languages or models that would allow for a straightforward relation of requirements to simulation runs. Instead, the requirements are expressed as unstructured natural language text that is hard to assess in a set of complex simulation runs. Therefore, the feedback loop between requirements and simulation is very long or non-existent at all. [ Principal idea ] We aim to close the gap between requirements specifications and simulation by proposing a lightweight markup language for requirements. Our markup language provides a set of annotations on different levels that can be applied to natural language requirements. The annotations are mapped to simulation events. As a result, meaningful information from a set of simulation runs is shown directly in the requirements specification. [ Contribution ] Instead of forcing the engineer to write requirements in a specific way just for the purpose of relating them to a simulator, the markup language allows annotating the already specified requirements up to a level that is interesting for the engineer. We evaluate our approach by analyzing 8 original requirements of an automotive system in a set of 100 simulation runs."
Time to Learn – Learning Timed Automata from Tests,Formal Modeling and Analysis of Timed Systems,,,,10.1007/978-3-030-29662-9_13,Martin TapplerBernhard K. AichernigKim Guldstrand LarsenFlorian Lorber,2019,http://link.springer.com/chapter/10.1007/978-3-030-29662-9_13,Chapter,,10,"Model learning has gained increasing interest in recent years. It derives behavioural models from test data of black-box systems. The main advantage offered by such techniques is that they enable model-based analysis without access to the internals of a system. Applications range from fully automated testing over model checking to system understanding. Current work focuses on learning variations of finite state machines. However, most techniques consider discrete time. In this paper, we present a novel method for learning timed automata, finite state machines extended with real-valued clocks. The learning method generates a model consistent with a set of timed traces collected via testing. This generation is based on genetic programming, a search-based technique for automatic program creation. We evaluate our approach on $$\mathbf {44}$$ timed systems, comprised of four systems from the literature (two industrial and two academic) and $$\mathbf {40}$$ randomly generated examples."
Rationalizing the Need of Architecture-Driven Testing of Interactive Systems,Human-Centered Software Engineering,,,,10.1007/978-3-030-05909-5_10,Alexandre CannyElodie BouzekriCélia MartiniePhilippe Palanque,2019,http://link.springer.com/chapter/10.1007/978-3-030-05909-5_10,Chapter,"Architecture-driven testing, Interactive system testing",10,"Testing interactive systems is known to be a complex task that cannot be exhaustive. Indeed, the infinite number of combination of user input and the complexity of information presentation exceed the practical limits of exhaustive and analytical approach to testing [ 31 ]. Most interactive software testing techniques are produced by applying and tuning techniques from the field of software testing to try to address the specificities of interactive applications. When some elements cannot be taken into account by the software testing technique, they are usually ignored. In this paper we propose to follow an opposite approach, starting from a generic architecture for interactive systems (including both software and hardware elements) for identifying in a systematic way, testing problems and testing needs. This architecture-driven approach makes it possible to identify how software testing knowledge and techniques can support interactive systems testing but also where the interactive systems engineering community should invest in order to test their idiosyncrasies too."
A Modular Hybrid Learning Approach for Black-Box Security Testing of CPS,Applied Cryptography and Network Security,,,,10.1007/978-3-030-21568-2_10,John Henry CastellanosJianying Zhou,2019,http://link.springer.com/chapter/10.1007/978-3-030-21568-2_10,Chapter,"Black-box security testing, Cyber-Physical Systems security, Model-based attack detection",10,"Evaluating the security of Cyber-Physical Systems (CPS) is challenging, mainly because it brings risks that are not acceptable in mission-critical systems like Industrial Control Systems (ICS). Model-based approaches help to address such challenges by keeping the risk associated with testing low. This paper presents a novel modelling framework and methodology that can easily be adapted to different CPS. Based on our experiments, HybLearner takes less than 140 s to build a model from historical data of a real-world water treatment testbed, and HybTester can simulate accurately about 60 min ahead of normal behaviour of the system including transitions of control strategies. We also introduce a security metrics ( time-to-critical-state ) that gives a measurement of how fast the system might reach a critical state, which is one of the use cases of the proposed framework to build a model-based attack detection mechanism."
A Fault-Driven Combinatorial Process for Model Evolution in XSS Vulnerability Detection,Advances and Trends in Artificial Intelligence. From Theory to Practice,,,,10.1007/978-3-030-22999-3_19,Bernhard GarnMarco RadavelliAngelo GargantiniManuel LeithnerDimitris E. Simos,2019,http://link.springer.com/chapter/10.1007/978-3-030-22999-3_19,Chapter,"Combinatorial testing, Model evolution, Security testing, XSS vulnerability",10,"We consider the case where a knowledge base consists of interactions among parameter values in an input parameter model for web application security testing. The input model gives rise to attack strings to be used for exploiting XSS vulnerabilities, a critical threat towards the security of web applications. Testing results are then annotated with a vulnerability triggering or non-triggering classification, and such security knowledge findings are added back to the knowledge base, making the resulting attack capabilities superior for newly requested input models. We present our approach as an iterative process that evolves an input model for security testing. Empirical evaluation on six real-world web application shows that the process effectively evolves a knowledge base for XSS vulnerability detection, achieving on average 78.8% accuracy."
Survey on Formal Methods and Tools in Railways: The ASTRail Approach,"Reliability, Safety, and Security of Railway Systems. Modelling, Analysis, Verification, and Certification",,,,10.1007/978-3-030-18744-6_15,Alessio FerrariMaurice H. ter BeekFranco MazzantiDavide BasileAlessandro FantechiStefania GnesiAndrea PiattinoDaniele Trentini,2019,http://link.springer.com/chapter/10.1007/978-3-030-18744-6_15,Chapter,"Formal methods, Model-based development, Railways",10,"Formal methods and tools have been widely applied to the development of railway systems during the last decades. However, no universally accepted formal framework has emerged, and railway companies wishing to introduce formal methods have little guidance for the selection of the most appropriate methods and tools to adopt. A work package (WP) of the European project ASTRail, funded under the Shift2Rail initiative, addresses this problem, by performing a survey that considers scientific literature, international projects, and practitioners’ perspectives to identify a collection of formal methods and tools to be applied in railways. This paper summarises the current results of this WP. We surveyed 114 scientific publications, 44 practitioners, and 8 projects to come to a shortlist of 14 methods considered suitable for system modelling and verification in railways. The methods and tools were reviewed according to a set of functional, language-related, and quality features. The current paper extends the body of knowledge with a set of publicly available documents that can be leveraged by companies for guidance on formal methods selection in railway system development."
SoTesTeR: Software Testing Techniques’ Recommender System Using a Collaborative Approach,Information Management and Big Data,,,,10.1007/978-3-030-11680-4_28,Ronald IbarraGlen Rodriguez,2019,http://link.springer.com/chapter/10.1007/978-3-030-11680-4_28,Chapter,"Collaborative repository, Content-based reasoning, k-Nearest Neighbors, Recommender system, Software testing techniques",10,"Software testing is a key factor on any software project; testing costs are significant in relation to development costs. Therefore, it is essential to select the most suitable testing techniques for a given project to find defects at the lower cost possible in the different testing levels. However, in several projects, testing practitioners do not have a deep understanding of the full array of techniques available, and they adopt the same techniques that were used in prior projects or any available technique without taking into consideration the attributes of each testing technique. Currently, there are researches oriented to support selection of software testing techniques; nevertheless, they are based on static catalogues, whose adaptation to any niche software application may be slow and expensive. In this work, we introduce a content-based recommender system that offer a ranking of software testing techniques based on a target project characterization and evaluation of testing techniques in similar projects. The repository of projects and techniques was completed through the collaborative effort of a community of practitioners. It has been found that the difference between recommendations of SoTesTeR and recommendations of a human expert are similar to the difference between recommendations of two different human experts."
Empowering Continuous Delivery in Software Development: The DevOps Strategy,Software Technologies,,,,10.1007/978-3-030-29157-0_11,Clauirton SiebraRosberg LacerdaItalo CerqueiraJonysberg P. QuintinoFabiana FlorentinFabio B. Q. da SilvaAndre L. M. Santos,2019,http://link.springer.com/chapter/10.1007/978-3-030-29157-0_11,Chapter,"Continuous delivery, DevOps, Software deployment",10,"Continuous Delivery refers to a software development practice where members of a team frequently integrate their work, so that the process of delivery can be easily conducted. However, this continuous integration and delivery requires a reliable collaboration between development and IT operation teams. The DevOps practices support this collaboration since they enable that the operation staff making use of the same infrastructure as developers for their systems work. Our study aims at presenting a practical DevOps implementation and analyzing how the process of software delivery and infrastructure changes was automated. Our approach follows the principles of infrastructure as code, where a configuration platform – PowerShell DSC – was used to automatically define reliable environments for continuous software delivery. In this context, we defined the concept of “stage for dev”, also using the Docker technology, which involves all the elements that enable members of a team to have the same production environment, locally configured in their personal machines and thus empowering the continuous integration and delivery of system releases."
Local Observability and Controllability Enforcement in Distributed Testing,Quality of Information and Communications Technology,,,,10.1007/978-3-030-29238-6_24,Bruno LimaJoão Pascoal FariaRobert Hierons,2019,http://link.springer.com/chapter/10.1007/978-3-030-29238-6_24,Chapter,"Controllability, Distributed systems, Integration testing, Model-based testing, Observability, UML",10,"To ensure interoperability and the correct end-to-end behavior of heterogenous distributed systems, it is important to conduct integration tests that verify the interactions with the environment and between the system components in key scenarios. The automation of such integration tests requires that test components are also distributed, with local testers deployed close to the system components, coordinated by a central tester. In such a test architecture, it is important to maximize the autonomy of the local testers to minimize the communication overhead and maximize the fault detection capability. A test scenario is called locally observable and locally controllable, if conformance errors can be detected locally and test inputs can be decided locally, respectively, by the local testers, without the need for exchanging coordination messages between the test components during test execution (i.e., without any communication overhead). For test scenarios specified by means of UML sequence diagrams that don’t exhibit those properties, we present in this paper an approach with tool support to automatically find coordination messages that, added to the given scenario, make it locally controllable and locally observable."
Automatic Test Data Generation for a Given Set of Applications Using Recurrent Neural Networks,Software Technologies,,,,10.1007/978-3-030-29157-0_14,Ciprian PaduraruMarius-Constantin MelemciucMiruna Paduraru,2019,http://link.springer.com/chapter/10.1007/978-3-030-29157-0_14,Chapter,"Fuzz testing, LSTM Tensorflow, Pipeline, Recurrent neural networks, Taint analysis",10,"To address the problem of automatic software testing against vulnerabilities, our work focuses on creating a tool capable in assisting users to generate automatic test sets for multiple programs under test at the same time. Starting with an initial set of inputs in a corpus folder, the tool works by clustering the inputs depending on their application target type, then produces a generative model for each of these clusters. The architecture of the models is falling in the recurrent neural network architecture class, and for training and inferencing the models we used the Tensorflow framework. Online-learning is supported by the tool, thus models can get better as long as new inputs for each application cluster are added to the corpus folder. Users can interact with the tool similar to the interface used in expert systems: customize various parameters exposed per cluster, or override various function hooks for learning and inferencing the model, with the purpose of getting finer control over the tool’s backend. As the evaluation section shows, the tool can be useful for creating important sets of new inputs, with good code coverage quality and less resources consumed."
Incorporating Data into EFSM Inference,Software Engineering and Formal Methods,,,,10.1007/978-3-030-30446-1_14,Michael FosterAchim D. BruckerRamsay G. TaylorSiobhán NorthJohn Derrick,2019,http://link.springer.com/chapter/10.1007/978-3-030-30446-1_14,Chapter,"EFSM inference, Model inference, Reverse engineering",10,"Models are an important way of understanding software systems. If they do not already exist, then we need to infer them from system behaviour. Most current approaches infer classical FSM models that do not consider data, thus limiting applicability. EFSMs provide a way to concisely model systems with an internal state but existing inference techniques either do not infer models which allow outputs to be computed from inputs, or rely heavily on comprehensive white-box traces to reveal the internal program state, which are often unavailable. In this paper, we present an approach for inferring EFSM models, including functions that modify the internal state. Our technique uses black-box traces which only contain information visible to an external observer of the system. We implemented our approach as a prototype."
Why Software Testing Fails: Common Pitfalls Observed in a Critical Smart Metering Project,Software Quality: The Complexity and Challenges of Software Engineering and Software Quality in the Cloud,,,,10.1007/978-3-030-05767-1_6,Stefan MohacsiRudolf Ramler,2019,http://link.springer.com/chapter/10.1007/978-3-030-05767-1_6,Chapter,"Common testing pitfalls, Smart metering, Software testing, System testing, Test management, Testing Anti-Patterns",10,"Over the last decades a considerable share of software engineering research has been dedicated to the area of software testing. Still, however, testing often fails or causes major problems in practice. In this paper we present insights and experiences from a large project in the energy sector. The obligatory switch from analog energy meters to smart metering technology poses a big challenge for many energy providers. Apart from technical issues concerning meters and transmission technology, the adaption of the internal business processes together with the development of backend software can turn out to be more difficult than expected. The criticality, size and complexity of the analyzed project are reflected in software and system testing, where the underestimated effort, mistakes, and wrong decisions caused serious difficulties. In our work we describe the observed testing problems and the underlying causes. Subsequently, we compare the identified problems with a catalogue of commonly known testing pitfalls and anti-patterns. The results show that the majority of the observed problems are not new or specific to the studied project. Furthermore, additional candidates for extending the list of common pitfalls are identified. Besides recommendations on how to mitigate the problems in the studied project, we conclude with the general insight that there is a great potential to improve software testing practice by developing measures for early recognition, communication, and avoiding of common mistakes."
TOOLympics 2019: An Overview of Competitions in Formal Methods,Tools and Algorithms for the Construction and Analysis of Systems,,,,10.1007/978-3-030-17502-3_1,Ezio BartocciDirk BeyerPaul E. BlackGrigory FedyukovichHubert GaravelArnd HartmannsMarieke HuismanFabrice KordonJulian NageleMihaela SighireanuBernhard SteffenMartin SudaGeoff SutcliffeTjark WeberAkihisa Yamada,2019,http://link.springer.com/chapter/10.1007/978-3-030-17502-3_1,Chapter,,10,"Evaluation of scientific contributions can be done in many different ways. For the various research communities working on the verification of systems (software, hardware, or the underlying involved mechanisms), it is important to bring together the community and to compare the state of the art, in order to identify progress of and new challenges in the research area. Competitions are a suitable way to do that. The first verification competition was created in 1992 (SAT competition), shortly followed by the CASC competition in 1996. Since the year 2000, the number of dedicated verification competitions is steadily increasing. Many of these events now happen regularly, gathering researchers that would like to understand how well their research prototypes work in practice. Scientific results have to be reproducible, and powerful computers are becoming cheaper and cheaper, thus, these competitions are becoming an important means for advancing research in verification technology. TOOLympics 2019 is an event to celebrate the achievements of the various competitions, and to understand their commonalities and differences. This volume is dedicated to the presentation of the 16 competitions that joined TOOLympics as part of the celebration of the $$25^{ th }$$ anniversary of the TACAS conference."
Ensuring the Consistency Between User Requirements and GUI Prototypes: A Behavior-Based Automated Approach,Human-Computer Interaction – INTERACT 2019,,,,10.1007/978-3-030-29381-9_39,Thiago Rocha SilvaMarco WincklerHallvard Trætteberg,2019,http://link.springer.com/chapter/10.1007/978-3-030-29381-9_39,Chapter,"Behavior-Driven Development (BDD), GUI Prototypes, User Requirements Assessment, User Stories",10,"In a user-centered design process, graphical user interface (GUI) prototypes may be seen as an important early artifact to design and validate user requirements before making strong commitments with a full-fledged version of the user interface. Ensuring the consistency of GUI prototypes with other representations of the user requirements is then a critical aspect of the design process. This paper presents an approach which extends Behavior-Driven Development (BDD) by employing an ontology in order to provide automated assessment for GUI prototypes as design artifacts. The approach has been evaluated by exploiting user requirements described by a group of experts in the flight tickets e-commerce domain. Such requirements gave rise to a set of User Stories that have been used to automatically check the consistency of Balsamiq prototypes which were reengineered from an existing web system for booking business trips. The results have shown our approach was able to identify different types of inconsistencies in the set of analyzed artifacts, allowing to build an effective correspondence between user requirements and their representation in GUI prototypes."
Formal Model Validation Through Acceptance Tests,"Reliability, Safety, and Security of Railway Systems. Modelling, Analysis, Verification, and Certification",,,,10.1007/978-3-030-18744-6_10,Tomas FischerDana Dghyam,2019,http://link.springer.com/chapter/10.1007/978-3-030-18744-6_10,Chapter,"Acceptance tests, Cucumber, Event-B, Formal methods, Gherkin, iUML-B, Validation",10,"When formal systems modelling is used as part of the development process, modellers need to understand the requirements in order to create appropriate models, and domain experts need to validate the final models to ensure they fit the needs of stakeholders. A suitable mechanism for such a validation are acceptance tests. In this paper we discuss how the principles of Behaviour-Driven Development (BDD) can be applied to (i) formal modelling and (ii) validation of behaviour specifications, thus coupling those two tasks. We show how to close the gap between the informal domain specification and the formal model, thus enabling the domain expert to write acceptance tests in a high-level language matching the formal specification. We analyse the applicability of this approach by providing the Gherkin scenarios for an formal model of a ‘fixed virtual block’ approach to train movement control, developed according to the Hybrid ERTMS/ETCS Level 3 principles specified by the EEIG ERTMS Users Group and presented as a case study on the 6. International ABZ Conference 2018."
Repairing Timed Automata Clock Guards through Abstraction and Testing,Tests and Proofs,,,,10.1007/978-3-030-31157-5_9,Étienne AndréPaolo ArcainiAngelo GargantiniMarco Radavelli,2019,http://link.springer.com/chapter/10.1007/978-3-030-31157-5_9,Chapter,,10,"Timed automata (TAs) are a widely used formalism to specify systems having temporal requirements. However, exactly specifying the system may be difficult, as the user may not know the exact clock constraints triggering state transitions. In this work, we assume the user already specified a TA, and (s)he wants to validate it against an oracle that can be queried for acceptance. Under the assumption that the user only wrote wrong guard transitions (i.e., the structure of the TA is correct), the search space for the correct TA can be represented by a Parametric Timed Automaton (PTA), i.e., a TA in which some constants are parametrized. The paper presents a process that (i) abstracts the initial (faulty) TA $$ ta_{init} $$ t a init in a PTA $$ pta $$ pta ; (ii) generates some test data (i.e., timed traces) from $$ pta $$ pta ; (iii) assesses the correct evaluation of the traces with the oracle; (iv) uses the IMITATOR tool for synthesizing some constraints $$\varphi $$ φ on the parameters of $$ pta $$ pta ; (v) instantiate from $$\varphi $$ φ a TA $$ ta_{rep} $$ t a rep as final repaired model. Experiments show that the approach is successfully able to partially repair the initial design of the user."
Software Assurance in an Uncertain World,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-030-16722-6_1,Marsha ChechikRick SalayTorin VigerSahar KokalyMona Rahimi,2019,http://link.springer.com/chapter/10.1007/978-3-030-16722-6_1,Chapter,,10,"From financial services platforms to social networks to vehicle control, software has come to mediate many activities of daily life. Governing bodies and standards organizations have responded to this trend by creating regulations and standards to address issues such as safety, security and privacy. In this environment, the compliance of software development to standards and regulations has emerged as a key requirement. Compliance claims and arguments are often captured in assurance cases, with linked evidence of compliance. Evidence can come from testcases, verification proofs, human judgment, or a combination of these. That is, experts try to build (safety-critical) systems carefully according to well justified methods and articulate these justifications in an assurance case that is ultimately judged by a human. Yet software is deeply rooted in uncertainty; most complex open-world functionality (e.g., perception of the state of the world by a self-driving vehicle), is either not completely specifiable or it is not cost-effective to do so; software systems are often to be placed into uncertain environments, and there can be uncertainties that need to be We argue that the role of assurance cases is to be the grand unifier for software development, focusing on capturing and managing uncertainty. We discuss three approaches for arguing about safety and security of software under uncertainty, in the absence of fully sound and complete methods: assurance argument rigor, semantic evidence composition and applicability to new kinds of systems, specifically those relying on ML."
Adaptation and Implementation of the ISO42010 Standard to Software Design and Modeling Tools,Model-Driven Engineering and Software Development,,,,10.1007/978-3-030-11030-7_11,Maged ElaasarFlorian NoyritOmar BadreddinSébastien Gérard,2019,http://link.springer.com/chapter/10.1007/978-3-030-11030-7_11,Chapter,"Architecture description language, Architecture framework, ISO 42010, Model driven architecture, Model driven development, Software design, Software modeling, SysML, UML",10,"Model cantered software development practices adoption remains limited to small niche domains. The broad development practices remain code centric. Modeling tool complexity is often cited as a significant factor limiting the adoption and negatively affecting user experience. Modeling and design tools complexity are due to multiple factors including complexity of the underlying language, weak support for methodologies, and insensitivity to users’ concerns. This results in modeling and design tools that expose all or most of their capabilities and elements at once, often overwhelming users and negatively affecting user experience. The problem is further exacerbated when a tool supports multiple domain-specific modeling languages that are defined on top of a base language such as UML. In this case, the tool customizations and visual elements necessary to support each language often interfere with each other and further exacerbate the modeling tool complexity. In this paper, we present a novel and systematic approach to reduce the complexity of design and modeling tools by introducing an interpretation and adaptation of the ISO42010 standard on architecture description specific to the software domain. We demonstrate this approach by providing a working implementation as part of the Papyrus opensource modeling framework. In this approach, we leverage the notions of Architecture Contexts and Architecture Viewpoints to enable heterogeneous UML-based languages to be independently supported and help contextualize the exposed tool capabilities. This paper presents the ISO42010 interpretation and adaptation to software design and architecture and a case study with several definitions of architecture contexts. The implementation of this novel approach demonstrates the ability for multiple modeling languages and notations to coexist without interference and provides significant reduction in the exposed capabilities in the UI. Reducing design and modeling tool complexity has a potential to significantly broaden the adoption of modeling and design practices in the software engineering sphere."
Testing for Integrity Flaws in Web Sessions,Computer Security – ESORICS 2019,,,,10.1007/978-3-030-29962-0_29,Stefano CalzavaraAlvise RabittiAlessio RagazzoMichele Bugliesi,2019,http://link.springer.com/chapter/10.1007/978-3-030-29962-0_29,Chapter,"CSRF, Session fixation, Session hijacking, Web sessions",10,"Web sessions are fragile and can be attacked at many different levels. Classic attacks like session hijacking, session fixation and cross-site request forgery are particularly dangerous for web session security, because they allow the attacker to breach the integrity of honest users’ sessions by forging requests which get authenticated on the victim’s behalf. In this paper, we systematize current countermeasures against these attacks and the shortcomings thereof, which may completely void protection under specific assumptions on the attacker’s capabilities. We then build on our security analysis to introduce black-box testing strategies to discover insecure session implementation practices on existing websites, which we implement in a browser extension called Dredd. Finally, we use Dredd to assess the security of 20 popular websites from Alexa, exposing a number of session integrity flaws."
Extracting High-Level System Specifications from Source Code via Abstract State Machines,Model and Data Engineering,,,,10.1007/978-3-030-32065-2_19,Flavio FerrarottiJosef PichlerMichael MoserGeorg Buchgeher,2019,http://link.springer.com/chapter/10.1007/978-3-030-32065-2_19,Chapter,,10,"We are interested in specifications which provide a consistent high-level view of systems. They should abstract irrelevant details and provide a precise and complete description of the behaviour of the system. This view of software specification can naturally be expressed by means of Gurevich’s Abstract State Machines (ASMs). There are many known benefits of such an approach to system specifications for software engineering and testing. In practice however, such specifications are rarely generated and/or maintained during software development. Addressing this problem, we present an exploratory study on (semi) automated extraction of high-level software specifications by means of ASMs. We describe, in the form of examples, an abstraction process which starts by extracting an initial ground-level ASM specification from Java source code (with the same core functionality), and ends in a high-level ASM specification at the desired level of abstraction. We argue that this process can be done in a (semi) automated way, resulting in a valuable tool to improve the current software engineering practices."
An Implementation Relation for Cyclic Systems with Refusals and Discrete Time,Software Engineering and Formal Methods,,,,10.1007/978-3-030-30446-1_21,Raluca LefticaruRobert M. HieronsManuel Núñez,2019,http://link.springer.com/chapter/10.1007/978-3-030-30446-1_21,Chapter,,10,"This paper explores a particular type of model, a cyclic model, in which there are sequences of observable actions separated by discrete time intervals, introduces a novel implementation relation and studies some properties of this relation. Implementation relations formalise what it means for an unknown model of the system under test (SUT) to be a correct implementation of a specification. Many implementation relations are variants of the well known ioco implementation relation, and this includes several timed versions of ioco. It transpires that the timed variants of ioco are not suitable for cyclic models. Our implementation relation encapsulates the discrete nature of time in cyclic models and takes into account not only the actions that models can perform but also the ones that they can refuse at each point of time. We prove that our implementation relation is a conservative extension of trace containment and present two alternative characterisations."
A Survey on Model-Based Testing Tools for Test Case Generation,Tools and Methods of Program Analysis,,,,10.1007/978-3-319-71734-0_7,Wenbin LiFranck Le GallNaum Spaseski,2018,http://link.springer.com/chapter/10.1007/978-3-319-71734-0_7,Chapter,"Model specification, Model-Based Testing, Survey, Test case
, Test description, Test generation, Tool",10,"Compared to traditional testing methods, Model-Based Testing (MBT) is able to manage and accomplish testing tasks in a cheaper and more efficient way. A number of MBT tools are developed to support MBT activities in the past few years, whereas the characteristics of these tools largely vary from one to another and users without prior knowledge can hardly choose appropriate tools. This paper aims at providing a survey on the emerging MBT tools following a list of criteria emphasizing on test case generation while illustrating aspects of test data and test script generation. Firstly, we introduce the general MBT process for a common understanding; we then present a list of criteria oriented to test case generation covering fours dimensions i.e., model specification, test generation, test description and overall support; following our proposed criteria, we survey and characterize the emerging MBT tools; at last we summarize the current limitations based on our survey and shed light on further directions of MBT tool development."
Model Based Testing of Cyber-Physical Systems,Formal Methods and Software Engineering,,,,10.1007/978-3-030-02450-5_27,Teck Ping Khoo,2018,http://link.springer.com/chapter/10.1007/978-3-030-02450-5_27,Chapter,"Cyber-Physical Systems, Model Based Testing, Testing framework",10,"Testing, inspection, and certification (TIC) are essential activities on consumer and industrial systems. The conformance to system specifications and standards can then provide assurances on system safety, security, reliability, and interoperability. TIC needs to evolve in tandem with growing system size and complexity. Common modern systems such as autonomous vehicles and smart health-care systems take the form of Cyber Physical Systems (CPSs). Model Based Testing (MBT) is one promising approach to test CPSs. An MBT framework for testing CPSs will be useful to systems testers and can raise the standard of systems testing as a whole."
Model-Based Testing for Avionic Systems Proven Benefits and Further Challenges,"Leveraging Applications of Formal Methods, Verification and Validation. Industrial Practice",,,,10.1007/978-3-030-03427-6_11,Jan PeleskaJörg BrauerWen-ling Huang,2018,http://link.springer.com/chapter/10.1007/978-3-030-03427-6_11,Chapter,"Avionic systems, HW/SW integration testing, Model-based testing, Scenario-based testing",10,"In this article, we report on the transition of model-based testing (MBT) from a widely discussed research discipline to an accepted technology that is currently becoming state of the art in industry; in particular, in the field of safety-critical systems testing. It is reviewed how focal points of MBT-related research in the past have found their way into today’s commercial MBT products. We describe the benefits of MBT that are – from our experience – most appreciated by practitioners. Moreover, some interesting open challenges are described, and potential future solutions are presented. The material presented in this paper is based on our practical experience with recent MBT campaigns performed for Airbus in Germany."
Scrum and V Lifecycle Combined with Model-Based Testing and Model Driven Architecture to Deal with Evolutionary System Issues,Model and Data Engineering,,,,10.1007/978-3-030-00856-7_5,Imane EssebaaSalima Chantit,2018,http://link.springer.com/chapter/10.1007/978-3-030-00856-7_5,Chapter,"Evolutionary system, Model Driven Architecture, Model transformations, Model-Based Testing, Scrum agile methodology, Test generation, V incremental lifecycle",10,"Model Driven Engineering (MDE) and Agile Methods (AM) are two principal domains that are in the way of improvement and evolution in order to facilitate the realisation of IT projects. However, these areas evolve separately despite the great number of researches that focus on improving realisation project’ techniques. Thus, our approach aims to provide an approach that combines two variants of MDE, Model Driven Architecture approach and Model-Based Testing with the V development lifecycle used in every scrum Agile Methodology sprint to deal with system evolution. In order to well illustrate this approach, we apply it on Rental Car Agency System realisation using Scrum methodology with some requirements’ evolution."
Model-Based Testing for Avionics Systems,Formal Methods,,,,10.1007/978-3-319-95582-7_40,Jörg BrauerUwe Schulze,2018,http://link.springer.com/chapter/10.1007/978-3-319-95582-7_40,Chapter,"Application Parameters, Model-based Development Techniques, Model-based Testing, Tension Panel, Voiding Function",10,"Model-based testing is considered state-of-the-art in verification and validation of safety-critical systems. This paper discusses some experiences of applying the model-based testing tool RTT-MBT for the evacuation function of an aircraft cabin controller. One challenge of this project was the parametric design of the software, which allows to tailor the software to a certain aircraft configuration via application parameters. Further challenges consisted of connecting hardware signals of the system under test to abstract model variables, and handling incremental test model development during an ongoing test campaign. We discuss solutions that we developed to successfully conduct this test campaign."
Model-Based Testing for General Stochastic Time,NASA Formal Methods,,,,10.1007/978-3-319-77935-5_15,Marcus GerholdArnd HartmannsMariëlle Stoelinga,2018,http://link.springer.com/chapter/10.1007/978-3-319-77935-5_15,Chapter,,10,"Many systems are inherently stochastic: they interact with unpredictable environments or use randomised algorithms. Then classical model-based testing is insufficient: it only covers functional correctness. In this paper, we present a new model-based testing framework that additionally covers the stochastic aspects in hard and soft real-time systems. Using the theory of stochastic automata for specifications, test cases and a formal notion of conformance, it provides clean mechanisms to represent underspecification, randomisation, and stochastic timing. Supporting arbitrary continuous and discrete probability distributions, the framework generalises previous work based on purely Markovian models. We cleanly define its theoretical foundations, and then outline a practical algorithm for statistical conformance testing based on the Kolmogorov-Smirnov test. We exemplify the framework’s capabilities and tradeoffs by testing timing aspects of the Bluetooth device discovery protocol."
An Extension of TRIANGLE Testbed with Model-Based Testing,Model Checking Software,,,,10.1007/978-3-319-94111-0_11,Laura PanizoAlmudena DíazBruno García,2018,http://link.springer.com/chapter/10.1007/978-3-319-94111-0_11,Chapter,"Mobile network testbed, Model checking, Model-based testing",10,"Traditional testing methods for mobile apps focus on detecting execution errors. However, the evolution of mobile networks towards 5G will require additional support for app developers to ensure also the performance and user-experience. Manual testing in a number of scenarios is not enough to satisfy the expectations of the apps final users. This paper presents the testing framework developed in the TRIANGLE project ( https://www.triangle-project.eu/ ) that integrates a complete mobile network testbed and a model-based testing approach, which is based on model checking, to automatically evaluate the apps performance in different network scenarios."
Towards a Model-Based Testing Framework for the Security of Internet of Things for Smart City Applications,"Smart Societies, Infrastructure, Technologies and Applications",,,,10.1007/978-3-319-94180-6_34,Moez KrichenOmar CheikhrouhouMariam LahamiRoobaea AlroobaeaAfef Jmal Maâlej,2018,http://link.springer.com/chapter/10.1007/978-3-319-94180-6_34,Chapter,"Coverage, Generation, Internet of Things, Security, Security models, Smart cities, Test, Verdicts",10,This is a work in progress in which we are interested in testing security aspects of Internet of Things for Smart Cities. For this purpose we follow a Model-Based approach which consists in: modeling the system under investigation with an appropriate formalism; deriving test suites from the obtained model; applying some coverage criteria to select suitable tests; executing the obtained tests; and finally collecting verdicts and analyzing them in order to detect errors and repair them.
MBT/CPN: A Tool for Model-Based Software Testing of Distributed Systems Protocols Using Coloured Petri Nets,Verification and Evaluation of Computer and Communication Systems,,,,10.1007/978-3-030-00359-3_7,Rui WangLars Michael KristensenVolker Stolz,2018,http://link.springer.com/chapter/10.1007/978-3-030-00359-3_7,Chapter,,10,"Model-based testing is an approach to software testing based on generating test cases from models. The test cases are then executed against a system under test. Coloured Petri Nets (CPNs) have been widely used for modeling, validation, and verification of concurrent software systems, but their application for model-based testing has only been explored to a limited extent. The contribution of this paper is to present the MBT/CPN tool, implemented through CPN Tools, to support test case generation from CPN models. We illustrate the application of our approach by showing how it can be used for model-based testing of a Go implementation of the coordinator in a two-phase commit protocol. In addition, we report on experimental results for Go-based implementations of a distributed storage protocol and the Paxos distributed consensus protocol. The experiments demonstrate that the generated test cases yield a high statement coverage."
Model Based Approach for Testing: Distributed Real-Time Systems Augmented with Online Monitors,Databases and Information Systems,,,,10.1007/978-3-319-97571-9_13,Deepak PalJüri Vain,2018,http://link.springer.com/chapter/10.1007/978-3-319-97571-9_13,Chapter,"Distributed systems, Low-latency systems, Model-based testing, Real-time database systems",10,"Testing distributed systems requires an integration of computation, communication and control in the test architecture. This may pose number of issues that may not be suitably addressed by traditional centralized test architectures. In this paper, a distributed test framework for testing distributed real-time systems is presented, where online monitors (executable code as annotations) are integrated to systems to record relevant events. The proposed test architecture is more scalable than centralized architectures in the sense of timing constraints and geographical distribution. By assuming the existence of a coverage correct centralized remote tester, we give a partitioning algorithm of it to produce distributed local testers which enables to meet more flexible performance constraints while preserving the remote tester’s functionality. The proposed approach not only preserves the correctness of the centralized tester but also allows to meet stronger timing constraints for solving test controllability and observability issues. The effectiveness of the proposed architecture is demonstrated by an illustrative example."
Applying Integrated Domain-Specific Modeling for Multi-concerns Development of Complex Systems,Model-Driven Engineering and Software Development,,,,10.1007/978-3-319-94764-8_11,Reinhard PröllAdrian RumpoldBernhard Bauer,2018,http://link.springer.com/chapter/10.1007/978-3-319-94764-8_11,Chapter,"Domain-specific modeling, Model transformation, Model-based analysis, Model-based testing",10,"Current systems engineering efforts are increasingly driven by trade-offs and limitations imposed by multiple factors: Growing product complexity as well as stricter regulatory requirements in domains such as automotive or aviation necessitate advanced design and development methods. At the core of these influencing factors lies a consideration of competing non-functional concerns, such as safety and reliability, performance, and the fulfillment of quality requirements. In an attempt to cope with these aspects, incremental evolution of model-based engineering practice has produced heterogeneous tool environments without proper integration and exchange of design artifacts. In order to overcome these shortcomings of current engineering practice, we propose a holistic, model-based architecture and analysis framework for seamless design, analysis, and evolution of integrated system models. We describe how heterogeneous domain-specific modeling languages can be embedded into a common general-purpose model in order to facilitate the integration between previously disjoint design artifacts. A case study demonstrates the suitability of this methodology for the design of a safety-critical embedded system, a hypothetical gas heating, with respect to reliability engineering and further quality assurance activities."
Effective Test Suite Design for Detecting Concurrency Control Faults in Distributed Transaction Systems,"Leveraging Applications of Formal Methods, Verification and Validation. Distributed Systems",,,,10.1007/978-3-030-03424-5_24,Simin CaiBarbara GallinaDag NyströmCristina Seceleanu,2018,http://link.springer.com/chapter/10.1007/978-3-030-03424-5_24,Chapter,,10,"Concurrency control faults may lead to unwanted interleavings, and breach data consistency in distributed transaction systems. However, due to the unpredictable delays between sites, detecting concurrency control faults in distributed transaction systems is difficult. In this paper, we propose a methodology, relying on model-based testing and mutation testing, for designing test cases in order to detect such faults. The generated test inputs are designated delays between distributed operations, while the outputs are the occurrence of unwanted interleavings that are consequences of the concurrency control faults. We mutate the distributed transaction specification with common concurrency control faults, and model them as UPPAAL timed automata, in which designated delays are encoded as stopwatches. Test cases are generated via reachability analysis using UPPAAL Model Checker, and are selected to form an effective test suite. Our methodology can reduce redundant test cases, and find the appropriate delays to detect concurrency control faults effectively."
20 Years of UPPAAL Enabled Industrial Model-Based Validation and Beyond,"Leveraging Applications of Formal Methods, Verification and Validation. Industrial Practice",,,,10.1007/978-3-030-03427-6_18,Kim G. LarsenFlorian LorberBrian Nielsen,2018,http://link.springer.com/chapter/10.1007/978-3-030-03427-6_18,Chapter,,10,"In this paper we review how the Uppaal Tool Suite served in industrial projects and was both driven and improved by them throughout the last 20 years. We show how the need of industry for model-based validation, performance evaluation and synthesis shaped the tool suite and how the tool suite aided the use cases it was applied in. The paper highlights a number of selected cases, including success stories and pitfalls, and we discuss the important roles of both basic research and industrial projects."
Lessons Learned Using FMI Co-simulation for Model-Based Design of Cyber Physical Systems,"Leveraging Applications of Formal Methods, Verification and Validation. Distributed Systems",,,,10.1007/978-3-030-03424-5_33,Luís Diogo CoutoStylianos BasagiannisEl Hassan RidouaneErica ZavaglioPasquale AntonanteHajer SaadaSara Falleni,2018,http://link.springer.com/chapter/10.1007/978-3-030-03424-5_33,Chapter,,10,"Model-Based Design is an effective way to carry out Cyber-Physical Systems (CPS) development. One of the main sets of challenges in CPS projects is dealing with the highly heterogeneous nature of the development teams. These challenges can be brought to the forefront by focusing on model integration through standards, such as the Functional Mockup Interface (FMI). We report on a case study of the application of an FMI-based workflow to the development of a Heat Ventilation and Air Conditioning (HVAC) system of a building. We report on ten challenges and lessons learned when using the FMI standard, focusing on collaborative aspects and model integration. As a conclusion we provide recommendations and examples for dealing with the CPS development challenges assessing to that end the importance of the FMI standard."
The Miles Before Formal Methods - A Case Study on Modeling and Analyzing a Passenger Lift System,Formal Methods and Software Engineering,,,,10.1007/978-3-030-02450-5_4,Teck Ping KhooJun Sun,2018,http://link.springer.com/chapter/10.1007/978-3-030-02450-5_4,Chapter,,10,"Cyber-Physical Systems (CPS) pervade our everyday lives. As users, we need assurances that such systems satisfy requirements on safety, reliability, security and interoperability. CPS presents a major challenge for formal analysis because of their complexity, physical dependencies and non-linearity, and for smart CPS - the ability to improve their behavior over time. Existing approaches on analyzing CPS (e.g., model checking and model-based testing) often assume the existence of a system model. Such approaches have limited application in practice as the models often do not exist. In this work, we report our experience on applying a three-step approach to analyzing a practical CPS: a passenger lift system in a commercial building. The three steps are (1) determining the right level of system abstraction, (2) building the model automatically using grammatical inference, and (3) analyzing the model. The inferred model is in the form of a probabilistic deterministic real time automaton, which allows us to verify the system against properties demanded by the lift requirement. The resulting models form the basis of formal analysis and potentially other approaches. We believe that our approach and experience are applicable to other CPSs."
"Life Sciences-Inspired Test Case Similarity Measures for Search-Based, FSM-Based Software Testing",Modelling Foundations and Applications,,,,10.1007/978-3-319-92997-2_13,Nesa AsoudehYvan Labiche,2018,http://link.springer.com/chapter/10.1007/978-3-319-92997-2_13,Chapter,"Fault detection, FSM, State-based testing, Test suite diversity",10,"Researchers and practitioners alike have the intuition that test cases diversity is positively correlated to fault detection. Empirical results already show that some measurement of diversity within a pre-existing state-based test suite (i.e., a test suite not necessarily created to have diverse tests in the first place) indeed relates to fault detection. In this paper we show how our procedure, based on a genetic algorithm, to construct an entire (all-transition) adequate test suite with as diverse tests as possible fares in terms of fault detection. We experimentally compare on a case study nine different ways of computing test suite diversity, including measures already used by others in software testing as well as measures inspired by the notion of diversity in the life sciences. Although our results confirm a positive correlation between diversity and fault detection, we believe our results raise more questions than they answer about the notion and measurement of test suite diversity, which leads us to argue that more work needs to be dedicated to this topic."
QuickChecking Patricia Trees,Trends in Functional Programming,,,,10.1007/978-3-319-89719-6_4,Jan Midtgaard,2018,http://link.springer.com/chapter/10.1007/978-3-319-89719-6_4,Chapter,"Functional Data Structures, Integer Keys, Okasaki, Patricia Tree, QuickCheck",10,"Patricia trees are a space-efficient, purely functional data structure, useful for efficiently implementing both integer sets and dictionaries with integer keys. In this paper we illustrate how to build a QuickCheck model of the data structure for the purpose of testing a mature OCaml library implementing it. In doing so, we encounter a subtle bug, initially inherited from a paper by Okasaki and Gill, and since then flying under the radar for almost two decades."
Randomized Event Sequence Generation Strategies for Automated Testing of Android Apps,Information Technology - New Generations,,,,10.1007/978-3-319-54978-1_72,David AdamoRenée BryceTariq M. King,2018,http://link.springer.com/chapter/10.1007/978-3-319-54978-1_72,Chapter,"Android, Automated testing, GUI testing, Mobile apps",10,"Mobile apps are often tested with automatically generated sequences of Graphical User Interface (GUI) events. Dynamic GUI testing algorithms construct event sequences by selecting and executing events from GUI states at runtime. The event selection strategy used in a dynamic GUI testing algorithm may directly influence the quality of the test suites it produces. Existing algorithms use a uniform probability distribution to randomly select events from each GUI state and they are often not directly applicable to mobile apps. In this paper, we develop a randomized algorithm to dynamically construct test suites with event sequences for Android apps. We develop two frequency-based event selection strategies as alternatives to uniform random event selection. Our event selection algorithms construct event sequences by dynamically altering event selection probabilities based on the prior selection frequency of events in each GUI state. We compare the frequency-based strategies to uniform random selection across nine Android apps. The results of our experiments show that the frequency-based event selection strategies tend to produce test suites that achieve better code coverage and fault detection than test suites constructed with uniform random event selection."
MoDeS3: Model-Based Demonstrator for Smart and Safe Cyber-Physical Systems,NASA Formal Methods,,,,10.1007/978-3-319-77935-5_31,András VörösMárton BúrIstván RáthÁkos HorváthZoltán MicskeiLászló BaloghBálint HegyiBenedek HorváthZsolt MázlóDániel Varró,2018,http://link.springer.com/chapter/10.1007/978-3-319-77935-5_31,Chapter,"Demonstrator, Education, Formal methods, Model-driven engineering, Smart cyber-physical systems",10,"We present MoDeS3, a complex research demonstrator illustrating the combined use of model-driven development, formal verification, safety engineering and IoT technologies for smart and safe cyber-physical systems. MoDeS3 represents a smart transportation system-of-systems composed of a model railway and a crane which may automatically load and unload cargo from trains where both subsystems need to fulfill functional and safety requirements. The demonstrator is built by using the model-based software engineering principle, while the system level safety is ensured by the combined use of design-time and runtime verification and validation techniques."
Model-Driven Engineering for Design-Runtime Interaction in Complex Systems: Scientific Challenges and Roadmap,Software Technologies: Applications and Foundations,,,,10.1007/978-3-030-04771-9_40,Hugo BruneliereRomina EramoAbel GómezValentin BesnardJean Michel BruelMartin GogollaAndreas KästnerAdrian Rutle,2018,http://link.springer.com/chapter/10.1007/978-3-030-04771-9_40,Chapter,"Correspondences, Design time modeling, Feedback, Interactions, Runtime modeling, Traceability",10,"This paper reports on the first Workshop on Model-Driven Engineering for Design-Runtime Interaction in Complex Systems (also called MDE@DeRun 2018) that took place during the STAF 2018 week. It explains the main objectives, content and results of the event. Based on these, the paper also proposes initial directions to explore for further research in the workshop area."
Extending Automated Protocol State Learning for the 802.11 4-Way Handshake,Computer Security,,,,10.1007/978-3-319-99073-6_16,Chris McMahon StoneTom ChothiaJoeri de Ruiter,2018,http://link.springer.com/chapter/10.1007/978-3-319-99073-6_16,Chapter,,10,"We show how state machine learning can be extended to handle time out behaviour and unreliable communication mediums. This enables us to carry out the first fully automated analysis of 802.11 4-Way Handshake implementations. We develop a tool that uses our learning method and apply this to 7 widely used Wi-Fi routers, finding 3 new security critical vulnerabilities: two distinct downgrade attacks and one router that can be made to leak some encrypted data to an attacker before authentication."
A Proposal of an Example and Experiments Repository to Foster Industrial Adoption of Formal Methods,"Leveraging Applications of Formal Methods, Verification and Validation. Industrial Practice",,,,10.1007/978-3-030-03427-6_20,Rupert SchlickMichael FeldererIstvan MajzikRoberto NardoneAlexander RaschkeColin SnookValeria Vittorini,2018,http://link.springer.com/chapter/10.1007/978-3-030-03427-6_20,Chapter,"Benchmarks, Formal methods, Formal models, Industrial adoption",10,"Formal methods (in a broad sense) have been around almost since the beginning of computer science. Nonetheless, there is a perception in the formal methods community that take-up by industry is low considering the potential benefits. We take a look at possible reasons and give candidate explanations for this effect. To address the issue, we propose a repository of industry-relevant example problems with an accompanying open data storage for experiment results in order to document, disseminate and compare exemplary solutions from formal model based methods. This would allow potential users from industry to better understand the available solutions and to more easily select and adopt a formal method that fits their needs. At the same time, it would foster the adoption of open data and good scientific practice in this research field."
Injecting Formal Verification in FMI-Based Co-simulations of Cyber-Physical Systems,Software Engineering and Formal Methods,,,,10.1007/978-3-319-74781-1_20,Luís Diogo CoutoStylianos BasagiannisEl Hassan RidouaneAlie El-Din MadyMiran HasanagicPeter Gorm Larsen,2018,http://link.springer.com/chapter/10.1007/978-3-319-74781-1_20,Chapter,,10,"Model-based design tools supporting the Functional Mockup Interface (FMI) standard, often employ specification languages ideal for modelling specific domain problems without capturing the overall behavior of a Cyber-Physical System (CPS). These tools tend to handle some important CPS characteristics implicitly, such as network communication handshakes. At the same time, formal verification although a powerful approach, is still decoupled to FMI co-simulation processes, as it can easily lead to infeasible explorations due to state space explosion of continuous or discrete representations. In this paper we exploit co-modelling and co-simulation concepts combined with the injection of formal verification results indirectly in a model-based design workflow that will enable verification engineering benefits in a heterogeneous, multi-disciplinary design process for CPSs. We demonstrate the approach using a Heating, Ventilation and Air Conditioning (HVAC) case study where communication delays may affect the CPS system’s analysis. We model discrete events based on the Vienna Development Method Real-Time dialect, Continuous Time phenomena using Modelica, and communications using PROMELA. Results are considered and inspected both at the level of constituent models and the overall co-simulation."
Automatic Test Case Generation for Concurrent Features from Natural Language Descriptions,Formal Methods: Foundations and Applications,,,,10.1007/978-3-030-03044-5_11,Rafaela AlmeidaSidney NogueiraAugusto Sampaio,2018,http://link.springer.com/chapter/10.1007/978-3-030-03044-5_11,Chapter,"Concurrent feature, CSP, Software testing",10,"Contemporary computing applications have an increasing level of concurrency; new techniques are demanded to tackle the challenge of testing the plentiful interactions that arise from concurrent behaviour. Current approaches for automatic test generation from natural language models do not allow the explicit specification of concurrent behaviour. This paper extends our previous test case generation approach to support concurrent mobile device features. A natural language notation is proposed to express the composition of sequential and concurrent behaviour. The notation can be automatically translated to a CSP model, from which tests are automatically produced using the FDR refinement checker. The approach is illustrated with a mobile application that includes concurrent features."
Applying Model-Driven Web Engineering to the Testing Phase of the ADAGIO Project,Current Trends in Web Engineering,,,,10.1007/978-3-030-03056-8_2,L. MoralesS. Moreno-LeonardoM. A. OliveroA. Jiménez-RamírezM. Mejías,2018,http://link.springer.com/chapter/10.1007/978-3-030-03056-8_2,Chapter,"Early Testing, Model-Driven Web Engineering, NDT, Web application",10,"The Model-Driven Engineering (MDE) has been used in recent years to promote better results in the development of Web Applications, in the field that has been called Model-Driven Web Engineering (MDWE). One of the advantages of applying MDWE is that it offers a solution to reduce the cost of the tests without affecting their quality execution. This paper presents the application of a MDWE methodology (Navigational Development Techniques, NDT) that provides support for all the phases of the lifecycle of a software project development proposing transformations between these phases, to manage the test phase of a real-world case study named ADAGIO. This project, among other goals, proposes the development of a web application whose main objective is to offer researchers the possibility of integrating and consolidating heterogeneous data sources, showing a unified vision of them, allowing to simplify the search task in different repositories as well as the relationship between the sources found."
Property-Aware Unit Testing of UML-RT Models in the Context of MDE,Modelling Foundations and Applications,,,,10.1007/978-3-319-92997-2_10,Reza AhmadiNicolas HiliJuergen Dingel,2018,http://link.springer.com/chapter/10.1007/978-3-319-92997-2_10,Chapter,,10,"Modern cyber-physical systems are complex to model due, among other things, to timing constraints and complex communications between components of such systems. Therefore, testing models of these systems is not straightforward. This paper presents an approach for automatically testing components of UML-RT models with respect to a set of formally defined properties. Compared to existing model-based techniques where abstract test cases are complemented with their concrete counterparts, our approach solely leverages on constructs provided by the modeling language to express all artifacts (component to test, test harness, the property of interest) and existing code generator to generate test cases. This helps to reduce the cost of ensuring the consistency between code- and model-level tests. Moreover, to reduce the number of test cases and the associated cost, our approach integrates our test case generators with slicing techniques to reduce the size of the components. A prototype implementation has been sketched and our approach has been evaluated over two case studies."
Modelling and Validating an Engineering Application in Kernel P Systems,Membrane Computing,,,,10.1007/978-3-319-73359-3_12,Raluca LefticaruMehmet Emin BakirSavas KonurMike StannettFlorentin Ipate,2018,http://link.springer.com/chapter/10.1007/978-3-319-73359-3_12,Chapter,"Bicycle, Cruise control, Electric bike, Kernel P systems, Membrane computing, Testing, Verification",10,"This paper illustrates how kernel P systems ( kP systems ) can be used for modelling and validating an engineering application, in this case a cruise control system of an electric bike. The validity of the system is demonstrated via formal verification, carried out using the k PWorkbench tool. Furthermore, we show how the kernel P system model can be tested using automata and X-machine based techniques."
Formal Modelling of Environment Restrictions from Natural-Language Requirements,Formal Methods: Foundations and Applications,,,,10.1007/978-3-030-03044-5_16,Tainã SantosGustavo CarvalhoAugusto Sampaio,2018,http://link.springer.com/chapter/10.1007/978-3-030-03044-5_16,Chapter,"Case grammar, Communicating Sequential Processes, Environment restrictions, Linear temporal logic, Natural language",10,"When creating system models, further to system behaviour one should take into account properties of the environment in order to achieve more meaningful models. Here, we extend a strategy that formalises data-flow reactive systems as CSP processes to take into account environment restrictions. Initially, these restrictions are written in natural language. Afterwards, with the aid of case-grammar theory, they are formalised by deriving LTL formulae automatically. Finally, these formulae are used to prune infeasible scenarios from the CSP-based system specification, in the light of the environment restrictions. Considering examples from the literature, and from the aerospace (Embraer) and the automotive (Mercedes) industry, we show the efficacy of our proposal in terms of state space reduction, up to 61% in some cases."
Sound Black-Box Checking in the LearnLib,NASA Formal Methods,,,,10.1007/978-3-319-77935-5_24,Jeroen MeijerJaco van de Pol,2018,http://link.springer.com/chapter/10.1007/978-3-319-77935-5_24,Chapter,,10,"In Black-Box Checking (BBC) incremental hypotheses of a system are learned in the form of finite automata. On these automata LTL formulae are verified, or their counterexamples validated on the actual system. We extend the LearnLib’s system-under-learning API for sound BBC, by means of state equivalence, that contrasts the original proposal where an upper-bound on the number of states in the system is assumed. We will show how LearnLib’s new BBC algorithms can be used in practice, as well as how one could experiment with different model checkers and BBC algorithms. Using the RERS 2017 challenge we provide experimental results on the performance of all LearnLib’s active learning algorithms when applied in a BBC setting. The performance of learning algorithms was unknown for this setting. We will show that the novel incremental algorithms TTT, and ADT perform the best."
Consumer-Driven API Testing with Performance Contracts,Advances in Service-Oriented and Cloud Computing,,,,10.1007/978-3-319-72125-5_11,Johannes StählinSebastian LangFabian KajzarChristian Zirpins,2018,http://link.springer.com/chapter/10.1007/978-3-319-72125-5_11,Chapter,"Application reuse, Cloud migration, Non-functional consumer-driven contract testing, RESTful web services and APIs",10,"Modern software applications are often based on a modular structure where services expose functions and data via an API. In an enterprise context, such APIs may be reused in varying contexts with alternative frontends and on different platforms. E.g., an intranet application may be reused by another department or as part of a public portal thereby migrating between different private clouds. When migrating services, it is imperative to assure their qualitative characteristics. Expectations of application users need to be satisfied despite of changes in service usage context and provisioning platform. The problem is (a) to adequately verify qualitative expectations after migration and (b) to optimize service provisioning respectively. In this position paper we discuss an adaptive API testing approach for reusable application services and APIs. Our work builds on a case study of application service reuse and migration at SAP SE. Subsequently, we propose performance contracts as a means to capture non-functional application requirements on user level. We utilize these contracts for consumer-driven API testing in order to verify and optimize the migration of services to different application contexts."
Deterministic High-Level Executable Models Allowing Efficient Runtime Verification,Model-Driven Engineering and Software Development,,,,10.1007/978-3-319-94764-8_6,Vladimir Estivill-CastroRené Hexel,2018,http://link.springer.com/chapter/10.1007/978-3-319-94764-8_6,Chapter,"Logic-labeled finite state machines, Model-driven software development, Run-time verification",10,"We present an architecture that enables run-time verification with executable models of behaviour. Our uniform modelling paradigm is logic-labelled finite-state machines (LLFSMs). Behaviours are constructed by parameterizable, loadable, and suspendable LLFSMs executed in predictable sequential schedules, but they are also verified at run-time by LLFSMs as well. Our architecture enables runtime verification (to monitor the quality of software during execution) as well as set up, tear down, and enforcement of quality behaviour during runtime. The LLFSMs models are executable and efficient because they are compiled (not interpreted). The LLFSMs can be derived from requirement engineering approaches such as behaviour trees, and also validated using test-driven development. However, in situations where software evolves incorporating elements of adaptive systems or machine learning, the software in execution may have never existed during development. We demonstrate the features of the architecture with illustrative case studies from robotics and embedded systems."
Test Derivation for SDN-Enabled Switches: A Logic Circuit Based Approach,Testing Software and Systems,,,,10.1007/978-3-319-99927-2_7,Jorge LópezNatalia KushikAsma BerririNina YevtushenkoDjamal Zeghlache,2018,http://link.springer.com/chapter/10.1007/978-3-319-99927-2_7,Chapter,"Logic circuits, Mutation testing, Run-time verification, SDN-enabled switches, Software Defined Networking (SDN)",10,"The paper is devoted to testing critical Software Defined Networking (SDN) components and in particular, SDN-enabled switches. A switch can be seen as a forwarding device with a set of configured rules and thus, can be modelled and analyzed as a ‘stateless’ system. Correspondingly, in this paper we propose to use appropriate logic circuits or networks to model the switch behavior. Both active and passive testing modes can benefit from such representation. First, this allows applying well-known test generation strategies such as for example, test derivation techniques targeting Single Stuck-at Faults (SSFs). We also specify a number of mutation operators for switch rules and propose an algorithm for eliminating equivalent mutants via SAT solving. Logic circuits simulating the behavior of the switches can be effectively utilized for run-time verification, and such logic circuit based approach is also discussed in the paper. Preliminary experimental results with Open vSwitch, on one hand, demonstrate the necessity of considering new fault models for logic circuits (apart from, for example well established SSFs) and on the other hand, confirm the efficiency of the proposed test generation and verification techniques."
Towards ‘Verifying’ a Water Treatment System,Formal Methods,,,,10.1007/978-3-319-95582-7_5,Jingyi WangJun SunYifan JiaShengchao QinZhiwu Xu,2018,http://link.springer.com/chapter/10.1007/978-3-319-95582-7_5,Chapter,,10,"Modeling and verifying real-world cyber-physical systems is challenging, which is especially so for complex systems where manually modeling is infeasible. In this work, we report our experience on combining model learning and abstraction refinement to analyze a challenging system, i.e., a real-world Secure Water Treatment system (SWaT). Given a set of safety requirements, the objective is to either show that the system is safe with a high probability (so that a system shutdown is rarely triggered due to safety violation) or not. As the system is too complicated to be manually modeled, we apply latest automatic model learning techniques to construct a set of Markov chains through abstraction and refinement, based on two long system execution logs (one for training and the other for testing). For each probabilistic safety property, we either report it does not hold with a certain level of probabilistic confidence, or report that it holds by showing the evidence in the form of an abstract Markov chain. The Markov chains can subsequently be implemented as runtime monitors in SWaT."
Leveraging Smart Environments for Runtime Resources Management,Software Quality: Methods and Tools for Better Software and Systems,,,,10.1007/978-3-319-71440-0_10,Paolo BarsocchiAntonello CalabróFrancesca LonettiEda MarchettiFilippo Palumbo,2018,http://link.springer.com/chapter/10.1007/978-3-319-71440-0_10,Chapter,"Access control policy, Monitoring, Sensors, Smart environment",10,"Smart environments (SE) have gained widespread attention due to their flexible integration into everyday life. Applications leveraging the smart environments rely on regular exchange of critical information and need accurate models for monitoring and controlling the SE behavior. Different rules are usually specified and centralized for correlating sensor data, as well as managing the resources and regulating the access to them, thus avoiding security flaws. In this paper, we propose a dynamic and flexible infrastructure able to perform runtime resources’ management by decoupling the different levels of SE control rules. This allows to simplify their continuous updating and improvement, thus reducing the maintenance effort. The proposed solution integrates low cost wireless technologies and can be easily extended to include other possible existing equipments. A first validation of the proposed infrastructure on a case study is also presented."
Are Your Requirements Covered?,Software Quality: Methods and Tools for Better Software and Systems,,,,10.1007/978-3-319-71440-0_6,Richard Mordinyi,2018,http://link.springer.com/chapter/10.1007/978-3-319-71440-0_6,Chapter,"Coverage, Issue tracking system, Requirement, Test scenario, Testing, Version control system",10,"The coverage of requirements is a fundamental need throughout the software life cycle. It gives project managers an indication how well the software meets expected requirements. A precondition for the process is to link requirements with project artifacts, like test cases. There are various (semi-) automated methods deriving traceable relations between requirements and test scenarios aiming to counteract time consuming and error-prone manual approaches. However, even if traceability links are correctly established coverage is calculated based on passed test scenarios without taking into account the overall code base written to realize the requirement in the first place. In this paper the “Requirements-Testing-Coverage” (ReTeCo) approach is described that establishes links between requirements and test cases by making use of knowledge available in software tools supporting the software engineering process and are part of the software engineering tool environment. In contrast to traditional approaches ReTeCo generates traceability links indirectly by gathering and analyzing information from version control system, ticketing system and test coverage tools. Since the approach takes into account a larger information base it is able to calculate coverage reports on a fine-grained contextual level rather than on the result of high-level artifacts."
Developers’ Initial Perceptions on TDD Practice: A Thematic Analysis with Distinct Domains and Languages,Agile Processes in Software Engineering and Extreme Programming,,,,10.1007/978-3-319-91602-6_5,Joelma ChomaEduardo M. GuerraTiago Silva da Silva,2018,http://link.springer.com/chapter/10.1007/978-3-319-91602-6_5,Chapter,"Qualitative study, TDD, Test-driven development, Test-first programming, Thematic analysis",10,"Test-Driven Development (TDD) is one of the most popular agile practices among software developers. To investigate the software developers’ initial perceptions when applying TDD, we have performed an exploratory study. This study was carried out with participants who had about ten years of professional experience (on average), the majority of whom with no experience using TDD. The study is in the context of an agile project course at the postgraduate level of a research institute. Participants individually developed medium size projects addressed to different domains and using different programming languages. Through a structured questionnaire with open and semi-open questions, we collected information on TDD effects such as the perceived benefits, encountered difficulties, and developer’s opinion about the quality improvement of the software. Afterward, we conducted a thematic analysis of the qualitative data. Most participants noticed improvements in code quality, but few have a more comprehensive view of the effects of TDD on software design. Our findings suggest that after overcoming the initial difficulties to understand where to start, and know how to create a test for a feature that does not yet exist, participants gain greater confidence to implement new features and make changes due to broad test coverage."
Theoretical Aspects of Consumer Metrics for Safety & Privacy,"Systems, Software and Services Process Improvement",,,,10.1007/978-3-319-97925-0_54,Thomas FehlmannEberhard Kranich,2018,http://link.springer.com/chapter/10.1007/978-3-319-97925-0_54,Chapter,"Functional size, Software metrics, Software testing, Test coverage, Test goals, Test intensity, Test size",10,"Software metrics are a matter of academic interest. Consumers, software developers, and other practitioners seem less interested in functional size than, maybe, in quality metrics. Functional size is useful for predicting cost of development; however, with today’s software development techniques and wide availability of open software, its size has become less important. Today, compliance, usability, and connectivity, are the most important cost drivers when developing software-intense products. However, functional size is essential for software testing. This is not yet widely accepted because today’s best practices in testing focus on code coverage. However, software must be tested against functionality. Code is usually not available for cloud functionality such as map services. Software-intense products, for instance when driving autonomous vehicles, or powering robots for daily life, rely on functionality from various origins, not on embedded software alone. This paper sketches the theoretical framework for software metrics that help consumers assessing the level of safety and privacy of their software."
Towards Minimizing the Impact of Changes Using Search-Based Approach,Search-Based Software Engineering,,,,10.1007/978-3-319-99241-9_14,Bogdan KorelNada AlmasriLuay Tahat,2018,http://link.springer.com/chapter/10.1007/978-3-319-99241-9_14,Chapter,"Extended finite state machine, Impact analysis, Model transformation, Search-based software engineering",10,"Software maintenance is becoming more challenging with the increased complexity of the software and the frequently applied modifications. To manage this complexity, systems development is headed towards Model-driven engineering (MDE) and search-based software engineering (SBSE). Additionally, prior to applying a change to these complex systems, change impact analysis is usually performed in order to determine the scope of the change, its feasibility, and the time and resources required to implement the change. The bigger the scope, the riskier the change is on the system. In this paper, we introduce a set of transformation rules for Extended Finite State Machine (EFSM) models of state-based systems. These transformation rules can be used as the basis for search-based model optimization in order to reduce the average impact of a potential change applied to an EFSM model. Assuming that Model-driven development is adopted for the implementation of a state-based system, reducing the change impact at the model level will lead to reducing the impact at the system level. An exploratory study is performed to measure the impact reduction for a given EFSM model when the transformation rules are applied by a search-based algorithm. The initial results show a promising usage of the transformation rules which can lead to a reduction of more than 50% of the initial average change impact of the model."
Under-Approximation Generation Driven by Relevance Predicates and Variants,Tests and Proofs,,,,10.1007/978-3-319-92994-1_4,J. JulliandO. KouchnarenkoP.-A. MassonG. Voiron,2018,http://link.springer.com/chapter/10.1007/978-3-319-92994-1_4,Chapter,"Loop variant, Predicate abstraction, Relevance predicate, Under-approximation generation",10,"In test generation, when computing a reachable concrete under-approximation of an event system’s predicate abstraction, we aim at covering each reachable abstract transition with at least one reachable concrete instance. As this is in general undecidable, an algorithm must finitely instantiate the abstract transitions for it to terminate. The approach defended in this paper is to first concretely explore the abstract graph, while concretizing the abstract transitions met at most once. However, some abstract transitions would require that loops were taken previously for them to become reached. To this end, in a second phase, a test engineer guides the exploration by describing a relevance predicate able to travel such loops. We give hints on how to design and express a relevance predicate, and provide a method for automatically extracting a variant out of it. A relevance guided concretization algorithm is given, whose termination is ensured by using this variant. Experimental results are provided that show the interest of the approach."
Conformance Testing and Inference of Embedded Components,Testing Software and Systems,,,,10.1007/978-3-319-99927-2_10,Alexandre PetrenkoFlorent Avellaneda,2018,http://link.springer.com/chapter/10.1007/978-3-319-99927-2_10,Chapter,"Active inference, Component-based systems, Conformance testing, Embedded testing, FSM learning, SAT solving, Testing in context",10,"The problems of active inference (learning) and conformance testing of a system modelled by an automaton have actively been studied for decades, however, much less attention has been paid to modular systems, modelled by communicating automata. In this paper, we consider a system of two communicating FSMs, one machine represents an embedded component and another the remaining part of the system, the context. Assuming that the context FSM is known, we want to learn the embedded FSM without directly interacting with it. This problem can be viewed as a generalization of the classical automata inference in isolation, i.e., it is the grey box learning problem. The proposed approach to solve this problem relies on a SAT-solving method for FSM inference from traces. It does not depend on the composition topology and allows at the same time to solve a related problem of conformance testing in context. The latter is to test whether an embedded implementation FSM composed with the given context is equivalent to the embedded specification FSM also composed with the context. The novelty of the conformance testing method is that it directly generates a complete test suite for the embedded machine and avoids using nondeterministic approximations with their tests, eliminating thus several sources of test redundancy inherent in the existing methods."
PIAnalyzer: A Precise Approach for PendingIntent Vulnerability Analysis,Computer Security,,,,10.1007/978-3-319-98989-1_3,Sascha GroßAbhishek TiwariChristian Hammer,2018,http://link.springer.com/chapter/10.1007/978-3-319-98989-1_3,Chapter,"Android, Information flow control, Intent analysis, Static analysis",10,"PendingIntents are a powerful and universal feature of Android for inter-component communication. A PendingIntent holds a base intent to be executed by another application with the creator’s permissions and identity without the creator necessarily residing in memory. While PendingIntents are useful for many scenarios, e.g., for setting an alarm or getting notified at some point in the future, insecure usage of PendingIntents causes severe security threats in the form of denial-of-service, identity theft, and privilege escalation attacks. An attacker may gain up to SYSTEM privileges to perform the most sensitive operations, e.g., deleting user’s data on the device. However, so far no tool can detect these PendingIntent vulnerabilities. In this work we propose PIAnalyzer, a novel approach to analyze PendingIntent related vulnerabilities. We empirically evaluate PIAnalyzer on a set of 1000 randomly selected applications from the Google Play Store and find 1358 insecure usages of PendingIntents, including 70 severe vulnerabilities. We manually inspected ten reported vulnerabilities out of which nine correctly reported vulnerabilities, indicating a high precision. The evaluation shows that PIAnalyzer is efficient with an average execution time of 13 seconds per application."
Measuring and Evaluating the Performance of Self-Organization Mechanisms Within Collective Adaptive Systems,"Leveraging Applications of Formal Methods, Verification and Validation. Distributed Systems",,,,10.1007/978-3-030-03424-5_14,Benedikt EberhardingerHella PonsarDominik KlumppWolfgang Reif,2018,http://link.springer.com/chapter/10.1007/978-3-030-03424-5_14,Chapter,,10,"By restructuring and reconfiguring itself at run-time, a collective adaptive system (CAS) is able to fulfill its requirements under uncertain, ever-changing environmental conditions. Indeed, this process of self-organization (SO) is of utmost importance for the ability of the CAS to perform. However, it is hard to design high-performing SO mechanisms, because the environmental conditions are partially unpredictable at design time. Thus, a crucial aid for the development of SO mechanisms is a tool set enabling performance evaluations at design time in order to select the best-fitting mechanism and parametrize it. We present a metric for measuring the performance of an SO mechanism as well as a framework that enables evaluation of this metric. The proposed metric is evaluated for different kinds of SO mechanisms in two case studies: a smart energy management system and a self-organizing production cell."
Test Case Generation with PathCrawler/LTest: How to Automate an Industrial Testing Process,"Leveraging Applications of Formal Methods, Verification and Validation. Industrial Practice",,,,10.1007/978-3-030-03427-6_12,Sébastien BardinNikolai KosmatovBruno MarreDavid MentréNicky Williams,2018,http://link.springer.com/chapter/10.1007/978-3-030-03427-6_12,Chapter,,10,"Automatic white-box testing based on formal methods is now a relatively mature technology and operational tools are available. Despite this, and the cost of manual testing, the technology is still rarely applied in an industrial setting. This paper describes how the specific needs of the user can be taken into account in order to build the necessary interface with a generic test tool. We present P ath C rawler /LT est , a generator of test inputs for structural coverage of C functions, recently extended to support labels. Labels offer a generic mechanism for specification of code coverage criteria and make it possible to prototype and implement new criteria for specific industrial needs. We describe the essential participation of the research branch of an industrial user in bridging the gap between the tool developers and their business unit and adapting P ath C rawler /LT est to the needs of the latter. We present the excellent results so far of their ongoing adoption and finish by mentioning possible improvements."
Effective Analysis of Attack Trees: A Model-Driven Approach,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-319-89363-1_4,Rajesh KumarStefano SchivoEnno RuijtersBuǧra Mehmet YildizDavid HuistraJacco BrandtArend RensinkMariëlle Stoelinga,2018,http://link.springer.com/chapter/10.1007/978-3-319-89363-1_4,Chapter,,10,"Attack trees (ATs) are a popular formalism for security analysis, and numerous variations and tools have been developed around them. These were mostly developed independently, and offer little interoperability or ability to combine various AT features. We present ATTop, a software bridging tool that enables automated analysis of ATs using a model-driven engineering approach. ATTop fulfills two purposes: 1. It facilitates interoperation between several AT analysis methodologies and resulting tools (e.g., ATE, ATCalc, ADTool 2.0), 2. it can perform a comprehensive analysis of attack trees by translating them into timed automata and analyzing them using the popular model checker Uppaal , and translating the analysis results back to the original ATs. Technically, our approach uses various metamodels to provide a unified description of AT variants. Based on these metamodels, we perform model transformations that allow to apply various analysis methods to an AT and trace the results back to the AT domain. We illustrate our approach on the basis of a case study from the AT literature."
Design-Time to Run-Time Verification of Microservices Based Applications,Software Engineering and Formal Methods,,,,10.1007/978-3-319-74781-1_12,Matteo CamilliCarlo BellettiniLorenzo Capra,2018,http://link.springer.com/chapter/10.1007/978-3-319-74781-1_12,Chapter,"Cloud applications, Formal methods @ runtime, Formal verification, Microservices, Petri nets",10,"Microservice based architectures have started to gain in popularity and are often adopted in the implementation of modern cloud, IoT, and large-scale distributed applications. Software life cycles, in this context, are characterized by short iterations, where several updates and new functionalities are continuously integrated many times a day. This paradigm shift calls for new formal approaches to systematic verification and testing of applications in production infrastructures. We introduce an approach to continuous, design- to run-time verification , of microservice based applications. This paper describes our envisioned approach, the current stage of this ongoing work, and the challenges ahead."
xR-Based Systems for Mindfulness Based Training in Clinical Settings,"Virtual, Augmented and Mixed Reality: Applications in Health, Cultural Heritage, and Industry",,,,10.1007/978-3-319-91584-5_3,Mark R. CostaDessa Bergen-CicoRocio HererroJessica NavarroRachel RazzaQiu Wang,2018,http://link.springer.com/chapter/10.1007/978-3-319-91584-5_3,Chapter,"Meditation, Mindfulness, Mixed reality, Virtual reality, Wellness",10,"Chronic and acute stress are persistent and troubling health concerns for many people and military veterans in particular. Clinicians are increasingly turning to mindfulness techniques to provide people with the skills they need to self-manage that stress. However, training and getting people to adhere to the practice is difficult. In this paper, we talk about a virtual reality based system designed specifically to help veterans learn mindfulness-based stress reduction techniques."
Design Approaches for Critical Embedded Systems: A Systematic Mapping Study,Evaluation of Novel Approaches to Software Engineering,,,,10.1007/978-3-319-94135-6_12,Daniel FeitosaApostolos AmpatzoglouParis AvgeriouFrank J. AffonsoHugo AndradeKatia R. FelizardoElisa Y. Nakagawa,2018,http://link.springer.com/chapter/10.1007/978-3-319-94135-6_12,Chapter,"Critical embedded system, Design, Systematic mapping study",10,"Critical Embedded Systems (CES) are systems in which failures are potentially catastrophic and, therefore, hard constraints are imposed on them. In the last years the amount of software accommodated within CES has considerably changed. For example, in smart cars the amount of software has grown about 100 times compared to previous years. This change means that software design for these systems is also bounded to hard constraints (e.g., high security and performance). Along the evolution of CES, the approaches for designing them are also changing rapidly, so as to fit the specialized needs of CES. Thus, a broad understanding of such approaches is missing. Therefore, this study aims to establish a fair overview on CESs design approaches. For that, we conducted a Systematic Mapping Study (SMS), in which we collected 1,673 papers from five digital libraries, filtered 269 primary studies, and analyzed five facets: design approaches, applications domains, critical quality attributes, tools, and type of evidence. Our findings show that the body of knowledge is vast and overlaps with other types of systems (e.g., real-time or cyber-physical systems). In addition, we have observed that some critical quality attributes are common among various application domains, as well as approaches and tools are oftentimes generic to CES."
Using a Formal B Model at Runtime in a Demonstration of the ETCS Hybrid Level 3 Concept with Real Trains,"Abstract State Machines, Alloy, B, TLA, VDM, and Z",,,,10.1007/978-3-319-91271-4_20,Dominik HansenMichael LeuschelDavid SchneiderSebastian KringsPhilipp KörnerThomas NaulinNader NayeriFrank Skowron,2018,http://link.springer.com/chapter/10.1007/978-3-319-91271-4_20,Chapter,"Animation, B-method, ETCS, Model-based testing",10,"In this article, we present a concrete realisation of the ETCS Hybrid Level 3 concept, whose practical viability was evaluated in a field demonstration in 2017. Hybrid Level 3 (HL3) introduces Virtual Sub-Sections (VSS) as sub-divisions of classical track sections with Trackside Train Detection (TTD). Our approach introduces an add-on for the Radio Block Centre (RBC) of Thales, called Virtual Block Function (VBF), which computes the occupation states of the VSSs according to the HL3 concept using the train position reports, train integrity information, and the TTD occupation states. From the perspective of the RBC, the VBF behaves as an Interlocking (IXL) that transmits all signal aspects for virtual signals introduced for each VSS to the RBC. We report on the development of the VBF, implemented as a formal B model executed at runtime using ProB and successfully used in a field demonstration to control real trains."
Robotics and Integrated Formal Methods: Necessity Meets Opportunity,Integrated Formal Methods,,,,10.1007/978-3-319-98938-9_10,Marie FarrellMatt LuckcuckMichael Fisher,2018,http://link.springer.com/chapter/10.1007/978-3-319-98938-9_10,Chapter,"Agent Programming Language, Probabilistic Temporal Logic (PTL), Robot Swarm, Robotic Systems, Safety Case",10,"Robotic systems are multi-dimensional entities, combining both hardware and software, that are heavily dependent on, and influenced by, interactions with the real world. They can be variously categorised as embedded, cyber-physical, real-time, hybrid, adaptive and even autonomous systems, with a typical robotic system being likely to contain all of these aspects. The techniques for developing and verifying each of these system varieties are often quite distinct. This, together with the sheer complexity of robotic systems, leads us to argue that diverse formal techniques must be integrated in order to develop, verify, and provide certification evidence for, robotic systems. Furthermore, we propose the fast evolving field of robotics as an ideal catalyst for the advancement of integrated formal methods research, helping to drive the field in new and exciting directions and shedding light on the development of large-scale, dynamic, complex systems."
Android Stack Machine,Computer Aided Verification,,,,10.1007/978-3-319-96142-2_29,Taolue ChenJinlong HeFu SongGuozhen WangZhilin WuJun Yan,2018,http://link.springer.com/chapter/10.1007/978-3-319-96142-2_29,Chapter,,10,"In this paper, we propose Android Stack Machine (ASM), a formal model to capture key mechanisms of Android multi-tasking such as activities, back stacks, launch modes, as well as task affinities. The model is based on pushdown systems with multiple stacks, and focuses on the evolution of the back stack of the Android system when interacting with activities carrying specific launch modes and task affinities. For formal analysis, we study the reachability problem of ASM. While the general problem is shown to be undecidable, we identify expressive fragments for which various verification techniques for pushdown systems or their extensions are harnessed to show decidability of the problem."
Foundation of a Framework to Support Compliance Checking in Construction Industry,Structured Object-Oriented Formal Language and Method,,,,10.1007/978-3-319-90104-6_7,Wuwei ShenGuangyuan LiChung-Ling LinHongliang Liang,2018,http://link.springer.com/chapter/10.1007/978-3-319-90104-6_7,Chapter,"Class diagram, Compliance checking, Conformance checking, Instance diagram, International codes",10,"Computer use is pervasive in our daily life and the increasing demand for computer applications has penetrated into various domains. Construction industry has become one of domains which are more reliable on the application of computer to implement regulatory compliance checking. Like many safety critical domains, the construction domain has its own set of international building codes on construction projects which must comply with. With the increasing complexity of construction projects, many manual compliance checking techniques have shown some serious issues. First, the manual techniques are error-prone due to human errors. Second, the complexity of a construction project exceeds the human limit to deal with. Third, the evolution of a construction project is inevitable and the human maintenance of a construction project is almost impossible because either the memory of the original project design has faked away or some development team members are gone. So, it has become a new trend to employ computers to support automatic regulatory compliance checking in construction industry. In this paper, we propose a novel framework to support compliance checking with the emphasis on the foundation of automatic regulatory compliance checking to certify whether a construction project complies with some international building codes. An example is illustrated how compliance checking is performed in the framework."
Towards a Runtime Verification Approach for Internet of Things Systems,Current Trends in Web Engineering,,,,10.1007/978-3-030-03056-8_8,Maurizio LeottaDavide AnconaLuca FranceschiniDario OlianasMarina RibaudoFilippo Ricca,2018,http://link.springer.com/chapter/10.1007/978-3-030-03056-8_8,Chapter,"Input Scenarios, Mobile Health, Runtime Veriﬁcation, Things Systems, Trace Expression",10,"Internet of Things systems are evolving at a rapid pace and their impact on our society grows every day. In this context developing IoT systems that are reliable and compliant with the requirements is of paramount importance. Unfortunately, few proposals for assuring the quality of these complex and often safety-critical systems are present in the literature. To this aim, runtime verification can be a valuable support to tackle such a complex task and to complement other software verification techniques based on static analysis and testing. This paper is a first step towards the application of runtime verification to IoT systems. In particular, we describe our approach based on a Prolog monitor, the definition of a formal specification (using trace expressions) describing the expected behaviour of the system, and the definition of appropriate input scenarios. Furthermore, we describe its application and preliminary evaluation using a simplified mobile health IoT system for the management of diabetic patients composed by sensors, actuators, Node-RED logic on the cloud, and smartphones."
Generative Model Driven Design for Agile System Design and Evolution: A Tale of Two Worlds,Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-030-00244-2_1,Tiziana Margaria,2018,http://link.springer.com/chapter/10.1007/978-3-030-00244-2_1,Chapter,,10,"In order to mainstream the production and evolution of IT at the levels of speed, scale, affordability and collaborative effort needed to truly make IT enter the fabric of every economical and societal endeavour, as is the projected future of our society in the next decade, the ease of learning, understanding, and applying new disruptive technologies must drastically improve. We argue that the needs of the people, the economical sectors, and the large-scale trends can only be met if the IT professions embrace and adopt a new way of producing and consuming IT, based on more formal descriptions, more models, more reasoning and analysis before expensive implementations are incurred, coupled with automatic transformations, generations, and analyses that take advantage of the models and formalized knowledge. We analyse briefly the various dimensions, derive a specification for the new IT and IT platforms, and provide a few examples of how the new thinking can disrupt the status quo but empower a better understanding, a more efficient organization, and a more automatic management of the many cross-dimensional issues that future connected software and systems will depend upon."
Using Abstraction with Interaction Sequences for Interactive System Modelling,Software Technologies: Applications and Foundations,,,,10.1007/978-3-030-04771-9_20,Jessica TurnerJudy BowenSteve Reeves,2018,http://link.springer.com/chapter/10.1007/978-3-030-04771-9_20,Chapter,"Formal methods, Interaction sequences, Interactive system testing",10,"Interaction sequences can be used as an abstraction of an interactive system. We can use such models to consider or verify properties of a system for testing purposes. However, interaction sequences have the potential to become unfeasibly long, leading to models which are intractable. We propose a method of reducing the state space of such sequences using the self-containment property. This allows us to hide (and subsequently expand) some of the model describing parts of the system not currently under consideration. Interaction sequences and their models can therefore be used to control the state space size of the models we create as an abstraction of an interactive system."
A Vision for Enhancing Security of Cryptography in Executables,Engineering Secure Software and Systems,,,,10.1007/978-3-319-94496-8_1,Otto BrechelmacherWillibald KrennThorsten Tarrach,2018,http://link.springer.com/chapter/10.1007/978-3-319-94496-8_1,Chapter,"Binary Rewriting, Crypto Functions, DynamoRIO, Runtime Manipulation, Symbolic Analysis Framework",10,"This paper proposes an idea on how to use existing techniques from late stage software customization to improve the security of software employing cryptographic functions. In our vision, we can verify an implemented algorithm and replace it with a faster or more trusted implementation if necessary. We also want to be able to add encryption to binaries that currently do not employ any, or gain access to unencrypted data if an application depends on encryption. To corroborate the feasibility of our vision, we developed a prototype that is able to identify cryptographic functions in highly optimized binary code and tests the identified functions for functional correctness, potentially also revealing backdoors."
Lightweight Verifiable Auditing for Outsourced Database in Cloud Computing,Distributed Computing and Internet Technology,,,,10.1007/978-3-319-72344-0_23,Mayank KumarSyam Kumar Pasupuleti,2018,http://link.springer.com/chapter/10.1007/978-3-319-72344-0_23,Chapter,"Cloud computing, Database, Embedded Merkle B tree, Lightweight homomorhic encryption",10,"Database outsourcing in Cloud Computing enables the data owner to store the data on cloud and assign the management to a cloud service provider (CSP), which provides various cloud services to the users. However, outsourcing database to cloud poses many challenges. One of the major concerns is confidentiality of the data. The general approach to tackle this issue is by encrypting the database before outsourcing, this helps in protecting confidentiality but poses a new problem of verifying the search results. We propose a lightweight verifiable auditing scheme for secure outsourcing of database, which encrypts the database and verifies search results with both parameters of correctness and completeness. We design our scheme based on a lightweight homomorphic encryption scheme (LHE) and efficient authenticated data structures to ensure the confidentiality and integrity of the database respectively."
A Model-Based Testing Method for Dynamic Aspect-Oriented Software,Computational Science and Its Applications – ICCSA 2017,,,,10.1007/978-3-319-62407-5_7,Maria Laura Pires SouzaFábio Fagundes Silveira,2017,http://link.springer.com/chapter/10.1007/978-3-319-62407-5_7,Chapter,"Dynamic aspect-oriented, Model-based testing, Mutation testing",10,"Aspect-oriented programming (AOP) is used to implement crosscutting concerns such as persistence and safety in program units called aspects. To ensure that these concerns behave as specified and do not introduce faults into the application, rigorous software testing practices should be applied. Even though there are statements in the literature that the adoption of AOP takes a software to get better quality, it does not provide correctness by itself. Therefore, the test remains an important activity to ensure aspects are correctly integrated into the main system. Additionally, in a dynamic environment: new aspects may be incompatible with aspects already woven; and aspects to be removed can hold the system to an inconsistent state. Available approaches in the literature do not directly investigate the problem of testing dynamic aspects within the context of a target application. This paper presents a method to apply tests in dynamic aspects that verify the interactions between aspects and classes, as well as among aspects. Aiming to support the method, we also introduce a model to represent the dynamic behavior of aspects and a new strategy to derive testing cases. To evaluate the effectiveness of the test cases generated by the method, mutation operators were applied to the model and simulated with a model checker. Results showed that the approach is capable of detecting faults in dynamic aspects interactions into a target application."
Model-Based Testing for Asynchronous Systems,Critical Systems: Formal Methods and Automated Verification,,,,10.1007/978-3-319-67113-0_5,Alexander Graf-BrillHolger Hermanns,2017,http://link.springer.com/chapter/10.1007/978-3-319-67113-0_5,Chapter,,10,"Model-based testing is a prominent validation technique, integrating well with other formal approaches to verification, such as model checking. Automated test derivation and execution approaches often struggle with asynchrony in communication between the implementation under test (IUT) and tester, a phenomenon present in most networked systems. Earlier attacks on this problem came with different restrictions on the specification model side. This paper presents a new and effective approach to model-based testing under asynchrony. By waiving the need to guess the possible output state of the IUT, we reduce the computational effort of the test generation algorithm while preserving soundness and conceptual completeness of the testing procedures. In addition, no restrictions on the specification model need to be imposed. We define a suitable conformance relation and we report on empirical results obtained from an industrial case study from the domain of electric mobility."
WSCLim: A Tool for Model-Based Testing of WS-BPEL Compositions Under Load Conditions,Tests and Proofs,,,,10.1007/978-3-319-61467-0_9,Afef Jmal MaâlejMoez KrichenMohamed Jmaïel,2017,http://link.springer.com/chapter/10.1007/978-3-319-61467-0_9,Chapter,"Load testing, Log analysis, Performance monitoring, Timed Automata, Web services composition",10,"Web services compositions must provide different utilities to hundreds even thousands of users simultaneously. An important challenge of testing these applications is load testing. For this purpose, we proposed in a previous work a test architecture aiming to study the limitations of WS-BPEL compositions under load conditions. We also concretized our solution by implementing a tool support (WSCLim). We introduce in this paper a case study on Hospital Blood Ordering for Transfusion Purposes in order to best illustrate our solution."
Learning-Based Testing for Safety Critical Automotive Applications,Model-Based Safety and Assessment,,,,10.1007/978-3-319-64119-5_13,Hojat KhosrowjerdiKarl MeinkeAndreas Rasmusson,2017,http://link.springer.com/chapter/10.1007/978-3-319-64119-5_13,Chapter,"Automotive software, Black-box testing, Learning-based testing, Machine learning, Model-based testing, Requirements testing, Temporal logic",10,"Learning-based testing (LBT) is an emerging paradigm for fully automated requirements testing. This approach combines machine learning and model-checking techniques for test case generation and verdict construction. LBT is well suited to requirements testing of low-latency safety critical embedded systems, such as can be found in the automotive sector. We evaluate the feasibility and effectiveness of applying LBT to two safety critical industrial automotive applications. We also benchmark our LBT tool against an existing industrial test tool that executes manually written test cases."
Fault-Based Testing for Refinement in CSP,Testing Software and Systems,,,,10.1007/978-3-319-67549-7_2,Ana CavalcantiAdenilso Simao,2017,http://link.springer.com/chapter/10.1007/978-3-319-67549-7_2,Chapter,,10,"The process algebra CSP has been studied as a modeling notation for test derivation. Work has been developed using its trace and failure semantics, and their refinement notions as conformance relations. In this paper, we propose a procedure for online test generation for selection of finite test sets for traces refinement from CSP models, based on the notion of fault domains, that is, focusing on the set of faulty implementations of interest. We investigate scenarios where the verdict of a test campaign can be reached after a finite number of test executions. We illustrate the usage of the procedure with a small case study."
Learning-Based Testing the Sliding Window Behavior of TCP Implementations,Critical Systems: Formal Methods and Automated Verification,,,,10.1007/978-3-319-67113-0_12,Paul Fiterău-BroşteanFalk Howar,2017,http://link.springer.com/chapter/10.1007/978-3-319-67113-0_12,Chapter,"Learning-based Testing, Register Automata, System Under Test (SUT), Tree Oracle, Window Behavior",10,"We develop a learning-based testing framework for register automaton models that can express the windowing behavior of TCP, thereby presenting the first significant application of register automata learning to realistic software for a class of automata with Boolean-arithmetic constraints over data values. We have applied our framework to TCP implementations belonging to different operating systems and have found a violation of the TCP specification in Linux and Windows. The violation has been confirmed by Linux developers."
Learning-Based Testing of Cyber-Physical Systems-of-Systems: A Platooning Study,Computer Performance Engineering,,,,10.1007/978-3-319-66583-2_9,Karl Meinke,2017,http://link.springer.com/chapter/10.1007/978-3-319-66583-2_9,Chapter,"Cyber-physical system, Learning-based testing, Machine learning, Model-based testing, Platooning, Requirements testing, System-of-systems",10,"Learning-based testing (LBT) is a paradigm for fully automated requirements testing that combines machine learning with model-checking techniques. LBT has been shown to be effective for unit and integration testing of safety critical components in cyber-physical systems, e.g. automotive ECU software. We consider the challenges faced, and some initial results obtained in an effort to scale up LBT to testing co-operative open cyber-physical systems-of-systems (CO-CPS). For this we focus on a case study of testing safety and performance properties of multi-vehicle platoons."
A Comparative Study of Software Testing Techniques,Networked Systems,,,,10.1007/978-3-319-59647-1_27,Meriem AtifiAbdelaziz MamouniAbdelaziz Marzak,2017,http://link.springer.com/chapter/10.1007/978-3-319-59647-1_27,Chapter,"Model-based testing, Risk-based testing, Software systems, Software testing, Software testing approaches",10,"Nowadays, software systems have become an essential element in our daily life. To ensure the quality and operation of software, testing activities have become primordial in the software development life cycle (SDLC). Indeed, software bugs can potentially cause dramatic consequences if the product is released to the end user without testing. The software testing role is to verify that the actual result and the expected result are consistent and ensure that the system is delivered without bugs. Many techniques, approaches and tools have been proposed to help check that the system is defect free. In this paper, we highlight two software testing techniques considered among the most used techniques to perform software tests, and then we perform a comparative study of these techniques, the approaches that supports studied techniques, and the tools used for each technique. We have selected the first technique based on the 2014 survey [ 62 ] that heighted the motivations for using the Model-based-testing, and by analyzing the survey results we have found that some MBT limits are benefits in Risk based testing, the second technique in our study."
Security of Web Application: State of the Art,"Information, Communication and Computing Technology",,,,10.1007/978-981-10-6544-6_17,Habib ur RehmanMohammed NazirKhurram Mustafa,2017,http://link.springer.com/chapter/10.1007/978-981-10-6544-6_17,Chapter,"Security testing approaches, Security testing limitations, Testing in industrial practices, Testing techniques, Web application security, Web testing",10,"As complexity inherent in web application is growing rapidly. Testing web applications with more sophisticated approaches is essentially needed. Several approaches for security testing are available, but only a few of them are appreciated in common IT industries and hence in practice. The paper recapitulates the current approaches, considering the limitations of real world applications. An effort has been made in the direction of bridging the gaps with the study of foremost web security concerns and the current web testing techniques, including their strengths and weaknesses. The paper highlights the security issues pertinent to web applications, along with actual practices in industries related to these issues. It also includes gap between practices and theories in the industry."
How is Security Testing Done in Agile Teams? A Cross-Case Analysis of Four Software Teams,Agile Processes in Software Engineering and Extreme Programming,,,,10.1007/978-3-319-57633-6_13,Daniela Soares CruzesMichael FeldererTosin Daniel OyetoyanMatthias GanderIrdin Pekaric,2017,http://link.springer.com/chapter/10.1007/978-3-319-57633-6_13,Chapter,"Agile testing, Case study research, Security testing",10,"Security testing can broadly be described as (1) the testing of security requirements that concerns confidentiality, integrity, availability, authentication, authorization, nonrepudiation and (2) the testing of the software to validate how much it can withstand an attack. Agile testing involves immediately integrating changes into the main system, continuously testing all changes and updating test cases to be able to run a regression test at any time to verify that changes have not broken existing functionality. Software companies have a challenge to systematically apply security testing in their processes nowadays. There is a lack of guidelines in practice as well as empirical studies in real-world projects on agile security testing; industry in general needs a more systematic approach to security. The findings of this research are not surprising, but at the same time are alarming. The lack of knowledge on security by agile teams in general, the large dependency on incidental pen-testers, and the ignorance in static testing for security are indicators that security testing is highly under addressed and that more efforts should be addressed to security testing in agile teams."
A Survey on Testing Distributed and Heterogeneous Systems: The State of the Practice,Software Technologies,,,,10.1007/978-3-319-62569-0_5,Bruno LimaJoão Pascoal Faria,2017,http://link.springer.com/chapter/10.1007/978-3-319-62569-0_5,Chapter,"Distributed systems, Heterogeneous systems, Software testing, State of the practice, Systems of systems",10,"Distributed and heterogeneous systems (DHS), running over interconnected mobile and cloud-based platforms, are used in a growing number of domains for provisioning end-to-end services to users. Testing DHS is particularly important and challenging, with little support being provided by current tools. In order to assess the current state of the practice regarding the testing of DHS and identify opportunities and priorities for research and innovation initiatives, we conducted an exploratory survey that was responded by 147 software testing professionals that attended industry-oriented software testing conferences. The survey allowed us to assess the relevance of DHS in software testing practice, the most important features to be tested in DHS, the current status of test automation and tool sourcing for testing DHS, and the most desired features in test automation solutions for DHS. Some follow up interviews allowed us to further investigate drivers and barriers for DHS test automation. We expect that the results presented in the paper are of interest to researchers, tool vendors and service providers in this field."
Exploratory Testing of Large-Scale Systems – Testing in the Continuous Integration and Delivery Pipeline,Product-Focused Software Process Improvement,,,,10.1007/978-3-319-69926-4_26,Torvald MårtenssonDaniel StåhlJan Bosch,2017,http://link.springer.com/chapter/10.1007/978-3-319-69926-4_26,Chapter,"Continuous delivery, Continuous integration, Exploratory testing, Large-scale systems, Software testing",10,"In this paper, we show how exploratory testing plays a role as part of a continuous integration and delivery pipeline for large-scale and complex software products. We propose a test method that incorporates exploratory testing as an activity in the continuous integration and delivery pipeline, and is based on elements from other testing techniques such as scenario-based testing, testing in teams and testing in time-boxed sessions. The test method has been validated during ten months by 28 individuals (21 engineers and 7 flight test pilots) in a case study where the system under test is a fighter aircraft. Quantitative data from the case study company shows that the exploratory test teams produced more problem reports than other test teams. The interview results show that both engineers and test pilots were generally positive or very positive when they described their experiences from the case study, and consider the test method to be an efficient way of testing the system in the case study."
Test Case/Step Minimization for Visual Programming Language Models and Its Application to Space Systems,Computational Science and Its Applications – ICCSA 2017,,,,10.1007/978-3-319-62407-5_11,Paulo Nolberto dos Santos AlarconValdivino Alexandre de Santiago Júnior,2017,http://link.springer.com/chapter/10.1007/978-3-319-62407-5_11,Chapter,"Model Checking, Model-Based Testing, Specification patterns, Test case/step minimization",10,"Visual Programming Languages have been widely used in the context of Model-Based Development, and they find a particular appeal for the design of satellite subsystems, such as the Attitude and Orbit Control Subsystem (AOCS) which is an extremely complex part of a spacecraft. The software testing community has been trying to ensure high quality products with as few defects as possible. Given that exhaustive generation and execution of software test cases are unfeasible in practice, one of the initiatives is to reduce the sets of test cases required to test a Software/System Under Test, while still maintaining the efficiency (ability to find product defects, code coverage). This paper presents a new methodology to generate test cases for Visual Programming Language models, aiming at minimizing the set of test cases/steps but maintaining efficiency. The approach, called specification Patterns, modified Condition/Decision coverage, and formal Verification to support Testing (PCDVT), combines the Modified Decision/Condition Coverage (MC/DC) criterion, Model Checking, specification patterns, and a minimization approach by identifying irreplaceable tests in a single method, taking advantage of the benefits of all these efforts in a unified strategy. Results showed that two instances of PCDVT presented a lower cost (smaller number of test steps) and, basically, the same efficiency (model coverage) if compared with a specialist ad hoc approach. We used the AOCS model of a Brazilian satellite in order to make the comparison between the methods."
Design Decisions in the Development of a Graphical Language for Risk-Driven Security Testing,Risk Assessment and Risk-Driven Quality Assurance,,,,10.1007/978-3-319-57858-3_8,Gencer ErdoganKetil Stølen,2017,http://link.springer.com/chapter/10.1007/978-3-319-57858-3_8,Chapter,"Domain-specific modeling language, Model-based testing, Risk-driven security testing, Security risk assessment",10,"We have developed a domain-specific modeling language named CORAL that employs risk assessment to help security testers select and design test cases based on the available risk picture. In this paper, we present CORAL and then discuss why the language is designed the way it is, and what we could have done differently."
Formal Verification of Financial Algorithms,Automated Deduction – CADE 26,,,,10.1007/978-3-319-63046-5_3,Grant Olney PassmoreDenis Ignatovich,2017,http://link.springer.com/chapter/10.1007/978-3-319-63046-5_3,Chapter,,10,"Many deep issues plaguing today’s financial markets are symptoms of a fundamental problem: The complexity of algorithms underlying modern finance has significantly outpaced the power of traditional tools used to design and regulate them. At Aesthetic Integration, we have pioneered the use of formal verification for analysing the safety and fairness of financial algorithms. With a focus on financial infrastructure (e.g., the matching logics of exchanges and dark pools and FIX connectivity between trading systems), we describe the landscape, and illustrate our Imandra formal verification system on a number of real-world examples. We sketch many open problems and future directions along the way."
An Approach for Isolated Testing of Self-Organization Algorithms,Software Engineering for Self-Adaptive Systems III. Assurances,,,,10.1007/978-3-319-74183-3_7,Benedikt EberhardingerGerrit AndersHella SeebachFlorian SiefertAlexander KnappWolfgang Reif,2017,http://link.springer.com/chapter/10.1007/978-3-319-74183-3_7,Chapter,"Adaptive systems, Quality assurance, Self-organization algorithms, Self-organizing systems, Software engineering, Software test",10,"We provide a systematic approach for testing self-organization (SO) algorithms. The main challenges for such a testing domain are the strongly ramified state space, the possible error masking, the interleaving of mechanisms, and the oracle problem resulting from the main characteristics of SO algorithms: their inherent non-deterministic behavior on the one hand, and their dynamic environment on the other. A key to success for our SO algorithm testing framework is automation, since it is rarely possible to cope with the ramified state space manually. The test automation is based on a model-based testing approach where probabilistic environment profiles are used to derive test cases that are performed and evaluated on isolated SO algorithms. Besides isolation, we are able to achieve representative test results with respect to a specific application. For illustration purposes, we apply the concepts of our framework to partitioning-based SO algorithms and provide an evaluation in the context of an existing smart-grid application."
Mutation Analysis of Stateflow to Improve the Modelling Analysis,Advances in Computing and Data Sciences,,,,10.1007/978-981-10-5427-3_19,Prachi GoyalManju NandaJ. Jayanthi,2017,http://link.springer.com/chapter/10.1007/978-981-10-5427-3_19,Chapter,"Formal methods, Mutation analysis, Safety critical systems, Stateflow integration",10,Formal methods possess great analyzing capability that has led to an increasing use by engineers in the development and verification-validation life-cycle of hardware and software critical systems. Mutation Analysis has been very effective in model design and safety analysis. In this paper primary idea is to integrate the mutation analysis of stateflow to the Integrated Mutation Analysis Tool. This enhanced property of the IMAT tool after integration will be able to analyze the functionalities of stateflow models of the highly critical systems. The effectiveness of the Stateflow mutation analysis can be validated using the case-study of Autopilot Mode Transition Logic.
Should We Learn Probabilistic Models for Model Checking? A New Approach and An Empirical Study,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-662-54494-5_1,Jingyi WangJun SunQixia YuanJun Pang,2017,http://link.springer.com/chapter/10.1007/978-3-662-54494-5_1,Chapter,"Genetic algorithm, Model learning, Probabilistic model checking",10,"Many automated system analysis techniques (e.g., model checking, model-based testing) rely on first obtaining a model of the system under analysis. System modeling is often done manually, which is often considered as a hindrance to adopt model-based system analysis and development techniques. To overcome this problem, researchers have proposed to automatically “learn” models based on sample system executions and shown that the learned models can be useful sometimes. There are however many questions to be answered. For instance, how much shall we generalize from the observed samples and how fast would learning converge? Or, would the analysis result based on the learned model be more accurate than the estimation we could have obtained by sampling many system executions within the same amount of time? In this work, we investigate existing algorithms for learning probabilistic models for model checking, propose an evolution-based approach for better controlling the degree of generalization and conduct an empirical study in order to answer the questions. One of our findings is that the effectiveness of learning may sometimes be limited."
Hardness of Deriving Invertible Sequences from Finite State Machines,SOFSEM 2017: Theory and Practice of Computer Science,,,,10.1007/978-3-319-51963-0_12,Robert M. HieronsMohammad Reza MousaviMichael Kirkedal ThomsenUraz Cengiz Türker,2017,http://link.springer.com/chapter/10.1007/978-3-319-51963-0_12,Chapter,"Finite Automaton, Finite State Machine, Generate Test Case, Input Sequence, System Under Test",10,"Many test generation algorithms use unique input/output sequences (UIOs) that identify states of the finite state machine specification M . However, it is known that UIO checking the existence of UIO sequences is PSPACE-complete. As a result, some UIO generation algorithms utilise what are called invertible sequences; these allow one to construct additional UIOs once a UIO has been found. We consider three optimisation problems associated with invertible sequences: deciding whether there is a (proper) invertible sequence of length at least K ; deciding whether there is a set of invertible sequences for state set $$S'$$ that contains at most K input sequences; and deciding whether there is a single input sequence that defines invertible sequences that take state set $$S''$$ to state set $$S'$$ . We prove that the first two problems are NP-complete and the third is PSPACE-complete. These results imply that we should investigate heuristics for these problems."
From Passive to Active FSM Inference via Checking Sequence Construction,Testing Software and Systems,,,,10.1007/978-3-319-67549-7_8,Alexandre PetrenkoFlorent AvellanedaRoland GrozCatherine Oriat,2017,http://link.springer.com/chapter/10.1007/978-3-319-67549-7_8,Chapter,"Active learning, Checking experiments, Checking sequences, FSM testing, Machine identification, Machine inference",10,"The paper focuses on the problems of passive and active FSM inference as well as checking sequence generation. We consider the setting where an FSM cannot be reset so that its inference is constrained to a single trace either given a priori in passive inference scenario or to be constructed in active inference scenario or aiming at obtaining checking sequence for a given FSM. In each of the last two cases, the expected result is a trace representing a checking sequence for an inferred machine, if it was not given. We demonstrate that this can be achieved by a repetitive use of a procedure that infers an FSM from a given trace (identifying a minimal machine consistent with a trace) avoiding equivalent conjectures. We thus show that FSM inference and checking sequence construction can be seen as two sides of the same coin. Following an existing approach of constructing conjectures by SAT solving, we elaborate first such a procedure and then based on it the methods for obtaining checking sequence for a given FSM and inferring a machine from a black box. The novelty of our approach is that it does not use any state identification facilities. We only assume that we know initially the input set and a bound on the number of states of the machine. Experiments with a prototype implementation of the developed approach using as a backend an existing SAT solver indicate that it scales for FSMs with up to a dozen of states and requires relatively short sequences to identify the machine."
Multiple Mutation Testing from Finite State Machines with Symbolic Inputs,Testing Software and Systems,,,,10.1007/978-3-319-67549-7_7,Omer Nguena TimoAlexandre PetrenkoS. Ramesh,2017,http://link.springer.com/chapter/10.1007/978-3-319-67549-7_7,Chapter,"Conformance testing, Constraint solving, Extended FSM, Fault model-based test generation, Mutation testing fault modelling, Symbolic inputs",10,"Recently, we proposed a mutation-testing approach from a classical finite state machine (FSM) for detecting nonconforming mutants in a given fault domain specified with a so-called mutation machine. In this paper, we lift this approach to a particular type of extended finite state machines called symbolic input finite state machine (SIFSM), where transitions are labeled with symbolic inputs, which are predicates on input variables possibly having infinite domains. We define a well-formed mutation SIFSM for describing various types of faults. Given a mutation SIFSM, we develop a method for evaluating the adequacy of a test suite and a method for generating tests detecting all nonconforming mutants. Experimental results with the prototype tool we have developed indicate that the approach is applicable to industrial-like systems."
Challenges in Composing and Decomposing Assurances for Self-Adaptive Systems,Software Engineering for Self-Adaptive Systems III. Assurances,,,,10.1007/978-3-319-74183-3_3,Bradley SchmerlJesper AnderssonThomas VogelMyra B. CohenCecilia M. F. RubiraYuriy BrunAlessandra GorlaFranco ZambonelliLuciano Baresi,2017,http://link.springer.com/chapter/10.1007/978-3-319-74183-3_3,Chapter,"Assurance Case, Goal Structuring Notation (GSN), Response Time Goals, Safety Case, Self-adaptive Systems",10,"Self-adaptive software systems adapt to changes in the environment, in the system itself, in their requirements, or in their business objectives. Typically, these systems attempt to maintain system goals at run time and often provide assurance that they will meet their goals under dynamic and uncertain circumstances. While significant research has focused on ways to engineer self-adaptive capabilities into both new and legacy software systems, less work has been conducted on how to assure that self-adaptation maintains system goals. For traditional, especially safety-critical software systems, assurance techniques decompose assurances into sub-goals and evidence that can be provided by parts of the system. Existing approaches also exist for composing assurances, in terms of composing multiple goals and composing assurances in systems of systems. While some of these techniques may be applied to self-adaptive systems, we argue that several significant challenges remain in applying them to self-adaptive systems in this chapter. We discuss how existing assurance techniques can be applied to composing and decomposing assurances for self-adaptive systems, highlight the challenges in applying them, summarize existing research to address some of these challenges, and identify gaps and opportunities to be addressed by future research."
Supporting the Integration of New Security Features in Embedded Control Devices Through the Digitalization of Production,"Systems, Software and Services Process Improvement",,,,10.1007/978-3-319-64218-5_30,Tobias RauterJohannes IberMichael KrisperChristian Kreiner,2017,http://link.springer.com/chapter/10.1007/978-3-319-64218-5_30,Chapter,,10,"Security is a vital property of Industrial Control Systems (ICS), especially in the context of critical infrastructure. In this work, we focus on distributed control devices for hydro-electric power plants. Much work has been done for specific lifecylce phases of distributed control devices such as development or operational phase. Our aim here is to consider the entire product lifecycle and the consequences of security feature implementations for a single lifecycle stage on other stages. At the same time, recent trends such as the digitization of production is an enabler of production process extensions that support the integration of such security features during the operational phase of a control devices. In particular, we propose a security concept that enables assurance of the integrity of software components and product configuration of other control devices in the same network. Moreover, we show how these concepts result in additional requirements for the production stages. We show how we meet these requirements and focus on a production process by extending previously proposed methods that enable the commissioning of secrets such as private keys during the manufacturing phase. We extend this process by extracting information about the configurations of the actually produced devices during production. Based on this information, the proposed security techniques can be integrated without considerable overhead for bootstrapping."
SysML to NuSMV Model Transformation via Object-Orientation,"Cyber Physical Systems. Design, Modeling, and Evaluation",,,,10.1007/978-3-319-51738-4_3,Georgiana CaltaisFlorian Leitner-FischerStefan LeueJannis  Weiser,2017,http://link.springer.com/chapter/10.1007/978-3-319-51738-4_3,Chapter,,10,This paper proposes a transformation of SysML models into the NuSMV input language. The transformation is performed automatically using SysMV-Ja and relies on a notion of intermediate model structuring the relevant SysML components in an object-oriented fashion.
Event-Based Runtime Verification of Temporal Properties Using Time Basic Petri Nets,NASA Formal Methods,,,,10.1007/978-3-319-57288-8_8,Matteo CamilliAngelo GargantiniPatrizia ScandurraCarlo Bellettini,2017,http://link.springer.com/chapter/10.1007/978-3-319-57288-8_8,Chapter,"Formal methods @ runtime, Petri nets, Runtime verification, Temporal properties, Timing analysis",10,"We introduce a formal framework to provide an efficient event-based monitoring technique, and we describe its current implementation as the MahaRAJA software tool. The framework enables the quantitative runtime verification of temporal properties extracted from occurring events on Java programs. The monitor continuously evaluates the conformance of the concrete implementation with respect to its formal specification given in terms of Time Basic Petri nets, a particular timed extension of Petri nets. The system under test is instrumented by using simple Java annotations on methods to link the implementation to its formal model. This allows a separation between implementation and specification that can be used for other purposes such as formal verification, simulation, and model-based testing. The tool has been successfully used to monitor at runtime and test a number of benchmarking case-studies. Experiments show that our approach introduces bounded overhead and effectively reduces the involvement of the monitor at run time by using negligible auxiliary memory. A comparison with a number of state-of-the-art runtime verification tools is also presented."
Abstraction Refinement for the Analysis of Software Product Lines,Tests and Proofs,,,,10.1007/978-3-319-61467-0_1,Ferruccio DamianiReiner HähnleMichael Lienhardt,2017,http://link.springer.com/chapter/10.1007/978-3-319-61467-0_1,Chapter,,10,"We generalize the principle of counter example-guided data abstraction refinement (CEGAR) to guided refinement of Software Product Lines (SPL) and of analysis tools. We also add a problem decomposition step. The result is a framework for formal SPL analysis via guided refinement and divide-and-conquer, through sound orchestration of multiple tools."
A New Evolutionary Algorithm for Synchronization,Applications of Evolutionary Computation,,,,10.1007/978-3-319-55849-3_40,Jakub KowalskiAdam Roman,2017,http://link.springer.com/chapter/10.1007/978-3-319-55849-3_40,Chapter,"Automata synchronization, Genetic algorithm, Knowledge-based evolution",10,"A synchronizing word brings all states of a finite automaton to the one particular state. From practical reasons the synchronizing words should be as short as possible. Unfortunately, the decision version of the problem is NP-complete. In this paper we present a new evolutionary approach for finding possibly short synchronizing words for a given automaton. As the optimization problem has two contradicting goals (the word’s length and the word’s rank) we use a 2 population feasible-infeasible approach. It is based on the knowledge on words’ ranks of all prefixes of a given word. This knowledge makes the genetic operators more efficient than in case of the standard letter-based operators."
Test Suite Reduction in Idempotence Testing of Infrastructure as Code,Tests and Proofs,,,,10.1007/978-3-319-61467-0_6,Katsuhiko IkeshitaFuyuki IshikawaShinichi Honiden,2017,http://link.springer.com/chapter/10.1007/978-3-319-61467-0_6,Chapter,,10,"Infrastructure as Code, which uses machine-processable code for managing, provisioning, and configuring computing infrastructure, has been attracting wide attention. In its application, the idempotence of the code is essential: the system should converge to the desired state even if the code is repeatedly executed possibly with failures or interruptions. Previous studies have used testing or static verification techniques to check whether the code is idempotent or not. The testing approach is impractically time-consuming, whereas the static verification approach is not applicable in many practical cases in which external scripts are used. In this paper, we present a method for efficiently checking idempotence by combining the testing and static verification approaches. The method dramatically decreases the number of test cases used to check code including external scripts by applying the static verification approach."
A Novel Learning Algorithm for Büchi Automata Based on Family of DFAs and Classification Trees,Tools and Algorithms for the Construction and Analysis of Systems,,,,10.1007/978-3-662-54577-5_12,Yong LiYu-Fang ChenLijun ZhangDepeng Liu,2017,http://link.springer.com/chapter/10.1007/978-3-662-54577-5_12,Chapter,"Buchi Automata (BA), Deterministic Finite Automaton (DFA), Observation Table, Solving Learning Tasks, Tree-structured Classification",10,"In this paper, we propose a novel algorithm to learn a Büchi automaton from a teacher who knows an $$\omega $$ -regular language. The algorithm is based on learning a formalism named family of DFAs (FDFAs) recently proposed by Angluin and Fisman [ 10 ]. The main catch is that we use a classification tree structure instead of the standard observation table structure. The worst case storage space required by our algorithm is quadratically better than the table-based algorithm proposed in [ 10 ]. We implement the first publicly available library ROLL (Regular Omega Language Learning), which consists of all $$\omega $$ -regular learning algorithms available in the literature and the new algorithms proposed in this paper. Experimental results show that our tree-based algorithms have the best performance among others regarding the number of solved learning tasks."
Asm2C++: A Tool for Code Generation from Abstract State Machines to Arduino,NASA Formal Methods,,,,10.1007/978-3-319-57288-8_21,Silvia BonfantiMarco CarissoniAngelo GargantiniAtif Mashkoor,2017,http://link.springer.com/chapter/10.1007/978-3-319-57288-8_21,Chapter,,10,"This paper presents Asm2C++ , a tool that automatically generates executable C++ code for Arduino from a formal specification given as Abstract State Machines (ASMs). The code generation process follows the model-driven engineering approach, where the code is obtained from a formal abstract model by applying certain transformation rules. The translation process is highly configurable in order to correctly integrate the underlying hardware. The advantage of the Asm2C++ tool is that it is part of the Asmeta framework that allows to analyze, verify, and validate the correctness of a formal model."
Towards a Model-Driven Security Assurance of Open Source Components,Software Engineering for Resilient Systems,,,,10.1007/978-3-319-65948-0_5,Irum RaufElena Troubitsyna,2017,http://link.springer.com/chapter/10.1007/978-3-319-65948-0_5,Chapter,,10,"Open Source software is increasingly used in a wide spectrum of applications. While the benefits of the open source components are unquestionable now, there is a great concern over security assurance provided by such components. Often open source software is a subject of frequent updates. The updates might introduce or remove a diverse range of features and hence violate security properties of the previous releases. Obviously, a manual inspection of security would be prohibitively slow and inefficient. Therefore, there is a great demand for the techniques that would allow the developers to automate the process of security assurance in the presence of frequent releases. The problem of security assurance is especially challenging because to ensure scalability, such main open source initiatives, as OpenStack adopt RESTful architecture. This requires new security assurance techniques to cater to stateless nature of the system. In this paper, we propose a model-driven framework that would allow the designers to model the security concerns and facilitate verification and validation of them in an automated manner. It enables a regular monitoring of the security features even in the presence of frequent updates. We exemplify our approach with the Keystone component of OpenStack."
Formal Analysis of Predictable Data Flow in Fault-Tolerant Multicore Systems,Formal Aspects of Component Software,,,,10.1007/978-3-319-57666-4_10,Boris MadzarJalil BoudjadarJuergen DingelThomas E. FuhrmanS. Ramesh,2017,http://link.springer.com/chapter/10.1007/978-3-319-57666-4_10,Chapter,,10,"The need to integrate large and complex functions into today’s vehicle electronic control systems requires high performance computing platforms, while at the same time the manufacturers try to reduce cost, power consumption and ensure safety. Traditionally, safety isolation and fault containment of software tasks have been achieved by either physically or temporally segregating them. This approach is reliable but inefficient in terms of processor utilization. Dynamic approaches that achieve better utilization without sacrificing safety isolation and fault containment appear to be of increasing interest. One of these approaches relies on predictable data flow introduced in PharOS and Giotto. In this paper, we extend the work on leveraging predictable data flow by addressing the problem of how the predictability of data flow can be proved formally for mixed criticality systems that run on multicore platforms and are subject to failures. We consider dynamic tasks where the timing attributes vary from one period to another. Our setting also allows for sporadic deadline overruns and accounts for criticality during fault handling. A user interface was created to allow automatic generation of the models as well as visualization of the analysis results, whereas predictability is verified using the Spin model checker."
Model-Based Testing as a Service for IoT Platforms,"Leveraging Applications of Formal Methods, Verification and Validation: Discussion, Dissemination, Applications",,,,10.1007/978-3-319-47169-3_55,Abbas AhmadFabrice BouquetElizabeta FourneretFranck Le GallBruno Legeard,2016,http://link.springer.com/chapter/10.1007/978-3-319-47169-3_55,Chapter,"Internet of Things, Model Based Testing, Standard compliance, Testing As A Service",10,"The Internet of Things (IoT) has increased its footprint becoming globally a ‘must have’ for today’s most innovative companies. Applications extend to multitude of domains, such as smart cities, healthcare, logistics, manufacturing, etc. Gartner Group estimates an increase up to 21 billion connected things by 2020. To manage ‘things’ heterogeneity and data streams over large scale and secured deployments, IoT and data platforms are becoming a central part of the IoT. To respond to this fast growing demand we see more and more platforms being developed, requiring systematic testing. Combining Model-Based Testing (MBT) technique and a service-oriented solution, we present Model-Based Testing As A Service (MBTAAS) for testing data and IoT platforms. In this paper, we present a first step towards MBTAAS for data and IoT Platforms, with experimentation on FIWARE, one of the EU most emerging IoT enabled platforms."
Model-Based Testing of Real-Time Distributed Systems,Databases and Information Systems,,,,10.1007/978-3-319-40180-5_19,Jüri VainEvelin HallingGert KanterAivo AnierDeepak Pal,2016,http://link.springer.com/chapter/10.1007/978-3-319-40180-5_19,Chapter,"Distributed systems, Low-latency systems, Model-based testing",10,"Modern financial systems have grown to the scale of global geographic distribution and latency requirements are measured in nanoseconds. Low-latency systems where reaction time is primary success factor and design consideration, are serious challenge to existing integration and system level testing techniques. While existing tools support prescribed input profiles they seldom provide enough reactivity to run the tests with simultaneous and interdependent input profiles at remote frontends. Additional complexities emerge due to severe timing constraints the tests have to meet when test navigation decision time ranges near the message propagation time. Sufficient timing conditions for remote online testing have been proven by Larsen et al. and implemented in $$\varDelta $$ Δ -testing method recently. We extend the $$\varDelta $$ Δ -testing by deploying testers on fully distributed test architecture. This approach reduces the test reaction time by almost a factor of two. We validate the method on a distributed time-sensitive global financial system case study."
Model-Based Testing of Probabilistic Systems,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-662-49665-7_15,Marcus GerholdMariëlle Stoelinga,2016,http://link.springer.com/chapter/10.1007/978-3-662-49665-7_15,Chapter,"False Rejection, Finite Path, Probabilistic Automaton, Statistical Hypothesis Testing, Trace Distribution",10,"This paper presents a model-based testing framework for probabilistic systems. We provide algorithms to generate, execute and evaluate test cases from a probabilistic requirements model. In doing so, we connect ioco -theory for model-based testing and statistical hypothesis testing: our ioco -style algorithms handle the functional aspects, while statistical methods, using $$\chi ^2$$ χ 2 tests and fitting functions, assess if the frequencies observed during test execution correspond to the probabilities specified in the requirements. Key results of our paper are the classical soundness and completeness properties, establishing the mathematical correctness of our framework; Soundness states that each test case is assigned the right verdict. Completeness states that the framework is powerful enough to discover each probabilistic deviation from the specification, with arbitrary precision. We illustrate the use of our framework via two case studies."
Evolving the ETSI Test Description Language,System Analysis and Modeling. Technology-Specific Aspects of Models,,,,10.1007/978-3-319-46613-2_8,Philip MakedonskiGusztáv AdamisMartti KäärikFinn KristoffersenXavier Zeitoun,2016,http://link.springer.com/chapter/10.1007/978-3-319-46613-2_8,Chapter,"Domain-specific modeling, Model-based testing, Test description language",10,"Increasing software and system complexity due to the integration of more and more diverse sub-systems presents new testing challenges. Standardisation and certification requirements in certain domains such as telecommunication, automotive, aerospace, and health-care contribute further challenges for testing systems operating in these domains. Consequently, there is a need for suitable methodologies, processes, languages, and tools to address these testing challenges. To address some of these challenges, the Test Description Language (TDL) has been developed at the European Telecommunications Standards Institute (ETSI) over the past three years. TDL bridges the gap between declarative test purposes and imperative test cases by offering a standardised language for the specification of test descriptions. TDL started as a standardised meta-model, subsequently enriched with a graphical syntax, exchange format, and a UML profile. A reference implementation of TDL has been developed as a common platform to accelerate the adoption of TDL and lower the barrier to entry for both end-users and tool-vendors. This article tells the story of the evolution of TDL from its conception."
Learning-Based Cross-Platform Conformance Testing,"Leveraging Applications of Formal Methods, Verification, and Validation",,,,10.1007/978-3-319-51641-7_4,Johannes NeubauerBernhard Steffen,2016,http://link.springer.com/chapter/10.1007/978-3-319-51641-7_4,Chapter,"Automata learning conformance testing, Higher-order test-block integration, User-level modeling",10,"In this paper we present learning-based cross-platform conformance testing (LCCT), an approach specifically designed to validate successful system migration. Key to our approach is the combination of (1) adequate user-level system abstraction, (2) higher-order integration of executable test-blocks, and (3) learning-based automatic model inference and comparison. The impact of LCCT will be illustrated along the migration of Springer’s Online Conference Service (OCS) from a browser-based implementation to using a RESTful web service API. Continuous LCCT allowed us in particular to systematically pinpoint spots where the original OCS depended on browser-based access control mechanisms, to eliminate them, and thus to maintain the OCS access control policy for the RESTFul API."
Systematic and Realistic Testing in Simulation of Control Code for Robots in Collaborative Human-Robot Interactions,Towards Autonomous Robotic Systems,,,,10.1007/978-3-319-40379-3_3,Dejanira Araiza-IllanDavid WesternAnthony G. PipeKerstin Eder,2016,http://link.springer.com/chapter/10.1007/978-3-319-40379-3_3,Chapter,,10,"Industries such as flexible manufacturing and home care will be transformed by the presence of robotic assistants. Assurance of safety and functional soundness for these robotic systems will require rigorous verification and validation. We propose testing in simulation using Coverage-Driven Verification (CDV) to guide the testing process in an automatic and systematic way. We use a two-tiered test generation approach, where abstract test sequences are computed first and then concretized (e.g., data and variables are instantiated), to reduce the complexity of the test generation problem. To demonstrate the effectiveness of our approach, we developed a testbench for robotic code, running in ROS-Gazebo, that implements an object handover as part of a human-robot interaction (HRI) task. Tests are generated to stimulate the robot’s code in a realistic manner, through stimulating the human, environment, sensors, and actuators in simulation. We compare the merits of unconstrained, constrained and model-based test generation in achieving thorough exploration of the code under test, and interesting combinations of human-robot interactions. Our results show that CDV combined with systematic test generation achieves a very high degree of automation in simulation-based verification of control code for robots in HRI."
Automated Support to Capture and Validate Security Requirements for Mobile Apps,Requirements Engineering Toward Sustainable World,,,,10.1007/978-981-10-3256-1_7,Noorrezam YusopMassila KamalrudinSafiah SidekJohn Grundy,2016,http://link.springer.com/chapter/10.1007/978-981-10-3256-1_7,Chapter,"EUC, EUI, Mobile apps, Model based testing strategy, Security attributes, Security requirements, Test driven development, Validation",10,"Mobile application usage has become widespread and significant as it allows interactions between people and services anywhere and anytime. However, issues related to security have become a major concern among mobile users as insecure applications may lead to security vulnerabilities that make them easily compromised by hackers. Thus, it is important for mobile application developers to validate security requirements of mobile apps at the earliest stage to prevent potential security problems. In this paper, we describe our automated approach and tool, called MobiMEReq that helps to capture and validate the security attributes requirements of mobile apps. We employed the concept of Test Driven Development (TDD) with a model-based testing strategy using Essential Use Cases (EUCs) and Essential User Interface (EUI) models. We also conducted an evaluation to compare the performance and correctness of our tool in various application domains. The results of the study showed that our tool is able to help requirements engineers to easily capture and validate security-related requirements of mobile applications."
Towards Model Construction Based on Test Cases and GUI Extraction,Testing Software and Systems,,,,10.1007/978-3-319-47443-4_15,Antti Jääskeläinen,2016,http://link.springer.com/chapter/10.1007/978-3-319-47443-4_15,Chapter,"Model extraction, Model-based testing, Software testing",10,"The adoption of model-based testing techniques is hindered by the difficulty of creating a test model. Various techniques to automate the modelling process have been proposed, based on software process artefacts or an existing product. This paper outlines a hybrid approach to model construction, based on two previously proposed methods. The presented approach combines information in pre-existing test cases with a model extracted from the graphical user interface of the product."
On Generating Test Cases from EDT Specifications,Evaluation of Novel Approaches to Software Engineering,,,,10.1007/978-3-319-30243-0_1,R. VenkateshUlka ShrotriAmey ZareSupriya Agrawal,2016,http://link.springer.com/chapter/10.1007/978-3-319-30243-0_1,Chapter,"Functional test generation, Random test case generation, Reactive systems",10,"In an earlier work we presented a cost-effective approach to generate test cases that cover functional requirements of reactive systems. The approach involved specifying requirements in EDT (Expressive Decision Tables) and generating test cases from them using RGRaF, a Row-Guided Random algorithm with Fuzzing. In this paper we propose DRAFT, a novel Dependency driven Random Algorithm with Fuzzing at Time boundaries, to improve requirement coverage. DRAFT is an enhancement over RGRaF in its ability to exploit dependencies between requirements. To compare DRAFT and other test case generation approaches - manual, pure random and RGRaF, we conducted experiments on four real-world applications. The experiments indicated that DRAFT achieves better coverage than RGRaF and its variants. When compared with the manual approach, our test cases subsumed all manual test cases and achieved up to $$60\,\%$$ reduction in effort."
Formal Model-Based Constraint Solving and Document Generation,Formal Methods: Foundations and Applications,,,,10.1007/978-3-319-49815-7_1,Michael Leuschel,2016,http://link.springer.com/chapter/10.1007/978-3-319-49815-7_1,Chapter,,10,"Constraint solving technology for formal models has made considerable progress in the last years, and has lead to many applications such as animation of high-level specifications, test case generation, or symbolic model checking. In this article we discuss the idea to use formal models themselves to express constraint satisfaction problems and to embed formal models as executable artefacts at runtime. As part of our work, we have developed a document generation feature, whose output is derived from such executable models. This present article has been generated using this feature, and we use the feature to showcase the suitability of formal modelling to express and solve various constraint solving benchmark examples. We conclude with current limitations and open challenges of formal model-based constraint solving."
Towards a Standardized Quality Assessment Framework for OCCI-Controlled Cloud Infrastructures,Cloud Computing and Services Science,,,,10.1007/978-3-319-29582-4_4,Yongzheng Liang,2016,http://link.springer.com/chapter/10.1007/978-3-319-29582-4_4,Chapter,"Cloud quality assessment, Cloud Standards, Industrie 4.0, Network Functions Virtualization, OCCI, Software Defined Network, Standardized testing, TTCN-3",10,"Considering standardized testing methodologies and related tool infrastructures as key elements of software quality assessment frameworks, for Clouds controlled by the Open Cloud Computing Interface OCCI this paper is going to present related first work based on the ETSI standardized test specification language TTCN-3. Initially motivated by studying the NIST Cloud Computing Program and the ETSI Cloud Standards Coordination (CSC) effort this approach is further stimulated by the recent evolution of the Cloud-oriented ETSI Network Functions Virtualization (NFV) and related projects such as the German Industrie 4.0."
Automatic Generation of Test Cases and Test Purposes from Natural Language,Formal Methods: Foundations and Applications,,,,10.1007/978-3-319-29473-5_9,Sidney NogueiraHugo L. S. AraujoRenata B. S. AraujoJuliano IyodaAugusto Sampaio,2016,http://link.springer.com/chapter/10.1007/978-3-319-29473-5_9,Chapter,"Editing, Prefix",10,"Use cases are widely used for requirements description in the software engineering practice. As a use case event flow is often written in natural language, it lacks tools for automatic analysis or processing. In this paper, we extend previous work that proposes an automatic strategy for generating test cases from use cases written in a Controlled Natural Language (CNL), which is a subset of English that can be processed and translated into a formal representation. Here we propose a state-based CNL for describing use cases. We translate state-based use case descriptions into CSP processes from which test cases can be automatically generated. In addition, we show how a similar notation can be used to specify test selection via the definition of state-based test purposes, which are also translated into CSP processes. Test generation and selection are mechanised by running refinement checking verifications using the CSP processes for use cases and test purposes. All the steps of the strategy are integrated into a tool that provides a GUI for authoring use cases and test purposes described in the proposed CNL, so the formal CSP notation is totally hidden from the test designer. We illustrate our tool and techniques with a running example."
Functional Testing of Java Programs,Trends in Functional Programming,,,,10.1007/978-3-319-39110-6_3,Clara Benac EarleLars-Åke Fredlund,2016,http://link.springer.com/chapter/10.1007/978-3-319-39110-6_3,Chapter,"Erlang, Java, Software testing",10,"This paper describes an approach to testing Java code using a functional programming language. Models for Java programs are expressed as Quviq Erlang QuickCheck properties, from which random tests are generated and executed. To remove the need for writing boilerplate code to interface Java and Erlang, a new library, JavaErlang, has been developed. The library provides a number of interesting features, e.g., it supports automatic garbage collection of Java objects communicated to Erlang, and permits Java classes to be written entirely in Erlang. Moreover, as the library is built on top of the Erlang distributed node concept, the Java program under test runs in isolation from the Erlang testing code. The chief advantage of this testing approach is that a functional programming language, with expressive data types and side-effect free libraries, is very suited to formulating models for imperative programs. The resulting testing methodology has been applied extensively to evaluate student Java exercises."
Model-Driven Active Automata Learning with LearnLib Studio,"Leveraging Applications of Formal Methods, Verification, and Validation",,,,10.1007/978-3-319-51641-7_8,Oliver BauerJohannes NeubauerMalte Isberner,2016,http://link.springer.com/chapter/10.1007/978-3-319-51641-7_8,Chapter,,10,"We present our reboot of LearnLib Studio , formerly being a part of the Next Generation LearnLib (NGLL) framework for model-based construction of automata learning solutions. The new version of LearnLib Studio is a from-scratch re-implementation, which is based on an improved open-source realization of LearnLib as well as our latest version of the jABC framework ( jABC4 ) for model-driven, service-oriented development of applications with recently added support for type-safe higher-order process modeling. Our all new version of LearnLib Studio provides an easy way to enable even users who do not necessarily have programming expertise to use and extend dedicated learning solutions with minimal manual effort. We illustrate the tool by applying automata learning to a concrete web service following the Representational State Transfer (REST) paradigm."
Risk-Based Interoperability Testing Using Reinforcement Learning,Testing Software and Systems,,,,10.1007/978-3-319-47443-4_4,André ReichstallerBenedikt EberhardingerAlexander KnappWolfgang ReifMarcel Gehlen,2016,http://link.springer.com/chapter/10.1007/978-3-319-47443-4_4,Chapter,"Generate Test Case, Model Checker, Reinforcement Learning, System Under Test, Test Suite",10,"Risk-based test strategies enable the tester to harmonize the number of specified test cases with imposed time and cost constraints. However, the risk assessment itself often requires a considerable effort of cost and time, since it is rarely automated. Especially for complex tasks such as testing the interoperability of different components it is expensive to manually assess the criticality of possible faults. We present a method that operationalizes the risk assessment for interoperability testing. This method uses behavior models of the system under test and reinforcement learning techniques to break down the criticality of given failure situations to the relevance of single system actions for being tested. Based on this risk assessment, a desired number of test cases is generated which covers as much relevance as possible. Risk models and test cases have been generated for a mobile payment system within an industrial case study."
How to Assure Correctness and Safety of Medical Software: The Hemodialysis Machine Case Study,"Abstract State Machines, Alloy, B, TLA, VDM, and Z",,,,10.1007/978-3-319-33600-8_30,Paolo ArcainiSilvia BonfantiAngelo GargantiniElvinia Riccobene,2016,http://link.springer.com/chapter/10.1007/978-3-319-33600-8_30,Chapter,,10,"Medical devices are nowadays more and more software dependent, and software malfunctioning can lead to injuries or death for patients. Several standards have been proposed for the development and the validation of medical devices, but they establish general guidelines on the use of common software engineering activities without any indication regarding methods and techniques to assure safety and reliability. This paper takes advantage of the Hemodialysis machine case study to present a formal development process supporting most of the engineering activities required by the standards, and provides rigorous approaches for system validation and verification. The process is based on the Abstract State Machine formal method and its model refinement principle."
Test Generation by Constraint Solving and FSM Mutant Killing,Testing Software and Systems,,,,10.1007/978-3-319-47443-4_3,Alexandre PetrenkoOmer Nguena TimoS. Ramesh,2016,http://link.springer.com/chapter/10.1007/978-3-319-47443-4_3,Chapter,"Conformance testing, Fault coverage analysis, Fault model-based test generation, Fault modelling, FSM, Mutation testing, Test coverage",10,"The problem of fault model-based test generation from formal models, in this case Finite State Machines, is addressed. We consider a general fault model which is a tuple of a specification, conformance relation and fault domain. The specification is a deterministic FSM which can be partially specified and not reduced. The conformance relation is quasi-equivalence, as all implementations in the fault domain are assumed to be completely specified FSMs. The fault domain is a set of all possible deterministic submachines of a given nondeterministic FSM, called a mutation machine. The mutation machine contains a specification machine and extends it with mutated transitions modelling potential faults. An approach for deriving a test suite which is complete (sound and exhaustive) for the given fault model is elaborated. It is based on our previously proposed method for analyzing the test completeness by logical encoding and SMT-solving. The preliminary experiments performed on an industrial controller indicate that the approach scales sufficiently well."
Web Service Test Evolution,Software Quality. The Future of Systems- and Software Development,,,,10.1007/978-3-319-27033-3_12,Harry M. Sneed,2016,http://link.springer.com/chapter/10.1007/978-3-319-27033-3_12,Chapter,"Automated web service testing, Data reverse engineering, Regression testing, Requirement-based testing, Test automation, Test maintenance, Test script evolution, Test-driven development, Web services",10,"In order to remain useful test scripts must evolve parallel to the test objects they are intended to test. In the approach described here the test objects are web services whose test script is derived from the web service interface definition. The test script structure is automatically generated from the WSDL structure with tags and attributes, however, the content, i.e. the test data has to be inserted by hand. From this script service requests are automatically generated and service responses automatically validated. As with other generated software artifacts, once the structure of the interface or the logic of the targeted service is changed, the content of the test script is no longer valid. It has to be altered and/or enhanced to fit the new interface structure and/or the altered service logic. In this paper the author proposes a semi-automated approach to solving this test maintenance problem and explains how it has been implemented in a web service testing tool by employing data reverse engineering techniques. The author also report on his experience with the approach when maintaining a test in the field."
Software that Meets Its Intent,"Leveraging Applications of Formal Methods, Verification and Validation: Discussion, Dissemination, Applications",,,,10.1007/978-3-319-47169-3_47,Marieke HuismanHerbert BosSjaak BrinkkemperArie van DeursenJan Friso GrootePatricia LagoJaco van de PolEelco Visser,2016,http://link.springer.com/chapter/10.1007/978-3-319-47169-3_47,Chapter,"Intended Behavior, Model Checker, Program Verifier, Proof Checker, Satisfiability Modulo Theory",10,"Software is widely used, and society increasingly depends on its reliability. However, software has become so complex and it evolves so quickly that we fail to keep it under control. Therefore, we propose intents : fundamental laws that capture a software systems’ intended behavior (resilient, secure, safe, sustainable, etc.). The realization of this idea requires novel theories, algorithms, tools, and techniques to discover, express, verify, and evolve software intents. Thus, future software systems will be able to verify themselves that they meet their intents. Moreover, they will be able to respond to deviations from intents through self-correction. In this article we propose a research agenda, outlining which novel theories, algorithms and tools are required."
A Model Interpreter for Timed Automata,"Leveraging Applications of Formal Methods, Verification and Validation: Foundational Techniques",,,,10.1007/978-3-319-47166-2_17,M. Usman IftikharJonas LundbergDanny Weyns,2016,http://link.springer.com/chapter/10.1007/978-3-319-47166-2_17,Chapter,"Model interpretation, Model-driven development, Timed automata, Virtual machine",10,"In the model-centric approach to model-driven development, the models used are sufficiently detailed to be executed. Being able to execute the model directly, without any intermediate model-to-code translation, has a number of advantages. The model is always up-to-date and runtime updates of the model are possible. This paper presents a model interpreter for timed automata, a formalism often used for modeling and verification of real-time systems. The model interpreter supports real-time system features like simultaneous execution, system wide signals, a ticking clock, and time constraints. Many existing formal representations can be verified, and many existing DSMLs can be executed. It is the combination of being both verifiable and executable that makes our approach rather unique."
Cost-Benefit Analysis of Using Dependency Knowledge at Integration Testing,Product-Focused Software Process Improvement,,,,10.1007/978-3-319-49094-6_17,Sahar TahviliMarkus BohlinMehrdad SaadatmandStig LarssonWasif AfzalDaniel Sundmark,2016,http://link.springer.com/chapter/10.1007/978-3-319-49094-6_17,Chapter,"Decision support system, Integration testing, Optimization, Prioritization, Process improvement, Return on investment, Software testing, Test case selection",10,"In software system development, testing can take considerable time and resources, and there are numerous examples in the literature of how to improve the testing process. In particular, methods for selection and prioritization of test cases can play a critical role in efficient use of testing resources. This paper focuses on the problem of selection and ordering of integration-level test cases. Integration testing is performed to evaluate the correctness of several units in composition. Further, for reasons of both effectiveness and safety, many embedded systems are still tested manually. To this end, we propose a process, supported by an online decision support system, for ordering and selection of test cases based on the test result of previously executed test cases. To analyze the economic efficiency of such a system, a customized return on investment (ROI) metric tailored for system integration testing is introduced. Using data collected from the development process of a large-scale safety-critical embedded system, we perform Monte Carlo simulations to evaluate the expected ROI of three variants of the proposed new process. The results show that our proposed decision support system is beneficial in terms of ROI at system integration testing and thus qualifies as an important element in improving the integration testing process."
Temporal Test Generation for Embedded System Based on Correlation Analysis of Timing Constraints,Software Engineering and Methodology for Emerging Domains,,,,10.1007/978-981-10-3482-4_15,Bo WangXiaoying BaiWenguang ChenXiaoyu Song,2016,http://link.springer.com/chapter/10.1007/978-981-10-3482-4_15,Chapter,"Correlation analysis, Embedded software, Temporal testing, Test generation, Timing constraint",10,"Timing constraints are critical to real-time embedded software. However, it is hard to verify and validate system temporal correctness when there exist multiple timing constraints with complex inter-dependencies. To facilitate temporal testing, the paper systematically analyzes the characteristics of timing constraints and their correlation patterns, using a modeling technique called Extended Semantic Interface Automata (ESIA). A Correlation-Based Partition Testing (CBPT) approach is proposed to generate temporal test cases. The value of time variables are sampled from equivalent partitions of test domain, which are identified by taking constraints and constraint correlations into considerations. Each partition of test vectors represents a typical timing scenario, such that the sampled test cases can validate both the correctness of system normal functionalities and system robustness in reaction to timing exceptions. The strategies to search and calculate test data are designed. Experiments are exercised on a Satellite Positioning System (SPS) software. The results show that the proposed approach can effectively reduce test cost, enhance test coverage, and efficiently detect various temporal defects."
Cyber-Physical Systems Engineering,Engineering Trustworthy Software Systems,,,,10.1007/978-3-319-29628-9_5,Bernd-Holger Schlingloff,2016,http://link.springer.com/chapter/10.1007/978-3-319-29628-9_5,Chapter,"Block diagrams, Code generation, Cyber-physical systems, Embedded systems, Model-based design, Requirements analysis, State-transition systems, Systems analysis, Systems modeling",10,Building complex embedded- and cyber-physical systems requires a holistic view on both product and process. The constructed system must interact with its physical environment and its human users in a smooth way. The development processes must provide a seamless transition between stages and views. Different modeling techniques and methods have been proposed to achieve this goal. In this chapter we present the fundamentals of cyber-physical systems engineering: identification and quantification of system goals; requirements elicitation and management; modeling and simulation in different views; and validation to ensure that the system meets its original design goals. A special focus is on the model-based design process. All techniques are demonstrated with appropriate examples and engineering tools.
Combining Model Learning and Model Checking to Analyze TCP Implementations,Computer Aided Verification,,,,10.1007/978-3-319-41540-6_25,Paul Fiterău-BroşteanRamon JanssenFrits Vaandrager,2016,http://link.springer.com/chapter/10.1007/978-3-319-41540-6_25,Chapter,"Abstraction Function, Automaton Learning, Equivalence Query, Membership Query, Model Check",10,"We combine model learning and model checking in a challenging case study involving Linux, Windows and FreeBSD implementations of TCP. We use model learning to infer models of different software components and then apply model checking to fully explore what may happen when these components (e.g. a Linux client and a Windows server) interact. Our analysis reveals several instances in which TCP implementations do not conform to their RFC specifications."
A Case Study for a Bidirectional Transformation Between Heterogeneous Metamodels in QVT Relations,Evaluation of Novel Approaches to Software Engineering,,,,10.1007/978-3-319-30243-0_8,Bernhard Westfechtel,2016,http://link.springer.com/chapter/10.1007/978-3-319-30243-0_8,Chapter,"Bidirectional Transformation, Ecore Model, Heterogeneous Metamodels, Object-relational Mapping, Unidirectional Transformations",10,"Model transformations constitute a key technology for model-driven software engineering. In additional to unidirectional transformations, bidirectional transformations may be required e.g. for round-trip engineering or bidirectional data conversion. Bidirectional transformations may be difficult to perform if the metamodels of source and target models differ significantly from each other, as it is the case for object-relational mappings. In this paper, we present a bidirectional transformation between Ecore models and relational schemata written in QVT Relations. The case study demonstrates that it is possible to encode a bidirectional transformation between heterogeneous metamodels in a single relational specification. Simultaneously, the case study also shows some inherent limitations of what can be achieved by bidirectional transformations."
Applying Abstract Interpretation to Verify EN-50128 Software Safety Requirements,"Reliability, Safety, and Security of Railway Systems. Modelling, Analysis, Verification, and Certification",,,,10.1007/978-3-319-33951-1_14,Daniel KästnerChristian Ferdinand,2016,http://link.springer.com/chapter/10.1007/978-3-319-33951-1_14,Chapter,"Abstract Interpretation-based Static Analysis, Data Races, Potential Runtime Errors, Stack Overflow, Worst-case Execution Time (WCET)",10,"Like other contemporary safety standards EN-50128 requires to identify potential functional and non-functional hazards and to demonstrate that the software does not violate the relevant safety goals. Examples of safety-relevant non-functional hazards are violations of resource bounds, especially stack overflows and deadline violations, as well as run-time errors and data races. They can cause erroneous and erratic program behavior, invalidate separation mechanisms in mixed-criticality software, and even trigger software crashes. Classical software verification methods like code review and testing with measurements cannot really guarantee the absence of errors. Abstract interpretation is a formal method for static program analysis which supports formal soundness proofs (it can be proven that no error is missed) and which scales. This article gives an overview of abstract interpretation and its application to compute safe worst-case execution time and stack bounds, and to find all potential run-time errors, and data races. We discuss the tool qualification of abstract interpretation-based static analyzers and describe their contribution with respect to EN-50128 compliant verification processes. We also illustrate their integration in the development process and report on practical experience."
Your Proof Fails? Testing Helps to Find the Reason,Tests and Proofs,,,,10.1007/978-3-319-41135-4_8,Guillaume PetiotNikolai KosmatovBernard BotellaAlain GiorgettiJacques Julliand,2016,http://link.springer.com/chapter/10.1007/978-3-319-41135-4_8,Chapter,"Deductive Veriﬁcation, Failed Proof, PathCrawler, Veriﬁcation Engine, Weak Contraction",10,"Applying deductive verification to formally prove that a program respects its formal specification is a very complex and time-consuming task due in particular to the lack of feedback in case of proof failures. Along with a non-compliance between the code and its specification (due to an error in at least one of them), possible reasons of a proof failure include a missing or too weak specification for a called function or a loop, and lack of time or simply incapacity of the prover to finish a particular proof. This work proposes a complete methodology where test generation helps to identify the reason of a proof failure and to exhibit a counterexample clearly illustrating the issue. We define the categories of proof failures, introduce two subcategories of contract weaknesses (single and global ones), and examine their properties. We describe how to transform a formally specified C program into C code suitable for testing, and illustrate the benefits of the method on comprehensive examples. The method has been implemented in StaDy , a plugin of the software analysis platform Frama-C . Initial experiments show that detecting non-compliances and contract weaknesses allows to precisely diagnose most proof failures."
Privacy-Preserving Targeted Mobile Advertising: Formal Models and Analysis,Data Privacy Management and Security Assurance,,,,10.1007/978-3-319-47072-6_7,Yang LiuAndrew Simpson,2016,http://link.springer.com/chapter/10.1007/978-3-319-47072-6_7,Chapter,"Internet Economy, Mobile Advertising, Personal Information, Prototype Solution, Tschantz",10,"Targeted Mobile Advertising (TMA) has emerged as a significant driver of the Internet economy. TMA gives rise to interesting challenges: there is a need to balance privacy and utility; there is a need to guarantee that applications’ access to resources is appropriate; and there is a need to ensure that the targeting of ads is effective. As many authors have argued, formal models are ideal vehicles for reasoning about privacy, as well as for reasoning about the relationship between privacy and utility. To this end, we describe how the formal notation Z has been used to develop formal models to underpin a prototype privacy-preserving TMA system. We give consideration to how formal models can help in underpinning the prototype system, in analysing privacy in the context of targeted mobile advertising, and in allowing users to specify control of their personal information."
The Kind 2 Model Checker,Computer Aided Verification,,,,10.1007/978-3-319-41540-6_29,Adrien ChampionAlain MebsoutChristoph StickselCesare Tinelli,2016,http://link.springer.com/chapter/10.1007/978-3-319-41540-6_29,Chapter,"Compositional Reasoning, Contract Reﬁnement, Initial State Predicate, Invariant Generation Techniques, Synchronous Reactive Systems",10,"Kind  2 is an open-source, multi-engine, SMT-based model checker for safety properties of finite- and infinite-state synchronous reactive systems. It takes as input models written in an extension of the Lustre language that allows the specification of assume-guarantee-style contracts for system components. Kind  2 was implemented from scratch based on techniques used by its predecessor, the PKind model checker. This paper discusses a number of improvements over PKind in terms of invariant generation. It also introduces two main features: contract-based compositional reasoning and certificate generation."
Transforming CPN Models into Code for TinyOS: A Case Study of the RPL Protocol,Application and Theory of Petri Nets and Concurrency,,,,10.1007/978-3-319-39086-4_10,Lars Michael KristensenVegard Veiset,2016,http://link.springer.com/chapter/10.1007/978-3-319-39086-4_10,Chapter,"Coloured Petri Nets (CPN), Destination-oriented Directed Acyclic Graph (DODAG), Substitution Transition, TinyOS Components, TinyOS Platform",10,"TinyOS is a widely used platform for the development of networked embedded systems offering a programming model targeting resource constrained devices. We present a semi-automatic software engineering approach where Coloured Petri Net (CPNs) models are used as a starting point for developing protocol software for the TinyOS platform. The approach consists of five refinement steps that allow a developer to gradually transform a platform-independent CPN model into a platform-specific model that enables automatic code generation. To evaluate our approach, we use it to obtain an implementation of the IETF RPL routing protocol for sensor networks."
Model-Based Testing for Composite Web Services in Cloud Brokerage Scenarios,Advances in Service-Oriented and Cloud Computing,,,,10.1007/978-3-319-14886-1_18,Mariam KiranAnthony J. H. Simons,2015,http://link.springer.com/chapter/10.1007/978-3-319-14886-1_18,Chapter,"Cloud Service, Component Service, Composite Service, Service Composition, Test Suite",10,"Cloud brokerage is an enabling technology allowing various services to be merged together for providing optimum quality of service for the end-users. Within this collection of composed services, testing is a challenging task which brokers have to take on to ensure quality of service. Most Software-as-a-Service (SaaS) testing has focused on high-level test generation from the functional specification of individual services, with little research into how to achieve sufficient test coverage of composite services. This paper explores the use of model-based testing to achieve testing of composite services, when two individual web services are tested and combined. Two example web services – a login service and a simple shopping service – are combined to give a more realistic shopping cart service. This paper focuses on the test coverage required for testing the component services individually and their composition. The paper highlights the problems of service composition testing, requiring a reworking of the combined specification and regeneration of the tests, rather than a simple composition of the test suites; and concludes by arguing that more work needs to be done in this area."
Model-Based Testing from Input Output Symbolic Transition Systems Enriched by Program Calls and Contracts,Testing Software and Systems,,,,10.1007/978-3-319-25945-1_3,Imen BoudhibaChristophe GastonPascale Le GallVirgile Prevosto,2015,http://link.springer.com/chapter/10.1007/978-3-319-25945-1_3,Chapter,"Feasibility, Input output symbolic transition systems, Model-based testing, Program contracts, Symbolic execution",10,"An Input Output Symbolic Transition System (IOSTS) specifies all expected sequences of input and output messages of a reactive system. Symbolic execution over this IOSTS then allows to generate a set of test cases that can exercise the various possible behaviors of the system it represents. In this paper, we extend the IOSTS framework with explicit program calls, possibly equipped with contracts specifying what the program is supposed to do. This approach bridges the gap between a model-based approach in which user-defined programs are abstracted away and a code-based approach in which small pieces of code are separately considered regardless of the way they are combined. First, we extend symbolic execution techniques for IOSTS with programs, in order to re-use classical test case generation algorithms. Second, we explore how constraints coming from IOSTS symbolic execution can be used to infer contracts for programs used in the IOSTS."
Model-Based Robustness Testing in Event-B Using Mutation,Software Engineering and Formal Methods,,,,10.1007/978-3-319-22969-0_10,Aymerick SavaryMarc FrappierMichael LeuschelJean-Louis Lanet,2015,http://link.springer.com/chapter/10.1007/978-3-319-22969-0_10,Chapter,"
                  Event-B
                , 
                  ProB
                , Intrusion testing, Model-based testing, Robustness testing, Specification mutation, Vulnerability analysis",10,"Robustness testing aims at finding errors in a system under invalid conditions, such as unexpected inputs. We propose a robustness testing approach for Event-B based on specification mutation and model-based testing. We assume that a specification describes the valid inputs of a system. By applying negation rules, we mutate the precondition of events to explore invalid behaviour. Tests are generated from the mutated specification using ProB . ProB has been adapted to efficiently process mutated events. Mutated events are statically checked for satisfiability and enability using constraint satisfaction, to prune the transition search space. This has dramatically improve the performance of test generation. The approach is applied to the Java Card bytecode verifier. Large mutated specifications (containing 921 mutated events) can be easily tackled to ensure a good coverage of the robustness test space."
Risk-Driven Vulnerability Testing: Results from eHealth Experiments Using Patterns and Model-Based Approach,Risk Assessment and Risk-Driven Testing,,,,10.1007/978-3-319-26416-5_7,Alexandre VernotteCornel BoteaBruno LegeardArthur MolnarFabien Peureux,2015,http://link.springer.com/chapter/10.1007/978-3-319-26416-5_7,Chapter,"eHealth web application, Empirical evaluation, Risk-driven testing, Security test pattern, Vulnerability testing",10,"This paper introduces and reports on an original tooled risk-driven security testing process called Pattern-driven and Model-based Vulnerability Testing. This fully automated testing process, drawing on risk-driven strategies and Model-Based Testing (MBT) techniques, aims to improve the capability of detection of various Web application vulnerabilities, in particular SQL injections, Cross-Site Scripting, and Cross-Site Request Forgery. It is based on a mixed modeling of the system under test: an MBT model captures the behavioral aspects of the Web application, while formalized vulnerability test patterns, selected from risk assessment results, drive the overall test generation process. An empirical evaluation, conducted on a complex and freely-accessible eHealth system developed by Info World, shows that this novel process is appropriate for automatically generating and executing risk-driven vulnerability test cases and is promising to be deployed for large-scale Web applications."
Model-Based Analysis for Safety Critical Software,"Computer Safety, Reliability, and Security",,,,10.1007/978-3-319-24255-2_9,Stefan GulanJens HarnischSven JohrRoberto KretschmerStefan RiegerRafael Zalman,2015,http://link.springer.com/chapter/10.1007/978-3-319-24255-2_9,Chapter,"AUTOSAR, Formal methods, Functional safety, ISO 26262, Model checking, Model-based testing, Safety analysis",10,"Safety-relevant software developed within the automotive domain is subject to the safety standard ISO 26262. In particular, a supplier must show that implemented safety mechanisms sufficiently address relevant failure modes. This involves complex and costly testing procedures. We introduce an early analysis approach for safety mechanisms implemented in safety-relevant software by combining model checking and model-based testing. Model checking is applied to verify the correctness of an abstract amodel of the system under test. The verified model is then used to automatically generate tests for the verification of the implemented Safety Elements. The approach has been evaluated in an industrial case study, addressing Analogue Digital Converters as part of the motor control within a hybrid electric vehicle. The results suggest that our approach allows to create high quality test suites. In addition, the test model helps to reduce misunderstandings due to imprecise specification of safety mechanisms."
"Require, Test and Trace IT",Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-319-19458-5_8,Bernhard K. AichernigKlaus HörmaierFlorian LorberDejan NičkovićStefan Tiran,2015,http://link.springer.com/chapter/10.1007/978-3-319-19458-5_8,Chapter,"Consistency checking, Formal specification, Incremental test-case generation, Model-based testing, Requirement interfaces, Requirements engineering, Synchronous systems, Test-case generation, Traceability",10,"We propose a framework for requirement-driven test generation that combines contract-based interface theories with model-based testing. We design a specification language, requirement interfaces , for formalizing different views (aspects) of synchronous data-flow systems from informal requirements. Multiple views of a system, modeled as requirement interfaces, are naturally combined by conjunction. We develop an incremental test generation procedure with several advantages. The test generation is driven by a single requirement interface at a time. It follows that each test assesses a specific aspect or feature of the system, specified by its associated requirement interface. Since we do not explicitly compute the conjunction of all requirement interfaces of the system, we avoid state space explosion while generating tests. However, we incrementally complete a test for a specific feature with the constraints defined by other requirement interfaces. This allows catching violations of any other requirement during test execution, and not only of the one used to generate the test. Finally, this framework defines a natural association between informal requirements, their formal specifications and the generated tests, thus facilitating traceability. We implemented a prototype test generation tool and we demonstrate its applicability on an industrial use case."
Bounded Determinization of Timed Automata with Silent Transitions,Formal Modeling and Analysis of Timed Systems,,,,10.1007/978-3-319-22975-1_19,Florian LorberAmnon RosenmannDejan NičkovićBernhard K. Aichernig,2015,http://link.springer.com/chapter/10.1007/978-3-319-22975-1_19,Chapter,"Bound Model Check, Bypass Transition, Observable Transition, Time Automaton, Unary Constraint",10,"Deterministic timed automata are strictly less expressive than their non-deterministic counterparts, which are again less expressive than those with silent transitions. As a consequence, timed automata are in general non-determinizable. This is unfortunate since deterministic automata play a major role in model-based testing, observability and implementability. However, by bounding the length of the traces in the automaton, effective determinization becomes possible. We propose a novel procedure for bounded determinization of timed automata. The procedure unfolds the automata to bounded trees, removes all silent transitions and determinizes via disjunction of guards. The proposed algorithms are optimized to the bounded setting and thus are more efficient and can handle a larger class of timed automata than the general algorithms. The approach is implemented in a prototype tool and evaluated on several examples. To our best knowledge, this is the first implementation of this type of procedure for timed automata."
A SysML Formal Framework to Combine Discrete and Continuous Simulation for Testing,Formal Methods and Software Engineering,,,,10.1007/978-3-319-25423-4_9,Jean-Marie GauthierFabrice BouquetAhmed HammadFabien Peureux,2015,http://link.springer.com/chapter/10.1007/978-3-319-25423-4_9,Chapter,"Constraint solving, Discrete & continuous simulation, Model-based testing, Model-driven engineering, Modelica, Real-time system, SysML",10,"The increasing interactions between huge amount of software and hardware subsystem (hydraulics, mechanics, electronics, etc.) lead to a new kind of complexity that is difficult to manage during the validation of safety-critical and complex embedded systems. This paper introduces a formal SysML-based framework to combine both discrete and continuous simulation to validate physical systems at the early stage of development. This original modelling framework takes as input a SysML model annotated with Modelica code and OCL constraints. Such a model provides a precise and unambiguous description of the designed system and its environment, involving both discrete and continuous features. This formal framework enables to automatically generate Modelica code to perform real-time simulation. On the basis of a constraint system derived from the discrete SysML/OCL modelling artefacts, it also makes it possible to automatically generate black-box test cases that can be used to validate the simulated system as well as the corresponding physical device. This framework has been validated by conclusive experiments conducted to prototype a new energy manager system for aeronautics."
Case Study: Automatic Test Case Generation for a Secure Cache Implementation,Tests and Proofs,,,,10.1007/978-3-319-21215-9_4,Roderick BloemDaniel HeinFranz RöckRichard Schumi,2015,http://link.springer.com/chapter/10.1007/978-3-319-21215-9_4,Chapter,"Automatic test case generation, Model checking, Model-based testing, Trap properties",10,"While many approaches for automatic test case generation have been proposed over the years, it is often difficult to predict which of them may work well on concrete problems. In this paper, we therefore present a case study in automatic, model-based test case generation: We implemented several graph-based methods that compute test cases with a model checker using trap properties, and evaluate these methods on a Secure Block Device implementation. We compare the number of generated test cases, the required generation time and the achieved code coverage. Our conclusions are twofold: First, automatic test case generation is feasible and beneficial for this case study, and even found a real bug in the implementation. Second, simple coverage methods on the model may already yield test suites of sufficient quality."
Mobile Application Verification: A Systematic Mapping Study,Computational Science and Its Applications -- ICCSA 2015,,,,10.1007/978-3-319-21413-9_11,Mehmet SahinogluKoray InckiMehmet S. Aktas,2015,http://link.springer.com/chapter/10.1007/978-3-319-21413-9_11,Chapter,"Literature review, Mobile application, Software testing, Systematic mapping, Verification",10,"The proliferation of mobile devices and applications has seen an unprecedented rise in recent years. Application domains of mobile systems range from personal assistants to point-of-care health informatics systems. Software development for such diverse application domains requires stringent and well-defined development process. Software testing is a type of verification that is required to achieve more reliable system. Even though, Software Engineering literature contains many research studies that address challenging issues in mobile application development, we could not have identified a comprehensive literature review study on this subject. In this paper, we present a systematic mapping of the Software Verification in the field of mobile applications. We provide definitive metrics and publications about mobile application testing, which we believe will allow fellow researchers to identify gaps and research opportunities in this field."
Selective Test Generation Approach for Testing Dynamic Behavioral Adaptations,Testing Software and Systems,,,,10.1007/978-3-319-25945-1_14,Mariam LahamiMoez KrichenHajer BarhoumiMohamed Jmaiel,2015,http://link.springer.com/chapter/10.1007/978-3-319-25945-1_14,Chapter,,10,"This paper presents a model-based black-box testing approach for dynamically adaptive systems. Behavioral models of such systems are formally specified using timed automata. With the aim of obtaining the new test suite and avoiding its regeneration in a cost effective manner, we propose a selective test generation approach. The latter comprises essentially three modules: (1) a model differencing module that detects similarities and differences between the initial and the evolved behavioral models, (2) an old test classification module that identifies reusable and retestable tests from the old test suite, and finally (3) a test generation module that generates new tests covering new behaviors and adapts old tests that failed during animation. To show its efficiency, the proposed technique is illustrated through the Toast application and compared to the classical Regenerate All and Retest All approaches."
Safety.Lab: Model-Based Domain Specific Tooling for Safety Argumentation,"Computer Safety, Reliability, and Security",,,,10.1007/978-3-319-24249-1_7,Daniel RatiuMarc ZellerLennart Killian,2015,http://link.springer.com/chapter/10.1007/978-3-319-24249-1_7,Chapter,"Assurance cases, Model driven engineering, Safety-critical systems, Tooling",10,"Assurance cases capture the argumentation that a system is safe by putting together pieces of evidence at different levels of abstraction and of different nature. Managing the interdependencies between these artefacts lies at the heart of any safety argument. Keeping the assurance case complete and consistent with the system is a manual and very ressource consuming process. Current tools do not address these challenges in constructing and maintaining safety arguments. In this paper we present a tooling prototype called Safety.Lab which features rich and deeply integrated models to describe requirements, hazards list, fault trees and architecture. We show how Safety.Lab opens opportunities to automate completeness and consistency checks for safety argumentation."
Applying Automata Learning to Embedded Control Software,Formal Methods and Software Engineering,,,,10.1007/978-3-319-25423-4_5,Wouter SmeenkJoshua MoermanFrits VaandragerDavid N. Jansen,2015,http://link.springer.com/chapter/10.1007/978-3-319-25423-4_5,Chapter,,10,"Using an adaptation of state-of-the-art algorithms for black-box automata learning, as implemented in the LearnLib tool, we succeeded to learn a model of the Engine Status Manager (ESM), a software component that is used in printers and copiers of Océ. The main challenge that we encountered was that LearnLib, although effective in constructing hypothesis models, was unable to find counterexamples for some hypotheses. In fact, none of the existing FSM-based conformance testing methods that we tried worked for this case study. We therefore implemented an extension of the algorithm of Lee and Yannakakis for computing an adaptive distinguishing sequence. Even when an adaptive distinguishing sequence does not exist, Lee and Yannakakis’ algorithm produces an adaptive sequence that ‘almost’ identifies states. In combination with a standard algorithm for computing separating sequences for pairs of states, we managed to verify states with on average 3 test queries. Altogether, we needed around 60 million queries to learn a model of the ESM with 77 inputs and 3.410 states. We also constructed a model directly from the ESM software and established equivalence with the learned model. To the best of our knowledge, this is the first paper in which active automata learning has been applied to industrial control software."
BPEL Integration Testing,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-662-46675-9_5,Seema JehanIngo PillFranz Wotawa,2015,http://link.springer.com/chapter/10.1007/978-3-662-46675-9_5,Chapter,"Mutation Score, Satisfying Assignment, Symbolic Execution, Test Case Generation, Test Suite",10,"Service-oriented architectures, and evolvements such as clouds, provide a promising infrastructure for future computing. They encapsulate an IP core’s functionality for easy access via well-defined business and web interfaces, and in turn allow us to flexibly realize complex software drawing on available expertise. In this paper, we take a look at some challenges we have to face during the task of testing such systems for verification purposes. In particular, we delve into the task of test suite generation, and compare the performance of two corresponding algorithms. In addition, we report on experiments for a collection of BPEL processes taken from the literature, in order to identify performance trends with respect to fault coverage metrics. Our results suggest that a structural reasoning might outperform a completely random approach."
Towards the Generation of Tests in the Test Description Language from Use Case Map Models,SDL 2015: Model-Driven Engineering for Smart Cities,,,,10.1007/978-3-319-24912-4_14,Patrice BouletDaniel AmyotBernard Stepien,2015,http://link.springer.com/chapter/10.1007/978-3-319-24912-4_14,Chapter,"Model-based testing, Test Description Language, Tool, Use Case Map",10,"The Test Description Language (TDL) is an emerging standard from the European Telecommunications Standards Institute (ETSI) that targets the abstract description of tests for communicating systems and other application domains. TDL is meant to be used as an intermediate format between requirements and executable test cases. This paper explores the automated generation of TDL test descriptions from requirements expressed as Use Case Map (UCM) models. One generation mechanism, which exploits UCM scenario definitions, is prototyped in the jUCMNav tool and illustrated through an example. This transformation enables the exploration of model-based testing where the use of TDL models simplifies the generation of tests in various languages (including the Testing and Test Control Notation – TTCN-3) from UCM requirements. Remaining challenges are also discussed in the paper."
Combining Time and Concurrency in Model-Based Statistical Testing of Embedded Real-Time Systems,Software Engineering and Formal Methods,,,,10.1007/978-3-662-49224-6_3,Daniel HommJürgen EckertReinhard German,2015,http://link.springer.com/chapter/10.1007/978-3-662-49224-6_3,Chapter,"Concurrency, System testing, Timed usage models",10,"Timed usage models (TUMs) represent a model-based statistical approach for system testing of real-time embedded systems. They enable an automatic test case generation and the calculation of parameters that aid the test process. However, a classical TUM only supports sequential uses of the system under test (SUT). It is not capable of dealing with concurrency, which is required for state of the art real-time embedded systems. Therefore, we introduce TUMs with parallel regions. They also allow automatic test case generation, which is carried out similarly to classical TUMs. But, the semi-Markov process (SMP) that is usually used for analysis is not suitable here. We apply Markov renewal theory and define an SMP with parallel regions, which is used to calculate parameters. We validated our analytical approach by simulations."
Efficient Guiding Strategies for Testing of Temporal Properties of Hybrid Systems,NASA Formal Methods,,,,10.1007/978-3-319-17524-9_10,Tommaso DreossiThao DangAlexandre DonzéJames KapinskiXiaoqing JinJyotirmoy V. Deshmukh,2015,http://link.springer.com/chapter/10.1007/978-3-319-17524-9_10,Chapter,"Goal Cell, Guide Strategy, Simulation Trace, Star Discrepancy, Temporal Logic",10,"Techniques for testing cyberphysical systems (CPS) currently use a combination of automatic directed test generation and random testing to find undesirable behaviors. Existing techniques can fail to efficiently identify bugs because they do not adequately explore the space of system behaviors. In this paper, we present an approach that uses the rapidly exploring random trees (RRT) technique to explore the state-space of a CPS. Given a Signal Temporal Logic (STL) requirement, the RRT algorithm uses two quantities to guide the search: The first is a robustness metric that quantifies the degree of satisfaction of the STL requirement by simulation traces. The second is a metric for measuring coverage for a dense state-space, known as the star discrepancy measure. We show that our approach scales to industrial-scale CPSs by demonstrating its efficacy on an automotive powertrain control system."
Scenario-Based Design and Validation of REST Web Service Compositions,Web Information Systems and Technologies,,,,10.1007/978-3-319-27030-2_10,Irum RaufFaezeh SiavashiDragos TruscanIvan Porres,2015,http://link.springer.com/chapter/10.1007/978-3-319-27030-2_10,Chapter,"Model-based testing, REST, TRON, UPPAAL, Web service composition",10,"We present an approach to design and validate RESTful composite web services based on user scenarios. We use the Unified Modeling Language (UML) to specify the requirements, behavior and published resources of each web service. In our approach, a service can invoke other services and exhibit complex and timed behavior while still complying with the REST architectural style. We specify user scenarios via UML Sequence Diagrams. The service specifications are transformed into UPPAAL timed automata for verification and test generation. The service requirements are propagated to the UPPAAL timed automata during the transformation. Their reachability is verified in UPPAAL and they are used for computing coverage level during test generation. We validate our approach with a case study of a holiday booking web service."
Runtime Verification of Expected Energy Consumption in Smartphones,Model Checking Software,,,,10.1007/978-3-319-23404-5_10,Ana Rosario EspadaMaría del Mar GallardoAlberto SalmerónPedro Merino,2015,http://link.springer.com/chapter/10.1007/978-3-319-23404-5_10,Chapter,"Analysis of traces, Energy consumption, Interval logic, Runtime verification",10,"Smartphones connected to Internet should work properly for days without a reset. One of the most critical non-functional properties to ensure the correct behavior is energy consumption. However, currently there is a lack of automated techniques to check whether the actual mobile consume is within the expected limits. To apply runtime verification techniques in this context, we need (a) detailed profiles of consumptions for specific actions in apps of interest (such as activate GPS, send a data packet to the network, etc.); (b) a method to automatically generate sufficiently representative use cases of the mobile behavior; (c) a language to describe the expected behavior in terms of energy consumption (energy properties); and (d) a method to monitor the mobile execution traces and analyze them against the energy properties. We aim to construct a tool chain addressing all these steps. We have already designed and implemented a model-based approach to automatically generate execution traces in mobile devices using Spin . This paper focuses on the formalization and analysis of energy properties with a specification language inspired by the interval logic. The paper presents this logic, the implementation of runtime verification using Büchi automata, and the practical use of the whole tool chain for model-based runtime verification of energy-related properties. Spin is a main ingredient for generating the test cases and checking the properties."
Empirical Evaluation of UML Modeling Tools–A Controlled Experiment,Modelling Foundations and Applications,,,,10.1007/978-3-319-21151-0_3,Safdar Aqeel SafdarMuhammad Zohaib IqbalMuhammad Uzair Khan,2015,http://link.springer.com/chapter/10.1007/978-3-319-21151-0_3,Chapter,"Controlled experiment, Empirical software engineering, Model driven software engineering, Modeling tools, UML ",10,"Model driven software engineering (MDSE) has shown to provide mark improvement in productivity and quality of software products. UML is a standard modeling language that is widely used in the industry to support MDSE. To provide tool support for MDSE, a large number of UML modeling tools are available, ranging from open-source tools to commercial tools with high price tag. A common decision faced while applying UML in practice is the selection of an appropriate tool for modeling. In this paper we conduct a study to compare three of the well-known modeling tools: IBM Rational Software Architect (RSA), MagicDraw, and Papyrus. In this study we conducted an experiment with undergraduate and graduate students. The goal is to compare the productivity of the software engineers while modeling with the tools. We measure the productivity in terms of modeling effort required to correctly complete a task, learnability, time and number of clicks required, and memory load required for the software engineer to complete a task. Our results show that MagicDraw performed significantly better in terms of learnability, memory load, and completeness of tasks. In terms of time and number of clicks, IBM RSA was significantly better while modeling class diagrams and state machines when compared to Papyrus. However no single tool outperformed others in all the modeling tasks with respect to time and number of clicks."
Advanced Test Modelling and Execution Based on the International Standardized Techniques TTCN-3 and UTP,Trustworthy Computing and Services,,,,10.1007/978-3-662-47401-3_32,Axel RennochMarc-Florian WendlandAndreas HoffmannMartin Schneider,2015,http://link.springer.com/chapter/10.1007/978-3-662-47401-3_32,Chapter,"Model-based test design, Test automation, TTCN-3, UML, UTP",10,"In systems and service engineering testing is an important part to get confidence in quality and trust in security issues. Standardized testing techniques support the unique definition of abstract test models, configurations and behavior scenarios that can be executed automatically. This contribution presents the state of the art and future directions of two international standards for testing: the Testing and Test Control Notation (TTCN-3) from the European Telecommunication Standardization Institute (ETSI), and the UML testing profile (UTP) from the Open Management Group (OMG). Special emphasize is given to the translation from UTP to TTCN-3 test models, automated test execution using standard-compliant tool support and related examples from European projects."
A Top-Down Design Approach for an Automated Testing Framework,"Ubiquitous Computing and Ambient Intelligence. Sensing, Processing, and Using Environmental Information",,,,10.1007/978-3-319-26401-1_4,Abel Méndez-PorrasMario Nieto HidalgoJuan Manuel García-ChamizoMarcelo JenkinsAlexandra Martínez Porras,2015,http://link.springer.com/chapter/10.1007/978-3-319-26401-1_4,Chapter,"Automated testing, Historical bug information, Interest points, Mobile applications, Top-down design, User-interaction features",10,"Mobile applications have become popular work tools. Portability and ease of Internet connectivity are characteristics that favor this adoption. However, mobile applications sometimes incorrectly process events associated with the user-interaction features. These features include content presentation or navigation. Rotating the devices, and gestures such as scroll or zoom into screens are some examples. There is a need to assess the quality with which mobile applications are processing these user-interaction features in order to improve their performance. In this paper, we present a top-down design approach for an automated testing framework for mobile applications. Our framework integrates digital image processing, GUI information, and historical bug information to identify new bugs based on user-interaction features. Our framework captures images before and after applying the user-interaction features and uses the SURF algorithm to identify interest points in each image. We compared interest points to note differences on the screens before and after applying the user-interaction features. This differences helps to find bugs in mobile applications. The first results show that it is feasible to identify bugs with user-interaction features using the proposed technique."
LearnLib Tutorial,Runtime Verification,,,,10.1007/978-3-319-23820-3_25,Malte IsbernerBernhard SteffenFalk Howar,2015,http://link.springer.com/chapter/10.1007/978-3-319-23820-3_25,Chapter,"Automaton Learning, Lower Common Ancestor, Membership Query, Observation Table, Regular Language",10,"Active automata learning is a promising technique to generate formal behavioral models of systems by experimentation. The practical applicability of active learning, however, is often hampered by the impossibility of realizing so-called equivalence queries , which are vital for ensuring progress during learning and finally resulting in correct models. This paper discusses the proposed approach of using monitoring as a means of generating counterexamples, explains in detail why virtually all existing learning algorithms are not suited for this approach, and gives an intuitive account of TTT, an algorithm designed to cope with counterexamples of extreme length. The essential steps and the impact of TTT are illustrated via experimentation with LearnLib , a free, open source Java library for active automata learning."
Stream X-Machines for Agent Simulation Test Case Generation,Agents and Artificial Intelligence,,,,10.1007/978-3-319-27947-3_3,Ilias SakellariouDimitris DranidisMarina NtikaPetros Kefalas,2015,http://link.springer.com/chapter/10.1007/978-3-319-27947-3_3,Chapter,"Agent based simulation, Formal methods, NetLogo, Test case generation",10,"Applying the Stream X-Machine formal method in the development of multi-agent simulations has a number of significant advantages, since it combines the power of executable specifications and test case generation. The present work supports this argument by reporting on the combined use of two tools that involve Stream X-Machines (SXM): the first is a domain specific language for effortlessly encoding agent behaviour using SXMs in a well known agent simulation platform. The second tool, supports among other things, automated test case generation using SXMs. The main benefits of using the specific formal approach in such a practical setting is that it offers a clear intuitive way of specifying agent behaviour and the automated generation of “agent simulation test scenarios” that can be used for validation."
An Industrial Case Study on Test Cases as Requirements,Agile Processes in Software Engineering and Extreme Programming,,,,10.1007/978-3-319-18612-2_3,Elizabeth BjarnasonMichael UnterkalmsteinerEmelie EngströmMarkus Borg,2015,http://link.springer.com/chapter/10.1007/978-3-319-18612-2_3,Chapter,"Acceptance test, Agile development, Behaviour-driven development, Case study, Requirements and test alignment",10,"It is a conundrum that agile projects can succeed ‘without requirements’ when weak requirements engineering is a known cause for project failures. While Agile development projects often manage well without extensive requirements documentation, test cases are commonly used as requirements. We have investigated this agile practice at three companies in order to understand how test cases can fill the role of requirements. We performed a case study based on twelve interviews performed in a previous study. The findings include a range of benefits and challenges in using test cases for eliciting, validating, verifying, tracing and managing requirements. In addition, we identified three scenarios for applying the practice, namely as a mature practice, as a de facto practice and as part of an agile transition. The findings provide insights into how the role of requirements may be met in agile development including challenges to consider."
Insertion Modeling and Symbolic Verification of Large Systems,SDL 2015: Model-Driven Engineering for Smart Cities,,,,10.1007/978-3-319-24912-4_1,Alexander LetichevskyOleksandr LetychevskyiVolodymyr PeschanenkoThomas Weigert,2015,http://link.springer.com/chapter/10.1007/978-3-319-24912-4_1,Chapter,"Large system development, Symbolic techniques, Verification",10,"Insertion modeling has been developed over the last decade as an approach to a general theory of interaction between agents and an environment in complex distributed multiagent systems. The original work in this direction proposed a model of interaction between agents and environments based on an insertion function and the algebra of behaviors (similar to process algebra). Over the recent years, insertion modeling has been applied to the verification of requirement specifications of distributed interacting systems and to the generation of tests from such requirements. Our system, VRS (Verification of Requirements Specifications), has successfully verified specifications in the field of telecommunication systems, embedded systems, and real-time systems. Formal requirements in VRS are presented by means of local descriptions with a succession relation. Formalized requirements are represented in a formalism that combines logical specifications with control descriptions provided by the graphical syntax of UCM (Use Case Map) diagrams. This paper overviews the main concepts of insertion modeling, presents new algorithms developed for symbolic verification, especially a new predicate transformer for local descriptions, and provides a formal description of the method of generating traces from such specifications (which is the key technology used to verify requirements and derive test suites)."
Evaluation of Autonomous Approaches Using Virtual Environments,"Virtual, Augmented and Mixed Reality",,,,10.1007/978-3-319-21067-4_51,Katharina StahlJörg StöckleinSijia Li,2015,http://link.springer.com/chapter/10.1007/978-3-319-21067-4_51,Chapter,"Anomaly Detection, Evaluation Environment, Mechatronic System, Virtual Environment, Virtual Prototype",10,"In this paper, we address the challenging problem of evaluating autonomous research approaches by the example of an online anomaly detection framework for dynamical real-time systems. We propose to use a virtual test environment that was conceptualized based on the specific evaluation requirements. The architecture is composed of all system parts required for evaluation: the operating system implementing the anomaly detection framework, reconfigurable autonomous applications, an execution platform device for the operating system and its applications, and the device’s environment. We demonstrate our concepts by the example of our miniature robot BeBot that acts as our virtual prototype (VP) to execute autonomous applications. With an interactive module, the virtual environment (VE) offers full control over the environment and the VP so that using different levels of hardware implementation for evaluation, but also failure injection at runtime becomes possible. Our architecture allows to determine clear system boundaries of the particular parts composed of perception function, decision making function and execution function which is essential for evaluating autonomous approaches. We define evaluation scenarios to show the effectiveness of each part of our approach and illustrate the powerfulness of applying virtual test environments to evaluate such approaches as the here referred one."
Maareech: Usability Testing Tool for Voice Response System Using XML Based User Models,"Design, User Experience, and Usability: Design Discourse",,,,10.1007/978-3-319-20886-2_10,Siddhartha AsthanaPushpendra Singh,2015,http://link.springer.com/chapter/10.1007/978-3-319-20886-2_10,Chapter,"Usability testing, User-models",10,"Interactive Voice Response Systems (IVRS) are popular voice-based systems to access information over the telephone. In developing regions, HCI researchers have shown keen interest in IVRS due to high affordability and reach among rural, poor, and illiterate users. However, IVRS are also notorious for their usability issues. This makes researchers thrive for more usable IVRS. The lack of automated usability testing tools for voice-based systems makes researchers depend on human subjects for testing their proposed IVR systems that are both costly and time-consuming. To address this research gap, we present Maareech, a usability testing tool for voice response systems using XML-based user models. Maareech has a flexible architecture to accommodate different user models that can be used to perform usability tests. In this paper, we discuss Maareech’s architecture and its ability to mimic IVR user behavior based on different user models."
Stochastic Local Search for Falsification of Hybrid Systems,Automated Technology for Verification and Analysis,,,,10.1007/978-3-319-24953-7_35,Jyotirmoy DeshmukhXiaoqing JinJames KapinskiOded Maler,2015,http://link.springer.com/chapter/10.1007/978-3-319-24953-7_35,Chapter,"Input Sequence, Input Space, Local Search, Tabu Search, Temporal Logic",10,"Falsification techniques for models of embedded control systems automate the process of testing models to find bugs by searching for model-inputs that violate behavioral specifications given by logical and quantitative correctness requirements. A recent advance in falsification is to encode property satisfaction as a cost function based on a finite parameterization of the (bounded-time) input signal, which allows formulating bug-finding as an optimization problem. In this paper, we present a falsification technique that uses a local search technique called Tabu search to search for optimal inputs. The key idea is to discretize the space of input signals and use the Tabu list to avoid revisiting previously encountered input signals. As local search techniques may converge to local optima, we introduce stochastic aspects such as random restarts, sampling and probabilistically picking suboptimal inputs to guide the technique towards a global optimum. Picking the right parameterization of the input space is often challenging for designers, so we allow dynamic refinement of the input space as the search progresses. We implement the technique in a tool called sitar , and show scalability of the technique by using it to falsify requirements on an early prototype of an industrial-sized automotive powertrain control design."
Model-in-the-Loop Testing of a Railway Interlocking System,Model-Driven Engineering and Software Development,,,,10.1007/978-3-319-27869-8_22,Fabio ScippacercolaRoberto PietrantuonoStefano RussoAndrás Zentai,2015,http://link.springer.com/chapter/10.1007/978-3-319-27869-8_22,Chapter,"Model-Driven Engineering, Model-Driven Testing, Safety-critical systems",10,"Model-driven techniques offer new solutions to support development and verification and validation (V&V) activities of software-intensive systems. As they can reduce costs, and ease the certification process as well, they are attractive also in safety-critical domains. We present an approach for Model-in-the-loop testing within an OMG-based model-driven process, aimed at supporting system V&V activities. The approach is based on the definition of a model of the system environment, named Computation Independent Test (CIT) model. The CIT enables various forms of system test, allowing early detection of design faults. We show the benefits of the approach with reference to a pilot project that is part of a railway interlocking system. The system, required to be CENELEC SIL-4 compliant, has been provided by the Hungarian company Prolan Co. in the context of an industrial-academic partnership."
NAT2TEST Tool: From Natural Language Requirements to Test Cases Based on CSP,Software Engineering and Formal Methods,,,,10.1007/978-3-319-22969-0_20,Gustavo CarvalhoFlávia BarrosAna CarvalhoAna CavalcantiAlexandre MotaAugusto Sampaio,2015,http://link.springer.com/chapter/10.1007/978-3-319-22969-0_20,Chapter,"Natural-language requirements, Test-case generation, Tool",10,"Formal models are increasingly being used as input for automated test-generation strategies. However, typically the requirements are captured as English text, and these formal models are not readily available. With this in mind, we have devised a strategy (NAT2TEST) to obtain formal models from natural language requirements automatically, particularly to generate sound test cases. Our strategy is extensible, since we consider an intermediate and hidden formal characterisation of the system behaviour from which other formal notations can be derived. Here, we present the NAT2TEST tool, which implements our strategy."
LTSmin: High-Performance Language-Independent Model Checking,Tools and Algorithms for the Construction and Analysis of Systems,,,,10.1007/978-3-662-46681-0_61,Gijs KantAlfons LaarmanJeroen MeijerJaco van de PolStefan BlomTom van Dijk,2015,http://link.springer.com/chapter/10.1007/978-3-662-46681-0_61,Chapter,"Language Module, Model Check, State Label, Transition Group, Winning Strategy",10,"In recent years, the LTSmin model checker has been extended with support for several new modelling languages, including probabilistic ( Mapa ) and timed systems ( Uppaal ). Also, connecting additional language front-ends or ad-hoc state-space generators to LTSmin was simplified using custom C-code. From symbolic and distributed reachability analysis and minimisation, LTSmin ’s functionality has developed into a model checker with multi-core algorithms for on-the-fly LTL checking with partial-order reduction, and multi-core symbolic checking for the modal μ calculus, based on the multi-core decision diagram package Sylvan . In LTSmin , the modelling languages and the model checking algorithms are connected through a Partitioned Next-State Interface ( Pins ), that allows to abstract away from language details in the implementation of the analysis algorithms and on-the-fly optimisations. In the current paper, we present an overview of the toolset and its recent changes, and we demonstrate its performance and versatility in two case studies."
Security and Privacy in Vehicular Communications with INTER-TRUST,Cyber Security and Privacy,,,,10.1007/978-3-319-25360-2_5,Juan M. Marín PérezAntonio Moragón JuanJaime Arrazola PérezJavier Monge RabadánAntonio F. Skarmeta Gómez,2015,http://link.springer.com/chapter/10.1007/978-3-319-25360-2_5,Chapter,"AOP, INTER-TRUST, ITS, Policy-based, Privacy, Security",10,"Security systems in Intelligent Transport Systems (ITS) are woefully underprepared for the security threats in the modern landscape. However, the real potential for loss of life in the event of a successful attack makes these systems the more important to protect against such intrusions. In this paper, a new security framework that is the result of the INTER-TRUST European project will be presented and proposed as a solution that could solve most of ITS’s current security problems. The solution provides dynamic and adaptable security with a set of monitoring tools that also enable the adaptation of security to different contexts or situations that makes away with the need to recode the original applications. An overview on ITS security and how specific security features can be provided to ITS applications by deploying the INTER-TRUST framework is analyzed. A proof of concept implementation has been also developed during this research with some experimental results."
Revealing Differences in Anatomical Remodelling of the Systemic Right Ventricle,Functional Imaging and Modeling of the Heart,,,,10.1007/978-3-319-20309-6_12,Ernesto ZacurJames WongReza RazaviTal GevaGerald GreilPablo Lamata,2015,http://link.springer.com/chapter/10.1007/978-3-319-20309-6_12,Chapter,"Computational anatomy, Discriminative analysis, Statistical shape analysis, Systemic right ventricle",10,"Cardiac remodelling, which refers to the change of the shape and size of the myocardium, is an adaptive response to developmental, disease and surgical processes. Traditional metrics of length, volume, aspect ratio or wall thickness are used in the clinic and in medical research, but have limited capabilities to describe complex structures such as the shape of cardiac ventricles. In this work we present an example of how computational analysis of cardiac anatomy can reveal more detailed description of developmental and remodelling patterns. The clinical problem is the analysis of the impact of two different surgical palliation techniques for hypoplastic left heart syndrome. Construction of a computational atlas and the statistical description of its variability are performed from the short axis stack of 128 subjects. Results unveil, for the first time in the literature, the differences in remodelling of the systemic right ventricle depending on the surgical palliation technique."
TDQMed: Managing Collections of Complex Test Data,Advances in Databases and Information Systems,,,,10.1007/978-3-319-23135-8_23,Johannes HeldRichard Lenz,2015,http://link.springer.com/chapter/10.1007/978-3-319-23135-8_23,Chapter,"Information extraction and integration, Knowledge discovery, Test-data quality",10,"Medical devices like Medical Linear Accelerators (LINAC) are extensively tested before they are used in routine practice. Such systems typically interact with multiple other systems that produce complex input data, like medical images annotated with extensive metadata. Before such a system is actually used in a hospital with real patients it has to be tested with test data as realistic as possible. Suitable test data, however, cannot be easily generated. For this reason vendors typically accumulate large collections of patient files over the years to have them available for various test scenarios. In the TDQMed project we have developed methods and tools that enable a tester to estimate both the quality of a test data collection and its applicability for a particular test goal. A prototype system has been implemented to demonstrate the feasibility of measuring specific test data related quality criteria like coverage of test space and closeness to reality. An evaluation with professional testers indicates that the overall approach is promising."
Rigorous Examination of Reactive Systems:,Runtime Verification,,,,10.1007/978-3-319-23820-3_28,Maren GeskeMalte IsbernerBernhard Steffen,2015,http://link.springer.com/chapter/10.1007/978-3-319-23820-3_28,Chapter,"Automaton Learning, Internal Logic, Model Check, Symbolic Execution, Verification Task",10,"In this paper we present the RERS challenge 2015, a free-style program analysis challenge on reactive systems to evaluate the effectiveness of different validation and verification techniques. It brings together researchers from different areas including static analysis, model checking, theorem proving, symbolic execution, and testing. The challenge characteristics and set-up are discussed, while special attention is given to the Runtime Verification track that was newly introduced."
Learning Register Automata with Fresh Value Generation,Theoretical Aspects of Computing - ICTAC 2015,,,,10.1007/978-3-319-25150-9_11,Fides AartsPaul Fiterau-BrosteanHarco KuppensFrits Vaandrager,2015,http://link.springer.com/chapter/10.1007/978-3-319-25150-9_11,Chapter,Expense,10,"We present a new algorithm for active learning of register automata. Our algorithm uses counterexample-guided abstraction refinement to automatically construct a component which maps (in a history dependent manner) the large set of actions of an implementation into a small set of actions that can be handled by a Mealy machine learner. The class of register automata that is handled by our algorithm extends previous definitions since it allows for the generation of fresh output values. This feature is crucial in many real-world systems (e.g. servers that generate identifiers, passwords or sequence numbers). We have implemented our new algorithm in a tool called Tomte."
Testing Business Processes Using TTCN-3,SDL 2015: Model-Driven Engineering for Smart Cities,,,,10.1007/978-3-319-24912-4_18,Bernard StepienKavya MallurLiam Peyton,2015,http://link.springer.com/chapter/10.1007/978-3-319-24912-4_18,Chapter,"Business processes, SOA, Testing, TTCN-3",10,Business Process Management (BPM) applications in the medical domain pose challenging testing problems that result from parallel execution of test behaviors performed by different actors. Hospitals nowadays function with the principle of pools of personnel. Each pool addresses a specific functionality and each member of the pool can pick any task that is proposed to the pool. The challenge for BPM testing is in the existence of dependencies between actors and the corresponding test description where the stimuli sent to the BPM that is the system under test (SUT) by one actor produces responses that affect a selected number of other actors belonging to a pool. Unit testing of such systems has proven to be of limited efficiency in detecting faults that can be detected only during parallel execution of test components representing actors. We propose an architecture based on the TTCN-3 model of separation of concern and its intensive parallel test component (PTC) concept which provides solutions that are beyond traditional telecommunication systems testing and which have revealed opportunities for improving TTCN-3.
A Genetic Algorithm for Automatic Business Process Test Case Selection,On the Move to Meaningful Internet Systems: OTM 2015 Conferences,,,,10.1007/978-3-319-26148-5_10,Kristof BöhmerStefanie Rinderle-Ma,2015,http://link.springer.com/chapter/10.1007/978-3-319-26148-5_10,Chapter,"Genetic algorithm, Process modeling and design, Process testing, Test case selection",10,"Process models tend to become more and more complex and, therefore, also more and more test cases are required to assure their correctness and stability during design and maintenance. However, executing hundreds or even thousands of process model test cases leads to excessive test suite execution times and, therefore, high costs. Hence, this paper presents a novel approach for process model test case selection which is able to address flexible user-driven test case selection requirements and which can integrate a diverse set of knowledge sources to select an appropriate minimal set of test cases which can be executed in minimal time. Additionally, techniques are proposed which enable the representation of unique coverage requirements and effects for each process node and process test case in a comprehensive way. For test case selection, a genetic algorithm is proposed. Its effectiveness is shown in comparison with other test case selection approaches."
Domain-Specific Languages with Scala,Formal Methods and Software Engineering,,,,10.1007/978-3-319-25423-4_1,Cyrille ArthoKlaus HavelundRahul KumarYoriyuki Yamagata,2015,http://link.springer.com/chapter/10.1007/978-3-319-25423-4_1,Chapter,"DSL, Evaluation, External and internal domain-specific language, Language design, Modeling, Programming, Scala",10,"Domain-Specific Languages (DSLs) are often classified into external and internal DSLs. An external DSL is a stand-alone language with its own parser. An internal DSL is an extension of an existing programming language, the host language, offering the user of the DSL domain-specific constructs as well as the constructs of the host language, thus providing a richer language than the DSL itself. In this paper we report on experiences implementing external as well as internal formal modeling DSLs with the Scala programming language, known in particular for its support for defining DSLs. The modeling languages include monitoring logics, a testing language, and a general purpose SysML inspired modeling language. We present a systematic overview of advantages and disadvantages of each option."
Helping the Tester Get It Right: Towards Supporting Agile Combinatorial Test Design,Software Engineering and Formal Methods,,,,10.1007/978-3-662-49224-6_4,Anna ZamanskyEitan Farchi,2015,http://link.springer.com/chapter/10.1007/978-3-662-49224-6_4,Chapter,,10,"Combinatorial test design (CTD) is an effective test planning technique that reveals faulty feature interaction in a given system. CTD takes a systematic approach to formally model the system to be tested, and propose test cases ensuring coverage of given conditions or interactions between parameters. In this position paper we propose a framework for supporting agile CTD, a human-centered methodology, which takes into account the human tester’s possible mistakes and supports revision and refinement. In this approach a combinatorial model of the system and test plans are constructed in an incremental and iterative way, providing the tester with the ability to refine and validate the constructions. We propose a formal framework which can be used as a theoretical foundation for the development of agile CTD support tools, and describe a use case of an envisioned tool."
Generating Performance Test Model from Conformance Test Logs,SDL 2015: Model-Driven Engineering for Smart Cities,,,,10.1007/978-3-319-24912-4_19,Gusztáv AdamisGábor KovácsGyörgy Réthy,2015,http://link.springer.com/chapter/10.1007/978-3-319-24912-4_19,Chapter,"FSM Learning, Sequential pattern mining, Test model",10,"In this paper, we present a method that learns a deterministic finite state machine from the conformance test logs of a telecommunication protocol; then that machine is used as test model for performance testing. The learning process is in contrast to most theoretical methods automatic; it applies a sequential pattern mining algorithm on the test logs, and uses a recently proposed metric for finding frequent and significant transition sequences. The method aims to help and speed up test model design, and at the same time it may not provide an exact solution, the equivalence of some states may not be proven. In the paper, we show the results of experiments on random machines, and issues and considerations that arise when the method was applied to 3GGP Telephony Application Server test logs."
An Approach to Derive Usage Models Variants for Model-Based Testing,Testing Software and Systems,,,,10.1007/978-3-662-44857-1_6,Hamza SamihHélène Le GuenRalf BoguschMathieu AcherBenoit Baudry,2014,http://link.springer.com/chapter/10.1007/978-3-662-44857-1_6,Chapter,"Model-based Testing, Orthogonal Variability Model, Product Line, Requirements, Usage Model, Usage Model Variant",10,"Testing techniques in industry are not yet adapted for product line engineering (PLE). In particular, Model-based Testing (MBT), a technique that allows to automatically generate test cases from requirements, lacks support for managing variability (differences) among a set of related product. In this paper, we present an approach to equip usage models, a widely used formalism in MBT, with variability capabilities. Formal correspondences are established between a variability model, a set of functional requirements, and a usage model. An algorithm then exploits the traceability links to automatically derive a usage model variant from a desired set of selected features. The approach is integrated into the professional MBT tool MaTeLo and is currently used in industry."
Model-Based Testing from Controlled Natural Language Requirements,Formal Techniques for Safety-Critical Systems,,,,10.1007/978-3-319-05416-2_3,Gustavo CarvalhoFlávia BarrosFlorian LapschiesUwe SchulzeJan Peleska,2014,http://link.springer.com/chapter/10.1007/978-3-319-05416-2_3,Chapter,"Case grammar, Natural language, Solver, Test case",10,"Model-Based Testing (MBT) techniques usually take as input models that are not available in the very beginning of a development. Therefore, its use is postponed. In this work we present an approach to MBT that takes as input requirements described in a Controlled Natural Language. Initially, the requirements are syntactically analyzed according to a domain specific language for describing system requirements, and their informal semantics is depicted based on the Case Grammar theory. Then, the requirements semantics is automatically represented as a Transition Relation, which provides formal basis for MBT, and test cases are generated with the support of a solver. Our approach was evaluated considering four examples from different domains. Within seconds, our approach generated 94 % of the test vectors manually written by specialists. Moreover, considering a mutant-based strength analysis, our approach yielded a mutation score between 54 % and 98 %."
Model-Based Testing in Cloud Brokerage Scenarios,Service-Oriented Computing – ICSOC 2013 Workshops,,,,10.1007/978-3-319-06859-6_17,Mariam KiranAndreas FriesenAnthony J. H. SimonsWolfgang K. R. Schwach,2014,http://link.springer.com/chapter/10.1007/978-3-319-06859-6_17,Chapter,"Cloud Broker, Cloud Service Brokerage, Lifecycle Governance, Model-based Testing, Web Service Testing",10,"In future Cloud ecosystems, brokers will mediate between service providers and consumers, playing an increased role in quality assurance, checking services for functional compliance to agreed standards, among other aspects. To date, most Software-as-a-Service (SaaS) testing has been performed manually, requiring duplicated effort at the development, certification and deployment stages of the service lifecycle. This paper presents a strategy for achieving automated testing for certification and re-certification of SaaS applications, based on the adoption of simple state-based and functional specifications. High-level test suites are generated from specifications, by algorithms that provide the necessary and sufficient coverage. The high-level tests must be grounded for each implementation technology, whether SOAP, REST or rich-client. Two examples of grounding are presented, one into SOAP for a traditional web service and the other into Selenium for a SAP HANA rich-client application. The results demonstrate good test coverage. Further work is required to fully automate the grounding."
Model-Based Testing: An Approach with SDL/RTDS and DIVERSITY,System Analysis and Modeling: Models and Reusability,,,,10.1007/978-3-319-11743-0_14,Julien DeltourAlain FaivreEmmanuel GaudinArnault Lapitre,2014,http://link.springer.com/chapter/10.1007/978-3-319-11743-0_14,Chapter,"Model-based testing, SDL, Test generation, TTCN-3",10,"The objective of the PragmaList Lab, a joint laboratory between PragmaDev and CEA LIST, is to integrate the test generation tool DIVERSITY in the SDL modeling environment Real Time Developer Studio (RTDS). The resulting environment aims to extend RTDS with a Model-Based Testing approach. After briefly describing the characteristics of RTDS and DIVERSITY, this paper presents the work done to integrate these two environments. Then, it highlights the main principles of DIVERSITY based on symbolic execution, which enables the generation of test cases in TTCN-3 format. The paper then presents the existing coverage criteria in the integrated generation of test cases. It concludes with the open strategy of the PragmaList approach to work together with industrial actors based on the definition and integration of new specific coverage criteria consistent with their validation constraints."
Environment-Model Based Testing of Control Systems: Case Studies,Tools and Algorithms for the Construction and Analysis of Systems,,,,10.1007/978-3-642-54862-8_55,Erwan JahierSimplice Djoko-DjokoChaouki MaizaEric Lafont,2014,http://link.springer.com/chapter/10.1007/978-3-642-54862-8_55,Chapter,"Black-box testing, Control-command, Dynamic systems, Reactive systems, Requirements engineering, SCADA, Synchronous Languages, Test Booklets",10,"A reactive system reacts to an environment it tries to control. Lurette is a black-box testing tool for such closed-loop systems. It focuses on environment modeling using Lutin, a language designed to perform guided random exploration of the System Under Test (SUT) environment, taking into account the feedback. The test decision is automated using Lustre oracles resulting from the formalisation of functional requirements. In this article, we report on experimentations conducted with Lurette on two industrial case studies. One deals with a dynamic system which simulates the behavior of the temperature and the pressure of a fluid in a pipe. The other one reports on how Lurette can be used to automate the processing of an existing test booklet of a Supervisory Control and Data Acquisition (SCADA) library module."
True Error or False Alarm? Refining Astrée’s Abstract Interpretation Results by Embedded Tester’s Automatic Model-Based Testing,"Computer Safety, Reliability, and Security",,,,10.1007/978-3-319-10557-4_12,Sayali SalviDaniel KästnerTom BienmüllerChristian Ferdinand,2014,http://link.springer.com/chapter/10.1007/978-3-319-10557-4_12,Chapter,"Abstract Interpretation, Code Fragment, False Alarm, Test Vector, True Error",10,"A failure of safety-critical software may cause high costs or even endanger human beings. Contemporary safety standards require to identify potential functional and non-functional hazards and to demonstrate that the software does not violate the relevant safety goals. Typically for ensuring functional program properties model-based testing is used while non-functional properties like occurrence of runtime errors are addressed by abstract interpretation-based static analysis. Hence the verification process is split into two distinct parts – currently without any synergy between them being exploited. In this article we present an approach to couple model-based testing with static analysis based on a tool coupling between Astrée and BTC Embedded Tester ® . Astrée reports all potential runtime errors in C programs. This makes it possible to prove the absence of runtime errors, but typically users have to deal with false alarms, i.e. spurious notifications about potential runtime errors. Investigating alarms to find out whether they are true errors which have to be fixed, or whether they are false alarms can cause significant effort. The key idea of this work is to apply model-based testing to automatically find test cases for alarms reported by the static analyzer. When a test case reproducing the error has been found, it has been proven that it is a true error; when no error has been found with full test coverage, it has been proven to be a false alarm. This can significantly reduce the alarm analysis effort and reduces the level of expertise needed to perform the code-level software verification. We describe the underlying concept and report on experimental results and future work."
Model-Based Shrinking for State-Based Testing,Trends in Functional Programming,,,,10.1007/978-3-642-45340-3_7,Pieter KoopmanPeter AchtenRinus Plasmeijer,2014,http://link.springer.com/chapter/10.1007/978-3-642-45340-3_7,Chapter,,10,Issues found in model-based testing of state-based systems are traces produced by the system under test that are not allowed by the model used as specification. It is usually easier to determine the error behind the reported issue when there is a short trace revealing the issue. Our model-based test system treats the system under test as a black box. Hence the test system cannot use internal information from the system under test to find short traces. This paper shows how the model can be used to systematically search for shorter traces producing an issue based on some trace revealing an issue.
Risk-Based Vulnerability Testing Using Security Test Patterns,"Leveraging Applications of Formal Methods, Verification and Validation. Specialized Techniques and Applications",,,,10.1007/978-3-662-45231-8_24,Julien BotellaBruno LegeardFabien PeureuxAlexandre Vernotte,2014,http://link.springer.com/chapter/10.1007/978-3-662-45231-8_24,Chapter,"CORAS, Model-Based Testing, Risk-Based Testing, Security test pattern, SQL Injection, Web application vulnerability",10,"This paper introduces an original security testing approach guided by risk assessment, by means of risk coverage, to perform and automate vulnerability testing for Web applications. This approach, called Risk-Based Vulnerability Testing, adapts Model-Based Testing techniques, which are mostly used currently to address functional features. It also extends Model-Based Vulnerability Testing techniques by driving the testing process using security test patterns selected from risk assessment results. The adaptation of such techniques for Risk-Based Vulnerability Testing defines novel features in this research domain. In this paper, we describe the principles of our approach, which is based on a mixed modeling of the System Under Test: the model used for automated test generation captures some behavioral aspects of the Web applications, but also includes vulnerability test purposes to drive the test generation process."
Complete Model-Based Equivalence Class Testing for the ETCS Ceiling Speed Monitor,Formal Methods and Software Engineering,,,,10.1007/978-3-319-11737-9_25,Cécile BraunsteinAnne E. HaxthausenWen-ling HuangFelix HübnerJan PeleskaUwe SchulzeLinh Vu Hong,2014,http://link.springer.com/chapter/10.1007/978-3-319-11737-9_25,Chapter,"Ceiling Speed Monitoring, Equivalence class partition testing, European Train Control System ETCS, Model-based testing, SysML",10,"In this paper we present a new test model written in SysML and an associated blackbox test suite for the Ceiling Speed Monitor (CSM) of the European Train Control System (ETCS). The model is publicly available and intended to serve as a novel benchmark for investigating new testing theories and comparing the capabilities of model-based test automation tools. The CSM application inputs velocity values from a domain which could not be completely enumerated for test purposes with reasonable effort. We therefore apply a novel method for equivalence class testing that – despite the conceptually infinite cardinality of the input domains – is capable to produce finite test suites that are complete (i.e. sound and exhaustive) for a given fault model. In this paper, an overview of the model and the equivalence class testing strategy is given, and tool-based evaluation results are presented. For the technical details we refer to the published model and a technical report that is also available on the same website."
A Model-Based Certification Framework for the EnergyBus Standard,"Formal Techniques for Distributed Objects, Components, and Systems",,,,10.1007/978-3-662-43613-4_6,Alexander Graf-BrillHolger HermannsHubert Garavel,2014,http://link.springer.com/chapter/10.1007/978-3-662-43613-4_6,Chapter,"Battery Pack, Energy Management System, Model Check, Test Execution, Test Graph",10,"The EnergyBus is an upcoming industrial standard for electric power transmission and management, based on the CANopen field bus. This paper reviews the particularities of the EnergyBus architecture and reports on the application of formal methods and protocol engineering tools to build a model-based conformance testing framework that is considered to become part of the certification process for EnergyBus-compliant products."
Evaluating Normalization Functions with Search Algorithms for Solving OCL Constraints,Testing Software and Systems,,,,10.1007/978-3-662-44857-1_2,Shaukat AliTao Yue,2014,http://link.springer.com/chapter/10.1007/978-3-662-44857-1_2,Chapter,"Empirical evaluation, Model-Based Testing, OCL, Search Algorithm, Test data",10,"The use of search algorithms requires the definition of a fitness function that guides the algorithms to find an optimal solution. The definition of a fitness function may require the use of a normalization function for various purposes such as assigning equal importance to various factors constituting a fitness function and normalizing only one factor of a fitness function to give it less/more importance than the others. In our previous work, we defined various branch distance functions (a commonly used heuristic in the literature at the code-level) corresponding to the constructs defined in the Object Constraint Language (OCL) to solve OCL constraints to generate test data for supporting automated Model-Based Testing (MBT). The definition of several of these distance functions required the use of a normalization function. In this paper, we extend the empirical evaluation reported in one of the works in the literature that compares the impact of using various normalization functions for calculating branch distances at the code-level on the performance of search algorithms. The empirical evaluation reported in this paper assesses the impact of the commonly used normalization functions for the branch distance calculation of OCL constraints at the model-level. Results show that for one of the newly studied algorithms Harmony Search (HS) and Random Search (RS), the use of the normalization functions has no impact on the performance of the search. However, HS achieved 100% success rates for all the problems, where RS obtained very poor success rates (less than 38%). Based on the results, we conclude that the randomness in creating a solution in search algorithms may mask the impact of using a normalization function."
Insights on the Use of OCL in Diverse Industrial Applications,System Analysis and Modeling: Models and Reusability,,,,10.1007/978-3-319-11743-0_16,Shaukat AliTao YueMuhammad Zohaib IqbalRajwinder Kaur Panesar-Walawege,2014,http://link.springer.com/chapter/10.1007/978-3-319-11743-0_16,Chapter,"Constraint Parsing, Constraint Solving, Industrial Applications, Object Constraint Language",10,"The Object Constraint Language (OCL) is a widely accepted language, standardized by OMG, for specifying constraints at various meta levels (e.g., meta-models and models). Despite its wide acceptance, there is a lack of understanding about terminology and purposes for which OCL can be used. In this paper, we aim to reduce this gap and provide guidance for applying OCL in practical contexts and we report our experience of applying OCL for different industrial projects in diverse domains: Communications and Control, Oil and Gas production, Energy Equipment and Services, and Recycling. Based on our experience, first, we unify the commonly used terminology in the literature for applying OCL in different ways for addressing diverse industrial problems. Second, we report the key results of the industrial application of OCL. Finally, we provide guidance to researchers and practitioners for choosing an appropriate meta level and purpose for their specific industrial problem at hand."
A Functional Verification of a Web Voting System,Computational Science and Its Applications – ICCSA 2014,,,,10.1007/978-3-319-09144-0_44,Maximiliano CristiáClaudia Frydman,2014,http://link.springer.com/chapter/10.1007/978-3-319-09144-0_44,Chapter,"Generate Test Case, Proof Obligation, Proof Script, Requirement Document, Vote System",10,"The Consejo Nacional de Investigaciones Científicas y Técni-cas (CONICET) is the most important research institution in Argentina. Its internal authorities are elected by around 8,000 researches across the country. During 2011 the CONICET developed a web voting system to replace the traditional mail-based system. In this paper we present the verification process conducted to assess the functional correctness of the voting system. This process is the result of integrating automatic and semi-automatic verification activities from formal proof to code inspection and model-based testing."
Back-To-Back Testing of Model-Based Code Generators,"Leveraging Applications of Formal Methods, Verification and Validation. Technologies for Mastering Change",,,,10.1007/978-3-662-45234-9_30,Sven JörgesBernhard Steffen,2014,http://link.springer.com/chapter/10.1007/978-3-662-45234-9_30,Chapter,"Code Generator, Source Language, System Under Test, Test Vector, Testing Approach",10,"In this paper, we present the testing approach of the Genesys code generator framework. The employed approach is based on back-to-back-testing, which tests the translation performed by a code generator from a semantic perspective rather than just checking for syntactic correctness of the generation result. We describe the basic testing framework and show that it scales in three dimensions: parameterized tests, testing across multiple target platforms and testing on multiple meta-levels. In particular, the latter is only possible due to the fact that Genesys code generators are constructed as models. Furthermore, in order to facilitate simplicity, Genesys consistently employs one single notation for all artifacts involved in this testing approach: Test data, test cases, the code generators under test, and even the testing framework itself are all modeled using the same graphical modeling language."
A Systematic Approach to Requirements Driven Test Generation for Safety Critical Systems,Model-Based Safety and Assessment,,,,10.1007/978-3-319-12214-4_4,Toby WilkinsonMichael ButlerJohn Colley,2014,http://link.springer.com/chapter/10.1007/978-3-319-12214-4_4,Chapter,"Event-B, Safety Critical Systems, STPA, Test Generation",10,"We describe ongoing work into the generation of test cases for safety critical systems using Event-B and the Rodin toolset. Verification of software to DO-178C is a two stage process. First a suite of test cases must be validated against the system requirements (requirements coverage), and then the software implementation is verified using the validated test suite. During verification of the implementation structural coverage is also measured. Our work focuses on the first step, the generation of test cases and their validation against the requirements. We construct closed-system models incorporating both the system to be tested and its environment. These models capture the system requirements, and describe the interactions between the system and its environment. In particular, safety constraints can be represented by invariants, and their preservation ensured through event guards. From these models test cases can be generated, and requirements coverage can be measured from model coverage."
Active Learning of Nondeterministic Systems from an ioco Perspective,"Leveraging Applications of Formal Methods, Verification and Validation. Technologies for Mastering Change",,,,10.1007/978-3-662-45234-9_16,Michele VolpatoJan Tretmans,2014,http://link.springer.com/chapter/10.1007/978-3-662-45234-9_16,Chapter,,10,"Model-based testing allows the creation of test cases from a model of the system under test. Often, such models are difficult to obtain, or even not available. Automata learning helps in inferring the model of a system by observing its behaviour. The model can be employed for many purposes, such as testing other implementations, regression testing, or model checking. We present an algorithm for active learning of nondeterministic, input-enabled, labelled transition systems, based on the well known Angluin’s L  ⋆  algorithm. Under some assumptions, for dealing with nondeterminism, input-enabledness and equivalence checking, we prove that the algorithm produces a model whose behaviour is equivalent to the one under learning. We define new properties for the structure used in the algorithm, derived from the semantics of labelled transition systems. Such properties help the learning, by avoiding to query the system under learning when it is not necessary."
Generating Test Data from a UML Activity Using the AMPL Interface for Constraint Solvers,Tests and Proofs,,,,10.1007/978-3-319-09099-3_14,Felix KurthSibylle SchuppStephan Weißleder,2014,http://link.springer.com/chapter/10.1007/978-3-319-09099-3_14,Chapter,"Activity Diagram, AMPL, Boundary Value Analysis, Constraint Solving, Infeasible Path Elimination, Mixed Integer Non–Linear Programming, Model–Based Testing",10,"Testing is one of the most wide-spread means for quality assurance. Modelling and automated test design are two means to improve effectivity and efficiency of testing. In this paper, we present a method to generate test data from UML activity diagrams and OCL constraints by combining symbolic execution and state–of–the–art constraint solvers. Our corresponding prototype implementation is integrated in the existing test generator ParTeG and generates C++ unit tests. Our key improvement is the transparent use of multiple industry strength solvers through a common interface; this allows the user to choose between an expressive constraint language or highly optimised test data generation. We use infeasible path elimination to improve the performance of test generation and boundary value analysis to improve the quality of the generated test data. We provide an industrial case study and measure the performance of our tool using different solvers in several scenarios."
The Relevance of Model-Driven Engineering Thirty Years from Now,Model-Driven Engineering Languages and Systems,,,,10.1007/978-3-319-11653-2_12,Gunter MussbacherDaniel AmyotRuth BreuJean-Michel BruelBetty H. C. ChengPhilippe ColletBenoit CombemaleRobert B. FranceRogardt HeldalJames HillJörg KienzleMatthias SchöttleFriedrich SteimannDave StikkolorumJon Whittle,2014,http://link.springer.com/chapter/10.1007/978-3-319-11653-2_12,Chapter,"challenges, Model-driven engineering, research opportunities",10,"Although model-driven engineering (MDE) is now an established approach for developing complex software systems, it has not been universally adopted by the software industry. In order to better understand the reasons for this, as well as to identify future opportunities for MDE, we carried out a week-long design thinking experiment with 15 MDE experts. Participants were facilitated to identify the biggest problems with current MDE technologies, to identify grand challenges for society in the near future, and to identify ways that MDE could help to address these challenges. The outcome is a reflection of the current strengths of MDE, an outlook of the most pressing challenges for society at large over the next three decades, and an analysis of key future MDE research opportunities."
Pragmatic Approach to Test Case Reuse - A Case Study in Android OS BiDiTests Library,Software Reuse for Dynamic Systems in the Cloud and Beyond,,,,10.1007/978-3-319-14130-5_9,Suriya Priya R. AsaithambiStan Jarzabek,2014,http://link.springer.com/chapter/10.1007/978-3-319-14130-5_9,Chapter,"Android Platform Test Libraries, Mobile Platform, Reusability, Software Testing, Test Clones, Test Construction Approach, Test Libraries",10,"Test libraries explode in size, but both practitioners and researchers report much redundancy among test cases. Similar functions require similar test cases. Redundancy may be particularly overwhelming in test libraries for mobile computing, where we need to test the same functionality implemented on various models/brands of mobile phones. Redundancies create reuse opportunities. We propose a generic adaptive test template (GATT) approach to contain explosion of test libraries by reusing common recurring test patterns instead of enumerating the same test case in many variant forms. The objective is to ease the test development and maintenance effort. The process starts with automated detection of test clones. We represent a group of similar test cases by a test template along with specifications for automated generation of test cases in a group. We illustrate GATT with examples from Android OS test libraries, and evaluate its benefits and trade-offs. The approach scales to large test libraries and is oblivious to application domains or programming languages. GATT is practical as it focuses on managing test libraries without affecting the follow up test execution. Therefore, it smoothly blends with any other existing techniques and tools used for testing."
"Security Testing Approaches – For Research, Industry and Standardization",Trustworthy Computing and Services,,,,10.1007/978-3-662-43908-1_49,Axel RennochIna SchieferdeckerJürgen Großmann,2014,http://link.springer.com/chapter/10.1007/978-3-662-43908-1_49,Chapter,"Fuzzing, Model-based security testing, Risk analysis, Test automation",10,"Recently, in the Security testing domain a lot of knowledge has been collected from a significant amount of research. The contribution provides an introduction to advanced security testing methods and techniques in the context of European research and standardization projects. This includes numerous guidelines and best practices that have been identified and are applied in the context of industrial case studies. In particular it addresses risk modeling, security test pattern, functional security tests as well as fuzz testing, as important contributions to systematic, automatized test approaches in research, industry and standardization."
A Trace Management Platform for Risk-Based Security Testing,Risk Assessment and Risk-Driven Testing,,,,10.1007/978-3-319-07076-6_9,Jürgen GroßmannMichael BergerJohannes Viehmann,2014,http://link.springer.com/chapter/10.1007/978-3-319-07076-6_9,Chapter,"Query Interpreter, Security Testing, Test Pattern, Trace Link, Trace Management",10,"The goal of risk-based security testing is to improve the security testing process in order to cover especially risky areas of the application under test and at the same time minimize the time to market and to improve the use of resources by focusing testing work on areas with the highest risks. In RBST risk factors are identified and risk-based security test cases are created and prioritized according to an applicable selection strategy. One of the challenges in RBST is to keep track of the different artifacts that are often managed by different tools. Traceability is the key to manage complex systems in development and testing. This paper introduces RISKTest , a trace management platform on the basis of Eclipse that supports the creation and documentation of cross-tool relations during test development and test execution. RISKTest is dedicated to risk-based security testing. Thus, we concentrate on the management of traces between the artifacts from risk assessment and testing and the definitions of services that automatically analyze the related artifacts for security and testing related aspects. RISKTest has been developed in the DIAMONDS and RASEN projects and evaluated within the project’s case studies."
The FITTEST Tool Suite for Testing Future Internet Applications,Future Internet Testing,,,,10.1007/978-3-319-07785-7_1,Tanja E. J. VosPaolo TonellaI. S. Wishnu B. PrasetyaPeter M. KruseOnn ShehoryAlessandra BagnatoMark Harman,2014,http://link.springer.com/chapter/10.1007/978-3-319-07785-7_1,Chapter,"Audit Testing, Service Composition, System Under Test, Test Case Generation, Test Case Prioritization",10,"Future Internet applications are expected to be much more complex and powerful, by exploiting various dynamic capabilities For testing, this is very challenging, as it means that the range of possible behavior to test is much larger, and moreover it may at the run time change quite frequently and significantly with respect to the assumed behavior tested prior to the release of such an application. The traditional way of testing will not be able to keep up with such dynamics. The Future Internet Testing (FITTEST) project ( http://crest.cs.ucl.ac.uk/fittest/ ), a research project funded by the European Commission (grant agreement n. 257574) from 2010 till 2013, was set to explore new testing techniques that will improve our capacity to deal with the challenges of testing Future Internet applications. Such techniques should not be seen as replacement of the traditional testing, but rather as a way to complement it. This paper gives an overview of the set of tools produced by the FITTEST project, implementing those techniques."
Acceptance Test Optimization,System Analysis and Modeling: Models and Reusability,,,,10.1007/978-3-319-11743-0_11,Mohamed MussaFerhat Khendek,2014,http://link.springer.com/chapter/10.1007/978-3-319-11743-0_11,Chapter,"Acceptance testing, Integration testing, Model Based Testing, Sequence diagrams, Test optimization",10,"Test case generation and execution may be time and effort consuming. At a given testing phase, test case execution can be optimized by avoiding the consideration of test cases that have already been exercised in a previous phase. For instance, one can avoid test case redundancy between integration testing and acceptance testing. Characterizing this redundancy is not straightforward since some integration test cases are applied on an incomplete system with test stubs emulating system components and therefore cannot be substituted to acceptance test cases. In this paper, we propose an approach that maps acceptance test cases to integration test cases and eliminates test cases that have already been exercised on the system during the integration testing phase."
Distinguishing Sequences for Partially Specified FSMs,NASA Formal Methods,,,,10.1007/978-3-319-06200-6_5,Robert M. HieronsUraz Cengiz Türker,2014,http://link.springer.com/chapter/10.1007/978-3-319-06200-6_5,Chapter,"Conformance Testing, Distinguishing Sequence, Finite State Machine, Input Sequence, Polynomial Space",10,"Distinguishing Sequences (DSs) are used inmany Finite State Machine (FSM) based test techniques. Although Partially Specified FSMs (PSFSMs) generalise FSMs, the computational complexity of constructing Adaptive and Preset DSs (ADSs/PDSs) for PSFSMs has not been addressed. This paper shows that it is possible to check the existence of an ADS in polynomial time but the corresponding problem for PDSs is PSPACE-complete . We also report on the results of experiments with benchmarks and over 8 ∗ 10 6 PSFSMs."
A Systematic Approach to Automatically Derive Test Cases from Use Cases Specified in Restricted Natural Languages,System Analysis and Modeling: Models and Reusability,,,,10.1007/978-3-319-11743-0_10,Man ZhangTao YueShaukat AliHuihui ZhangJi Wu,2014,http://link.springer.com/chapter/10.1007/978-3-319-11743-0_10,Chapter,"Natural Language, Restricted Test Case Specification, Restricted Use Case Modeling, Test Case Specification, Test Cases, Test Generation, Transformation and Automation, Use Cases",10,"In many domains, such as avionics, oil and gas, and maritime, a common practice is to derive and execute test cases manually from requirements, where both requirements and test cases are specified in natural language (NL) by domain experts. The manual execution of test cases is largely dependent on the domain experts who wrote the test cases. The process of manual writing of requirements and test cases introduces ambiguity in their description and, in addition, test cases may not be effective since they may not be derived by systematically applying coverage criteria. In this paper, we report on a systematic approach to support automatic derivation of manually executable test cases from use cases. Both use cases and test cases are specified in restricted NLs along with carefully-defined templates implemented in a tool. We evaluate our approach with four case studies (in total having 30 use cases and 579 steps from flows of events), two of which are industrial case studies from the oil/gas and avionics domains. Results show that our tool was able to correctly process all the case studies and systematically (by following carefully-defined structure coverage criteria) generate 30 TCSs and 389 test cases. Moreover, our approach allows defining different test coverage criteria on requirements other than the one already implemented in our tool."
On the Usage of TGGs for Automated Model Transformation Testing,Theory and Practice of Model Transformations,,,,10.1007/978-3-319-08789-4_1,Martin WieberAnthony AnjorinAndy Schürr,2014,http://link.springer.com/chapter/10.1007/978-3-319-08789-4_1,Chapter,"Eclipse Modelling Framework, Graph Grammar, Model Transformation, System Under Test, Test Suite",10,"As model transformations are fundamental to model-driven engineering, assuring their quality is a central task which can be achieved by testing with sufficiently adequate and large test suites. As the latter requirement can render manual testing prohibitively costly in practice, a high level of automation is advisable. Triple Graph Grammars (TGGs) have been shown to provide a promising solution to this challenge as not only test case generators , but also generic test oracles can be derived from them. It is, however, unclear if such generated test suites are indeed adequate and, as different strategies can be used to steer the test generation process, a systematic means of comparing and evaluating such test suites and strategies is required. In this paper, we extend existing work on TGG-based testing by(i) presenting a generic framework for TGG-based testing, (ii) describing a concrete instantiation of this framework with our TGG tool eMoflon, and (iii) exploring how the well-known technique of mutation analysis can be used to evaluate a set of test generation strategies by analyzing the generated test suites."
Distributed Testing of Concurrent Systems: Vector Clocks to the Rescue,Theoretical Aspects of Computing – ICTAC 2014,,,,10.1007/978-3-319-10882-7_22,Hernán Ponce-de-LeónStefan HaarDelphine Longuet,2014,http://link.springer.com/chapter/10.1007/978-3-319-10882-7_22,Chapter,"Concurrent System, Conformance Testing, Local Clock, System Under Test, Time Stamp",10,"The ioco relation has become a standard in model-based conformance testing. The co-ioco conformance relation is an extension of this relation to concurrent systems specified with true-concurrency models. This relation assumes a global control and observation of the system under test, which is not usually realistic in the case of physically distributed systems. Such systems can be partially observed at each of their points of control and observation by the sequences of inputs and outputs exchanged with their environment. Unfortunately, in general, global observation cannot be reconstructed from local ones, so global conformance cannot be decided with local tests. We propose to append time stamps to the observable actions of the system under test in order to regain global conformance from local testing."
An Abstraction Technique for Testing Decomposable Systems by Model Checking,Tests and Proofs,,,,10.1007/978-3-319-09099-3_3,Paolo ArcainiAngelo GargantiniElvinia Riccobene,2014,http://link.springer.com/chapter/10.1007/978-3-319-09099-3_3,Chapter,"Computation Tree Logic, Kripke Structure, Linear Temporal Logic, Model Check, Test Generation",10,"Test generation by model checking exploits the capability of model checkers to return counterexamples upon property violations. The approach suffers from the state explosion problem of model checking. For property verification, different abstraction techniques have been proposed to tackle this problem. However, such techniques are not always suitable for test generation. In this paper we focus on Decomposable by Dependency Asynchronous Parallel (DDAP) systems, composed by several subsystems running in parallel and connected together in a way that the inputs of one subsystem are provided by another subsystem. We propose a test generation approach for DDAP systems based on a decompositional abstraction that considers one subsystem at a time. It builds tests for the single subsystems and combines them later in order to obtain a global system test. Such approach avoids the exponential increase of the test generation time and memory consumption. The approach is proved to be sound, but not complete."
An Evaluation of the Effectiveness of the Atomic Section Model,Model-Driven Engineering Languages and Systems,,,,10.1007/978-3-319-11653-2_3,Sunitha ThummalaJeff Offutt,2014,http://link.springer.com/chapter/10.1007/978-3-319-11653-2_3,Chapter,"Atomic section modeling, Model based testing, Test criteria, Web applications",10,"Society increasingly depends on web applications for business and pleasure. As the use of web applications continues to increase, the number of failures, some minor and some major, continues to grow. A significant problem is that we still have relatively weak abilities to test web applications. Traditional testing techniques do not adequately model or test these novel technologies. The atomic section model (ASM), models web applications to support design, analysis, and testing. This paper presents an empirical study to evaluate the effectiveness of the ASM. The model was implemented into a tool, WASP, which extracts the ASM from the implementation and supports various test criteria. We studied ten web applications, totaling 156 components and 11,829 lines of code. Using WASP, we generated 207 tests, which revealed 31 faults.Seventeen of those faults exposed internal information about the application and server."
Formalizing DSL Semantics for Reasoning and Conformance Testing,Software Engineering and Formal Methods,,,,10.1007/978-3-319-10431-7_7,Sarmen KeshishzadehArjan J. Mooij,2014,http://link.springer.com/chapter/10.1007/978-3-319-10431-7_7,Chapter,"Code Generation, Conformance Testing, Domain Specific Language (DSL), Model-based Testing, Semantics",10,"A Domain Specific Language (DSL) focuses on the essential concepts in a certain problem domain, thus abstracting from low-level implementation details. In combination with code generators, DSLs bring software development closer to domain requirements. The development of DSLs usually centers around the grammar and a code generator; there is little attention for the semantics of the DSL. However, a formal semantics is essential for reasoning about specifications in terms of the DSL (i.e., DSL instances). We argue that the semantics should be expressed independent of a code generator. Thus semantic issues can be revealed that could otherwise remain undetected. We also use the semantics to define the conformance of an implementation to a DSL instance, and to automatically test conformance of the (generated) implementation code to a DSL instance. We illustrate our approach using an industrial prototype DSL for collision prevention."
On the Complexity of Input Output Conformance Testing,Formal Aspects of Component Software,,,,10.1007/978-3-319-07602-7_18,Neda NorooziMohammad Reza MousaviTim A. C. Willemse,2014,http://link.springer.com/chapter/10.1007/978-3-319-07602-7_18,Chapter,"Input Output Transition Systems, Interface Automata, Ioco Testing Theory, Model-based Testing, Suspension Traces",10,"Input-output conformance (ioco) testing is a well-known approach to model-based testing. In this paper, we study the complexity of checking ioco. We show that the problem of checking ioco is PSPACE-complete. To provide a more efficient algorithm, we propose a more restricted setting for checking ioco, namely with deterministic models and show that in this restricted setting ioco checking can be performed in polynomial time."
Twenty-Five Years of Formal Methods and Railways: What Next?,Software Engineering and Formal Methods,,,,10.1007/978-3-319-05032-4_13,Alessandro Fantechi,2014,http://link.springer.com/chapter/10.1007/978-3-319-05032-4_13,Chapter,"Automatic Code Generation, Formal Method, Formal Verification, Model Check, Software Model Check",10,"Since more than 25 years, railway signalling is the subject of successful industrial application of formal methods in the development and verification of its computerized equipment. However the evolution of the technology of railways signalling systems in this long term has had a strong influence on the way formal methods can be applied in their design and implementation. At the same time important advances had been also achieved in the formal methods area. The scope of the formal methods discipline has enlarged from the methodological provably correct software construction of the beginnings to the analysis and modelling of increasingly complex systems, always on the edge of the ever improving capacity of the analysis tools, thanks to the technological advances in formal verification of both qualitative and quantitative properties of such complex systems. The thesis we will put forward in this paper is that the complexity of future railway systems of systems can be addressed with advantage only by a higher degree of distribution of functions on local interoperable computers - communicating by means of standard protocols - and by adopting a multi-level formal modelling suitable to support the verification at different abstraction levels, and at different life-cycle times, of the safe interaction among the distributed functions."
Minimum Number of Test Paths for Prime Path and Other Structural Coverage Criteria,Testing Software and Systems,,,,10.1007/978-3-662-44857-1_5,Anurag DwarakanathAruna Jankiti,2014,http://link.springer.com/chapter/10.1007/978-3-662-44857-1_5,Chapter,"Minimum Flow, Minimum Number of Test Paths, Model Based Testing, Prime Path Coverage",10,"The software system under test can be modeled as a graph comprising of a set of vertices, V and a set of edges, E . Test Cases are Test Paths over the graph meeting a particular test criterion. In this paper, we present a method to achieve the minimum number of Test Paths needed to cover different structural coverage criteria. Our method can accommodate Prime Path, Edge-Pair, Simple & Complete Round Trip, Edge and Node coverage criteria. Our method obtains the optimal solution by transforming the graph into a flow graph and solving the minimum flow problem. We present an algorithm for the minimum flow problem that matches the best known solution complexity of $ O\left(\left\vert{V}\right\vert\left\vert{E}\right\vert\right)$ . Our method is evaluated through two sets of tests. In the first, we test against graphs representing actual software. In the second test, we create random graphs of varying complexity. In each test we measure the number of Test Paths, the length of Test Paths, the lower bound on minimum number of Test Paths and the execution time."
Modeling and Analyzing Using ASMs: The Landing Gear System Case Study,ABZ 2014: The Landing Gear Case Study,,,,10.1007/978-3-319-07512-9_3,Paolo ArcainiAngelo GargantiniElvinia Riccobene,2014,http://link.springer.com/chapter/10.1007/978-3-319-07512-9_3,Chapter,"Abstract State Machine, Computation Tree Logic, Ground Model, Monitor Function, Transition Rule",10,"The paper presents an Abstract State Machine (ASM) specification of the Landing Gear System case study, and shows how the ASMETA framework can be used to support the modeling and analysis (validation and verification) activities for developing a rigorous and correct model in terms of ASMs. We exploit the two fundamental concepts of the ASM method, i.e., the notion of ground model and the refinement principle, and we achieve model development and model analysis by the combined use of formal methods for specification and for verification."
Using CP in Automatic Test Generation for ABB Robotics’ Paint Control System,Principles and Practice of Constraint Programming,,,,10.1007/978-3-319-10428-7_6,Morten MossigeArnaud GotliebHein Meling,2014,http://link.springer.com/chapter/10.1007/978-3-319-10428-7_6,Chapter,"Constraint Programming, Global Constraint, Process Control System, Test Execution, Test Scenario",10,"Designing industrial robot systems for welding, painting, and assembly, is challenging because they are required to perform with high precision, speed, and endurance. ABB Robotics has specialized in building highly reliable and safe robotized paint systems based on an integrated process control system . However, current validation practices are primarily limited to manually designed test scenarios. A tricky part of this validation concerns testing the timing aspects of the control system, which is particularly challenging for paint robots that need to coordinate paint activation with the robot motion control. To overcome these challenges, we have developed and deployed a costeffective, automated test generation technique based on Constraint Programming, aimed at validating the timing behavior of the process control system. We designed a constraint optimization model in SICStus Prolog, using arithmetic and logic constraints including use of global constraints. This model has been integrated into a fully automated continuous integration environment, allowing the model to be solved on demand prior to test execution, which allows us to obtain the most optimal and diverse set of test scenarios for the present system configuration. After three months of daily operational use of the constraint model in our testing process, we have collected data on its performance and bug finding capabilities. We report on these aspects, along with our experiences and the improvements gained by the new testing process."
The TTT Algorithm: A Redundancy-Free Approach to Active Automata Learning,Runtime Verification,,,,10.1007/978-3-319-11164-3_26,Malte IsbernerFalk HowarBernhard Steffen,2014,http://link.springer.com/chapter/10.1007/978-3-319-11164-3_26,Chapter,"Finite Automaton, Membership Query, Model Check, Observation Table, Symbol Execution",10,"In this paper we present TTT, a novel active automata learning algorithm formulated in the Minimally Adequate Teacher (MAT) framework. The distinguishing characteristic of TTT is its redundancy-free organization of observations, which can be exploited to achieve optimal (linear) space complexity. This is thanks to a thorough analysis of counterexamples, extracting and storing only the essential refining information. TTT is therefore particularly well-suited for application in a runtime verification context, where counterexamples (obtained, e.g., via monitoring) may be excessively long: as the execution time of a test sequence typically grows with its length, this would otherwise cause severe performance degradation. We illustrate the impact of TTT’s consequent redundancy-free approach along a number of examples."
Software Quality Testing Model for Mobile Application,Mobile Web Information Systems,,,,10.1007/978-3-319-10359-4_16,Zhenyu LiuYun HuLizhi Cai,2014,http://link.springer.com/chapter/10.1007/978-3-319-10359-4_16,Chapter,,10,"With the rapid development of the network technology, intelligent device and mobile applications has been the developed fastly. The mobile device will increasingly widely used even replace the traditional computer, the application test for mobile Internet was put on the agenda. From this paper, the characteristics of mobile applications are analyzed. The paper proposed quality model and quality attributes corresponding to testing requirements for mobile applications under mobile Internet. Also relevant properties testing techniques and methods is given to pay attention during the test from different test view, which indicating that the quality of the final model could be effective for mobile applications."
Fomal Methods and Analyses in Software Product Line Engineering,"Leveraging Applications of Formal Methods, Verification and Validation. Technologies for Mastering Change",,,,10.1007/978-3-662-45234-9_18,Ina SchaeferMaurice H. ter Beek,2014,http://link.springer.com/chapter/10.1007/978-3-662-45234-9_18,Chapter,"Coverage Criterion, Delta Module, Formal Method, Label Transition System, Software Product Line",10,"Software product line engineering (SPLE) [5,11] aims to develop a family of software-intensive systems via systematic, large-scale reuse in order to reduce time-to-market and costs and to increase the quality of individual products. In order to achieve these goals, formal methods offer promising analysis techniques, which are best applied throughout the product-line lifecycle so as to maximize their overall efficiency and effectiveness."
Learning Extended Finite State Machines,Software Engineering and Formal Methods,,,,10.1007/978-3-319-10431-7_18,Sofia CasselFalk HowarBengt JonssonBernhard Steffen,2014,http://link.springer.com/chapter/10.1007/978-3-319-10431-7_18,Chapter,"Data Language, Data Word, Priority Queue, Root Location, Symbolic Execution",10,"We present an active learning algorithm for inferring extended finite state machines (EFSM)s, combining data flow and control behavior. Key to our learning technique is a novel learning model based on so-called tree queries . The learning algorithm uses the tree queries to infer symbolic data constraints on parameters, e.g., sequence numbers, time stamps, identifiers, or even simple arithmetic. We describe sufficient conditions for the properties that the symbolic constraints provided by a tree query in general must have to be usable in our learning model. We have evaluated our algorithm in a black-box scenario, where tree queries are realized through (black-box) testing. Our case studies include connection establishment in TCP and a priority queue from the Java Class Library."
Test Coverage Estimation Using Threshold Accepting,Automated Technology for Verification and Analysis,,,,10.1007/978-3-319-11936-6_9,Thao DangNoa Shalev,2014,http://link.springer.com/chapter/10.1007/978-3-319-11936-6_9,Chapter,,10,"This paper is concerned with model-based testing of hybrid systems. In our previous work [6], we proposed a test generation algorithm, called gRRT, guided by a coverage measure defined using the star discrepancy notion. An important ingredient in this algorithm is a procedure for dynamically estimating the coverage, which is done based on a box partition of the continuous state space. The goal of this estimation is to identify the areas in the state space which have not been sufficiently visited. A drawback of this guiding method is that its complexity depends on the number of the boxes in the partition, which needs to be fine enough to guarantee a good coverage estimate. Thus in high dimensions the method can become very costly. To enhance the scalability of the algorithm gRRT we propose in this paper a new guiding method, motivated by the observation that trying to optimize the coverage in each exploration step is, on one hand, computationally costly, and on the other hand, not always a good choice since this may make the system try to expand in the directions which are not reachable (due to the controllability of the system). Instead of considering all the boxes in the partition, we propose to use a randomized search to quickly find a region that yields a high local discrepancy value. This randomized search is based on threshold accepting, a well-known integer optimization heuristic. We also present some experimental results obtained on a challenging circuit benchmark and a number of randomly generated examples, which shows that the new guiding method allows achieving better time and coverage efficiency."
An Expressive Semantics of Mocking,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-642-54804-8_27,Josef SvenningssonHans SvenssonNicholas SmallboneThomas ArtsUlf NorellJohn Hughes,2014,http://link.springer.com/chapter/10.1007/978-3-642-54804-8_27,Chapter,,10,"We present a semantics of mocking, based on a process calculus-like formalism, and an associated mocking framework. We can build expressive mocking specifications from a small, orthogonal set of operators. Our framework detects and rejects ambiguous specifications as a validation measure. We report our experience testing software components for the car industry, which needed the full power of our framework."
A TASM-Based Requirements Validation Approach for Safety-Critical Embedded Systems,Reliable Software Technologies – Ada-Europe 2014,,,,10.1007/978-3-319-08311-7_5,Jiale ZhouYue LuKristina Lundqvist,2014,http://link.springer.com/chapter/10.1007/978-3-319-08311-7_5,Chapter,"Brake Force, Brake Pedal, Execution Semantic, Model Check, Requirement Validation",10,"Requirements validation is an essential activity to carry out in the system development life cycle, and it confirms the completeness and consistency of requirements through various levels. Model-based formal methods can provide a cost-effective solution to requirements validation in a wide range of domains such as safety-critical applications. In this paper, we extend a formal language Timed Abstract State Machine (TASM) with two newly defined constructs Event and Observer , and propose a novel requirements validation approach based on the extended TASM. Specifically, our approach can: 1) model both functional and non-functional (e.g. timing and resource consumption) requirements of the system at different levels and, 2) perform requirements validation by utilizing our developed toolset and a model checker. Finally, we demonstrate the applicability of our approach in real world usage through an industrial case study of a Brake-by-Wire system."
Domain-Specific Code Generator Modeling: A Case Study for Multi-faceted Concurrent Systems,"Leveraging Applications of Formal Methods, Verification and Validation. Technologies for Mastering Change",,,,10.1007/978-3-662-45234-9_33,Stefan NaujokatLouis-Marie TraonouezMalte IsbernerBernhard SteffenAxel Legay,2014,http://link.springer.com/chapter/10.1007/978-3-662-45234-9_33,Chapter,"Code Generator, Eclipse Modeling Framework, Graphical Editor, Label Transition System, Markov Decision Process",10,"In this paper we discuss an elaborate case study utilizing the domain-specific development of code generators within the Cinco meta tooling suite. Cinco is a framework that allows for the automatic generation of a wide range of graphical modeling tools from an abstract high-level specification. The presented case study makes use of Cinco to rapidly construct custom graphical interfaces for multi-faceted, concurrent systems, comprising non-functional properties like time, probability, data, and costs. The point of this approach is to provide user communities and their favorite tools with graphical interfaces tailored to their specific needs. This will be illustrated by generating graphical interfaces for timed automata (TA), probabilistic timed automata (PTA), Markov decision processes (MDP) and simple labeled transition systems (LTS). The main contribution of the presented work, however, is the metamodel-based domain-specific construction of the corresponding code generators for the verification tools Uppaal , Spin , Plasma-lab , and Prism ."
IncQuery-D: A Distributed Incremental Model Query Framework in the Cloud,Model-Driven Engineering Languages and Systems,,,,10.1007/978-3-319-11653-2_40,Gábor SzárnyasBenedek IzsóIstván RáthDénes HarmathGábor BergmannDániel Varró,2014,http://link.springer.com/chapter/10.1007/978-3-319-11653-2_40,Chapter,"Graph Database, Model Query, Query Evaluation, Resource Description Framework, SPARQL Query",10,"Queries are the foundations of data intensive applications. In model-driven software engineering (MDE), model queries are core technologies of tools and transformations. As software models are rapidly increasing in size and complexity, traditional tools exhibit scalability issues that decrease productivity and increase costs [17]. While scalability is a hot topic in the database community and recent NoSQL efforts have partially addressed many shortcomings, this happened at the cost of sacrificing the ad-hoc query capabilities of SQL. Unfortunately, this is a critical problem for MDE applications due to their inherent workload complexity. In this paper, we aim to address both the scalability and ad-hoc querying challenges by adapting incremental graph search techniques – known from the EMF-IncQuery framework – to a distributed cloud infrastructure. We propose a novel architecture for distributed and incremental queries, and conduct experiments to demonstrate that IncQuery-D , our prototype system, can scale up from a single workstation to a cluster that can handle very large models and complex incremental queries efficiently."
Tutorial: Automata Learning in Practice,"Leveraging Applications of Formal Methods, Verification and Validation. Technologies for Mastering Change",,,,10.1007/978-3-662-45234-9_34,Falk HowarMalte IsbernerBernhard Steffen,2014,http://link.springer.com/chapter/10.1007/978-3-662-45234-9_34,Chapter,"Automaton Learning, Lower Common Ancestor, Membership Query, Regular Language, Span Tree",10,"The paper reviews active automata learning with a particular focus on sources of redundancy. In particular, it gives an intuitive account of TTT, an algorithm based on three tree structures which concisely capture all the required information. This guarantees minimal memory consumption and it drastically reduces the length of membership queries, in particular in application scenarios like monitoring-based learning, where long counter examples arise. The essential steps and the impact of TTT are illustrated via experimentation with LearnLib , a free, open source Java library for active automata learning."
Integrity Assurance for Outsourced Databases without DBMS Modification,Data and Applications Security and Privacy XXVIII,,,,10.1007/978-3-662-43936-4_1,Wei WeiTing Yu,2014,http://link.springer.com/chapter/10.1007/978-3-662-43936-4_1,Chapter,"Data Integrity, Database Outsourcing, Radix-Path Identifier",10,"Database outsourcing has become increasingly popular as a cost-effective solution to provide database services to clients. Previous work proposed different approaches to ensuring data integrity, one of the most important security concerns in database outsourcing. However, to the best of our knowledge, existing approaches require modification of DBMSs to facilitate data authentication, which greatly hampers their adoption in practice. In this paper, we present the design and implementation of an efficient and practical integrity assurance scheme without requiring any modification to the DBMS at the server side . We develop novel schemes to serialize Merkle B-tree based authentication structures into a relational database that allows efficient data retrieval for integrity verification. We design efficient algorithms to accelerate query processing with integrity protection. We further build a proof-of-concept prototype and conduct extensive experiments to evaluate the performance overhead of the proposed schemes. The experimental results show that our scheme imposes a low overhead for queries and a reasonable overhead for updates while ensuring integrity of an outsourced database without special support from server-side DBMSs."
Using Model Driven Security Approaches in Web Application Development,Information and Communication Technology,,,,10.1007/978-3-642-55032-4_42,Christoph HochreinerZhendong MaPeter KiesebergSebastian SchrittwieserEdgar Weippl,2014,http://link.springer.com/chapter/10.1007/978-3-642-55032-4_42,Chapter,"Case Diagram, Goal Model, Input Validation, Misuse Case, Model Drive Engineer",10,"With the rise of Model Driven Engineering (MDE) as a software development methodology, which increases productivity and, supported by powerful code generation tools, allows a less error-prone implementation process, the idea of modeling security aspects during the design phase of the software development process was first suggested by the research community almost a decade ago. While various approaches for Model Driven Security (MDS) have been proposed during the years, it is still unclear, how these concepts compare to each other and whether they can improve the security of software projects. In this paper, we provide an evaluation of current MDS approaches based on a simple web application scenario and discuss the strengths and limitations of the various techniques, as well as the practicability of MDS for web application security in general."
Learning Fragments of the TCP Network Protocol,Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-319-10702-8_6,Paul Fiterău-BroşteanRamon JanssenFrits Vaandrager,2014,http://link.springer.com/chapter/10.1007/978-3-319-10702-8_6,Chapter,"Mapper Component, Sequence Number, Session Initiation Protocol, System Under Test, Transmission Control Protocol",10,"We apply automata learning techniques to learn fragments of the TCP network protocol by observing its external behaviour. We show that different implementations of TCP in Windows 8 and Ubuntu induce different automata models, thus allowing for fingerprinting of these implementations. In order to infer our models we use the notion of a mapper component introduced by Aarts, Jonsson and Uijen, which abstracts the large number of possible TCP packets into a limited number of abstract actions that can be handled by the regular inference tool LearnLib. Inspection of the learned models reveals that both Windows 8 and Ubuntu 13.10 violate RFC 793."
A Framework for Business Rules,Advances in Conceptual Modeling,,,,10.1007/978-3-319-14139-8_9,Naveen PrakashDeepak Kumar SharmaDeepika PrakashDheerendra Singh,2014,http://link.springer.com/chapter/10.1007/978-3-319-14139-8_9,Chapter,"BRG Manifesto, Business Motivation Model, business rule management, Business rules, Semantics of Business Vocabulary and business Rules",10,"The subject of business rules is complex. We propose a 4-dimensional framework to better understand, communicate, and realize such rules in organizations and application systems. Our 4-dimensions are domain , that considers the role of business rules in business; system for properties of business rule management systems; application platform to understand support for business rules applications; and representation for expressing business rules. We derive these from work of the Business Rules Group, namely, the Business Rules Manifesto, Business Motivation Model, and Semantics of Business Vocabulary and business Rules, SBVR. We characterize our research position in terms of this framework."
Learning Regular Languages over Large Alphabets,Tools and Algorithms for the Construction and Analysis of Systems,,,,10.1007/978-3-642-54862-8_41,Oded MalerIrini-Eleftheria Mens,2014,http://link.springer.com/chapter/10.1007/978-3-642-54862-8_41,Chapter,"Automaton Learning, Evidence Function, Membership Query, Regular Language, Target Language",10,"This work is concerned with regular languages defined over large alphabets, either infinite or just too large to be expressed enumeratively. We define a generic model where transitions are labeled by elements of a finite partition of the alphabet. We then extend Angluin’s L * algorithm for learning regular languages from examples for such automata. We have implemented this algorithm and we demonstrate its behavior where the alphabet is the set of natural numbers."
Mining State-Based Models from Proof Corpora,Intelligent Computer Mathematics,,,,10.1007/978-3-319-08434-3_21,Thomas GransdenNeil WalkinshawRajeev Raman,2014,http://link.springer.com/chapter/10.1007/978-3-319-08434-3_21,Chapter,"Extended State Machines, Interactive Theorem Proving, Model Inference",10,Interactive theorem provers have been used extensively to reason about various software/hardware systems and mathematical theorems. The key challenge when using an interactive prover is finding a suitable sequence of proof steps that will lead to a successful proof requires a significant amount of human intervention. This paper presents an automated technique that takes as input examples of successful proofs and infers an Extended Finite State Machine as output. This can in turn be used to generate proofs of new conjectures. Our preliminary experiments show that the inferred models are generally accurate (contain few false-positive sequences) and that representing existing proofs in such a way can be very useful when guiding new ones.
The Design and Implementation of the Random HTML Tags and Attributes-Based XSS Defence System,Advances in Swarm Intelligence,,,,10.1007/978-3-319-11897-0_24,Heng LinYiwen YanHongfei CaiWei Zhang,2014,http://link.springer.com/chapter/10.1007/978-3-319-11897-0_24,Chapter,"cross-site scripting, defence system, random, tag prefix",10,"At present, cross site scripting (XSS) is still one of the biggest threat for Internet security. But the defensive approach is still feature matching mostly; that is, to check for a matching and filter in all information submitted. However, filtering technology has many disadvantages as heavy-workload, complex-operation, high-risk and so on. For this reason, our system use the randomization techniques of HTML tags and attributes innovatively, based on the prefix of HTML tags and attributes, to determine the tags and attributes are Web designers expect to generate or other users insert in, and then we follow the results to carry out different policies, only tags and attributes that Web designers expected to generate can be rendered and implemented. By this way, we can defend against XSS attacks completely. The test results show that the system is able to solve a variety of problems in filtering technology. It uses simple and convenient operation and safe and secure effect to free developers from heavy filtering work. System has a good compatibility and portability across platforms, it also can connect with all web-based applications seamlessly. In all, system defend against XSS better and meet the need of today’s XSS attacks defence."
Web Application Relations Mapping,Database and Expert Systems Applications,,,,10.1007/978-3-319-10085-2_13,Radek MaříkZdeněk KoubaMichal Pantůček,2014,http://link.springer.com/chapter/10.1007/978-3-319-10085-2_13,Chapter,"association mining, data flow, GUI events, reverse engineering, software comprehension, SQL statements",10,"Web applications are developed and modified often so fast that architects, developers, and managers lose their control over quality of such software products. Reverse engineering techniques focused on different aspects of software implementation might help in keeping comprehension to implementation of web applications at appropriate level required for fulfilling change requests. We focus our effort on a reconstruction of implicit associations among GUI data items and back-end database entities. Our approach is based on an association analysis and mining using a synchronized log of GUI events and related counterparts of SQL statements. Recovered dependencies between GUI and back-end databases can be utilized advantageously in an automated design of web application data flow testing."
Wind Turbine System: An Industrial Case Study in Formal Modeling and Verification,Formal Techniques for Safety-Critical Systems,,,,10.1007/978-3-319-05416-2_15,Jagadish SuryadevaraGaetana SapienzaCristina SeceleanuTiberiu SeceleanuStein-Erik EllevsethPaul Pettersson,2014,http://link.springer.com/chapter/10.1007/978-3-319-05416-2_15,Chapter,"EAST-ADL, Industrial case-study, MARTE/CCSL, Model checking, UPPAAL, Verification, Wind turbine system",10,"In the development of embedded systems, the formal analysis of system artifacts, such as structural and behavioral models, helps the system engineers to understand the overall functional and timing behavior of the system. In this case study paper, we present our experience in applying formal verification and validation (V&V) techniques, we had earlier proposed, for an industrial wind turbine system (WTS). We demonstrate the complementary benefits of formal verification in the context of existing V&V practices largely based on simulation and testing . We also discuss some modeling trade-offs and challenges we have identified with the case-study, which are worth being emphasized. One issue is related, for instance, to the expressiveness of the system artifacts, in view of the known limitations of rigorous verification, e.g. model-checking , of industrial systems."
Formal System Modelling Using Abstract Data Types in Event-B,"Abstract State Machines, Alloy, B, TLA, VDM, and Z",,,,10.1007/978-3-662-43652-3_20,Andreas FürstThai Son HoangDavid BasinNaoto SatoKunihiko Miyazaki,2014,http://link.springer.com/chapter/10.1007/978-3-662-43652-3_20,Chapter,"abstract data types, Event-B, refinement",10,"We present a formal modelling approach using Abstract Data Types (ADTs) for developing large-scale systems in Event-B. The novelty of our approach is the combination of refinement and instantiation techniques to manage the complexity of systems under development. With ADTs, we model system components on an abstract level, specifying only the necessary properties of the components. At the same time, we postpone the introduction of their concrete definitions to later development steps. We evaluate our approach using a largescale case study in train control systems. The results show that our approach helps reduce system details during early development stages and leads to simpler and more automated proofs."
Developing Corpus-Based Translation Methods between Informal and Formal Mathematics: Project Description,Intelligent Computer Mathematics,,,,10.1007/978-3-319-08434-3_34,Cezary KaliszykJosef UrbanJiří VyskočilHerman Geuvers,2014,http://link.springer.com/chapter/10.1007/978-3-319-08434-3_34,Chapter,,10,"The goal of this project is to (i) accumulate annotated informal/formal mathematical corpora suitable for training semi-automated translation between informal and formal mathematics by statistical machine-translation methods, (ii) to develop such methods oriented at the formalization task, and in particular (iii) to combine such methods with learning-assisted automated reasoning that will serve as a strong semantic component. We describe these ideas, the initial set of corpora, and some initial experiments done over them."
Issues in Applying Model Based Process Improvement in the Cloud Computing Domain,Software Process Improvement and Capability Determination,,,,10.1007/978-3-319-13036-1_21,Jeremy CadeLian WenTerry Rout,2014,http://link.springer.com/chapter/10.1007/978-3-319-13036-1_21,Chapter,"Behavior Engineering, Cloud Computing, Process Model, Software Process",10,"Cloud Computing offers organisations a range of benefits, both economic and technological. However the decision to deploy an application or service to the cloud is a not a trivial one. Organisations need to be fully aware of not only the business requirements for a given application or service, but also the technological requirements and or constraints of the cloud. Model-based process assessment and improvement has been shown to support organisational change in different domains of application, but there are few reports of application in cloud computing. As a first step in defining suitable models to support process management, the impact of working with cloud resources on existing standard processes has been examined using the techniques of behavior engineering. A path for future work is proposed."
In-Place Natural and Effortless Navigation for Large Industrial Scenarios,"Design, User Experience, and Usability. User Experience Design for Diverse Interaction Platforms and Environments",,,,10.1007/978-3-319-07626-3_52,Lucas S. FigueiredoMariana PinheiroEdvar Vilar NetoThiago MenezesJoão Marcelo TeixeiraVeronica TeichriebPedro AlessioDaniel Freitas,2014,http://link.springer.com/chapter/10.1007/978-3-319-07626-3_52,Chapter,"body gestures, in-place navigation, natural interaction",10,"Here we address the problem of navigating in virtual environments with fixed display visualizations (e.g. projections and tvs) by using natural gestures. Gesture metaphors have proven to be a powerful tool for human computer interaction. Examples arise from smartphones to state of the art projects like the Holodesk (from Microsoft Research). However, regarding the use of gestures for navigation in virtual environments, a specific limitation arises in respect to the user movimentation in the real space. The gestures should provide the user a way of turning the virtual camera direction without losing the view of the screen. Moreover, the user must be able to move long distances in the virtual environment without trespassing real world boundaries and without becoming fatigued."
Randomised Testing of a Microprocessor Model Using SMT-Solver State Generation,Formal Methods for Industrial Critical Systems,,,,10.1007/978-3-319-10702-8_13,Brian CampbellIan Stark,2014,http://link.springer.com/chapter/10.1007/978-3-319-10702-8_13,Chapter,"HOL, microprocessor models, Randomised testing, SMT",10,"We validate a HOL4 model of the ARM Cortex-M0 microcontroller core by testing the model’s behaviour on randomly chosen instructions against a real chip. The model and our intended application involve precise timing information about instruction execution, but the implementations are pipelined, so checking the behaviour of single instructions would not give us sufficient confidence in the model. Thus we test the model using sequences of randomly chosen instructions. The main challenge is to meet the constraints on the initial and intermediate execution states: we must ensure that memory accesses are in range and that we respect restrictions on the instructions. By careful transformation of these constraints an off-the-shelf SMT solver can be used to find suitable states for executing test sequences."
3D Rectangulations and Geometric Matrix Multiplication,Algorithms and Computation,,,,10.1007/978-3-319-13075-0_6,Peter FloderusJesper JanssonChristos LevcopoulosAndrzej LingasDzmitry Sledneu,2014,http://link.springer.com/chapter/10.1007/978-3-319-13075-0_6,Chapter,"Geometric decompositions, Matrix multiplication, Minimum number rectangulation, Polyhedron, Time complexity",10,"The problem of partitioning an input rectilinear polyhedron $$P$$ into a minimum number of 3D rectangles is known to be NP-hard. We first develop a $$4$$ -approximation algorithm for the special case in which $$P$$ is a 3D histogram. It runs in $$O(m \log m)$$ time, where $$m$$ is the number of corners in $$P$$ . We then apply it to compute the arithmetic matrix product of two $$n \times n$$ matrices $$A$$ and $$B$$ with nonnegative integer entries, yielding a method for computing $$A \times B$$ in $$\tilde{O}(n^2+ \min \{ r_Ar_B, n\min \{r_A,\ r_B\}\})$$ time, where $$\tilde{O}$$ suppresses polylogarithmic (in $$n$$ ) factors and where $$r_A$$ and $$r_B$$ denote the minimum number of 3D rectangles into which the 3D histograms induced by $$A$$ and $$B$$ can be partitioned, respectively."
Model-Based Testing for Verification Back-Ends,Tests and Proofs,,,,10.1007/978-3-642-38916-0_3,Cyrille ArthoArmin BiereMartina Seidl,2013,http://link.springer.com/chapter/10.1007/978-3-642-38916-0_3,Chapter,"Application Programming Interface, Conjunctive Normal Form, Propositional Formula, Software Product Line, System Under Test",10,"Many verification tools used in practice rely on sophisticated SAT and SMT solvers. These reasoning engines are assumed and expected to be correct, but, in general, too complex to be fully verified. Therefore, effective testing techniques have to be employed. In this paper, we show how to employ model-based testing (MBT) to test sequences of application programming interface (API) calls and different system configurations. We applied this approach to our SAT solver Lingeling and compared it to existing testing approaches, revealing the effectiveness of MBT for the development of reliable SAT solvers."
Case Studies in Learning-Based Testing,Testing Software and Systems,,,,10.1007/978-3-642-41707-8_11,Lei FengSimon LundmarkKarl MeinkeFei NiuMuddassar A. SindhuPeter Y. H. Wong,2013,http://link.springer.com/chapter/10.1007/978-3-642-41707-8_11,Chapter,"Kripke Structure, Model Check, Requirement Modeling, Slip Rate, System Under Test",10,"We present case studies which show how the paradigm of learning-based testing (LBT) can be successfully applied to black-box requirements testing of industrial reactive systems. For this, we apply a new testing tool LBTest, which combines algorithms for incremental black-box learning of Kripke structures with model checking technology. We show how test requirements can be modeled in propositional linear temporal logic extended by finite data types. We then provide benchmark performance results for LBTest applied to three industrial case studies."
Modbat: A Model-Based API Tester for Event-Driven Systems,Hardware and Software: Verification and Testing,,,,10.1007/978-3-319-03077-7_8,Cyrille Valentin ArthoArmin BiereMasami HagiyaEric PlatonMartina SeidlYoshinori TanabeMitsuharu Yamamoto,2013,http://link.springer.com/chapter/10.1007/978-3-319-03077-7_8,Chapter,"model-based testing, Software testing, test case derivation",10,"Model-based testing derives test executions from an abstract model that describes the system behavior. However, existing approaches are not tailored to event-driven or input/output-driven systems. In particular, there is a need to support non-blocking I/O operations, or operations throwing exceptions when communication is disrupted. Our new tool “Modbat” is specialized for testing systems where these issues are common. Modbat uses extended finite-state machines to model system behavior. Unlike most existing tools, Modbat offers a domain-specific language that supports state machines and exceptions as first-class constructs. Our model notation also handles non-determinism in the system under test, and supports alternative continuations of test cases depending on the outcome of non-deterministic operations. These features allow us to model a number of interesting libraries succinctly. Our experiments show the flexibility of Modbat and how language support for model features benefits their correct use."
Experience with Industrial Adoption of Business Process Models for User Acceptance Testing,Modelling Foundations and Applications,,,,10.1007/978-3-642-39013-5_14,Deepali KholkarPooja YelureHarshit TiwariAjay DeshpandeAditya Shetye,2013,http://link.springer.com/chapter/10.1007/978-3-642-39013-5_14,Chapter,"Business Analyst, Business Process Model, Business Process Modeling Notation, Business Rule, Unify Modeling Language",10,"Model based testing or the generation of tests from machine readable models has been widely deployed in industry for testing embedded systems and devices. Attempts are being made to extend its use to business systems. However, in spite of its potential for process improvement, its large-scale adoption for testing business systems is not yet seen, mainly due to little data being available on such use. This paper presents the findings from industrial deployment of a business process model based testing approach for User Acceptance Testing of large banking and insurance systems. The approach met with easier acceptance from the user community due to use of business process models and has proved to scale to very large models. It resulted in an overall productivity benefit of 20-30% in test design and planning, in addition to digitization of domain and process knowledge and has been successfully adopted organization-wide. Benefits as well as issues faced in large-scale adoption are discussed along with solutions found and open problems."
Unfolding-Based Test Selection for Concurrent Conformance,Testing Software and Systems,,,,10.1007/978-3-642-41707-8_7,Hernán Ponce de LeónStefan HaarDelphine Longuet,2013,http://link.springer.com/chapter/10.1007/978-3-642-41707-8_7,Chapter,"Coverage Criterion, Label Transition System, Partial Order, System Under Test, Test Suite",10,"Model-based testing has mainly focused on models where currency is interpreted as interleaving (like the ioco theory for labeled transition systems), which may be too coarse when one wants concurrency to be preserved in the implementation. In order to test such concurrent systems, we choose to use Petri nets as specifications and define a concurrent conformance relation named co-ioco . We propose a test generation algorithm based on Petri net unfolding able to build a complete test suite w.r.t our co-ioco conformance relation. In addition we propose a coverage criterion based on a dedicated notion of complete prefixes that selects a manageable test suite."
Identification and Selection of Interaction Test Scenarios for Integration Testing,System Analysis and Modeling: Theory and Practice,,,,10.1007/978-3-642-36757-1_2,Mohamed MussaFerhat Khendek,2013,http://link.springer.com/chapter/10.1007/978-3-642-36757-1_2,Chapter,"Components, Integration, Interactions, Model Based Testing, Testing",10,"Integration testing checks for compatibility and interoperability between the components in the system. Integration test models are, typically, generated independently from the other testing level models. In our research, we aim at a model-based framework across unit, integration, and acceptance level testing. This paper contributes to this framework and for the generation of integration test models from unit test models. More precisely, we focus on component interaction test scenarios identification and selection. Following our approach, at each integration step, unit test cases with interaction scenarios involving the component and the context are identified, selected and merged to build the integration test model for the next step. Unit test stubs and drivers are reused in the integration test model. Redundant test cases are eliminated from the generated test models."
Model-Driven Test Code Generation,Evaluation of Novel Approaches to Software Engineering,,,,10.1007/978-3-642-32341-6_11,Beatriz Pérez LamanchaPedro RealesMacario PoloDanilo Caivano,2013,http://link.springer.com/chapter/10.1007/978-3-642-32341-6_11,Chapter,"Model Transformation, Object Management Group, Sequence Diagram, Software Product Line, System Under Test",10,"Model-driven Testing (MDT) refers a model-based testing that follows Model Driven Engineering paradigm, i.e., the test cases are automated generated using models extracted from software artifacts through model transformations. In previous work, we developed a model to model transformation that takes as input UML 2.0 sequence diagrams, and automatically derive test cases scenarios that conforms the UML Testing Profile. In this work, these test case scenarios are automatically transformed using model to text transformation. This transformation, which can be applied to obtain test cases in a variety of programming languages, is implemented with MOFScript, which is also an OMG standard."
Towards a GUI Test Model Using State Charts and Programming Code,Testing Software and Systems,,,,10.1007/978-3-642-41707-8_18,Daniel MauserAlexander KlausKonstantin Holl,2013,http://link.springer.com/chapter/10.1007/978-3-642-41707-8_18,Chapter,"automotive, human machine interface, model based testing",10,"Modern human machine interfaces provide a sophisticated structure and logic to ease their use. As they are the only mean to control the system behind, extensive testing and highest quality is required in the automotive domain. A common testing approach in literature is to derive the necessary test cases from a formal model. However, redundancy and data dependency still hinder manual modeling in the industrial context. In this paper, we present preliminary work to address these obstacles. As a first step, we combined depictive state charts with reusable programming code. We modeled parts of the graphical user interface of a state-of-the-art infotainment system and successfully generated a test suite that covers our testing goal to reach each button at least once."
Automatic Grammar-Based Test Generation,Testing Software and Systems,,,,10.1007/978-3-642-41707-8_2,Hai-Feng GuoZongyan Qiu,2013,http://link.springer.com/chapter/10.1007/978-3-642-41707-8_2,Chapter,"Coverage Tree, Generate Test Case, Production Rule, Software Product Line, Test Generation",10,"In this paper, we present an automatic grammar-based test generation approach which takes a symbolic grammar as input, requires zero control input from users, and produces well-distributed test cases. Our approach utilizes a novel dynamic stochastic model where each variable is associated with a tuple of probability distributions, which are dynamically adjusted along the derivation. The adjustment is based on a tabling strategy to keep track of the recursion of each grammar variable. We further present a test generation coverage tree illustrating the distribution of generated test cases and their detailed derivations, more importantly, it provides various implicit balance control mechanisms. We implemented this approach in a Java-based system, named Gena . Experimental results demonstrate the effectiveness of our test generation approach and show the balanced distribution of generated test cases over grammatical structures."
Systematic Review on Software Product Line Testing,Software and Data Technologies,,,,10.1007/978-3-642-29578-2_4,Beatriz Pérez LamanchaMacario PoloMario Piattini,2013,http://link.springer.com/chapter/10.1007/978-3-642-29578-2_4,Chapter,"Software product lines, Software testing, Survey, Systematic review, Test",10,"This article presents a systematic review of the literature about Testing in Software Product Lines. The objective is to analyze the existing approaches to testing in software product lines, discussing the significant issues related to this area of knowledge and providing an up-to-date state of the art, which can serve as a basis for innovative research activities. The paper includes an analysis on how SPL research can contribute to dynamize the research in software testing."
Behavioral Fuzzing Operators for UML Sequence Diagrams,System Analysis and Modeling: Theory and Practice,,,,10.1007/978-3-642-36757-1_6,Martin SchneiderJürgen GroßmannNikolay TcholtchevIna SchieferdeckerAndrej Pietschker,2013,http://link.springer.com/chapter/10.1007/978-3-642-36757-1_6,Chapter,"Fuzzing, Model-based Testing, Security Testing, UML",10,"Model-based testing is a recognized method for testing the functionality of a system under test. However, it is not only the functionality of a system that has to be assessed. Also the security aspect has to be tested, especially for systems that provide interfaces to the Internet. In order to find vulnerabilities that could be exploited to break into or to crash a system, fuzzing is an established technique in industry. Model-based fuzzing complements model-based testing of functionality in order to find vulnerabilities by injecting invalid input data into the system. While it focuses on invalid input data, we present a complementary approach called behavioral fuzzing. Behavioral fuzzing does not inject invalid input data but sends an invalid sequence of messages to the system under test. We start with existing UML sequence diagrams – e.g. functional test cases – and modify them by applying fuzzing operators in order to generate invalid sequences of messages. We present the identified fuzzing operators and propose a classification for them. A description of a case study from the ITEA-2 research project DIAMONDS as well as preliminary results are presented."
Incremental Refinement Checking for Test Case Generation,Tests and Proofs,,,,10.1007/978-3-642-38916-0_1,Bernhard K. AichernigElisabeth JöbstlMatthias Kegele,2013,http://link.springer.com/chapter/10.1007/978-3-642-38916-0_1,Chapter,"action systems, conformance, constraint solving, model-based testing, mutation testing, refinement, SMT solving",10,"We combine model-based testing and mutation testing to automatically generate a test suite that achieves a high mutation adequacy score. The original model representing the system under test is mutated. To generate test cases that detect whether a modelled fault has been implemented, we perform a refinement check between the original and the mutated models. Action systems serve as formal models. They are well-suited to model reactive systems and allow non-determinism. We extend our previous work by two techniques to improve efficiency: (1) a strategy to efficiently handle a large number of mutants and (2) incremental solving. A case study illustrates the potential of our improvements. The runtime for checking appr. 200 mutants could be reduced from 20s to 3s. We implemented our algorithms in two versions: one uses a constraint solver, the other one an SMT solver. Both show similar performance."
A Generic Fault Model for Quality Assurance,Model-Driven Engineering Languages and Systems,,,,10.1007/978-3-642-41533-3_6,Alexander PretschnerDominik HollingRobert EschbachMatthias Gemmar,2013,http://link.springer.com/chapter/10.1007/978-3-642-41533-3_6,Chapter,,10,"Because they are comparatively easy to implement, structural coverage criteria are commonly used for test derivation in model- and code-based testing. However, there is a lack of compelling evidence that they are useful for finding faults, specifically so when compared to random testing. This paper challenges the idea of using coverage criteria for test selection and instead proposes an approach based on fault models. We define a general fault model as a transformation from correct to incorrect programs and/or a partition of the input data space. Thereby, we leverage the idea of fault injection for test assessment to test derivation. We instantiate the developed general fault model to describe existing fault models. We also show by example how to derive test cases."
A Grey-Box Approach for Automated GUI-Model Generation of Mobile Applications,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-642-37057-1_19,Wei YangMukul R. PrasadTao Xie,2013,http://link.springer.com/chapter/10.1007/978-3-642-37057-1_19,Chapter,"Android Application, Call Graph, Graphical User Interface, Mobile Platform, Symbolic Execution",10,"As the mobile platform continues to pervade all aspects of human activity, and mobile applications, or mobile apps for short, on this platform tend to be faulty just like other types of software, there is a growing need for automated testing techniques for mobile apps. Modelbased testing is a popular and important testing approach that operates on a model of an app’s behavior. However, such a model is often not available or of insufficient quality. To address this issue, we present a novel grey-box approach for automatically extracting a model of a given mobile app. In our approach, static analysis extracts the set of events supported by the Graphical User Interface (GUI) of the app. Then dynamic crawling reverse-engineers a model of the app, by systematically exercising these events on the running app. We also present a tool implementing this approach for the Android platform. Our empirical evaluation of this tool on several Android apps demonstrates that it can efficiently extract compact yet reasonably comprehensive models of high quality for such apps."
State-Driven Testing of Distributed Systems,Principles of Distributed Systems,,,,10.1007/978-3-319-03850-6_9,Domenico CotroneoRoberto NatellaStefano RussoFabio Scippacercola,2013,http://link.springer.com/chapter/10.1007/978-3-319-03850-6_9,Chapter,"Experimental Dependability Assessment, Fault Injection, Fault Tolerance, Genetic Algorithms, State-based Testing, Workload",10,"In distributed systems, failures are often caused by software faults that manifest themselves only when the system enters a particular, rarely occurring system state. It thus becomes important to identify these failure-prone states during testing. We propose a state-driven testing approach for distributed systems, able to execute tests in hard-to-reach states in a repeatable and accurate way. Moreover, we present the implementation and experimental evaluation of the approach in the context of a fault-tolerant flight data processing system. Experimental results confirm the feasibility of the approach, and the accuracy and reproducibility of tests."
Testing Idempotence for Infrastructure as Code,Middleware 2013,,,,10.1007/978-3-642-45065-5_19,Waldemar HummerFlorian RosenbergFábio OliveiraTamar Eilam,2013,http://link.springer.com/chapter/10.1007/978-3-642-45065-5_19,Chapter,"Convergence, Idempotence, Infrastructure as Code, Middleware Deployment, Software Automation, Software Testing",10,"Due to the competitiveness of the computing industry, software developers are pressured to quickly deliver new code releases. At the same time, operators are expected to update and keep production systems stable at all times. To overcome the development–operations barrier, organizations have started to adopt Infrastructure as Code (IaC) tools to efficiently deploy middleware and applications using automation scripts. These automations comprise a series of steps that should be idempotent to guarantee repeatability and convergence. Rigorous testing is required to ensure that the system idempotently converges to a desired state, starting from arbitrary states. We propose and evaluate a model-based testing framework for IaC. An abstracted system model is utilized to derive state transition graphs, based on which we systematically generate test cases for the automation. The test cases are executed in light-weight virtual machine environments. Our prototype targets one popular IaC tool (Chef), but the approach is general. We apply our framework to a large base of public IaC scripts written by operators, showing that it correctly detects non-idempotent automations."
An Implementation Relation and Test Framework for Timed Distributed Systems,Testing Software and Systems,,,,10.1007/978-3-642-41707-8_6,Christophe GastonRobert M. HieronsPascale Le Gall,2013,http://link.springer.com/chapter/10.1007/978-3-642-41707-8_6,Chapter,"distributed systems, model based testing, symbolic input output transition systems, timed systems",10,"Many systems interact with their environment at physically distributed interfaces and the distributed nature of any observations made is known to complicate testing. This paper concerns distributed testing, where a separate tester is placed at each localised interface and may only observe what happens at this interface. Most previous work on distributed model based testing has used models that are either finite state machines or input output transition systems. In this paper we define a framework for distributed testing from timed input output transition systems along with corresponding test hypotheses and a distributed conformance relation."
Automated Test Case Selection Using Feature Model: An Industrial Case Study,Model-Driven Engineering Languages and Systems,,,,10.1007/978-3-642-41533-3_15,Shuai WangArnaud GotliebShaukat AliMarius Liaaen,2013,http://link.springer.com/chapter/10.1007/978-3-642-41533-3_15,Chapter,"Component Family Model, Feature Model, Product Line, Test Case Selection",10,"Automated test case selection for a new product in a product line is challenging due to several reasons. First, the variability within the product line needs to be captured in a systematic way; second, the reusable test cases from the repository are required to be identified for testing a new product. The objective of such automated process is to reduce the overall effort for selection (e.g., selection time), while achieving an acceptable level of the coverage of testing functionalities. In this paper, we propose a systematic and automated methodology using a Feature Model for Testing (FM_T) to capture commonalities and variabilities of a product line and a Component Family Model for Testing (CFM_T) to capture the overall structure of test cases in the repository. With our methodology, a test engineer does not need to manually go through the repository to select a relevant set of test cases for a new product. Instead, a test engineer only needs to select a set of relevant features using FM_T at a higher level of abstraction for a product and a set of relevant test cases will be selected automatically. We applied our methodology to a product line of video conferencing systems called Saturn developed by Cisco and the results show that our methodology can reduce the selection effort significantly. Moreover, we conducted a questionnaire-based study to solicit the views of test engineers who were involved in developing FM_T and CFM_T. The results show that test engineers are positive about adapting our methodology and models (FM_T and CFM_T) in their current practice."
Using Logic Coverage to Improve Testing Function Block Diagrams,Testing Software and Systems,,,,10.1007/978-3-642-41707-8_1,Eduard Paul EnoiuDaniel SundmarkPaul Pettersson,2013,http://link.springer.com/chapter/10.1007/978-3-642-41707-8_1,Chapter,"function block diagram, logic coverage, model-driven engineering, structural testing, timed automata",10,"In model-driven development, testers are often focusing on functional model-level testing, enabling verification of design models against their specifications. In addition, in safety-critical software development, testers are required to show that tests cover the structure of the implementation. Testing cost and time savings could be achieved if the process of deriving test cases for logic coverage is automated and provided test cases are ready to be executed. The logic coverage artifacts, i.e., predicates and clauses, are required for different logic coverage, e.g., MC/DC. One way of dealing with test case generation for ensuring logic coverage is to approach it as a model-checking problem, such that model-checking tools automatically create test cases. We show how logic coverage criteria can be formalized and used by a model-checker to provide test cases for ensuring coverage on safety-critical software described in the Function Block Diagram programming language. Based on our experiments, this approach, supported by a tool chain, is an applicable and useful way of generating test cases for covering Function Block Diagrams."
Constraints: The Core of Supporting Automated Product Configuration of Cyber-Physical Systems,Model-Driven Engineering Languages and Systems,,,,10.1007/978-3-642-41533-3_23,Kunming NieTao YueShaukat AliLi ZhangZhiqiang Fan,2013,http://link.springer.com/chapter/10.1007/978-3-642-41533-3_23,Chapter,"Classification, Configuration, Constraints, Cyber-Physical Systems, Industrial Case Studies, Product Line Engineering",10,"In the context of product line engineering of cyber-physical systems, there exists a large number of constraints to support, for example, consistency checking of design decisions made in hardware and software components during configuration. Manual configuration is not feasible in this context considering that managing and manipulating all these constraints in a real industrial context is very complicated and thus warrants an automated solution. Typical automation activities in this context include automated configuration value inference, optimizing configuration steps and consistency checking. However, to this end, relevant constraints have to be well-specified and characterized in the way such that automated configuration can be enabled. In this paper, we classify and characterize constraints that are required to be specified to support most of the key functionalities of any automated product configuration solution, based on our experience of studying three industrial product lines."
Machine-Readable Privacy Certificates for Services,On the Move to Meaningful Internet Systems: OTM 2013 Conferences,,,,10.1007/978-3-642-41030-7_31,Marco AnisettiClaudio A. ArdagnaMichele BezziErnesto DamianiAntonino Sabetta,2013,http://link.springer.com/chapter/10.1007/978-3-642-41030-7_31,Chapter,"certification, privacy, testing",10,"Privacy-aware processing of personal data on the web of services requires managing a number of issues arising both from the technical and the legal domain. Several approaches have been proposed to matching privacy requirements (on the clients side) and privacy guarantees (on the service provider side). Still, the assurance of effective data protection (when possible) relies on substantial human effort and exposes organizations to significant (non-)compliance risks. In this paper we put forward the idea that a privacy certification scheme producing and managing machine-readable artifacts in the form of privacy certificates can play an important role towards the solution of this problem. Digital privacy certificates represent the reasons why a privacy property holds for a service and describe the privacy measures supporting it. Also, privacy certificates can be used to automatically select services whose certificates match the client policies (privacy requirements). Our proposal relies on an evolution of the conceptual model developed in the Assert4Soa project and on a certificate format specifically tailored to represent privacy properties. To validate our approach, we present a worked-out instance showing how privacy property Retention-based unlinkability can be certified for a banking financial service."
Automated Model-in-the-Loop Testing of Continuous Controllers Using Search,Search Based Software Engineering,,,,10.1007/978-3-642-39742-4_12,Reza MatinnejadShiva NejatiLionel BriandThomas BruckmannClaude Poull,2013,http://link.springer.com/chapter/10.1007/978-3-642-39742-4_12,Chapter,"Controller Property, Exploration Algorithm, Hybrid Automaton, Industry Partner, Random Search",10,"The number and the complexity of software components embedded in today’s vehicles is rapidly increasing. A large group of these components monitor and control the operating conditions of physical devices (e.g., components controlling engines, brakes, and airbags). These controllers are known as continuous controllers . In this paper, we study testing of continuous controllers at the Model-in-Loop (MiL) level where both the controller and the environment are represented by models and connected in a closed feedback loop system. We identify a set of common requirements characterizing the desired behavior of continuous controllers, and develop a search-based technique to automatically generate test cases for these requirements. We evaluated our approach by applying it to a real automotive air compressor module. Our experience shows that our approach automatically generates several test cases for which the MiL level simulations indicate potential violations of the system requirements. Further, not only do our approach generates better test cases faster than random test case generation, but we also achieve better results than test scenarios devised by domain experts."
Big Metamodels Are Evil,Model-Driven Engineering Languages and Systems,,,,10.1007/978-3-642-41533-3_9,Frédéric FondementPierre-Alain MullerLaurent ThiryBrice WittmannGermain Forestier,2013,http://link.springer.com/chapter/10.1007/978-3-642-41533-3_9,Chapter,"Model Drive Engineering, Model Transformation, Object Management Group, Unify Modeling Language, Unify Modeling Language Model",10,"While reuse is typically considered a good practice, it may also lead to keeping irrelevant concerns in derived elements. For instance, new metamodels are usually built upon existing metamodels using additive techniques such as profiling and package merge. With such additive techniques, new metamodels tend to become bigger and bigger, which leads to harmful overheads of complexity for both tool builders and users. In this paper, we introduce ≪ package unmerge≫ - a proposal for a subtractive relation between packages - which complements existing metamodel-extension techniques."
Adaptive Homing and Distinguishing Experiments for Nondeterministic Finite State Machines,Testing Software and Systems,,,,10.1007/978-3-642-41707-8_3,Natalia KushikKhaled El-FakihNina Yevtushenko,2013,http://link.springer.com/chapter/10.1007/978-3-642-41707-8_3,Chapter,"adaptive homing and distinguishing experiments, conformance testing, Nondeterministic finite state machine",10,"Adaptive experiments are well defined in the context of finite state machine (FSM) based analysis, in particular, in FSM based testing where homing and distinguishing experiments with FSMs are used in test derivation. In this paper, we define and propose algorithms for deriving adaptive homing and distinguishing experiments for non-initialized nondeterministic finite state machines (NFSM). For NFSMs, the construction of adaptive experiments is rather complex as the partition over produced outputs does not define a partition over the set of states but rather a collection of intersecting subsets, and thus, the refinement of such subsets is more difficult than the refinement of a partition. Given a complete non-initialized observable NFSM, we establish necessary and sufficient conditions for having adaptive homing and distinguishing experiments and evaluate the upper bound on the height of these experiments. Simple application examples demonstrating a proposed approach are provided."
A CSP Timed Input-Output Relation and a Strategy for Mechanised Conformance Verification,Formal Methods and Software Engineering,,,,10.1007/978-3-642-41202-8_11,Gustavo CarvalhoAugusto SampaioAlexandre Mota,2013,http://link.springer.com/chapter/10.1007/978-3-642-41202-8_11,Chapter,"Conformance Relation, Constraint Solver, CSP, Data, Time",10,"Here we propose a timed input-output conformance relation (named CSPTIO) based on the process algebra CSP. In contrast to other relations, CSPTIO analyses data-flow reactive systems and conformance verification is mechanised in terms of a high-level strategy by reusing successful techniques and tools: refinement checking (particularly, using the FDR tool) and SMT solving (using Z3). Therefore, conformance verification does not require the implementation of specific algorithms or the manipulation of complex data structures. Furthermore, the mechanisation is proved sound. To analyse the usefulness of CSPTIO, we first consider a toy example. Then we analyse critical systems from two different domains: aeronautics and automotive. CSPTIO detected all undesired behaviours in the analysed implementation models."
Building Rich Internet Applications Models: Example of a Better Strategy,Web Engineering,,,,10.1007/978-3-642-39200-9_25,Suryakant ChoudharyMustafa Emre DincturkSeyed M. MirtaheriGuy-Vincent JourdanGregor v. BochmannIosif Viorel Onut,2013,http://link.springer.com/chapter/10.1007/978-3-642-39200-9_25,Chapter,"AJAX, Crawling, Modeling, RIAs",10,"Crawling “classical” web applications is a problem that has been addressed more than a decode ago. Efficient crawling of web applications that use advanced technologies such as AJAX (called Rich Internet Applications, RIAs) is still an open problem. Crawling is important not only for indexing content, but also for building models of the applications, which is necessary for automated testing, automated security and accessibility assessments and in general for using software engineering tools. This paper presents a new strategy to crawl RIAs. It uses the concept of Model-Based Crawling (MBC) first introduced in [1], and introduces a new model, the “menu model”, which we show to be much simpler than previous models for MBC and more effective at building models than previously published methods. This method and others are compared against a set of experimental and real RIAs."
Issues and Ongoing Work on State-Driven Workload Generation for Distributed Systems,Dependable Computing,,,,10.1007/978-3-642-38789-0_9,Roberto NatellaFabio Scippacercola,2013,http://link.springer.com/chapter/10.1007/978-3-642-38789-0_9,Chapter,"Distributed Systems, Fault Injection, Fault Tolerance, Genetic Algorithms, Off-line synchronization, State-based Testing, Workload",10,"The dependability of a complex distributed system needs to be assured against the several conditions, namely states , in which it can operate. Generating a workload able to cover a desired target state of a distributed system is still a difficult task, since the relationship between the workload and states is nontrivial due to system complexity and non-deterministic factors. This work discusses our ongoing work on a state-driven workload generation approach for distributed systems, based on an evolutionary algorithm, and its preliminary implementation for testing a fault-tolerant distributed system for flight data processing."
Combining Testing and Runtime Verification Techniques,Model-Based Methodologies for Pervasive and Embedded Software,,,,10.1007/978-3-642-38209-3_3,Kevin FalzonGordon J. Pace,2013,http://link.springer.com/chapter/10.1007/978-3-642-38209-3_3,Chapter,"Outgoing Transition, Runtime Monitoring, Runtime Verification, Test Case Generation, Testing Oracle",10,"Testing is an established and integral part of the system design and development process, but incomplete coverage still leaves room for potential undiscovered bugs. Runtime verification addresses this issue by integrating verification oracles into the code, allowing for reparatory action to be taken in case of system failure after deployment. Despite the complementarity of the two approaches, the application of the two approaches at different stages in the development and deployment process results in much duplication of effort. In this paper we investigate the combination of the two approaches, by showing how one can use testing oracles to derive correct runtime verification monitors. We show how this can be achieved using QuickCheck and Larva , and apply the resulting framework to Riak, a fault-tolerant distributed database written in Erlang."
WebMate: Generating Test Cases for Web 2.0,Software Quality. Increasing Value in Software and Systems Development,,,,10.1007/978-3-642-35702-2_5,Valentin DallmeierMartin BurgerTobias OrthAndreas Zeller,2013,http://link.springer.com/chapter/10.1007/978-3-642-35702-2_5,Chapter,"automate testing, test case generation, Web 2.0, web applications",10,"Web applications are everywhere—well tested web applications however are in short supply. The mixture of JavaScript, HTML and CSS in a variety of different browsers makes it virtually impossible to apply static analysis techniques. In this setting, systematic testing becomes a real challenge. We present a technique to automatically generate tests for Web 2.0 applications. Our approach systematically explores and tests all distinct functions of a web application. Our prototype implementation WEBMATE handles interfaces as complex as Facebook and is able to cover up to 7 times as much code as existing tools. The only requirements to use WEBMATE are the address of the application and, if necessary, user name and password."
System Level Formal Verification via Model Checking Driven Simulation,Computer Aided Verification,,,,10.1007/978-3-642-39799-8_21,Toni ManciniFederico MariAnnalisa MassiniIgor MelattiFabio MerliEnrico Tronci,2013,http://link.springer.com/chapter/10.1007/978-3-642-39799-8_21,Chapter,"Discrete Event System, Event List, Model Check, Simulation Campaign, Simulation Scenario",10,"We show how by combining Explicit Model Checking techniques and simulation it is possible to effectively carry out (bounded) System Level Formal Verification of large Hybrid Systems such as those defined using model-based tools like Simulink . We use an explicit model checker (namely, CMurphi ) to generate all possible ( finite horizon ) simulation scenarios and then optimise the simulation of such scenarios by exploiting the ability of simulators to save and restore visited states. We show feasibility of our approach by presenting experimental results on the verification of the fuel control system example in the Simulink distribution. To the best of our knowledge this is the first time that (exhaustive) verification has been carried out for hybrid systems of such a size."
Log File Analysis with Context-Free Grammars,Advances in Digital Forensics IX,,,,10.1007/978-3-642-41148-9_10,Gregory BosmanStefan Gruner,2013,http://link.springer.com/chapter/10.1007/978-3-642-41148-9_10,Chapter,"context-free grammars, Intrusion detection, log file analysis",10,"Classical intrusion analysis of network log files uses statistical machine learning or regular expressions. Where statistically machine learning methods are not analytically exact, methods based on regular expressions do not reach up very far in Chomsky’s hierarchy of languages. This paper focuses on parsing traces of network traffic using context-free grammars. “Green grammars” are used to describe acceptable log files while “red grammars” are used to represent known intrusion patterns. This technique can complement or augment existing approaches by providing additional precision. Analytically, the technique is also more powerful than existing techniques that use regular expressions."
An Approach to Testing Java Implementation against Its UML Class Model,Model-Driven Engineering Languages and Systems,,,,10.1007/978-3-642-41533-3_14,Hector M. ChavezWuwei ShenRobert B. FranceBenjamin A. Mechling,2013,http://link.springer.com/chapter/10.1007/978-3-642-41533-3_14,Chapter,"Class diagram, Java, Model checking, UML",10,"Model Driven Engineering (MDE) aims to expedite the software development process by providing support for transforming models to running systems. Many modeling tools provide forward engineering features that automatically translate a model into a skeletal program that developers must complete. Inconsistencies between a design model and its implementation can result as a consequence of manually-added code. Manually checking that an implementation conforms to the model is a daunting task. Thus, there is a need for MDE tools that developers can use to check whether an implementation conforms to a model, especially when generated code is manually modified. This paper presents an approach for testing that an implementation satisfies the constraints specified in its design model. We also describe a prototypical tool that supports the approach, and we describe how its application to two Eclipse UML2 projects uncovered errors."
Data-Flow Based Model Analysis and Its Applications,Model-Driven Engineering Languages and Systems,,,,10.1007/978-3-642-41533-3_43,Christian SaadBernhard Bauer,2013,http://link.springer.com/chapter/10.1007/978-3-642-41533-3_43,Chapter,"Abstract Syntax, Dependency Graph, Meta Model, Object Constraint Language, Reference Node",10,"In this paper we present a data-flow based approach to static model analysis to address the problem of current methods being either limited in their expressiveness or employing formalisms which complicate seamless integration with standards and tools in the modeling domain. By applying data-flow analysis - a technique widely used for static program analysis - to models, we realize what can be considered a generic “programming language” for context-sensitive model analysis through declarative specifications. This is achieved by enriching meta models with data-flow attributes which are afterward instantiated for models. The resulting equation system is subjected to a fixed-point computation that yields a static approximation of the model’s dynamic behavior as specified by the analysis. The applicability of the approach is evaluated in the context of a running example, the examination of viable application domains and a statistical review of the algorithm’s performance."
Remote Testing of Timed Specifications,Testing Software and Systems,,,,10.1007/978-3-642-41707-8_5,Alexandre DavidKim G. LarsenMarius MikučionisOmer L. Nguena TimoAntoine Rollet,2013,http://link.springer.com/chapter/10.1007/978-3-642-41707-8_5,Chapter,"Causal Order, Communication Latency, Label Transition System, System Under Test, Test Purpose",10,We present a study and a testing framework on black box remote testing of real-time systems using Uppaal-TIGA. One of the essential challenges of remote testing is the communication latency between the tester and the system under test (SUT) that may lead to interleaving of inputs and outputs. This affects the generation of inputs for the SUT and the observation of outputs that may trigger a wrong test verdict. We model the overall test setup using Timed Input-Output Automata (TIOA) and present an adapted asynchronous semantics with explicit communication delays. We propose the $\varDelta$ -testability criterion for the requirement model where $\varDelta$ describes the communication latency. The test case generation problem is then reduced into a controller synthesis problem. We use Uppaal-TIGA for this purpose to solve a timed game with partial observability between the tester and the communication media together with the SUT. The objective of the game corresponds to a test purpose.
Validating Code-Level Behavior of Dynamic Adaptive Systems in the Face of Uncertainty,Search Based Software Engineering,,,,10.1007/978-3-642-39742-4_8,Erik M. FredericksAndres J. RamirezBetty H. C. Cheng,2013,http://link.springer.com/chapter/10.1007/978-3-642-39742-4_8,Chapter,"genetic algorithm, novelty search, search-based software engineering, software assurance",10,"A dynamically adaptive system (DAS) self-reconfigures at run time in order to handle adverse combinations of system and environmental conditions. Techniques are needed to make DASs more resilient to system and environmental uncertainty. Furthermore, automated support to validate that a DAS provides acceptable behavior even through reconfigurations are essential to address assurance concerns. This paper introduces F enrir , an evolutionary computation-based approach to address these challenges. By explicitly searching for diverse and interesting operational contexts and examining the resulting execution traces generated by a DAS as it reconfigures in response to adverse conditions, F enrir can discover undesirable behaviors triggered by unexpected environmental conditions at design time, which can be used to revise the system appropriately. We illustrate F enrir by applying it to a dynamically adaptive remote data mirroring network that must efficiently diffuse data even in the face of adverse network conditions."
Augmenting Sequence Enumeration with String-Rewriting for Requirements Analysis and Behavioral Specification,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-642-37057-1_13,Lan LinJesse H. PooreRobert EschbachRobert M. HieronsChristopher Robinson-Mallett,2013,http://link.springer.com/chapter/10.1007/978-3-642-37057-1_13,Chapter,"requirements engineering, sequence enumeration, sequence-based specification, software specification, string-rewriting",10,"Sequence enumeration is a method for deriving a system model based on informal requirements. Under sequence enumeration, stimulus (input) sequences are considered in a breadth-first manner, with the expected system response to each sequence given. Not all sequences of stimuli are considered since a sequence need not be extended if either it is illegal (it cannot be applied in practice) or it can be reduced to another sequence previously considered (the sequences take the system to the same state). Sequence enumeration is mostly a manual process, which leads to a model that can be used as the basis for automation. This paper describes a method, based on string-rewriting, that automates parts of sequence enumeration. This automation has the potential to reduce both the cost and time involved in sequence enumeration but also to reduce the scope for human error. In addition to outlining this method, we discuss our experiences in applying it to four case studies."
Inferring Automata with State-Local Alphabet Abstractions,NASA Formal Methods,,,,10.1007/978-3-642-38088-4_9,Malte IsbernerFalk HowarBernhard Steffen,2013,http://link.springer.com/chapter/10.1007/978-3-642-38088-4_9,Chapter,"Automaton Learning, Input Alphabet, Input Symbol, Membership Query, Observation Table",10,"A major hurdle for the application of automata learning to realistic systems is the identification of an adequate alphabet: it must be small enough, in particular finite, for the learning procedure to converge in reasonable time, and it must be expressive enough to describe the system at a level where its behavior is deterministic. In this paper, we combine our automated alphabet abstraction approach, which refines the global alphabet of the system to be learned on the fly during the learning process, with the principle of state-local alphabets: rather than determining a single global alphabet, we infer the optimal alphabet abstraction individually for each state. Our experimental results show that this does not only lead to an increased comprehensibility of the learned models, but also to a better performance of the learning process: indeed, besides the drastic – yet foreseeable – reduction in terms of membership queries, we also observed interesting cases where the number of equivalence queries was reduced."
POGen: A Test Code Generator Based on Template Variable Coverage in Gray-Box Integration Testing for Web Applications,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-642-37057-1_25,Kazunori SakamotoKaizu TomohiroDaigo HamuraHironori WashizakiYoshiaki Fukazawa,2013,http://link.springer.com/chapter/10.1007/978-3-642-37057-1_25,Chapter,"software testing, template engine, test code generation, test coverage, web application",10,"Web applications are complex; they consist of many subsystems and run on various browsers and platforms. This makes it difficult to conduct adequate integration testing to detect faults in the connections between subsystems or in the specific environments. Therefore, establishing an efficient integration testing method with the proper test adequacy criteria and tools is an important issue. In this paper, we propose a new test coverage called template variable coverage. We also propose a novel technique for generating skeleton test code that includes accessor methods and improves the template variable coverage criterion, using a tool that we developed called POGen. Our experiments show that template variable coverage correlates highly with the capability to detect faults, and that POGen can reduce testing costs."
Testing with Inputs and Outputs in CSP,Fundamental Approaches to Software Engineering,,,,10.1007/978-3-642-37057-1_26,Ana CavalcantiRobert M. Hierons,2013,http://link.springer.com/chapter/10.1007/978-3-642-37057-1_26,Chapter,"Conformance Relation, Exhaustive Test, Output Event, System Under Test, Test Execution",10,"This paper addresses refinement and testing based on CSP models, when we distinguish input and output events. From a testing perspective, there is an asymmetry: the tester (or the environment) controls the inputs, and the system under test controls the outputs. The standard models and refinement relations of CSP are, therefore, not entirely suitable for testing. Here, we adapt the CSP stable-failures model, resulting in the notion of input-output failures refinement. We compare that with the ioco relation often used in testing.Finally, we adapt the CSP testing theory, and show that some tests become unnecessary."
Machine Learning for Emergent Middleware,"Trustworthy Eternal Systems via Evolving Software, Data and Knowledge",,,,10.1007/978-3-642-45260-4_2,Amel BennaceurValérie IssarnyDaniel SykesFalk HowarMalte IsbernerBernhard SteffenRichard JohanssonAlessandro Moschitti,2013,http://link.springer.com/chapter/10.1007/978-3-642-45260-4_2,Chapter,"Automata learning, Automated Mediation, Interoperability, Machine learning, Natural language processing",10,"Highly dynamic and heterogeneous distributed systems are challenging today’s middleware technologies. Existing middleware paradigms are unable to deliver on their most central promise, which is offering interoperability. In this paper, we argue for the need to dynamically synthesise distributed system infrastructures according to the current operating environment, thereby generating “Emergent Middleware” to mediate interactions among heterogeneous networked systems that interact in an ad hoc way. The paper outlines the overall architecture of Enablers underlying Emergent Middleware, and in particular focuses on the key role of learning in supporting such a process, spanning statistical learning to infer the semantics of networked system functions and automata learning to extract the related behaviours of networked systems."
A New Test-Generation Methodology for System-Level Verification of Production Processes,Hardware and Software: Verification and Testing,,,,10.1007/978-3-642-39611-3_19,Allon AdirAlex GoryachevLev GreenbergTamer SalmanGil Shurek,2013,http://link.springer.com/chapter/10.1007/978-3-642-39611-3_19,Chapter,"Production processes / Manufacturing processes, Test generation, Transaction-based modeling, UML/SysML",10,"The continuing growth in the complexity of production processes is driven mainly by the integration of smart and cheap devices, such as sensors and custom hardware or software components. This naturally leads to higher complexity in fault detection and management, and, therefore to a higher demand for sophisticated quality control tools. A production process is commonly modeled prior to its physical construction to enable early testing. Many simulation platforms were developed to assess the widely varying aspects of the production process, including physical behavior, hardware-software functionality, and performance. However, the efficacy of simulation for the verification of modeled processes is still largely limited by manual operation and observation. We propose a massive random-biased, ontology-based, test-generation methodology for system-level verification of production processes. The methodology has been successfully applied for simulation-based processor hardware verification and proved to be a cost-effective solution. We show that it can be similarly beneficial in the verification of production processes and control."
Regression Testing for Model Transformations: A Multi-objective Approach,Search Based Software Engineering,,,,10.1007/978-3-642-39742-4_16,Jeffery ShelburgMarouane KessentiniDaniel R. Tauritz,2013,http://link.springer.com/chapter/10.1007/978-3-642-39742-4_16,Chapter,"model transformation, multi-objective optimization, search-based software engineering, testing",10,"In current model-driven engineering practices, metamodels are modified followed by an update of transformation rules. Next, the updated transformation mechanism should be validated to ensure quality and robustness. Model transformation testing is a recently proposed effective technique used to validate transformation mechanisms. In this paper, a more efficient approach to model transformation testing is proposed by refactoring the existing test case models, employed to test previous metamodel and transformation mechanism versions, to cover new changes. To this end, a multi-objective optimization algorithm is employed to generate test case models that maximizes the coverage of the new metamodel while minimizing the number of test case model refactorings as well as test case model elements that have become invalid due to the new changes. Validation results on a widely used transformation mechanism confirm the effectiveness of our approach."
Path-Aware Time-Triggered Runtime Verification,Runtime Verification,,,,10.1007/978-3-642-35632-2_21,Samaneh NavabpourBorzoo BonakdarpourSebastian Fischmeister,2013,http://link.springer.com/chapter/10.1007/978-3-642-35632-2_21,Chapter,,10,"A time-triggered monitor runs in parallel with the program under inspection and periodically samples the program state to evaluate a set of properties. However, a time-triggered monitor working with a fixed sampling frequency often suffers from redundant sampling, which results in excessive overhead. In this paper, we propose an effective approach to reduce redundant sampling. Our approach calculates the sampling frequency with respect to the program behavior at run time. We further advance this approach to dynamically adjust the sampling frequency at run time by predicting the program behavior using symbolic execution. Experiments show that our approach reduces the sampling frequency, runtime overhead, and the number of redundant samples by up to 3.5 times, 69%, and 86%, respectively."
State Coverage: An Empirical Analysis Based on a User Study,SOFSEM 2013: Theory and Practice of Computer Science,,,,10.1007/978-3-642-35843-2_40,Dries VanoverbergheEmma EyckmansFrank Piessens,2013,http://link.springer.com/chapter/10.1007/978-3-642-35843-2_40,Chapter,"state coverage, test adequacy metric, user study",10,"State coverage is a relatively new metric to evaluate the quality of test suites. While most existing test adequacy criteria measure the degree of exploration of the code under test, state coverage estimates the strength of the assertions in the test suite. Initial experiments have shown that there is a correlation between state coverage and mutation adequacy, and that expert users can discover new faults by modifying the test suite to increase state coverage. Since the faults injected by mutation testing are relatively simple, it is not clear whether these experiment are valid in a broader setting. Furthermore, these results may not be reproducible by average users, since they usually lack full understanding of the internals of the tool. This paper presents a user-based experiment to evaluate whether the state coverage of a test suite correlates with the number defects it discovers. While the results of the experiments fail to confirm this hypothesis, they do raises important questions. First, test suites with high state coverage should be good in finding logical software faults, but these faults occur less frequently than structural faults. Second, state coverage is not monotonic in the size of the test suite. Therefore, adding new test cases which check new properties and detect new faults can often reduce state coverage. Based on this, we suggest a number of improvements."
Systematic Testing of Graph Transformations: A Practical Approach Based on Graph Patterns,Theory and Practice of Model Transformations,,,,10.1007/978-3-642-38883-5_18,Martin WieberAndy Schürr,2013,http://link.springer.com/chapter/10.1007/978-3-642-38883-5_18,Chapter,"Coverage, Programmed Graph Transformations, Testing",10,"Correctness is an essential property of model transformations. Although testing is a well-accepted method for assuring software quality in general, the properties of declarative transformation languages often prevent a direct application of testing strategies from imperative programming languages. A key challenge of transformation testing concerns limiting the testing effort by a good stop criterion . In this work, we tackle this issue for programmed graph transformations , and present a practical methodology to derive sufficient test suites based on a new coverage notion inspired by mutation analysis. We systematically generate requirement (graph) patterns from the transformation under test, applying different requirement construction strategies, and analyze the approach in terms of practicability, test suite quality and the ability to guide and support test case construction."
Challenges of Testing Periodic Messages in Avionics Systems Using TTCN-3,Testing Software and Systems,,,,10.1007/978-3-642-41707-8_14,Bernard StepienLiam Peyton,2013,http://link.springer.com/chapter/10.1007/978-3-642-41707-8_14,Chapter,"avionics, periodic messages, testing, TTCN-3",10,"The TTCN-3 language was conceived initially for testing telecommunications protocols that consist of sequences of discrete messages between communicating entities. TTCN-3 has a clear model of separation of concerns between an abstract layer, where test behavior is specified, and a concrete layer, where messages are encoded / decoded and sent and received to/from the system under test. This model, however, is cumbersome for testing protocols with periodic messages as used in avionics systems. This paper presents an innovative approach to addressing issues involving periodic messages in TTCN-3, based on our experiences working with avionics systems. Extensions to the TTCN-3 standard are proposed, based on our approach. We also demonstrate how the approach can be used for test system certification and requirements verification for avionics systems."
Testing Stochastic Systems Using MoVoS Tool: Case Studies,Information and Software Technologies,,,,10.1007/978-3-642-41947-8_26,Kenza BouaroudjDjamel-Eddine SaidouniIlham Kitouni,2013,http://link.springer.com/chapter/10.1007/978-3-642-41947-8_26,Chapter,"canonical tester, formal testing models, maximality semantics, refusals graphs",10,"MoVoS tool is an implementation of testing theory based on stochastic refusals graph. It allows the automatic extraction of test cases from specification of stochastic systems. Those systems are modeled by Maximality based Labeled Stochastic Transition System “MLSTS”. In This paper, we present the application of MoVoS tool on two cases studies to valid it. Those case studies permit us to illustrate the functionality of tool and to show that this tool can deal with large system."
Automatic Inference of Erlang Module Behaviour,Integrated Formal Methods,,,,10.1007/978-3-642-38613-8_18,Ramsay TaylorKirill BogdanovJohn Derrick,2013,http://link.springer.com/chapter/10.1007/978-3-642-38613-8_18,Chapter,"Behaviour Inference, Callback Function, Initial Trace, Locker Module, Positive Trace",10,"Previous work has shown the benefits of using grammar inference techniques to infer models of software behaviour for systems whose specifications are not available. However, this inference has required considerable direction from an expert user who needs to have familiarity with the system’s operation, and must be actively involved in the inference process. This paper presents an approach that can be applied automatically to infer a model of the behaviour of Erlang modules with respect to their presented interface. It integrates the automated learning system StateChum with the automated refactoring tool Wrangler to allow both interface discovery and behaviour inference to proceed without human involvement."
A Fast Algorithm Finding the Shortest Reset Words,Computing and Combinatorics,,,,10.1007/978-3-642-38768-5_18,Andrzej KisielewiczJakub KowalskiMarek Szykuła,2013,http://link.springer.com/chapter/10.1007/978-3-642-38768-5_18,Chapter,"Černý conjecture, Synchronizing automaton, synchronizing word",10,"In this paper we present a new fast algorithm for finding minimal reset words for finite synchronizing automata, which is a problem appearing in many practical applications. The problem is known to be computationally hard, so our algorithm is exponential in the worst case, but it is faster than the algorithms used so far and it performs well on average. The main idea is to use a bidirectional BFS and radix (Patricia) tries to store and compare subsets. Also a number of heuristics are applied. We give both theoretical and practical arguments showing that the effective branching factor is considerably reduced. As a practical test we perform an experimental study of the length of the shortest reset word for random automata with n  ≤ 300 states and 2 input letters. In particular, we obtain a new estimation of the expected length of the shortest reset word $\approx 2.5\sqrt{n-5}$ ."
Fast-Forward Runtime Monitoring — An Industrial Case Study,Runtime Verification,,,,10.1007/978-3-642-35632-2_22,Christian ColomboGordon J. Pace,2013,http://link.springer.com/chapter/10.1007/978-3-642-35632-2_22,Chapter,"Label Transition System, Monitor State, System Trace, Transition System, Translation Function",10,"Amongst the challenges of statefully monitoring large-scale industrial systems is the ability to efficiently advance the monitors to the current state of the system. This problem presents itself under various guises such as when a monitoring system is being deployed for the first time, when monitors are changed and redeployed, and when asynchronous monitors fall too much behind the system. We propose fast-forward monitoring — a means of reaching the monitoring state at a particular point in time in an efficient manner, without actually traversing all the transitions leading to that state, and which we applied to a financial transaction system with millions of transactions already affected. In this paper we discuss our experience and present a generic theory of monitor fast-forwarding instantiating it for efficient monitor deployment in real-life systems."
Reducing Monitoring Overhead by Integrating Event- and Time-Triggered Techniques,Runtime Verification,,,,10.1007/978-3-642-40787-1_18,Chun Wah Wallace WuDeepak KumarBorzoo BonakdarpourSebastian Fischmeister,2013,http://link.springer.com/chapter/10.1007/978-3-642-40787-1_18,Chapter,"Basic Block, Execution Path, Linear Temporal Logic, Monitoring Mode, Symbolic Execution",10,"Runtime verification is a formal technique used to check whether a program under inspection satisfies its specification by using a runtime monitor. Existing monitoring approaches use one of two ways for evaluating a set of logical properties: (1) event-triggered , where the program invokes the monitor when the state of the program changes, and (2) time-triggered , where the monitor periodically preempts the program and reads its state. Realizing the former is straightforward, but the runtime behaviour of event-triggered monitors are difficult to predict. Time-triggered monitoring (designed for real-time embedded systems), on the other hand, provides predictable monitoring behavior and overhead bounds at run time. Our previous work shows that time-triggered monitoring can potentially reduce the runtime overhead provided that the monitor samples the program state at a low frequency. In this paper, we propose a hybrid method that leverages the benefits of both event- and time-triggered methods to reduce the overall monitoring overhead. We formulate an optimization problem, whose solution is a set of instrumentation instructions that switches between event-triggered and time-triggered modes of monitoring at run time; the solution may indicate the use of exactly one mode or a combination of the two modes. We fully implemented this method to produce instrumentation schemes for C programs that run on an ARM Cortex-M3 processor, and experimental results validate the effectiveness of this approach."
A Metric for Testing Program Verification Systems,Tests and Proofs,,,,10.1007/978-3-642-38916-0_4,Bernhard BeckertThorsten BormerMarkus Wagner,2013,http://link.springer.com/chapter/10.1007/978-3-642-38916-0_4,Chapter,"Code Coverage, Coverage Criterion, Java Modeling Language, Proof Search, Test Suite",10,"The correctness of program verification systems is of great importance, and it needs to be checked and demonstrated to users and certification agencies. One of the contributing factors to the correctness of the whole verification system is the correctness of the background axiomatization, respectively the correctness of calculus rules. In this paper, we examine how testing verification systems is able to provide evidence for the correctness of the rule base or the axiomatization. For this, we present a new coverage criterion called axiomatization coverage, which allows us to judge the quality of existing test suites for verification systems. We evaluate this coverage criterion at two verification tools using the test suites provided by each tool."
Constraint Specification and Test Generation for OSEK/VDX-Based Operating Systems,Software Engineering and Formal Methods,,,,10.1007/978-3-642-40561-7_21,Yunja Choi,2013,http://link.springer.com/chapter/10.1007/978-3-642-40561-7_21,Chapter,"Constraint Type, Model Check, Regular Language, Task Model, Test Sequence",10,"This work suggests a method for systematically constructing an environment model for automotive operating systems compliant with the OSEK/VDX international standard by introducing a constraint specification language, OSEK_CSL, and defining its underlying formal models. OSEK_CSL is designed for specifying constraints of OSEK/VDX using a pre-defined set of constraint types identified from the OSEK/VDX standard. Each constraint specified in OSEK_CSL is interpreted as a context-free language and is converted into push-down automata using NuSMV, which allows automated test sequence generation using LTL model checking. This approach supports selective applications of constraints and thus is able to control the “degree” of test sequences with respect to test purposes. An application of the suggested approach demonstrates its effectiveness in identifying safety problems."
A Fault Injection Based Approach to Assessment of Quality of Test Sets for BPEL Processes,Evaluation of Novel Approaches to Software Engineering,,,,10.1007/978-3-642-54092-9_6,Damian GrelaKrzysztof SapiechaJoanna Strug,2013,http://link.springer.com/chapter/10.1007/978-3-642-54092-9_6,Chapter,"BPEL, Business Processes, Fault Injection, Mutation Testing, Orchestration, Test Sets Quality Assessment, Web-Services",10,"Mutation testing is an effective technique for assessing a quality of test sets for software systems, but it suffers from high computational costs of generating and executing a large number of mutants. In the domain of BPEL processes each mutant needs to be deployed before it can be executed, thus the cost of processing mutants increases further. In contrast to mutation testing, fault injection is able to inject faults directly into the original process what reduces the redeployment requirement. The paper presents an experiment of the application of software fault injection to assess quality of test sets for BPEL processes. Faults are introduced by a Software Fault Injector for BPEL Processes (SFIBP). SFIBP simulates effects of the faults by modifying invocations of web-services and their internal variables. The experiment proved high superiority of the application of the SFIBP over the mutation testing, especially in the case of time requirements."
