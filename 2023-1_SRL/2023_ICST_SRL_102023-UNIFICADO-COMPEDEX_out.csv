database,type,year,itle,authors,keywords,pages,abstract
ACM,Conference Paper,2018,A Study on the Impact of Model Evolution in MBT Suites,"Silva AG,Andrade WL,Alves EL","Model-Based Testing, Use Case Evolution, Test Suite Maintenance",8,"Software testing is known to be a key-factor for the success of a software development project. In this context, Model-Based Testing (MBT) plays an important role by providing an automated way for generating test cases from system models. However, although MBT can be helpful for creating sound test cases, its use can be very sensitive to model changes. Model edits often lead to a great number of obsolete test cases, as the software and its models evolve. This fact is even more evident in agile projects where requirement artifacts are very volatile. This paper presents an empirical study designed for investigating how model edits can impact MBT test suites. For that, we run a case study in the context of two industrial projects that apply agile methodologies combined with the use of MBT. We observed the evolution of specification models and their impact on generated MBT suites. Our results showed that 86% of the generated test cases were discarded due to model edits and their impact. However, a deeper analysis found that 52% of these tests were impacted only by syntactic model edits, which indicate they could be reused with little revision efforts."
ACM,Conference Paper,2019,Reducing the Discard of MBT Test Cases using Distance Functions,"Diniz T,Alves EL,Silva AG,Andrade WL","test suite evolution, MBT, agile development, distance functions",10,"Model-Based Testing (MBT) is used for generating test suites from system models. However, as software evolves, its models tend to be updated, which often leads to obsolete test cases that are discarded. Test case discard can be very costly since essential data, such as execution history, are lost. In this paper, we investigate the use of distance functions to help to reduce the discard of MBT tests. For that, we ran a series of empirical studies using artifacts from industrial systems, and we analyzed how ten distance functions can classify the impact of MBT-centred use case edits. Our results showed that distance functions are effective for identifying low impact edits that lead to test cases that can be updated with little effort. Moreover, we found the optimal configuration for each distance function. Finally, we ran a case study that showed that, by using distance functions, we could reduce the discard of test cases by 15%."
ACM,Conference Paper,2023,Designing a Test Model for a Configurable System: An Exploratory Study of Preprocessor Directives and Feature Toggles,"Fischer S,Michelon GK,Assunção WK,Ramler R,Egyed A","variability mechanism, test case generation, software testing, software product lines",9,"Testing is important in software development, but it has high cost. Thus, techniques to reduce the cost of software testing have been proposed. Model-based testing, one of such techniques, focuses on automatizing the generation of test cases. In the context of highly configurable systems, model-based testing must capture the system behavior and also encode the variability that exists among the variants. Previous research has shown promising results in applying model-based testing to configurable systems. Test models that encode variability into them directly improve the reasoning for faults from interactions. However, there is no study about the use of different variability mechanisms to encode variability in test models. In this paper, we investigate advantages and drawbacks of test model designs exploring the use of two variability mechanisms, namely preprocessor directives and feature toggles. The results are discussed in regard to run-time reasoning and re-configuration, alongside with metrics about complexity and maintainability. With this work, we contribute to the testing activity of highly configurable systems by providing engineers insights of comparing two well-known and widely used variability mechanisms, which can support informed decisions when choosing for which mechanisms to use for model-based testing."
ACM,Conference Paper,2021,Lightweight MBT testing for national e-health portal in Norway,"Gafurov D,Grovan MS,Hurum AE","helsenorge, GDPR testing, model based testing",5,"We present lightweight model-based testing (MBT) of privacy and authorization concepts of national portal for electronic health services in Norway (which has over a million of visits per month). We have developed test models for creating and updating privacy levels and authorization categories using finite state machine. Our models emphasize not only positive but also negative behavioral aspects of the system. Using edge and edge-pair coverage as an acceptance criteria we identify and systematically derive abstract tests (high level user scenario) from models. Abstract tests are further refined and transformed into concrete tests with detailed steps and data. Although derivation of abstract tests and their transformation into concrete ones are manual, execution of concrete tests and generation of test report are automated. In total, we extracted 85 abstract test cases which resulted in 80 concrete test cases with over 550 iterations. Automated execution of all tests takes about 1 hour, while manual execution of one takes about 5 minutes (over 40 times speedup). MBT contributed to shift the focus of our intellectual work effort into model design rather than test case design, thus making derivation of test scenarios systematic and straight forward. In addition, applying MBT augmented and extended our traditional quality assurance techniques by facilitating better comprehension of new privacy and authorization concepts. Graphical models served as a useful aid in learning these concepts for newcomers."
ACM,Conference Paper,2014,Improving code coverage in android apps testing by exploiting patterns and automatic test case generation,"Amalfitano D,Amatucci N,Fasolino AR,Gentile U,Mele G,Nardone R,Vittorini V,Marrone S","gui testing, mobile applications, model driven engineering, reverse engineering, automatic test case generation",6,"This work aims at defining a procedure and a set of mechanisms able to improve the quality of the code coverage in automated software reverse engineering processes, and specifically in automated GUI-driven testing of Android apps. Existing automated model-based testing techniques, based on reverse engineering, generate test cases which can be executed directly on the software's GUI. We propose to augment the code coverage of these techniques, by exploiting information from patterns, defined at different levels (application design, state-based model, interaction with Android services), and generating additional test cases that may increase the coverage capability of GUI-Ripping based testing technique. The generation of the additional test cases is accomplished by defining an automatable procedure which exploits an existing GUI testing approach and a pattern based approach used in a different context."
ACM,Conference Paper,2017,Guided test case generation for mobile apps in the TRIANGLE project: work in progress,"Panizo L,Salmerón A,Gallardo MM,Merino P","Spin, Model-based testing, test case generation",4,"The evolution of mobile networks and the increasing number of scenarios for mobile applications requires new approaches to ensure their quality and performance. The TRIANGLE project aims to develop an integrated testing framework that allows the evaluation of applications and devices in different network scenarios. This paper focuses on the generation of user interactions that will be part of the test cases for applications. We propose a method that combines model-based testing and guided search, based on the Key Performance Indicators to be measured, and we have evaluated our proposal with an example. Our ultimate goal is to integrate the guided generation of user flows into the TRIANGLE testing framework to automatically generate and execute test cases."
ACM,Conference Paper,2019,Learning from Difference: An Automated Approach for Learning Family Models from Software Product Lines,"Damasceno CD,Mousavi MR,Simao A","software product lines, family model, model learning, 150% model",12,"Substantial effort has been spent on extending specification notations and their associated reasoning techniques to software product lines (SPLs). Family-based analysis techniques operate on a single artifact, referred to as a family model, that is annotated with variability constraints. This modeling approach paves the way for efficient model-based testing and model checking for SPLs. Albeit reasonably efficient, the creation and maintenance of family models tend to be time consuming and error-prone, especially if there are crosscutting features. To tackle this issue, we introduce FFSMDiff, a fully automated technique to learn featured finite state machines (FFSM), a family-based formalism that unifies Mealy Machines from SPLs into a single representation. Our technique incorporates variability to compare and merge Mealy machines and annotate states and transitions with feature constraints. We evaluate our technique using 34 products derived from three different SPLs. Our results support the hypothesis that families of Mealy machines can be effectively merged into succinct FFSMs with fewer states, especially if there is high feature sharing among products. These indicate that FFSMDiff is an efficient family-based model learning technique."
ACM,Conference Paper,2013,XSS pattern for attack modeling in testing,"Bozic J,Wotawa F","cross-site scripting, attack pattern model, model-based testing, security testing",4,"Security issues of web applications are still a current topic of interest especially when considering the consequences of unintended behaviour. Such services might handle sensitive data about several thousands or millions of users. Hence, exploiting services or other undesired effects that cause harm on users has to be avoided. Therefore, for software developers of such applications one of the major tasks in providing security is to embed testing methodologies into the software development cycle, thus minimizing the subsequent damage resulting in debugging and time intensive upgrading. Model-based testing evolved as one of the methodologies which offer several theoretical and practical approaches in testing the system under test (SUT) that combine several input generation strategies like mutation testing, using of concrete and symbolic execution etc. by putting the emphasis on specification of the model of an application. In this work we propose an approach that makes use of an attack pattern model in form of a UML state machine for test case generation and execution. The paper also discusses the current implementation of our attack pattern testing tool using a XSS attack pattern and demonstrates the execution in a case study."
ACM,Conference Paper,2023,Variability-aware Behavioural Learning,Fortz S,"Variability Mining, Reverse Engineering, Featured Transition Systems, Active Automata Learning, Software Product Lines",5,"Addressing variability proactively during software engineering activities means shifting from reasoning on individual systems to reasoning on families of systems. Adopting appropriate variability management techniques can yield important economies of scale and quality improvements. Conversely, variability can also be a curse, especially for Quality Assurance (QA), i.e., verification and testing of such systems, due to the combinatorial explosion of the number of software variants. Featured Transition Systems (FTSs) were introduced as a way to represent and reason about the behaviour of Variaility-intensive Systems (VISs). By labelling a transition system with feature expressions, FTSs capture multiple variants of a system in a single model, enabling reasoning at the family level. They have shown significant improvements in automated QA activities such as model-checking and model-based testing, as well as guiding design exploration activities. Yet, as most model-based approaches, FTS modelling requires both strong human expertise and significant effort that would be unaffordable in many cases, in particular for large legacy systems with outdated specifications and/or systems that evolve continuously. Therefore, this PhD project aims to automatically learn FTSs from existing artefacts, to ease the burden of modelling FTS and support continuous QA activities. To answer this research challenge, we propose a two-phase approach. First, we rely on deep learning techniques to locate variability from execution traces. For this purpose, we implemented a tool called VaryMinions. Then, we use these annotated traces to learn an FTS. In this second part, we adapt the seminal L algorithm to learn behavioural variability. Both frameworks are open-source and we evaluated them separately on several datasets of different sizes and origins (e.g., software product lines and configurable business processes)."
ACM,Conference Paper,2014,"Software paradigms, assessment types and non-functional requirements in model-based integration testing: a systematic literature review","Häser F,Felderer M,Breu R","systematic literature review, non-functional requirements, model-based integration testing, assessment types",10,"Context: In modern systems, like cyber-physical systems, where software and physical services are interacting, safety, security or performance play an important role. In order to guarantee the correct interoperability of such systems, with respect to functional and non-functional requirements, integration testing is an effective measure to achieve this. Model-based testing moreover not only enables early definition and validation, but also test automation. This makes it a good choice to overcome urgent challenges of integration testing. Objective: Many publications on model-based integration testing (MBIT) approaches can be found. Nevertheless, a study giving a systematic overview on the underlying software paradigms, measures for guiding the integration testing process as well as non-functional requirements they are suitable for, is missing. The aim of this paper is to find and synthesize the relevant primary studies to gain a comprehensive understanding of the current state of model-based integration testing. Method: For synthesizing the relevant studies, we conducted a systematic literature review (SLR) according to the guidelines of Kitchenham. Results: The systematic search and selection retrieved 83 relevant studies from which data has been extracted. Our review identified three assessment criteria for guiding the testing process, namely static metrics, dynamic metrics and stochastic &random. In addition it shows that just a small fraction considers non-functional requirements. Most approaches are for component-oriented systems. Conclusion: Results from the SLR show that there are two major research gaps. First, there is an accumulated need for approaches in the MBIT field that support non-functional requirements, as they are gaining importance. Second, means for steering the integration testing process, especially together with automation, need to evolve."
COMPENDEX,Conference article (CA),2022,A Model-Based Testing System for Safety of Railway Interlocking,"Su, Haoxiang (1); Chai, Ming (1); Liu, Hongjie (1); Chai, Jinchuan (2); Yue, Chaopeng (3)",Acceptance tests - Efficiency - Model checking - Railroads - Safety devices - Safety testing - Software testing,6,"Testing is an important safety assurance technique for railway interlocking systems. Model-based testing (MBT) allows for designing and maintaining tests with high-level models and generating test suites from these models automatically. Although MBT has the potential to improve testing efficiency and quality, it is not clear whether this technique is applicable for testing complex variant-rich interlocking software. In this paper, we report our experience in introducing MBT in inter-locking testing. We develop feature models of the interlocking route control process to improve the reusability of the models. The experimental results show that our approach is able to improve the quality and efficiency of real-world interlocking acceptance testing. © 2022 IEEE."
COMPENDEX,Conference article (CA),2022,An Approach for Model Based Testing of Augmented Reality Applications,"Tramontana, Porfirio (1); De Luca, Marco (1); Fasolino, Anna Rita (1)",Augmented reality - Computer aided software engineering - Graphical user interfaces - Software testing,,"The popularity of Augmented Reality (AR) applications has strongly been increased with the worldwide success of the Pokemon Go videogame released by Niantic in 2016. However, AR offers tangible benefits in many further areas beyond entertainment, such as advertisement, education, navigation, maintenance, health, and so on. With the growing spread and success of AR applications in these fields, there has also been a growing necessity for approaches and technologies for assuring the quality of these applications, such as testing. A few technologies and frameworks have been recently proposed supporting the implementation and execution of test scripts that can be used to exercise the applications, but there still is a lack of effective techniques and tools for the automatic generation of executable test cases. In this paper, we investigate the possibility of using Model Based Testing techniques to generate executable test scripts from Finite State Machines modeling the behaviour of the GUI of AR applications, similarly to other GUI based applications. We have applied several model coverage criteria to design test suites and we have shown the feasibility of this approach by testing two small example applications involving Unity3D and Vuforia technologies. © 2021 The Authors."
COMPENDEX,Journal article (JA),2022,Model-based testing leveraged for automated web tests,"Mattiello, Guilherme Ricken (1); Endo, André Takeshi (1)",Open source software - Software testing - Automation - Graphical user interfaces - Testing,29,"Agile methods and their practices have fostered the widespread presence of automated test cases. Such test cases have been successfully and extensively adopted to test different software levels, from unit tests (e.g., JUnit) to end-to-end Web Graphical User Interface (GUI) tests (e.g., Selenium Webdriver). While test execution is mostly automated by existing tools, test design remains a manual task. In the pursuit of a more automated test case generation approach, the use of models has been advocated by the model-based testing (MBT) technique. Current MBT approaches assume a top-down workflow in which testers design models, test cases are generated from models, and then scripts are written to automate test execution. Nevertheless, writing automated tests is nowadays a developer’s responsibility and testers face a scenario in which automated tests might be reused to produce new model-based tests. This paper aimed to improve the synergy between existing automated tests and MBT. To do so, we present an approach that infers a model from existing tests, a tester leverages this model to include new tests, and then test code is generated. We analyzed the proposed approach in the context of Web applications with system-level GUI tests that employ the Page Object pattern. For MBT, we adopted event-driven models augmented with parameters and test input data. We evaluated the approach’s applicability with a prototype tool called MoLeWe and an experimental study with nine open-source Web applications. The results provide some evidence that using MoLeWe may help to include new tests faster than manually coding them, while increasing the overall code coverage of the test suite. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature."
COMPENDEX,Conference article (CA),2020,TesCaV: An Approach for Learning Model-Based Testing and Coverage in Practice,"Marín, Beatriz (1); Alarcón, Sofía (1); Giachetti, Giovanni (2); Snoeck, Monique (3)",Model checking - Software testing - Well testing - Computer software selection and evaluation - Learning systems,16,"Academy and industry permanently remark the importance of software-testing techniques to improve software quality and to reduce development and maintenance costs. A testing method to be considered for this purpose is Model-Based Testing (MBT), which generates test cases from a model that represents the structure and the behavior of the system to be developed. The generated test suite is easier to maintain and adapt to changes in requirements or evolution of the developed system. However, teaching and learning MBT techniques are not easy tasks; students need to know the different testing techniques to assure that the requirements are fulfilled as well as to identify any failure in the software system modeled. In this work, we present TesCaV, an MBT teaching tool for university students, which is based on a model-driven technology for the automatic software generation from UML diagrams. TesCaV allows validating the test cases defined by students and graphically determines the level of testing coverage over the system modeled. Preliminary results show TesCaV as a promising approach for MBT teaching/learning processes. © 2020, Springer Nature Switzerland AG."
COMPENDEX,Conference article (CA),2021,Model-Based Testing of Smart Home Systems Using EFSM and CEFSM,"Albahli, Afnan (1); Andrews, Anneliese (1)",Automation - Black-box testing - Computer software selection and evaluation - Intelligent buildings - Model checking - Software reliability,6,The Internet of Things (IoT) is the future of communication. The number of devices connected to the Internet has been growing dramatically and is expected to continue to grow. This increase causes a huge challenge for software quality. New testing approaches need to be developed and investigated to assure quality and efficiency of such systems. The main challenge with IoT devices is that their functionality varies greatly depending on the device type and how it is connected. In order to maintain feasibility of these functionality systems need to be modeled. This paper proposes a testing approach for a smart home system (SHS) modeled by Extended Finite State Machines (EFSMs) and Communicating Extended Finite State Machines (CEFSMs). We generate tests for individual devices in the SHS as well as the interaction between devices. © 2021 IEEE.
COMPENDEX,Conference article (CA),2020,Lightweight MBT Testing for National e-Health Portal in Norway,"Gafurov, Davrondzhon (1); Grovan, Margrete Sunde (1); Hurum, Arne Erik (1)",Model checking - Quality assurance - Concretes,5,"We present lightweight model-based testing (MBT) of privacy and authorization concepts of national portal for electronic health services in Norway (which has over a million of visits per month). We have developed test models for creating and updating privacy levels and authorization categories using finite state machine. Our models emphasize not only positive but also negative behavioral aspects of the system. Using edge and edge-pair coverage as an acceptance criteria we identify and systematically derive abstract tests (high level user scenario) from models. Abstract tests are further refined and transformed into concrete tests with detailed steps and data. Although derivation of abstract tests and their transformation into concrete ones are manual, execution of concrete tests and generation of test report are automated. In total, we extracted 85 abstract test cases which resulted in 80 concrete test cases with over 550 iterations. Automated execution of all tests takes about 1 hour, while manual execution of one takes about 5 minutes (over 40 times speedup). MBT contributed to shift the focus of our intellectual work effort into model design rather than test case design, thus making derivation of test scenarios systematic and straight forward. In addition, applying MBT augmented and extended our traditional quality assurance techniques by facilitating better comprehension of new privacy and authorization concepts. Graphical models served as a useful aid in learning these concepts for newcomers. © 2020 ACM."
COMPENDEX,Conference article (CA),2020,Model-Based Testing of Read only Graph Queries,"Lambers, Leen (1); Schneider, Sven (1); Weisgut, Marcel (1)",Application programs - Model checking - Query languages - Software testing - Computer circuits,11,"Modern software applications often interface with graph-structured data managed by graph databases queried with specific graph query languages. Writing, understanding, and maintaining graph queries can be difficult and error-prone. Important decisions taken by the software application are in many cases based on the outcome of these graph queries. If test design does not account for the complexity incorporated in these queries, considerable parts of the business logic of such applications will not be tested appropriately.We aim at tackling the challenge of developing dedicated testing techniques for graph queries. In particular, we present a first model-based testing approach for read only queries supporting automated test creation, execution, and evaluation. We model queries using a well-established graph logic, being expressively equivalent to first-order logic on graphs. We develop a first coverage criterion requiring the presence of a test case returning an empty query result as well as the presence of a test case returning a non-empty result. We present the architecture of our model-based testing approach, which is supported by a first implementation. We illustrate our approach with complex read only graph queries from an industrial benchmark case study. © 2020 IEEE."
COMPENDEX,Journal article (JA),2022,Effect of MBT on landfill behavior: an Italian case study,"Amato, Alessia (1); Magi Galluzzi, Lorenzo (2); Beolchini, Francesca (1)",Ammonia - Biochemical engineering - Energy utilization - Leachate treatment - Stabilization,13,"Bad choices in municipal waste (MW) management cause negative effects on sustainability. Evolving regulation has identified prevention and recycling as the best strategies; nevertheless, disposal in landfilling sites plays an essential role since a complete zero-waste scenario is not realistic, currently. Nowadays, policies require a preliminary waste stabilization to decrease the putrescible content. Therefore, mechanical biological treatment (MBT) has replaced the previous crushing, aimed at simple volume reduction. Literature has proved the effectiveness of MBT when MW collection system is ineffective. The present paper considered a facility in an area with a high-performance MW collection system. A long-term (1999–2019) on-site sampling allowed the comparison between two sites of the facility: the old site (before the MBT activation) and the new area, where the stabilized waste is disposed of. Monitoring of biogas, leachate (analyzed parameters: pH, BOD5, COD, ammonia-nitrogen) and odorous emissions was performed to verify the effect of the stabilization process. The considered long period and the on-site sampling support the relevance of the results, compared to the available literature, often referred to as laboratory scale. The results proved the relatively low benefit of stabilization at the considered facility, which cannot justify the energy consumption of MBT. © 2022, The Author(s)."
COMPENDEX,Conference article (CA),2019,Reducing the discard of MBT test cases using distance functions,"Diniz, Thomaz (1); Silva, Anderson G.F. (1); Alves, Everton L.G. (1); Andrade, Wilkerson L. (1)",Software testing - Testing,10,"Model-Based Testing (MBT) is used for generating test suites from system models. However, as software evolves, its models tend to be updated, which often leads to obsolete test cases that are discarded. Test case discard can be very costly since essential data, such as execution history, are lost. In this paper, we investigate the use of distance functions to help to reduce the discard of MBT tests. For that, we ran a series of empirical studies using artifacts from industrial systems, and we analyzed how ten distance functions can classify the impact of MBT-centred use case edits. Our results showed that distance functions are effective for identifying low impact edits that lead to test cases that can be updated with little effort. Moreover, we found the optimal configuration for each distance function. Finally, we ran a case study that showed that, by using distance functions, we could reduce the discard of test cases by 15%. © 2019 Association for Computing Machinery."
COMPENDEX,Conference article (CA),2018,Model based testing of cyber-physical systems,"Khoo, Teck Ping (1)",Model checking - Interoperability - Embedded systems - Specifications,4,"Testing, inspection, and certification (TIC) are essential activities on consumer and industrial systems. The conformance to system specifications and standards can then provide assurances on system safety, security, reliability, and interoperability. TIC needs to evolve in tandem with growing system size and complexity. Common modern systems such as autonomous vehicles and smart health-care systems take the form of Cyber Physical Systems (CPSs). Model Based Testing (MBT) is one promising approach to test CPSs. An MBT framework for testing CPSs will be useful to systems testers and can raise the standard of systems testing as a whole. © Springer Nature Switzerland AG 2018."
COMPENDEX,Conference article (CA),2018,A study on the impact of model evolution in MBT suites,"Silva, Anderson G.F. (1); Andrade, Wilkerson L. (1); Alves, Everton L.G. (1)",Agile manufacturing systems - Model checking - Software design,8,"Software testing is known to be a key-factor for the success of a software development project. In this context, Model-Based Testing (MBT) plays an important role by providing an automated way for generating test cases from system models. However, although MBT can be helpful for creating sound test cases, its use can be very sensitive to model changes. Model edits often lead to a great number of obsolete test cases, as the software and its models evolve. This fact is even more evident in agile projects where requirement artifacts are very volatile. This paper presents an empirical study designed for investigating how model edits can impact MBT test suites. For that, we run a case study in the context of two industrial projects that apply agile methodologies combined with the use of MBT. We observed the evolution of specification models and their impact on generated MBT suites. Our results showed that 86% of the generated test cases were discarded due to model edits and their impact. However, a deeper analysis found that 52% of these tests were impacted only by syntactic model edits, which indicate they could be reused with little revision efforts. © 2018 Association for Computing Machinery."
COMPENDEX,Conference article (CA),2019,From requirements to automated acceptance tests of interactive apps: An integrated model-based testing approach,"Maciel, Daniel (1); Paiva, Ana C.R. (1); Da Silva, Alberto Rodrigues (2)",Software design - Specifications - Specification languages - Automation - Software testing - Model checking,8,"Frequently software testing tends to be neglected at the beginning of the projects, only performed on the late stage. However, it is possible to benefit from combining requirement with testing specification activities. On one hand, acceptance tests specification will require less manual effort since they are defined or generated automatically from the requirements specification. On the other hand, the requirements specification itself will end up having higher quality due to the use of a more structured language, reducing typical problems such as ambiguity, inconsistency and incorrectness. This research proposes an approach that promotes the practice of tests specification since the very beginning of projects, and its integration with the requirements specification itself. It is a model-driven approach that contributes to maintain the requirements and tests alignment, namely between requirements, test cases, and low-level automated test scripts. To show the applicability of the approach, two complementary languages are adopted: the ITLingo RSL that is particularly designed to support both requirements and tests specification; and the Robot language, which is a low-level keyword-based language for the specification of test scripts. The approach includes model-to-model transformation techniques, such as test cases into test scripts transformations. In addition, these test scripts are executed by the Robot test automation framework. Copyright © 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved"
COMPENDEX,Conference article (CA),2018,Scrum and V lifecycle combined with model-based testing and model driven architecture to deal with evolutionary system issues,"Essebaa, Imane (1); Chantit, Salima (1)",Software testing - Architecture - Life cycle - Model checking - Software architecture - Agile manufacturing systems,15,"Model Driven Engineering (MDE) and Agile Methods (AM) are two principal domains that are in the way of improvement and evolution in order to facilitate the realisation of IT projects. However, these areas evolve separately despite the great number of researches that focus on improving realisation project’ techniques. Thus, our approach aims to provide an approach that combines two variants of MDE, Model Driven Architecture approach and Model-Based Testing with the V development lifecycle used in every scrum Agile Methodology sprint to deal with system evolution. In order to well illustrate this approach, we apply it on Rental Car Agency System realisation using Scrum methodology with some requirements’ evolution. © Springer Nature Switzerland AG 2018."
COMPENDEX,Journal article (JA),2018,Increasing test efficiency by risk-driven model-based testing,"Sahin Gebizli, Ceren (1); Kirkici, Abdulhadi (1); Sözer, Hasan (2)",Model checking - Testing - Smartphones - Software testing - Markov processes,10,"We introduce an approach and a tool, RIMA, for adapting test models used for model-based testing to augment information regarding failure risk. We represent test models in the form of Markov chains. These models comprise a set of states and a set of state transitions that are annotated with probability values. These values steer the test case generation process, which aims at covering the most probable paths. RIMA refines these models in 3 steps. First, it updates transition probabilities based on a collected usage profile. Second, it updates the resulting models based on fault likelihood at each state, which is estimated based on static code analysis. Third, it performs updates based on error likelihood at each state, which is estimated with dynamic analysis. The approach is evaluated with two industrial case studies for testing digital TVs and smart phones. Results show that the approach increases test efficiency by revealing more faults in less testing time. © 2018"
COMPENDEX,Conference article (CA),2020,Supporting efficient test automation using lightweight MBT,"Bernard, Elodie (1); Ambert, Fabrice (1); Legeard, Bruno (1)",Testing - Software design - Model checking - Software testing,11,"The Agile and DevOps transformation of software development practices enhances the need for increased automation of functional testing, especially for regression testing. This poses challenges both in the effort that needs to be devoted to the creation and maintenance of automated test scripts, and in their relevance (i.e. their alignment with business needs). Test automation is still difficult to implement and maintain and the return on investment comes late while projects tend to be short. In this context, we have experimented a lightweight model-based test automation approach to address both productivity and relevance challenges. It integrates test automation through a simple process and tool-chain experimented on large IT projects. © 2020 IEEE."
COMPENDEX,Conference article (CA),2018,SATE: Model-Based Testing with Design-to-Test and Plant Features,"Ma, Canlong (1); Jordan, Claudius (1); Provost, Julien (1)",Programmable logic controllers - Computer circuits - Controllers - Model checking - Programmed control systems,6,"In this paper we present SATE, a tool aiming at increasing test efficiency of model-based testing of DES using two approaches: design-to-test and plant features. First, the design-to-test approach automatically modifies the design while maintaining the original system behavior to overcome controllability, observability and SIC-testability issues. Secondly, testing with plant features reduces the number of test cases taking into account restrictions on the input space of programmable logic controllers caused by the plant that is to be controlled. © 2018"
COMPENDEX,Conference article (CA),2016,Model-based testing of mobile systems - An empirical study on QuizUp Android app,"Gudmundsson, Vignir (1); Lindvall, Mikael (2); Aceto, Luca (1); Bergthorsson, Johann (3); Ganesan, Dharmalingam (2)",Android (operating system) - Software testing,15,"We present an empirical study in which model-based testing (MBT) was applied to a mobile system: the Android client of QuizUp, the largest mobile trivia game in the world. The study shows that traditional MBT approaches based on extended finite-state machines can be used to test a mobile app in an effective and efficient way. Non-trivial defects were detected on a deployed system that has millions of users and was already well tested. The duration of the overall testing effort was of three months, including the construction of the models. Maintaining a single behavioral model for the app was key in order to test it in an efficient way. © Gudmundsson et al."
COMPENDEX,Conference article (CA),2016,Matts - A step towards model based testing,"Herpel, H.-J. (1); Willich, G. (1); Li, J. (1); Xie, J. (1); Johansen, B. (1); Kvinnesland, K. (2); Krueger, S. (1); Barrios, P. (3)",Model checking - Application programs - Concretes - Software testing - Testing,,"In this paper we describe a Model Based approach to testing of on-board software and compare it with traditional validation strategy currently applied to satellite software. The major problems that software engineering will face over at least the next two decades are increasing application complexity driven by the need for autonomy and serious application robustness. In other words, how do we actually get to declare success when trying to build applications one or two orders of magnitude more complex than today's applications. To solve the problems addressed above the software engineering process has to be improved at least for two aspects: 1) Software design and 2) Software testing. The software design process has to evolve towards model-based approaches with extensive use of code generators. Today, testing is an essential, but time and resource consuming activity in the software development process. Generating a short, but effective test suite usually requires a lot of manual work and expert knowledge. In a modelbased process, among other subtasks, test construction and test execution can also be partially automated. The basic idea behind the presented study was to start from a formal model (e.g. State Machines), generate abstract test cases which are then converted to concrete executable test cases (input and expected output pairs). The generated concrete test cases were applied to an on-board software. Results were collected and evaluated wrt. applicability, cost-efficiency, effectiveness at fault finding, and scalability."
COMPENDEX,Conference article (CA),2016,Model based testing of satellite on-board software - An industrial use case,"Herpel, H.J. (1); Kerep, M. (1); Li, J. (2); Xie, J. (2); Johansen, B. (2); Kvinnesland, K. (2); Krueger, S. (3); Barrios, P. (3)",Software testing - Concretes - Model checking - Application programs - Software design,,"In this paper we describe a Model Based approach to testing of on-board software and compare it with traditional validation strategy currently applied to satellite software. The major problems that software engineering will face over at least the next two decades are increasing application complexity driven by the need for autonomy and serious application robustness. In other words, how do we actually get to declare success when trying to build applications one or two orders of magnitude more complex than today's applications. To solve the problems addressed above the software engineering process has to be improved at least for two aspects: 1) Software design and 2) Software testing. The software design process has to evolve towards model-based approaches with extensive use of code generators. Today, testing is an essential, but time and resource consuming activity in the software development process. Generating a short, but effective test suite usually requires a lot of manual work and expert knowledge. In a model-based process, among other subtasks, test construction and test execution can also be partially automated. The basic idea behind the presented study was to start from a formal model (e.g. State Machines), generate abstract test cases which are then converted to concrete executable test cases (input and expected output pairs). The generated concrete test cases were applied to an on-board software. Results were collected and evaluated wrt. applicability, cost-efficiency, effectiveness at fault finding, and scalability. © 2016 IEEE."
COMPENDEX,Journal article (JA),2017,Quasi dimensional numerical investigation of syngas fuelled engine operation: MBT operation and parametric sensitivity analysis,"Shivapuji, Anand M. (1); Dasappa, S. (1)",Combustion - Engine cylinders - Alternative fuels - Sensitivity analysis - Quality control - Synthesis gas,18,"The formulation, validation and application of a thermodynamic quasi dimensional SI engine simulation model for syngas fuelled operation is reported. The QD approach establishes the dependence of turbulent combustion on mixture thermo-physical properties and fluid domain average turbulent parameters, eliminating the need for domain discretization (unlike in multi-dimensional models). Turbulent combustion is formulated along the Eddy Entrainment Laminar Burn-up concept (Williams-Klimov criterion) with non-linear dependence of mixture burn rate on local laminar flame speed and turbulent intensity. Simulations are reported for syngas fuelled operation of a six cylinder engine and compared with experimental pressure and heat release traces. Maximum brake torque stoichiometric operation pressure and heat release simulation traces evolve closely with corresponding experimental traces. The simulation peak pressure and IMEP deviations remain within 5% and 2% of experimental traces respectively while the position of peak pressure overlaps within ±0.5 deg. Parametric sensitivity analysis for load, mixture quality and ignition timing are also addressed. Overall, the simulation results are in accordance within 5% of experimental results as long as the parametric variations are within the regimes of tuning of empirical correlations. In general, the versatility and robustness of quasi dimensional approach to simulate non-regular bio-derived alternative fuels is established. © 2017 Elsevier Ltd"
COMPENDEX,Journal article (JA),2014,Supporting the Combined Selection of Model-Based Testing Techniques,"Dias-Neto, Arilo Claudio (1); Travassos, Guilherme Horta (2)",Application programs - Model checking - Testing - Recommender systems,17,"The technical literature on model-based testing (MBT) offers us several techniques with different characteristics and goals. Contemporary software projects usually need to make use of different software testing techniques. However, a lack of empirical information regarding their scalability and effectiveness is observed. It makes their application difficult in real projects, increasing the technical difficulties to combine two or more MBT techniques for the same software project. In addition, current software testing selection approaches offer limited support for the combined selection of techniques. Therefore, this paper describes the conception and evaluation of an approach aimed at supporting the combined selection of MBT techniques for software projects. It consists of an evidence-based body of knowledge with 219 MBT techniques and their corresponding characteristics and a selection process that provides indicators on the level of adequacy (impact indicator) amongst MBT techniques and software projects characteristics. Results from the data analysis indicate it contributes to improve the effectiveness and efficiency of the selection process when compared to another selection approach available in the technical literature. Aiming at facilitating its use, a computerized infrastructure, evaluated into an industrial context and evolved to implement all the facilities needed to support such selection approach, is presented. © 2014 IEEE."
COMPENDEX,Conference article (CA),2014,Model-based testing of web service with EFSM,"Sun, Fuzhen (1, 2); Liao, Lejian (1); Zhang, Longbo (2)",Software testing - WSDL - Fault detection - Model checking - Websites,10,"Web services are becoming more and more widespread as an emerging technology; it is hard to test Web services because they are distributed applications with numerous aspects of runtime behavior that are different from typical applications. This paper presents a new approach to testing Web services based on Extended Finite State Machine (EFSM). Web Services Description Language (WSDL) file alone does not provide dynamic behavior information. This problem can be overcome by appending the formal model of EFSM to standard WSDL, we can generate a set of test cases which has a better test coverage than other methods. Moreover, a procedure for deriving an EFSM model from WSDL specification is provided to help a service provider augment, the EFSM model describing dynamic behaviors of the Web service. To show the efficacy of our approach, we applied our approach to Parlay-X Web services. In this way, we can test Web services with greater confidence in potential fault detection. © Springer-Verlag Berlin Heidelberg 2014."
COMPENDEX,Conference article (CA),2013,Distributed online test generation for model-based testing,"Kanstrén, Teemu (1, 2); Kekkonen, Tuomas (1)",Software testing - Model checking,8,"In online model-based testing, test execution is interleaved with test generation. Test cases should be generated and executed with minimal delay, while still achieving targeted coverage criteria quickly. Extensive model analysis in such case is not possible as any delays in choosing the next step will immediately impact the response times of test execution. The algorithms thus need to be as fast as possible, where a limiting factor is the available computing power. Experts working on the test models used for the generation often need to be able to quickly edit the models, generate test cases, and use the feedback to further evolve the models. Reserving large-scale computing resources while editing the model is unnecessary, but performing the analysis on them for test generation can improve the execution response time significantly. In this paper, we present an approach and algorithm for distributing the online test generation analysis part concurrently over the network, while enabling the expert to work on the models and execute the test cases locally at the same time. © 2013 IEEE."
COMPENDEX,Conference article (CA),2023,Studying Synchronization Issues for Extended Automata,"Kushik, Natalia (1); Yevtushenko, Nina (2)",Model checking,8,"The paper presents a study of synchronization issues for one of non-classical state models, i.e., a state identification problem widely used in the area of Model based Testing (MBT) and run-time verification/monitoring. We consider Finite Automata (FA) augmented with the context variables and their related updates when the transitions are executed. For such Extended Automata (EA) we define the notions of merging and synchronizing sequences that serve as reset words in MBT, and show that under certain conditions and when every context variable is defined over a ring, it is possible for the extended automata of the studied class to 'repeat' the necessary and sufficient conditions established for the classical automata. Otherwise, in a general case, the problem can be reduced to deriving reset words for classical FA that represent corresponding EA slices. Copyright © 2023 by SCITEPRESS - Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)"
COMPENDEX,Conference article (CA),2023,From BDD Scenarios to Test Case Generation,"Zameni, Tannaz (1); Van Den Bos, Petra (1); Tretmans, Jan (2, 3); Foederer, Johan (4); Rensink, Arend (1)",Boolean functions - Software testing,9,"Model-based testing (MBT) offers the possibility of automatic generation and execution of tests. However, it is not yet widely used in industry due to the difficulty in creating and maintaining models. On the other hand, Behavior Driven Development (BDD) is becoming more popular in the agile development process to achieve a common understanding of the system under development among stakeholders and to automate testing. However, BDD scenarios are written in human language and are usually not precise enough. Moreover, tests extracted from BDD scenarios are too short and incomplete; they only cover a very small part of the system. Our goal is to combine these two approaches to benefit from the usability of BDD and the test automation capabilities of MBT. In this paper, we first define a formal model of scenarios that we call BDD Transition Systems, second, we create more complete tests by composing scenarios (model composition), and finally, we generate and execute tests automatically. We demonstrate the applicability of this approach in a real-world example: an industrial printer. © 2023 IEEE."
COMPENDEX,Conference article (CA),2019,Exploiting MDE for platform-independent testing of service orchestrations,"Leal, Lucas (1); Montecchi, Leonardo (1); Ceccarelli, Andrea (2); Martins, Eliane (1)",Interoperability - Software testing - Information services - Model checking - Service oriented architecture (SOA),4,"Service Oriented Architecture (SOA) is a common design pattern that allows building applications composed of several services. It promotes features as interoperability, scalability, and software reuse. Services composing a SOA system may evolve and change during runtime, often outside the control of the owner of the application, which makes the verification and validation processes complex. Among all the automated techniques to validate the behavior of an SOA application, is Model-Based Testing (MBT). MBT requires an accurate model of the application in order to generate suitable test cases. However, the intrinsic of a SOA application sets significant challenges to MBT effectiveness. In this paper we discuss the challenges in the testing of SOA applications, and we propose the use of Model-Driven Engineering (MDE) to improve the flexibility of testing tools. Finally, we outline our plan for realizing MDE-driven MBT within an existing online testing framework. © 2019 IEEE."
COMPENDEX,Conference article (CA),2019,Enhancing Acceptance Test-Driven Development with Model-Based Test Generation,"Ramler, Rudolf (1); Klammer, Claus (1)",Graphical user interfaces - Model checking - Automation,2,"Acceptance test-driven development is widely used in practice. However, writing and maintaining acceptance tests is a costly and time-consuming activity, in particular when a system is tested via the GUI. In model-based testing, the tests are automatically generated from a model of the system. In this paper, we report our experience from applying a combination of acceptance test-driven development and model-based testing in several real-world projects from industry. With the application of model-based testing, we increased test coverage and extend testing to usage scenarios not exercised by the existing acceptance tests. In the industry projects, MBT was used as an enhancement rather than a replacement for ATDD. By creating a layered test automation architecture, we were able to reuse the established automation for model-based testing and to apply both approaches simultaneously. This strategy also helped us to minimize the risks and to reduce the effort involved in introducing MBT in the projects. © 2019 IEEE."
COMPENDEX,Conference article (CA),2022,Testing Against Non-deterministic FSMs: A Probabilistic Approach for Test Suite Minimization,"Kushik, Natalia (1); Yevtushenko, Nina (2, 3); López, Jorge (4)",Specifications - Software testing - Model checking,7,"The paper is devoted to model based testing against non-deterministic specifications. Such test derivation strategies are well developed, for example against non-deterministic Finite State Machines, however the length of the corresponding test suite can be exponential w.r.t. the number of specification states. We therefore discuss how a test suite can be minimized or reduced when certain level of guarantee concerning its fault coverage is still preserved. The main idea behind the approach is to augment the specification by assigning probabilities for the non-deterministic transitions and later on evaluate the probability of each test sequence to detect the relevant faulty implementation. Given a probability P which is user-defined, we propose an approach for minimizing a given exhaustive test suite TS such that, it stays exhaustive with the probability no less than P. © 2022, IFIP International Federation for Information Processing."
COMPENDEX,Conference article (CA),2023,Designing a Test Model for a Configurable System: An Exploratory Study of Preprocessor Directives and Feature Toggles,"Fischer, Stefan (1); Michelon, Gabriela Karoline (2); Assunção, Wesley K. G. (2); Ramler, Rudolf (1); Egyed, Alexander (2)",Encoding (symbols) - Machine design - Model checking - Product design - Software design - Well testing,9,"Testing is important in software development, but it has high cost. Thus, techniques to reduce the cost of software testing have been proposed. Model-based testing, one of such techniques, focuses on automatizing the generation of test cases. In the context of highly configurable systems, model-based testing must capture the system behavior and also encode the variability that exists among the variants. Previous research has shown promising results in applying model-based testing to configurable systems. Test models that encode variability into them directly improve the reasoning for faults from interactions. However, there is no study about the use of different variability mechanisms to encode variability in test models. In this paper, we investigate advantages and drawbacks of test model designs exploring the use of two variability mechanisms, namely preprocessor directives and feature toggles. The results are discussed in regard to run-Time reasoning and re-configuration, alongside with metrics about complexity and maintainability. With this work, we contribute to the testing activity of highly configurable systems by providing engineers insights of comparing two well-known and widely used variability mechanisms, which can support informed decisions when choosing for which mechanisms to use for model-based testing. © 2023 Owner/Author."
COMPENDEX,Conference article (CA),2022,Impact of Software Quality on 'gA-FC' Software Testing Technique,"Hooda, Susheela (1); Lamba, Vikas (1); Kaur, Sharanpreet (2); Sharma, Vidhu Kiran (1); Kumar, Raju (3); Sood, Vandana (1)",Application programs - Computer software selection and evaluation - Model checking - Testing,6,Testing of Software quality is an important and crucial task which must be performed on every software product to meet the customer's expectation and to deliver a quality software. Model based testing reduces the reoccurring cost and time for test suites maintained in long term. Recently a 'GA-FC'software testing approach based on model based testing has formulated for aspect-oriented software system which reduces the size of the test suites and testing time. Performance analysis of 'GA-FC'demonstrates its efficiency in terms of maximum coverage of aspects and minimization of the size of the test suite. This paper discusses the impact of software quality on 'GA-FC'technique on medium size application of aspect-oriented software system. © 2022 IEEE.
COMPENDEX,Conference article (CA),2021,Towards an automatic model-based scrum methodology,"Chantit, Salima (1); Essebaa, Imane (1)",Agile manufacturing systems - Computer software reusability - Software architecture - Software design,6,"Software systems evolve continuously and must be developed quickly to fit user requirements and new advances in technology. This has led the software engineering to propose several methods and approaches to overcome the development and maintenance of these software systems. In this regard, Agile Methodologies and Model-Driven Engineering (MDE) are two main approaches that have emerged in recent years and suggest a solution to some of the issues associated with Software systems developments. MDE focuses on software reuse through models and on generative approaches based on separation of concerns whereas Agile Methods promote the use of simpler models and best practices for programming to achieve quick feedback from clients within a development process. However, these two approaches have evolved separately and there are only a few works related to their combination. This paper presents a customized V development life cycle based on models which combines the two MDE variants: The MDA approach in the V left branch with the MBT approach to generate tests of the V right branch. In addition, we integrate this customized V life cycle in the agile Scrum methodology to facilitate the management of each Scrum sprint. © 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)"
COMPENDEX,Conference article (CA),2018,A model-based test case management approach for integrated sets of domain-specific models,"Proll, Reinhard (1); Bauer, Bernhard (1)",Embedded systems - Testing - Information management - Software testing - Model checking - Quality assurance,10,"Due to rapid improvements in the area of embedded processing hardware, the complexity of developed systems constantly increases. In order to ensure a high quality level of such systems, related quality assurance concepts have to evolve. The introduction of Model-Based Testing (MBT) approaches has shown promising results by automating and abstracting multiple activities of the software testing life cycle. Nevertheless, there is a strong need for approaches supporting scoped test models, i.e. subsets of test cases, reflecting specific test purposes driven by risk-oriented development strategies. Therefore, we developed an integrated and model-based approach supporting test case management, which incorporates the beneficial aspects of abstract development methodologies with predominant research for test case management in non-model-based scenarios. Based on a new model artifact, the integration model, tasks like cross-domain information mapping and the integration of domain-specific KPIs derived by analyses favor the subsequently applied constraint-based mechanism for test case management. Further, a prototypical implementation of these concepts within the Architecture And Analysis Framework (A3F) is elaborated and further evaluated based on representative application scenarios. A comparative view on related work leads to a conclusive statement regarding our future work. © 2018 IEEE."
COMPENDEX,Journal article (JA),2023,Model-based security testing in IoT systems: A Rapid Review,"Lonetti, Francesca (1); Bertolino, Antonia (1); Di Giandomenico, Felicita (1)",Complex networks - Learning systems - Model checking,,"Context: Security testing is a challenging and effort-demanding task in IoT scenarios. The heterogeneous devices expose different vulnerabilities that can influence the methods and cost of security testing. Model-based security testing techniques support the systematic generation of test cases for the assessment of security requirements by leveraging the specifications of the IoT system model and of the attack templates. Objective: This paper aims to review the adoption of model-based security testing in the context of IoT, and then provides the first systematic and up-to-date comprehensive classification and analysis of research studies in this topic. Method: We conducted a systematic literature review analyzing 803 publications and finally selecting 17 primary studies, which satisfied our inclusion criteria and were classified according to a set of relevant analysis dimensions. Results: We report the state-of-the-art about the used formalisms, the test techniques, the objectives, the target applications and domains; we also identify the targeted security attacks, and discuss the challenges, gaps and future research directions. Conclusion: Our review represents the first attempt to systematically analyze and classify existing studies on model-based security testing for IoT. According to the results, model-based security testing has been applied in core IoT domains. Models complexity and the need of modeling evolving scenarios that include heterogeneous open software and hardware components remain the most important shortcomings. Our study shows that model-based security testing of IoT applications is a promising research direction. The principal future research directions deal with: extending the existing modeling formalisms in order to capture all peculiarities and constraints of complex and large scale IoT networks; the definition of context-aware and dynamic evolution modeling approaches of IoT entities; and the combination of model-based testing techniques with other security test strategies such as penetration testing or learning techniques for model inference. © 2023 The Authors"
COMPENDEX,Conference article (CA),2016,An approach for verification of a satellite simulator - An evolving system,"Da Silva, Paulo Diego Barbosa (1); Ambrosio, Ana Maria (2); Villani, Emilia (1); Azevedo, Denise Rotondi (2)",Space research - Satellites - Formal verification - Software testing - Satellite simulators,7,"Satellite simulators are developed in the context of a space mission lifecycle to represent the real behavior of a satellite during operation and may be used for different purposes. To attend a particular purpose new functions are added or modified according to the mission phase needs, requiring models re-adaptation in a system evolving concept. The process of verification of satellite simulator software requires high-efficiency in accomplishing realistic functional and behavioral requirements. Based on the complex set of requirements the satellite behavior is represented in the simulator through software models specified by tables of cause-effect rules. Considering that the Satellite Simulator is an evolving systems and it needs to assure that the logic implemented in the simulator conforms to the requirements, the manual verification process becomes impracticable, therefore demanding a compatible verification approach. The approach suggested here unifies two techniques Conformance and Fault Inject (CoFI), constructed on Model-Based Testing and Model Checking added to a method so that it can translate the tables of cause-effect rules into finite state machines. This paper presents the verification approach illustrating it with the Data Collection Subsystem (DCS) model of the CBERS satellite simulator being developed at National Institute for Space Research (INPE). © 2016 IEEE."
COMPENDEX,Journal article (JA),2019,Extending MUD profiles through an automated IoT security testing methodology,"Matheu, Sara Nieves (1); Hernandez-Ramos, Jose Luis (2); Perez, Salvador (1, 3); Skarmeta, Antonio F. (1)",Model checking - Access control - Semantics,20,"Defining the intended behaviour of IoT devices is considered as a key aspect to detect and mitigate potential security attacks. In this direction, the Manufacturer Usage Description (MUD) has been recently standardised to reduce the attack surface of a certain device through the definition of access control policies. However, the semantic model is only intended to provide network level restrictions for the communication of such device. In order to increase the expressiveness of this approach, we propose the use of an automated IoT security testing methodology, so that testing results are used to generate augmented MUD profiles, in which additional security aspects are considered. For the enforcement of these profiles, we propose the use of different access control technologies addressing application layer security concerns. Furthermore, the methodology is based on the use of Model-Based Testing (MBT) techniques to automate the generation, design and implementation of security tests. Then, we describe the application of the resulting approach to the Elliptic Curve Diffie-Hellman over COSE (EDHOC) protocol, which represents a standardisation effort to build a lightweight authenticated key exchange protocol for IoT constrained scenarios. © 2013 IEEE."
COMPENDEX,Conference article (CA),2023,Timed Transition Tour for Race Detection in Distributed Systems,"Vinarskii, Evgenii (1); Kushik, Natalia (1); Yevtushenko, Nina (2, 3); López, Jorge (4); Zeghlache, Djamal (1)",Application programs - Software testing,8,"The paper is devoted to detecting output races in distributed systems. We perform such detection through testing their implementations. As an underlying model for our test generation strategy we consider a Timed Finite State Machine or a TFSM (for short), where each input/output transition is augmented with a timed guard and an output delay. A potential output race can thus be simulated as an output delay mutant; this formalism is introduced in the paper. In order to build a test suite, we adapt a well-known test generation strategy, a transition tour method. The novelty of the proposed method relies on choosing appropriate timestamps for inputs, yielding a timed transition tour. We discuss its fault coverage for output race detection. As an application case study, we consider a Software Defined Networking (SDN) framework where the system under test is represented by the composition of a controller and a switch. Experimental results show that the timed transition tour can detect races in the behavior of the widely used ONOS controller. Copyright © 2023 by SCITEPRESS - Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)"
COMPENDEX,Conference article (CA),2018,SimEvo: A Toolset for Simulink Test Evolution & Maintenance,"Rapos, Eric J. (1); Cordy, James R. (2)",Maintenance - Model checking,6,"As Simulink models evolve and change during development, test evolution and maintenance can often be overlooked. SimEvo provides a toolset to assist Simulink developers in coevolving test harnesses and test cases alongside their source models. Primarily a collection of testing tools, SimEvo combines the impact analysis features of the SimPact impact analysis tool to identify instances of necessary test case changes and potentially affected blocks, with the SimTH test harness generator to automatically determine if changes need to be made to the test harness model, and automatically generate a new one if necessary. This paper examines the implementation of SimTH, its integration with SimPact into the workbench SimEvo, and an overall analysis of the contributions of the toolset. © 2018 IEEE."
COMPENDEX,Journal article (JA),2015,An empirical comparison of model-based and capture and replay approaches for performance testing,"Macedo Rodrigues, Elder (1); Moreira de Oliveira, Flávio (1); Teodoro Costa, Leandro (1); Bernardino, Maicon (1); Zorzo, Avelino Francisco (1); do Rocio Senger Souza, Simone (2); Saad, Rodrigo (3)",Automatic programming - Model checking,30,"A variety of testing tools has been developed to support and automate the software testing activity. Some of them may use different techniques such as Model-based Testing (MBT) or Capture and Replay (CR). Model-based Testing is a technique for automatic generation of testing artifacts based on software models. One of the main benefits of using MBT is related to the easiness of maintaining models over code; hence, it is likely that using models as a source for automatic generation of scripts requires less effort and reduces the number of faults. Otherwise, CR-based tools basically record the user interaction with the System Under Test (SUT) and then playback the recorded test. This paper presents our effort on setting up and running an experimental study performed in order to evaluate the effort to use MBT and CR-based tools to generate performance scripts. Thus, we apply an MBT and a CR approaches for the purpose of evaluation with respect to the effort to generate scripts and scenarios from the perspective of the performance testers and the performance test engineers in the context of undergraduates, M.Sc. and Ph.D. students, performance testers and performance test engineers for the generation of performance test scripts and scenarios. Our results indicate that, for simple testing tasks, the effort of using a CR-based tool was lower than using an MBT tool, but as the complexity or size of the activities of the testing tasks increases, the advantage of using MBT increased significantly. © 2014, Springer Science+Business Media New York."
COMPENDEX,Conference article (CA),2018,Uncovering Unknown System Behaviors in Uncertain Networks with Model and Search-Based Testing,"Ji, Ruihua (1); Li, Zhong (1); Chen, Shouyu (1); Pan, Minxue (1, 2); Zhang, Tian (1, 2); Ali, Shaukat (2); Yue, Tao (2); Li, Xuandong (1)",Learning algorithms - Search engines - Model checking - Software testing - Information services - Open source software - Open systems - Testing - Evolutionary algorithms,11,"Modern software systems rely on information networks for communication. Such information networks are inherently unpredictable and unreliable. Consequently, software systems behave in an unstipulated manner in uncertain network conditions. Discovering unknown behaviors of these software systems in uncertain network conditions is essential to ensure their correct behaviors. Such discovery requires the development of systematic and automated methods. We propose an online and iterative model-based testing approach to evolve test models with search algorithms. Our ultimate aim is to discover unknown expected behaviors that can only be observed in uncertain network conditions. Also, we have implemented an adaptive search-based test case generation strategy to generate test cases that are executed on the system under test. We evaluated our approach with an open source video conference application-Jitsi with three search algorithms in comparison with random search. Results show that our approach is efficient in discovering unknown system behaviors. In particular, (1+1) Evolutionary Algorithm outperformed the other algorithms. © 2018 IEEE."
COMPENDEX,Journal article (JA),2017,Uncertainty-wise evolution of test ready models,"Zhang, Man (1); Ali, Shaukat (1); Yue, Tao (1, 2); Norgre, Roland (3)",Health care - Model checking - Embedded systems - Cyber Physical System - Learning systems,20,"Context Cyber-Physical Systems (CPSs), when deployed for operation, are inherently prone to uncertainty. Considering their applications in critical domains (e.g., healthcare), it is important that such CPSs are tested sufficiently, with the explicit consideration of uncertainty. Model-based testing (MBT) involves creating test ready models capturing the expected behavior of a CPS and its operating environment. These test ready models are then used for generating executable test cases. It is, therefore, necessary to develop methods that can continuously evolve, based on real operational data collected during the operation of CPSs, test ready models and uncertainty captured in them, all together termed as Belief Test Ready Models (BMs) Objective Our objective is to propose a model evolution framework that can interactively improve the quality of BMs, based on operational data. Such BMs are developed by one or more test modelers (belief agents) with their assumptions about the expected behavior of a CPS, its expected physical environment, and potential future deployments. Thus, these models explicitly contain subjective uncertainty of the test modelers. Method We propose a framework (named as UncerTolve) for interactively evolving BMs (specified with extended UML notations) of CPSs with subjective uncertainty developed by test modelers. The key inputs of UncerTolve include initial BMs of CPSs with known subjective uncertainty and real data collected from the operation of CPSs. UncerTolve has three key features: 1) Validating the syntactic correctness and conformance of BMs against real operational data via model execution, 2) Evolving objective uncertainty measurements of BMs via model execution, and 3) Evolving state invariants (modeling test oracles) and guards of transitions (modeling constraints for test data generation) of BMs with a machine learning technique. Results As a proof-of-concept, we evaluated UncerTolve with one industrial CPS case study, i.e., GeoSports from the healthcare domain. Using UncerTolve, we managed to evolve 51% of belief elements, 18% of states, and 21% of transitions as compared to the initial BM developed in an industrial setting. Conclusion UncerTolve can successfully evolve model elements of the initial BM, in addition to objective uncertainty measurements using real operational data. The evolved model can be used to generate additional test cases covering evolved model elements and objective uncertainty. These additional test cases can be used to test the current and future deployments of a CPS to ensure that it will handle uncertainty gracefully during its operations. © 2017"
COMPENDEX,Conference article (CA),2022,Morest: Model-based RESTful API Testing with Execution Feedback,"Liu, Yi (1); Li, Yuekang (1); Deng, Gelei (1); Liu, Yang (1); Wan, Ruiyuan (2); Wu, Runchao (2); Ji, Dandan (3); Xu, Shiheng (2); Bao, Minli (2)",Black-box testing - Model checking - Web services,12,"RESTful APIs are arguably the most popular endpoints for accessing Web services. Blackbox testing is one of the emerging techniques for ensuring the reliability of RESTful APIs. The major challenge in testing RESTful APIs is the need for correct sequences of API operation calls for in-depth testing. To build meaningful operation call sequences, researchers have proposed techniques to learn and utilize the API dependencies based on OpenAPI specifications. However, these techniques either lack the overall awareness of how all the APIs are connected or the flexibility of adaptively fixing the learned knowledge. In this paper, we propose Morest, a model-based RESTful API testing technique that builds and maintains a dynamically updating RESTful-service Property Graph (RPG) to model the behaviors of RESTful-services and guide the call sequence generation. We empirically evaluated Morest and the results demonstrate that Morest can successfully request an average of 152.66%-232.45% more API operations, cover 26.16%-103.24% more lines of code, and detect 40.64%-215.94% more bugs than state-of-the-art techniques. In total, we applied Morest to 6 real-world projects and found 44 bugs (13 of them cannot be detected by existing approaches). Specifically, 2 of the confirmed bugs are from Bitbucket, a famous code management service with more than 6 million users. © 2022 ACM."
COMPENDEX,Conference article (CA),2019,Optimizing regression testing with functional flow block reliability diagram,"Chourey, Vaishali (1); Sharma, Meena (2)",Model checking - Software reliability - Integration testing - Regression analysis - Reliability analysis,7,"Model based testing techniques are widely used to generate tests from models and their specifications. Regression Testing is critical in evolving software systems. It implies that Software undergoes continuous integration and subsequent testing of modules and components to develop a final release of the software. Recent research on test automation have revealed challenges in testing such as enormous test cases generated that are either redundant or irrelevant tests. This prevents the critical parts of code from testing and leave faults uncovered. Manual testing also slows the process and makes exhaustive testing for quality difficult. This paper proposes an approach to generate regression tests from model synthesized from UML interaction diagrams and also prioritize tests. The algorithm generate test suites from the proposed intermediate model. The reliability analysis is performed on blocks and the results govern the prioritization of tests. Copyright © 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved"
COMPENDEX,Conference article (CA),2018,Toward a Constraint Based Test Case Generation of Parallel BPEL Process,"Serbout, Sara (1); Benattou, Mohammed (1)",Flow graphs - Software testing - Data flow analysis - Parallel flow - Graphic methods - Process control,,"Business Process Execution Language (BPEL) offers the possibility to implement customized business processes in a record time. Testing is crucial to ensure the quality of BPEL process. The aim of this paper is to propose a constraint based approach to test parallel BPEL process. In our work, we propose an algorithm to transform a parallel BPEL process into a Parallel Control Flow Graph (PCFG), we augment PCFG with pre and post conditions, and we drive then a suite of feasible test cases. © 2018 IEEE."
COMPENDEX,Journal article (JA),2019,Learning and statistical model checking of system response times,"Aichernig, Bernhard K. (1); Bauerstätter, Priska (2); Jöbstl, Elisabeth (3); Kann, Severin (3); Koroec, Robert (3); Krenn, Willibald (2); Mateis, Cristinel (2); Schlick, Rupert (2); Schumi, Richard (1)",Learning systems - Response time (computer systems) - Statistics - Testing - User profile - Web services,39,"Since computers have become increasingly more powerful, users are less willing to accept slow responses of systems. Hence, performance testing is important for interactive systems. However, it is still challenging to test if a system provides acceptable performance or can satisfy certain response-time limits, especially for different usage scenarios. On the one hand, there are performance-testing techniques that require numerous costly tests of the system. On the other hand, model-based performance analysis methods have a doubtful model quality. Hence, we propose a combined method to mitigate these issues. We learn response-time distributions from test data in order to augment existing behavioral models with timing aspects. Then, we perform statistical model checking with the resulting model for a performance prediction. Finally, we test the accuracy of our prediction with hypotheses testing of the real system. Our method is implemented with a property-based testing tool with integrated statistical model checking algorithms. We demonstrate the feasibility of our techniques in an industrial case study with a web-service application. © 2019, The Author(s)."
COMPENDEX,Journal article (JA),2019,Hierarchical featured state machines,"Fragal, Vanderson Hafemann (1); Simao, Adenilso (1); Mousavi, Mohammad Reza (2)",Software design - Testing - Computer software - Model checking,22,"Variants of the Finite State Machine (FSM) model have been extensively used to describe the behavior of reactive systems. In particular, several model-based testing techniques have been developed to support test case generation from FSMs and test case execution. Most of such techniques require several validation properties to hold for the underlying test models. Featured Finite State Machine (FFSM) is an extension of the FSM model proposed in our earlier publication that represents the abstract behavior of an entire Software Product Line (SPL). By validating an FFSM, we validate all valid products configurations of the SPL looking forward configurable test suites. However, modeling a large SPL using flat FFSMs may lead to a huge and hard-to-maintain specification. In this paper, we propose an extension of the FFSM model, named Hierarchical Featured State Machine (HFSM). Inspired by Statecharts and UML state machines, we introduce the HFSM model to improve model readability by grouping up FFSM conditional states and transitions into abstracted entities. Our ultimate goal is to use HFSMs as test models. To this end, we first define some syntactic and semantical validation criteria for HFSMs as prerequisites for using them as test models. Moreover, we implement an adapted graphical Eclipse-based editor from the Yakindu Project for modeling, derivation, and checking feature-oriented properties using Satisfiability Modulo Theory (SMT) solver tools. We investigate the applicability of our approach by applying it to an HFSM for a realistic case study (the Body Comfort System). The results indicate that HFSMs can be used to compactly represent and efficiently validate the behavior of parallel components in SPLs. © 2018 Elsevier B.V."
COMPENDEX,Conference article (CA),2020,Initial Pose Estimation of 3D Object with Severe Occlusion Using Deep Learning,"Lomaliza, Jean-Pierre (1); Park, Hanhoon (1, 2)",Learning systems - Deep neural networks - Textures - Augmented reality - Convolutional neural networks - Convolution - Gesture recognition - Target tracking - Object detection,12,"During the last decade, augmented reality (AR) has gained explosive attention and demonstrated high potential on educational and training applications. As a core technique, AR requires a tracking method to get 3D poses of a camera or an object. Hence, providing fast, accurate, robust, and consistent tracking methods have been a main research topic in the AR field. Fortunately, tracking the camera pose using a relatively small and less-textured known object placed on the scene has been successfully mastered through various types of model-based tracking (MBT) methods. However, MBT methods requires a good initial camera pose estimator and estimating an initial camera pose from partially visible objects remains an open problem. Moreover, severe occlusions are also challenging problems for initial camera pose estimation. Thus, in this paper, we propose a deep learning method to estimate an initial camera pose from a partially visible object that may also be severely occluded. The proposed method handles such challenging scenarios by relying on the information of detected subparts of a target object to be tracked. Specifically, we first detect subparts of the target object using a state-of-the-art convolutional neural networks (CNN). The object detector returns two dimensional bounding boxes, associated classes, and confidence scores. We then use the bounding boxes and classes information to train a deep neural network (DNN) that regresses to camera’s 6-DoF pose. After initial pose estimation, we attempt to use a tweaked version of an existing MBT method to keep tracking the target object in real time on mobile platform. Experimental results demonstrate that the proposed method can estimate accurately initial camera poses from objects that are partially visible or/and severely occluded. Finally, we analyze the performance of the proposed method in more detail by comparing the estimation errors when different number of subparts are detected. © 2020, Springer Nature Switzerland AG."
COMPENDEX,Conference article (CA),2019,The SAMBA approach for self-adaptive model-based online testing of services orchestrations,"Leal, Lucas (1); Ceccarelli, Andrea (1); Martins, Eliane (1)",Service oriented architecture (SOA) - Software testing - Life cycle - Model checking,6,"Service Oriented Architecture (SOA) is a popular design pattern that allows building applications composed of loosely-coupled and autonomous services. Such services may evolve and change at runtime, often outside the control of the owner of the application. Consequently, typical validation approaches, like offline testing performed before services deployment, are necessary but not sufficient: offline testing cannot assure the correct behavior of the SOA during its execution. To cope with the evolution of services and their orchestrations, in this paper we present a Self-Adaptive Model-BAsed online testing framework called SAMBA. SAMBA aims to assess the proper behavior of a SOA during its lifecycle executing model-based online testing at runtime, under the coordination of a MAPE-K control loop. SAMBA is assessed in a case study, where its detection capability are proved through functional, mutation and fault injection tests. © 2019 IEEE."
COMPENDEX,Conference article (CA),2019,A model-based approach to generate dynamic synthetic test data,"Tan, Chao (1)",Machine learning - Model checking,3,"Having access to high-quality test data is an important requirement to ensure effective cross-organizational integration testing. The common practice for addressing this need is to generate synthetic data. However, existing approaches cannot generate representative datasets that can evolve to allow the simulation of the dynamics of the systems under test. In this PhD project, and in collaboration with an industrial partner, we investigate the use of machine learning techniques for developing novel solutions that can generate synthetic, dynamic and representative test data. © 2019 IEEE."
COMPENDEX,Journal article (JA),2019,Model-based test suite generation for graph transformation system using model simulation and search-based techniques,"Kalaee, Akram (1); Rafe, Vahid (1)",Search engines - Flow graphs - Open systems - Metadata - Integration testing - Model checking - Data flow analysis - Heuristic algorithms,29,"Context: Test generation by model checking is a useful technique in model-based testing that allows automatic generation of test cases from models by utilizing the counter-examples/witnesses produced through a model checker. However, generating redundant test cases and state space explosion problem are two major obstacles to transfer this technique into industrial practice. Objective: An idea to cope with these challenges consists in an intelligent model checking for exploring only a portion of the state space according to the test objectives. Motivated by this idea, we propose an approach that exploits meta-heuristic algorithms to adapt a model checker when used for integration testing of systems formally specified by graph transformations. Method: This method is not based on model checking algorithms, but rather uses the modeling and simulation features of the underlying model checker. In the proposed approach, a population of test suites that each of which is a set of paths on the state space, is evolved towards satisfying the all def-use test objectives. Consequently, a test suite with high coverage is generated. Results: To assess the efficiency of our approach, it is implemented in GROOVE, an open source toolset for designing and model checking graph transformation systems. Empirical results based on some case studies, confirm a significant improvement in terms of coverage, speed and memory usage, in comparison with the state of the art techniques. Conclusion: Our analysis reveals that intelligent model checking can appropriately address the challenges of traditional model-checking-assisted testing. We further conclude that graph transformation specification is an efficient modeling solution to behavioral testing and graph transformation tools have a great potential for developing a model-based testing tool. © 2018 Elsevier B.V."
COMPENDEX,Conference article (CA),2018,End-to-end Automatic Business Process Validation,"Paiva, Ana C.R. (1); Flores, Nuno H. (1); Faria, João P. (1); Marques, José M.G. (2)",Model checking,6,"Business Process Testing is the act of validating that end-to-end transactions through enterprise systems continue to work correctly as the underlying packaged applications evolve. End-to-end automatic business process validation can be a challenging task, but an important way to check that business rules continue to work properly and that problems are detected and corrected as soon as possible. This paper presents the design of a test automation platform, ETAP-Pro, to test end-to-end business processes that aims to overcome some challenges in validating business processes. © 2018 The Authors. Published by Elsevier B.V."
COMPENDEX,Conference article (CA),2019,Extending UTP 2 with cascading arbitration specifications,"Wendland, Marc-Florian (1); Schneider, Martin (1); Hoffmann, Andreas (1)",Reusability - Maintainability - Model checking,7,"In testing, the term arbitration describes the process of calculating the verdict after the execution of a test case or test suite. The calculation of the verdict follows a defined rule set that clearly specifies which verdict to produce under which conditions. In many situations, these rules simply follow the scheme that any deviation between the expected and the actual response of the system under test leads to fail. UTP 2 introduces the concept of arbitration specifications on various hierarchy levels to determine the final verdict of an arbitration target. It provides default arbitration specifications that adhere to the above-mentioned straightforward calculation of verdicts, but allows for overriding these default ones with user-defined arbitration specifications. Unfortunately, this override mechanism adversely affects the maintainability of test cases and test actions because of its high degree of intrusion. Arbitration targets, such as test sets, test cases and procedural elements, and arbitration specifications are tightly coupled with each other, losing the ability to reuse these arbitration targets in a different context with different arbitration specifications. In this paper, we suggest to replace this highly intrusive override mechanism with a decoupling binding mechanism. This binding mechanism increases both comprehensibility and maintainability of test specifications on one hand, because arbitration targets remain independent of any potential arbitration specification. On the other hand, it offers a high degree of reusability and flexibility to the user because of a cascading override mechanism inspired by W3C cascading style sheets. Copyright © A-TEST 2019 - ACM SIGSOFT International Workshop on Automating TEST Case Design, Selection, and Evaluation, co-located with ESEC/FSE 2019.All right reserved."
COMPENDEX,Journal article (JA),2018,Test Generation from Event System Abstractions to Cover Their States and Transitions,"Julliand, J. (1); Kouchnarenko, O. (1); Masson, P.A. (1); Voiron, G. (1)",Model checking - Concretes,14,"Model-based testing of event systems can take advantage of considering abstractions rather than explicit models, for controlling their size. When abstracting still a test has to be a concrete connected and reachable event sequence. This paper presents a test generation method based on computing a reachable and connected under-approximation of the abstraction of an event system. We compute the under-approximation with concrete instances of the abstract transitions, that cover all the states and transitions of the predicatebased abstraction. We propose an algorithmic method that instantiates each of the abstract transitions, and maintains for widening it a frontier of concretely reached states. We present heuristics to favour the instances connectivity. The idea is to prolong whenever possible the already reached sequences of concrete transitions, and to parameterize the order in which the states and actions occur. This concrete under-approximation ends up covering partially (at best totally) the reachable abstract transitions. The computed tests are paths of the under-approximation. The paper also reports on an implementation, which permits to provide experimental results confirming the interest of the approach with related heuristics. © 2018, Pleiades Publishing, Ltd."
COMPENDEX,Journal article (JA),2019,Extension to Interaction Flow Modeling Language (IFML) for Android Application Modeling,"Lu, Yi-Fei (1); Pan, Min-Xue (1); Zhang, Tian (1); Wang, Lin-Zhang (1); Li, Xuan-Dong (1)",Semantics - Flow control - Android (operating system) - Graphical user interfaces - Model checking,20,"Under the widespread of smartphones and tablets, Android devices have gradually become one of the most important elements in our daily life. Along with it, Android applications are now flourishing and their complexity increases geometrically. Meanwhile, Android fragmentation is aggravating, which forces developers to design and develop the same Android apps for different Android versions and devices. In this case, employing models are proposed for requirements and designs in Android app development. With models, dividing and conquering these requirements and designs are possible which reduces the general complexity. At the same time, models of high expression help developers to better understand the purpose and finally guide the development work. However, the traditional models are no longer suitable, since Android apps are even-driven and GUI centric. Therefore, Interaction Flow Modeling Language (IFML) is adopted, the new OMG standard for front-end design and event interaction, in Android app modeling to describe apps' GUI structures and workflows and guide the development. Furthermore, an extension of IFML is proposed for Android to improve its usability and compatibility for Android apps. A formal definition of the IFML model is also given in this paper. The rich semantics of IFML models can elaborate the designs for Android apps, which will further systematically guide the development of these apps during their evolution. Moreover, these IFML models are used to check the consistency between design and implementation in the form of testing. In this way, the effort of writing test cases is reduced and productivity is enhanced as the apps evolve. A tool for modeling and testing for Android apps with IFML is presented, called ADAMANT. To verify the proposed approach's feasibility, ADAMANT is applied on five real-world apps. The results show that the use of the extended IFML in Android app development is effective, and the IFML models can directly be used for testing, ensuring the design is in consistent with the implementation. In this manner, it ensures the quality of development and benefits the sustainable development of apps. © Copyright 2019, Institute of Software, the Chinese Academy of Sciences. All rights reserved."
COMPENDEX,Conference article (CA),2020,Toward an equation-oriented framework for diagnosis of complex systems,"Feldman, Alexander (1); Provan, Gregory (1)",Computer circuits - Inference engines - Model checking - Economic and social effects - Computational efficiency,10,"Diagnosis of complex systems is a critical area for most real-world systems. Given the wide range of system types, including physical systems, logic circuits, state-machines, control systems, and software, there is no commonly-accepted modeling language or inference algorithms for model-Based Diagnosis (MBD) of such systems. Designing a language that can be used for modeling such a wide class of systems, while being able to efficiently solve the model, is a formidable task. The computational efficiency with which a given model can be solved, although often neglected by designers of modeling languages, is a key to parameter identification and answering MBD challenges. We address this freedom-of-modeling versus model-solving efficiency trade-off challenge by evolving a language for MBD of physical system, called LYDIA. In this paper we report on the abilities of LYDIA to model a class of physical systems, the algorithms that we use for solving MBD problems and the results that we have obtained for several challenging systems. © is held by the author/owner(s). The proceedings are published by Linköping University Electronic Press. Proceedings available at: http://www.ep.liu.se/ecp_home/index.en.aspx?issue=084"
COMPENDEX,Conference article (CA),2018,Model-Based Runtime Monitoring of Smart City Systems,"Incki, Koray (1); Ari, Ismail (1)",Smart city - Model checking - System of systems,8,"The pace of proliferation for smart systems in city wide applications is unmatched. The introduction of Internet of Things (IoT), an enabler of smart city phenomenon, has incubated a productive environment for such innovations. Smart things equipped with IoT capabilities, allow for developing smart city applications at such large scale that each application can be represented as a system of systems (SoS). Nevertheless, the complexity of engineering such SoS has been a major challenge in developing and maintaining smart city applications. One of the engineering challenges that industry face today is the verification of a SoS smart city application at runtime. We introduce utilization of a model-based runtime monitoring approach for providing reliable service. We propose to use message sequence charts for representing a smart city application, later allow the practitioners to express expected behavior of an application in terms of complex-event processing patterns. We demonstrate the fidelity of our approach on a sample smart parking system. Our approach is one of its kind in enabling a non-intrusive monitoring of IoT behavior at runtime (online). © 2018 The Authors. Published by Elsevier Ltd."
COMPENDEX,Journal article (JA),2016,Petri net based test case generation for evolved specification,"Ding, Zuohua (1); Jiang, Mingyue (1); Chen, Haibo (1); Jin, Zhi (2); Zhou, Mengchu (3)",Model checking - Testing - Software testing - Petri nets - Concrete testing - Reusability,,"Model-based testing can use a model to test a concrete program’s implementation. When the model is changed due to the evolution of the specification, it is important to maintain the test suites up to date, such that it can be used for regression testing. A complete regeneration of the whole test suite from the new model, although inefficient, is still frequently used in practice. To address this problem effectively, we propose a test case reusability analysis technique to identify reusable test cases of the original test suite based on graph analysis, such that we can generate new test cases to cover only the change-related parts of the new model. The Market Information System (MIS) is employed to demonstrate the feasibility and effectiveness of the proposed method. Our experimental results show that the use of our method saves about 31.5% test case generation cost. © 2016, Science China Press and Springer-Verlag Berlin Heidelberg."
COMPENDEX,Journal article (JA),2016,ProMiner: Bi-directional consistency checking framework based on system properties,"Ge, Xu-Jun (1); Wang, Ling (1); Xu, Li-Hua (1); Guo, Jian (2); Zhu, Hui-Biao (2)",Software testing - Temporal logic - Software design - Computer circuits - Testing,15,"Model-Driven development is currently a highly regarded software development paradigm among software developers and researchers, and model-based testing techniques are usually applied during the development to ensure the quality of software systems. With the growing size and complexity of software systems, maintaining the consistency between software models and their implementation become more and more challenging. While traditional model-based testing focuses on ensuring the software implementation comply with its designed model, this work addresses particularly the situation where the implementation is modified while software models are left outdated due to workarounds or other unexpected changes during development. The paper presents an automated consistency checking framework, ProMiner, which extends traditional model-based testing with mining software properties that represent the identified inconsistencies as linear temporal logic (LTL). Experiments show that this extended consistency checking technique effectively helps software designer to narrow down the specific locations of software models that need to be updated with respects to its running implementation. © Copyright 2016, Institute of Software, the Chinese Academy of Sciences. All rights reserved."
COMPENDEX,Conference article (CA),2017,Model-Based API Testing of Apache ZooKeeper,"Artho, Cyrille (1, 2); Gros, Quentin (3); Rousset, Guillaume (3); Banzai, Kazuaki (4); Ma, Lei (5); Kitamura, Takashi (2); Hagiya, Masami (4); Tanabe, Yoshinori (7); Yamamoto, Mitsuharu (6)",Digital storage - Application programming interfaces (API),11,"Apache ZooKeeper is a distributed data storage that is highly concurrent and asynchronous due to network communication, testing such a system is very challenging. Our solution using the tool 'Modbat' generates test cases for concurrent client sessions, and processes results from synchronous and asynchronous callbacks. We use an embedded model checker to compute the test oracle for non-deterministic outcomes, the oracle model evolves dynamically with each new test step. Our work has detected multiple previously unknown defects in ZooKeeper. Finally, a thorough coverage evaluation of the core classes show how code and branch coverage strongly relate to feature coverage in the model, and hence modeling effort. © 2017 IEEE."
COMPENDEX,Conference article (CA),2016,D-MBTDD: An Approach for Reusing Test Artefacts in Evolving System,"Ussami, Thais Harumi (1); Martins, Eliane (1); Montecchi, Leonardo (2)",Agile manufacturing systems - Model checking - Software testing - Software design - Iterative methods,8,"Agile software development methodologies use an iterative and incremental development in order to handle evolving systems. Consolidated techniques in the field of testing have been applied to these techniques with the main purpose of aiding in the test creation stage. An example is Model-Based Test Driven Development (MBTDD) which joins the concepts of Model-Based Testing (MBT) and Test Driven Development (TDD). However, when iterative and incremental processes are used, problems appear as the consequence of the evolution of the system, such as: how to reuse the test artefacts, and how to select the relevant tests for implementing the new version of the system. In this context, this work proposes a process called D-MBTDD in which the agile development of a system is guided by model-based tests, focusing on helping with the reuse of test artefacts and on the process of identifying tests relevant to development. The information about the modifications between two versions of the test model are used in this approach, which was compared to the Regenerate-All approach, which regenerates test cases along the iterations and does not reuse any of them. © 2016 IEEE."
COMPENDEX,Conference article (CA),2016,Model-Based continuous verification,"Fan, Lingling (1); Chen, Sen (1); Xu, Lihua (1); Yang, Zongyuan (1); Zhu, Huibiao (1, 2)",Codes (symbols) - Iterative methods - Computer programming languages - Software testing - Legacy systems,8,"Model-based engineering has emerged as a key set of technologies to engineer software systems. While system source code is expected to match with the designed model, legacy systems and workarounds during deployment would undoubtedly change the source code, making the actual running implementation mismatch with its model. Such mismatch poses a challenge of maintaining the conformance between the model and the corresponding implementation. Prior techniques, such as model checking and model-based testing, simply assumed the sole correctness of the model or the implementation, which is naive since they both could contain correct information (e.g. representing either the software requirements or the actual running environment).In this paper, we aim to address this problem through model-based continuous verification (ConV), an iterative verification process that links the traditional model checking phase with the software testing phase to a feedback loop, ensuring the conformance between the system model and its implementation. It allows to execute the abstract test cases over the implementation through a semi-automatic binding mechanism to guide the update of the code, and augments system properties from the actually running system to guide the update of the model through model checking. Based on these techniques, we implemented Eunomia, a conformance verification system, to support the continuous verification process. Experiments show that Eunomia can effectively detect and locate inconsistencies both in the model and the source code. © 2016 IEEE."
COMPENDEX,Conference article (CA),2015,Test script generation based on design documents for web application testing,"Tanno, Haruto (1); Zhang, Xiaojing (1)",Application programs - Computer software selection and evaluation - Design - Software testing - Testing - Model checking - Quality assurance,2,"Testing is critical for software quality assurance, but as most of this work is done manually, it is an area ripe for cost reductions. One good approach to cost reduction is to produce test scripts, the inputs of the test execution tool, and to execute tests automatically. However, when applying this approach, making and maintaining the test scripts are costly tasks. To solve this problem, we propose an approach to automatically generate test scripts from design documents, which are artifacts of the design process, using model-based testing. We confirm effectiveness of our approach by comparing it to an existing approach. © 2015 IEEE."
COMPENDEX,Conference article (CA),2015,Model-based integration testing of ROS packages: A mobile robot case study,"Ernits, Juhan (1); Halling, Evelin (1); Kanter, Gert (1); Vain, Jüri (1)",Topology - Ability testing - Black-box testing - Model checking - Mobile robots,,"We apply model-based testing - a black box testing technology - to improve the state of the art of integration testing of navigation and localisation software for mobile robots built in ROS. Online model-based testing involves building executable models of the requirements and executing them in parallel with the implementation under test (IUT). In the current paper we present an automated approach to generating a model from the topological map that specifies where the robot can move to. In addition, we show how to specify scenarios of interest and how to add human models to the simulated environment according to a specified scenario. We measure the quality of the tests by code coverage, and empirically show that it is possible to achieve increased test coverage by specifying simple scenarios on the automatically generated model of the topological map. The scenarios augmented by adding humans to specified rooms at specified stages of the scenario simulate the changes in the environment caused by humans. Since we test navigation at coordinate and topological level, we report on finding problems related to the topological map. © 2015 IEEE."
COMPENDEX,Conference article (CA),2016,Functional Flow Diagram(FFD): Semantics for evolving software,"Chourey, Vaishali (1); Sharma, Meena (2)",Computer software reusability - Flowcharting - Model checking,7,"In the current scenario, component-based system development approaches have led to reuse based development and espousal of large-scale software systems. To analyze the design of such systems and assess its performance is not a trivial task. Model-based testing tools have maturely signified the success of functional testing of such systems. An urge to spawn the testing of non-functional behavior from development models is further expected. Reliability assessment is one such aspect. However, the design models have not been employed in the prevailing non-functional assessment techniques. Assuming the strength of such models and the need to devise assessment measures, an attempt to formalize architectural models to this context is presented in the paper. Our paper focuses on deriving an intermediate notation for non-functional evaluation of the software systems. The concept of modeling, annotating constraints and making a visual of component interaction patterns is the scope of the work. The new model thus generated has features similar to the System's Engineering 'Functional Flow Diagram' and will be used with same definitions for the software components. © 2016 IEEE."
COMPENDEX,Conference article (CA),2013,"Test generation for RTES from SysML models: Context, motivations and research proposal","Gauthier, Jean-Marie (1)",Interactive computer systems - Real time systems - Model checking - Embedded systems,2,"This paper presents the context, motivations and perspectives of my PhD research about model-based testing for real-time and embedded systems using SysML. This work is based on an existing model-based approach which has been proposed during the VETESS project. This approach aims to generate tests for embedded systems. In this paper, we identify areas of improvement, which permit us to evolve the initial approach by taking into account real-time aspects. This will contribute to an automated Model-Based Testing toolchain for real-time and embedded systems. © 2013 IEEE."
COMPENDEX,Conference article (CA),2018,Model based approach for testing: Distributed real-time systems augmented with online monitors,"Pal, Deepak (1); Vain, Jüri (1)",Geographical distribution - Distributed database systems - Integration testing - Model checking - Online systems - Interactive computer systems - Distributed computer systems - Real time systems,16,"Testing distributed systems requires an integration of computation, communication and control in the test architecture. This may pose number of issues that may not be suitably addressed by traditional centralized test architectures. In this paper, a distributed test framework for testing distributed real-time systems is presented, where online monitors (executable code as annotations) are integrated to systems to record relevant events. The proposed test architecture is more scalable than centralized architectures in the sense of timing constraints and geographical distribution. By assuming the existence of a coverage correct centralized remote tester, we give a partitioning algorithm of it to produce distributed local testers which enables to meet more flexible performance constraints while preserving the remote tester’s functionality. The proposed approach not only preserves the correctness of the centralized tester but also allows to meet stronger timing constraints for solving test controllability and observability issues. The effectiveness of the proposed architecture is demonstrated by an illustrative example. © Springer Nature Switzerland AG 2018."
COMPENDEX,Journal article (JA),2023,"Three birds with one stone: Contemporaneously boosting passive, active and self-healing properties for long-term anticorrosion coatings","Cheng, Meng (1); Liu, Junhao (1); Liu, Yuqi (1); Jiang, Hao (1); Li, Chunling (1, 2); Sun, Shuangqing (1, 2); Hu, Songqing (1, 2)",Birds - Composite coatings - Copper compounds - Copper corrosion - Corrosion inhibitors - Electrolytic reduction - Graphene - Oxygen - Self-healing materials - Silica - Sodium chloride,,"Stimuli-responsive coatings can self-repair their own anticorrosion function in response to environmental changes, but they do not exhibit ideal long-term protective effect due to the lack of ability to regulate corrosive media, while this is vital to practical metal protection. Inspired by catalytic oxygen reduction, Cu-N center doped graphene oxide grafted with hollow periodic mesoporous organosilica nanocontainer (MBT@HPMO/Cu-GO) is synthesized via facile adsorption-pyrolysis strategy. Herein, introduced MBT@HPMO/Cu-GO is to simultaneously endow coatings with corrosive media shielding, active oxygen consumption and stimuli-responsive functions, thus 'three birds with one stone'. The target catalyst exhibits excellent oxygen depletion performance (half-wave potential of 0.85 V) and is uniformly dispersed in the coating to construct steric hindrance against corrosive media. This dual effect allows composite coating to maintain the excellent anticorrosion performance over 60 days under oxygen environment. In addition, MBT@HPMO/Cu-GO can release inhibitor at corrosion sites in response to environment change when coating is damaged, so as to restore the protective ability of coating, with impedance increased from 2.4 × 107 Ω·cm2 to 1.5 × 108 Ω·cm2. Such multifunctional coating exploration overcomes the protective limitation of current self-healing coatings and sheds light on the design of intelligent long-term anticorrosion coatings. © 2023 Elsevier B.V."
COMPENDEX,Conference article (CA),2014,"Experiences with formal engineering: Model-based specification, implementation and testing of a software bus at Neopost","Sijtema, M. (2); Belinfante, A. (1); Stoelinga, M.I.A. (1); Marinelli, L. (3)",Buses - Cost effectiveness - Formal methods - Cost engineering - Software testing,22,"We report on the actual industrial use of formal methods during the development of a software bus. During an internship at Neopost Inc., of 14 weeks, we developed the server component of a software bus, called the XBus, using formal methods during the design, validation and testing phase: we modeled our design of the XBus in the process algebra mCRL2, validated the design using the mCRL2-simulator, and fully automatically tested our implementation with the model-based test tool JTorX. This resulted in a well-tested software bus with a maintainable architecture. Writing the model (mdev), simulating it, and testing the implementation with JTorX only took 17% of the total development time. Moreover, the errors found with model-based testing would have been hard to find with conventional test methods. Thus, we show that formal engineering can be feasible, beneficial and cost-effective. The findings above, reported earlier by us in (Sijtema et al., 2011) [1], were well-received, also in industrially oriented conferences (Ferreira and Romanenko, 2010) [2] and [3]. In this paper, we look back on the case study, and carefully analyze its merits and shortcomings. We reflect on (1) the added benefits of model checking, (2) model completeness and (3) the quality and performance of the test process. Thus, in a second phase, after the internship, we model checked the XBus protocol - this was not done in [1] since the Neopost business process required a working implementation after 14 weeks. We used the CADP tool evaluator4 to check the behavioral requirements obtained during the development. Model checking did not uncover errors in model mdev, but revealed that model mdev was neither complete nor optimized: in particular, requirements to the so-called bad weather behavior (exceptions, unexpected inputs, etc.) were missing. Therefore, we created several improved models, checked that we could validate them, and used them to analyze quality and performance of the test process. Model checking was expensive: it took us approx. 4 weeks in total, compared to 3 weeks for the entire model-based testing approach during the internship. In the second phase, we analyzed the quality and performance of the test process, where we looked at both code and model coverage. We found that high code coverage (almost 100%) is in most cases obtained within 1000 test steps and 2 minutes, which matches the fact that the faults in the XBus were discovered within a few minutes. Summarizing, we firmly believe that the formal engineering approach is cost-effective, and produces high quality software products. Model checking does yield significantly better models, but is also costly. Thus, system developers should trade off higher model quality against higher costs. © 2013 Elsevier B.V. All rights reserved."
COMPENDEX,Conference article (CA),2013,Fifty shades of grey in SOA testing,"Wotawa, Franz (1); Schulz, Marco (1); Pill, Ingo (1); Jehan, Seema (1); Leitner, Philipp (2); Hummer, Waldemar (2); Schulte, Stefan (2); Hoenisch, Philipp (2); Dustdar, Schahram (2)",Black-box testing - Model checking - Information services - Service oriented architecture (SOA),4,"Testing is undisputedly a fundamental verification principle in the software landscape. Today's products require us to effectively handle and test huge, complex systems and in this context to tackle challenging traits like heterogeneity, distribution and controllability to name just a few. The advent of Service-Oriented Architectures with their inherent technological features like dynamics and heterogeneity exacerbated faced challenges, requiring us to evolve our technology. The traditional view of white or black box testing, for example, does not accommodate the multitude of shades of grey one should be able to exploit effectively for system-wide tests. Today, while there are a multitude of approaches for testing single services, there is still few work on methodological system tests for SOAs. In this paper we propose a corresponding workflow for tackling SOA testing and diagnosis, discuss SOA test case generation in more detail, and report preliminary research in that direction. © 2013 IEEE."
COMPENDEX,Conference article (CA),2014,"Software paradigms, assessment types and non-functional requirements in model-based integration testing: A systematic literature review","Häser, Florian (1); Felderer, Michael (1); Breu, Ruth (1)",Embedded systems - Model checking - Interoperability - Stochastic systems - Cyber Physical System - Integration - Safety testing,,"Context: In modern systems, like cyber-physical systems, where software and physical services are interacting, safety, security or performance play an important role. In order to guarantee the correct interoperability of such systems, with respect to functional and non-functional requirements, integration testing is an effective measure to achieve this. Model-based testing moreover not only enables early definition and validation, but also test automation. This makes it a good choice to overcome urgent challenges of integration testing. Objective: Many publications on model-based integration testing (MBIT) approaches can be found. Nevertheless, a study giving a systematic overview on the underlying software paradigms, measures for guiding the integration testing process as well as non-functional requirements they are suitable for, is missing. The aim of this paper is to find and synthesize the relevant primary studies to gain a comprehensive understanding of the current state of model-based integration testing. Method: For synthesizing the relevant studies, we conducted a systematic literature review (SLR) according to the guidelines of Kitchenham. Results: The systematic search and selection retrieved 83 relevant studies from which data has been extracted. Our review identified three assessment criteria for guiding the testing process, namely static metrics, dynamic metrics and stochastic &random. In addition it shows that just a small fraction considers non-functional requirements. Most approaches are for component-oriented systems. Conclusion: Results from the SLR show that there are two major research gaps. First, there is an accumulated need for approaches in the MBIT field that support non-functional requirements, as they are gaining importance. Second, means for steering the integration testing process, especially together with automation, need to evolve. Copyright 2014 ACM."
COMPENDEX,Conference article (CA),2016,Examining the co-evolution relationship between Simulink Models and their test cases,"Rapos, Eric J. (1); Cordy, James R. (1)",Testing - Model checking,7,"This paper presents an industrial case study that explores the co-evolution relationship between Matlab Simulink Models and their associated test suites. Through an analysis of differences between releases of both the models and their tests, we are able to determine what the relation between the model evolution and test evolution is, or if one exists at all. Using this comparison methodology, we present empirical results from a production system of 64 Matlab Simulink Models evolving over 9 releases. In our work we show that in this system there is a strong co-evolution relationship (a correlation value of r = 0:9; p © 2016 ACM."
COMPENDEX,Conference article (CA),2017,Test case/step minimization for visual programming language models and its application to space systems,"Santos Alarcon, Paulo Nolberto Dos (1); Santiago, Valdivino Alexandre De (1)",Specifications - Visual languages - Orbits - Software testing - Efficiency,16,"Visual Programming Languages have been widely used in the context of Model-Based Development, and they find a particular appeal for the design of satellite subsystems, such as the Attitude and Orbit Control Subsystem (AOCS) which is an extremely complex part of a spacecraft. The software testing community has been trying to ensure high quality products with as few defects as possible. Given that exhaustive generation and execution of software test cases are unfeasible in practice, one of the initiatives is to reduce the sets of test cases required to test a Software/System Under Test, while still maintaining the efficiency (ability to find product defects, code coverage). This paper presents a new methodology to generate test cases for Visual Programming Language models, aiming at minimizing the set of test cases/steps but maintaining efficiency. The approach, called specification Patterns, modified Condition/Decision coverage, and formal Verification to support Testing (PCDVT), combines the Modified Decision/Condition Coverage (MC/DC) criterion, Model Checking, specification patterns, and a minimization approach by identifying irreplaceable tests in a single method, taking advantage of the benefits of all these efforts in a unified strategy. Results showed that two instances of PCDVT presented a lower cost (smaller number of test steps) and, basically, the same efficiency (model coverage) if compared with a specialist ad hoc approach. We used the AOCS model of a Brazilian satellite in order to make the comparison between the methods. © Springer International Publishing AG 2017."
COMPENDEX,Conference article (CA),2016,Evolving the ETSI test description language,"Makedonski, Philip (1); Adamis, Gusztáv (2); Käärik, Martti (3); Kristoffersen, Finn (4); Zeitoun, Xavier (5)",Model checking - Modeling languages - Integration testing,16,"Increasing software and system complexity due to the integration of more and more diverse sub-systems presents new testing challenges. Standardisation and certification requirements in certain domains such as telecommunication, automotive, aerospace, and health-care contribute further challenges for testing systems operating in these domains. Consequently, there is a need for suitable methodologies, processes, languages, and tools to address these testing challenges. To address some of these challenges, the Test Description Language (TDL) has been developed at the European Telecommunications Standards Institute (ETSI) over the past three years. TDL bridges the gap between declarative test purposes and imperative test cases by offering a standardised language for the specification of test descriptions. TDL started as a standardised meta-model, subsequently enriched with a graphical syntax, exchange format, and a UML profile. A reference implementation of TDL has been developed as a common platform to accelerate the adoption of TDL and lower the barrier to entry for both end-users and tool-vendors. This article tells the story of the evolution of TDL from its conception. © Springer International Publishing AG 2016."
COMPENDEX,Journal article (JA),2023,Anticorrosion Coating with Heterogeneous Assembly of Nanofillers Modulated by a Magnetic Field,"Pengpeng, Lu (1); Xue, Fu (2); Xin, Li (2); Li, Xu (2); Fan, Yong (2); Zhao, Jie (1); Tian, Limei (1); Sun, Jiyu (1); Ren, Luquan (1)",Corrosion inhibitors - Corrosion rate - Magnetic fields - Magnetite - Mica - Nanomagnetics - Nanoparticles - Passivation,14,"An anticorrosive coating with randomly distributed passive barriers and regionally enriched active corrosion inhibitors is developed by integrating mica nanosheets (MNSs) and magnetic-responsive core-shell mesoporous nanoparticles with 2-mercaptobenzothiazole (Fe3O4@mSiO2/MBT) under magnetic field incubation. The bottom enriched Fe3O4@mSiO2/MBT rapidly releases the MBT to form a passivation layer on corrosion sites, enhancing the corrosion inhibition efficiency by 30.36% compared with the control (NP0.7EP-R). The impedance modulus |Z|0.01 Hz of the sample (NP0.7/MNS0.5/EP) increases by five orders of magnitude compared with that of its control (NP0.7/MNS0EP) after 30 days of corrosion immersion. NP0.7/MNS0.5/EP exhibited the lowest corrosion rate (3.984 × 10-5 mm/year) as compared to the other samples. Notably, the coating in a fractured state still maintains superior corrosion inhibition even after 40 day salt spray testing. The differentiated distribution of nanofillers was well confirmed by optical microscopy and SEM-EDS, and the synergistic effect of the active/passive integrated anticorrosive coating with merits of both comprehensive protection and fast responsiveness was systematically explored. © 2023 American Chemical Society."
COMPENDEX,Conference article (CA),2013,XSS pattern for attack modeling in testing,"Bozic, Josip (1); Wotawa, Franz (1)",Application programs - Program debugging - Software design - Model checking - Software testing,4,"Security issues of web applications are still a current topic of interest especially when considering the consequences of unintended behaviour. Such services might handle sensitive data about several thousands or millions of users. Hence, exploiting services or other undesired effects that cause harm on users has to be avoided. Therefore, for software developers of such applications one of the major tasks in providing security is to embed testing methodologies into the software development cycle, thus minimizing the subsequent damage resulting in debugging and time intensive upgrading. Model-based testing evolved as one of the methodologies which offer several theoretical and practical approaches in testing the system under test (SUT) that combine several input generation strategies like mutation testing, using of concrete and symbolic execution etc. by putting the emphasis on specification of the model of an application. In this work we propose an approach that makes use of an attack pattern model in form of a UML state machine for test case generation and execution. The paper also discusses the current implementation of our attack pattern testing tool using a XSS attack pattern and demonstrates the execution in a case study. © 2013 IEEE."
COMPENDEX,Conference article (CA),2023,Comparative study on model based test of automotive automatic control system,"Gao, Zhenhua (1)",Automation - Model checking - Software testing,5,"In today's automotive industry, due to the increasingly complex nature of ECUs, there is a great need to create a model that can be tested early to maintain functional functioning. However, there are not many solutions that teach us how to organize and run these tests for maximum coverage. This article evaluates prototype CANoe+, which maximizes the coverage of test cases generated using the CANoe and GraphWalker tools from the perspective of software developers and software testers. CANoe+ was significantly more effective than CANOE alone when the Mann-Whitney Wilcoxon statistical test was used in the experiment. Such experimental results add to the existing evidence and demonstrate the irreplaceable advantages of using model-based testing techniques such as C.. © 2023 IEEE."
COMPENDEX,Conference article (CA),2014,Co-evolution of model-based tests for industrial automotive software,"Rapos, Eric J. (1)",Model checking - Software testing,663,"Model-based software is evolving at an increasing rate, and this has an impact on model-based test suites, often causing unnecessary regeneration of tests. Our work proposes that by examining evolution patterns of Simulink automotive models and their associated test models we can identify the direct impacts of evolution on the tests. Using these evolution patterns, we propose the design of a process to ensure that as a Simulink model evolves its associated test models are automatically adapted, requiring minimal computation. This will lead to the development of a prototype tool capable of performing this model-based test co-evolution of tests alongside source models and presenting results to test engineers. © 2014 IEEE."
COMPENDEX,Journal article (JA),2022,High Moisture Stability for Enhanced Quality Perovskite Solar Cells Induced by Front and Back Layer Synergistic Passivation of Perovskite,"Gong, Xiaoli (1); Li, Haimin (1); Liu, Xingchong (1); Wang, Hanyu (1); Ni, Yafei (1); Lei, Yue (1); Zhou, Ruonan (1); Zou, Wenjing (1); Tang, Yanling (1); Liu, Shuqian (1)",Durability - Efficiency - Humidity control - Layered semiconductors - Lead compounds - Passivation - Perovskite solar cells - Stability,,"Moisture stability is one of the key factors that hinders the commercialization of perovskite solar cells (PSCs). Herein, a new method of front and back layer synergistic passivation of perovskite is investigated. On the front layer, porous PbI2 nanostructures are induced by N-tert-butyl-2-benzothiazolesulfenamide (TBBS), which is added into PbI2 precursor solution and thermally decomposed to tert-butylamine (TBA) and 2-mercaptobenzothiazole (2-MBT) during annealing process. TBA volatilization leaves voids to induce porous PbI2, promoting diffusion of organic salts, facilitating crystallization of perovskite. Thickness of perovskite with TBBS doping increases from 527.7 to 561.2 nm, and the champion power conversion efficiency (PCE) increases from 19.71% to 20.97%. On the back layer, hydrophobic hole transport material PTAA is introduced onto perovskite surface to fill cation vacancies. Eventually, the highest efficiency of 22.35% with outstanding moisture stability is achieved after front and back layer synergistic passivation, which can maintain 71.14% of its initial efficiency after 7 days under high relative humidity (RH = 65 ± 2%) in ambient conditions without any encapsulation, while the control one can only remain 12.38%. © 2022 Wiley-VCH GmbH."
COMPENDEX,Journal article (JA),2022,3D Finite Element Study of the Physiological Anchorage Control Concept on Anchorage Molars in Lingual Orthodontics,"Zhao, Jiayuan (1); Su, Majing (1); Zhao, Qian (1); Liu, Jiajie (1); Wang, Junbin (1); Wang, Junjie (1); An, Xiaoli (1)",Anchorages (foundations) - Finite element method - Physiology - Tensile strength - Tensile stress,,"Objective. To study the effect of the physiological anchorage control concept on anchorage molars in lingual and labial orthodontic techniques. Methods. Three-dimensional finite element models, including the right maxillary first molar, periodontal ligament, alveolar bone, and buccal tube, were established. The models were divided into the McLaughlin-Bennett-Trevisi (MBT™) straight-wire model with 0-degree maxillary first molar axial inclination and the physiologic anchorage Speewire system (PASS) model with -7-degree maxillary first molar axial inclination. Simulated sliding retraction forces (1 N, 1.5 N, and 2 N) were loaded on the buccal side and lingual side, and retraction forces (0.5 N, 0.75 N, and 1 N) were loaded on the buccal and lingual sides simultaneously. The displacements, principal stresses, and von Mises stresses of the periodontal ligament under different conditions were derived. Results. The anchorage molars showed different degrees of rotation, tipping, intrusion, and extrusion. As the force increased, these displacement trends also increased. The mesial displacement of the buccal + lingual force loading was less than that of the other two groups. Under the same force load method, the mesial displacement of the PASS group was less than that of the MBT group. Tilt movement increases the tensile stress of the distal cervical margin and root mesial apical third and the compressive stress of the mesial cervical margin and root distal apical third. The maximum stress of the periodontal ligament was less than that of the other two groups when the lingual force was loaded. Conclusion. The physiological anchorage control concept in lingual orthodontics provides better sagittal anchorage control than in labial orthodontics, but there is no significant difference numerically. Attention should be given to the control of torsion, torque, and arch width. Tilt movement increases the PDL stress of the cervical margin and root apical third. The sliding retraction force should be loaded lingually to maintain the force value of 1∼1.5 N. © 2022 Jiayuan Zhao et al."
COMPENDEX,Journal article (JA),2022,Can the biological stage of a mechanical–biological treatment plant that is designed for mixed municipal solid waste be successfully utilized for effective composting of selectively collected biowaste?,"Bernat, Katarzyna (1); Kulikowska, Dorota (1); Wojnowska-Baryla, Irena (1); Kamiska, Anna (2)",Biochemical engineering - Biogeochemistry - Biological materials - Composting - Municipal solid waste - Organic compounds - Rate constants - Recycling - Stabilization - Waste treatment,11,"Although the requirements for overall recycling rates can only be met when organic recycling is not overlooked, information is scarce regarding adaption to biowaste composting of existing mechanical–biological treatment (MBT) plants originally designed for stabilization of organic municipal solid waste (OFMSW). Thus, this study aimed to assess the suitability of the operational conditions in the biological part of a full-scale MBT plant now used for stabilization of OFMSW (working line: closed-module–covered-pile–open-pile) with a view to producing compost from biowaste. Temperatures above 75 °C were maintained in the closed module and reached again in the covered pile, indicating that intensive organic-matter mineralization occurred in both stages. In the covered pile, the temperature sharply decreased, indicating depletion of easily biodegradable organic matter. An aerobic 4-day respiration test (AT4) value below 10 mg O2/g dry matter, the cut-off for assessing compost stability, was obtained after 8 weeks. However, a high content of humic substances (HS), reflecting compost maturity, was obtained only after 120 days. The increase in HS content proceeded in two phases. In the first phase (45–84 day), the rate constant and the rate of HS formation were lower than in the second phase (84–120 day) (0.072 vs. 0.087 day−1, 1.97 vs. 3.06 mg C/(g organic matter·d)). All the above-mentioned indicators and the nutrient content (N, P, K, Mg, Ca) in the compost indicates that the biological stage of an MBT plant can successfully treat biowaste. This is in accordance with a circular economy and will contribute to increasing recycling rates. © 2022 The Authors"
COMPENDEX,Conference article (CA),2014,Powertrain control verification benchmark,"Jin, Xiaoqing (1); Deshmukh, Jyotirmoy V. (1); Kapinski, James (1); Ueda, Koichi (1); Butts, Ken (1)",Benchmarking - Powertrains - Industrial research - Temporal logic - Control systems - Model checking,10,"Industrial control systems are often hybrid systems that are required to satisfy strict performance requirements. Verifying designs against requirements is a difficult task, and there is a lack of suitable open benchmark models to assess, evaluate, and compare tools and techniques. Benchmark models can be valuable for the hybrid systems research community, as they can communicate the nature and complexity of the problems facing industrial practitioners. We present a collection of benchmark problems from the automotive powertrain control domain that are focused on verification for hybrid systems; the problems are intended to challenge the research community while maintaining a manageable scale. We present three models of a fuel control system, each with a unique level of complexity, along with representative requirements in signal temporal logic (STL). We provide results obtained by applying a state of the art analysis tool to these models, and finally, we discuss challenge problems for the research community. Copyright is held by the owner/author(s)."
COMPENDEX,Conference article (CA),2018,Managing aircraft by trajectory: Literature review and lessons learned,"Leiden, Kenneth (1); Fernandes, Alicia (1); Atkins, Stephen (1)",Air transportation - Air traffic control - Automation - Aircraft - Air navigation,9,"In order to realize the full potential of the Next Generation Air Transportation System (NextGen), improved management along planned trajectories between air navigation service providers (ANSPs) and system users (e.g., pilots and airline dispatchers) is needed. Automation improvements and increased data communications between aircraft and ground automation would make the concept of Management by Trajectory (MBT) possible. Key components of the MBT concept include: • The ability for air traffic controllers and managers to quickly generate, evaluate and implement changes to an aircraft's trajectory. • Imposing constraints on flight operator-preferred trajectories only to the extent necessary to maintain safe and efficient traffic flows. • A method for the exchange of trajectory information between ground automation systems and the aircraft that allows for trajectory synchronization and trajectory negotiation. MBT addresses shortfalls that remain in the Trajectory Based Operations (TBO) solution set, despite years of research into various aspects of transitioning from the current airspace environment to TBO. This paper provides findings and insights from a literature survey of TBO-related concepts and technologies. These insights can be applied to improve the feasibility and ultimate adoption of MBT. © 2018 IEEE."
COMPENDEX,Conference article (CA),2020,Model-based knock prediction and its stochastic feedforward compensation,"Li, Ruixue C. (1); Zhu, Guoming G. (2)",Stochastic models - Stochastic systems,6,"This article studies the correlation between incylinder mixture temperature at intake valve closing and the engine knock, along with cycle-to-cycle knock variability based on a knock predictive model developed earlier. Based on the correlated stochastic relationship, a feedforward knock limit control strategy is developed to reduce the knock cycle-to-cycle variability and maintain the knock mean-intensity within a desired up bound while keeping spark timing close to engine MBT (maximum brake torque) timing as close as possible. The proposed feedforward control strategy is evaluated based on the knock predictive model in terms of knock mean-intensity and standard deviation and demonstrated its capability of reducing the knock cycle-to-cycle variability under the knock intensity constraint. © 2020 IEEE."
COMPENDEX,Conference article (CA),2020,Improving Heavy Duty Natural Gas Engine Efficiency: A Systematic Approach to Application of Dedicated EGR,"Kocsis, Michael C. (1); Mitchell, Robert (1); Moiz, Ahmed Abdul (1); Kalaskar, Vickey (1); Williams, D. Ryan (1); Sjovall, Scott (1)",Carbon dioxide - Ignition - Gas engines - Natural gas,,"The worldwide trend of tightening CO2 emissions standards and desire for near zero emissions is driving development of high efficiency natural gas engines for a low CO2 replacement of traditional diesel engines. A Cummins Westport ISX12 G was previously converted to a Dedicated EGR® (D-EGR®) configuration with two out of the six cylinders acting as the EGR producing cylinders. Using a systems approach, the combustion and turbocharging systems were optimized for improved efficiency while maintaining the potential for achieving 0.02 g/bhp-hr NOX standards. A prototype variable nozzle turbocharger was selected to maintain the stock torque curve. The EGR delivery method enabled a reduction in pre-turbine pressure as the turbine was not required to be undersized to drive EGR. A high energy Dual Coil Offset (DCO®) ignition system was utilized to maintain stable combustion with increased EGR rates. High compression ratio, reduced squish pistons were designed to maintain MBT combustion phasing and fast burn rates along the torque curve. The final engine configuration was tested on the Heavy-Duty Supplemental Emissions Test (SET), a 13-mode steady-state engine dynamometer test. The engine was able to achieve a weighted average efficiency improvement of 12% over the baseline configuration with a peak BTE of 41.7%. © 2020 SAE International. All Rights Reserved."
COMPENDEX,Journal article (JA),2020,"Polymeric Films for the Encapsulation, Storage, and Tunable Release of Therapeutic Microbes","Qiu, Kunyu (1); Young, Isabella (1); Woodburn, Blaide M. (2); Huang, Yirui (1); Anselmo, Aaron C. (1)",Controlled drug delivery - Targeted drug delivery - Semiconducting films - Functional polymers - Bacteria,,"Microbe-based therapeutics (MBTs) are an emerging therapeutic modality for treating gastrointestinal infections and inflammatory bowel diseases. Current formulations for oral delivery of MBTs use capsules to achieve safe gastric transit, but oral formulations that control the spatiotemporal concentration of MBTs are yet to be developed, despite well-established connections between all therapeutics and their location, concentration, and distribution at sites of action. The development of a multi-functional polymer-based encapsulation system to formulate MBTs for enhanced storage and delivery through formulation of a model MBT, Lactobacillus casei ATCC393, is reported here. This approach enables the additive inclusion of excipients and polymers to grant specific functions, toward the development of a modular MBT platform. Through addition of established excipients, the formulation provides long-term storage of the encapsulated MBT. By adding higher molecular weight polymers, the release kinetics of the encapsulated MBTs can be modified. The inclusion of a mucoadhesive polymer significantly increases the adhesion force between the formulation and the intestinal tissue. Together, mucoadhesive and sustained release properties can be used to modulate the spatiotemporal concentration of MBTs. The formulation is compatible with standard oral capsules, thus maintaining existing clinical advantages of oral capsules while providing new functions from film encapsulation. © 2020 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim"
COMPENDEX,Journal article (JA),2018,An investigation on utilization of biogas and syngas produced from biomass waste in premixed spark ignition engine,"Kan, Xiang (1, 2); Zhou, Dezhi (3); Yang, Wenming (3); Zhai, Xiaoqiang (4); Wang, Chi-Hwa (2)",Computational fluid dynamics - Anaerobic digestion - Thermal efficiency,13,"Syngas and biogas are two typical biofuels generated from biomass wastes through gasification and anaerobic digestion processes, which are considered to be the future fuels for IC engines. In this work, the utilization of biogas and syngas produced from horticultural waste in a premixed spark ignition engine was investigated. An experimentally validated KIVA4-based CFD simulation integrated with CHEMKIN was performed to evaluate engine performance fuelled by syngas and biogas under both single and blended-fuel modes. Effects of ignition timing, hydrogen content in syngas and methane content in biogas on both energetic and environmental performance have been studied. The indicated thermal efficiency (ITE) of syngas fueled engine at wide open throttle (WOT) condition under maximum brake torque (MBT) operation was found to be higher than that of biogas fueled engine, meanwhile, with much lower NOx emission. In addition, a comparison of the engine performance between the single and blended-fuel modes under different syngas mixing ratios was conducted in terms of ITE and NOX emission. The results suggest that the utilization of syngas and biogas under blended-fuel mode can not only maintain the MBT energetic performance under single-fuel mode, but also show its potential in reducing NOx emission and lessening the tendency of knock onset. © 2017 Elsevier Ltd"
COMPENDEX,Conference proceeding (CP),2022,"RCIS-WS and RP 2022 - Joint Proceedings of RCIS 2022 Workshops and Research Projects Track, co-located with the 16th International Conference on Research Challenges inInformation Science, RCIS 2022",,,,The proceedings contain 19 papers. The topics discussed include: a proposal for measuring understandability of business process models; an approach for model based testing of augmented reality applications; a methodology for modeling digital transformation of organizations to integrate automated decision-making tools based on artificial intelligence; Electrospindle 4.0: towards zero defect manufacturing of spindles; ENACTEST - European innovation alliance for testing education; SCIBA - a prototype of the computerized cartographic system of an archaeological bibliography; the morphemic project and its unified user interface; and towards AIDOaRT objectives via joint model-based architectural effort.
COMPENDEX,Journal article (JA),2016,Plant Assimilation Kinetics and Metabolism of 2-Mercaptobenzothiazole Tire Rubber Vulcanizers by Arabidopsis,"LeFevre, Gregory H. (1, 2, 5); Portmann, Andrea C. (1, 2, 4); Müller, Claudia E. (1, 2); Sattely, Elizabeth S. (1, 3); Luthy, Richard G. (1, 2)",Biomolecules - Rubber - Soil conservation - Hydroponics - Metabolites - Water conservation - Seed,10,"2-Mercaptobenzothiazole (MBT) is a tire rubber vulcanizer found in potential sources of reclaimed water where it may come in contact with vegetation. In this work, we quantified the plant assimilation kinetics of MBT using Arabidopsis under hydroponic conditions. MBT depletion kinetics in the hydroponic medium with plants were second order (t1/2 = 0.52 to 2.4 h) and significantly greater than any abiotic losses (>18 times faster; p = 0.0056). MBT depletion rate was related to the initial exposure concentration with higher rates at greater concentrations from 1.6 μg/L to 147 μg/L until a potentially inhibitory level (1973 μg/L) lowered the assimilation rate. 9.8% of the initial MBT mass spike was present in the plants after 3 h and decreased through time. In-source LC-MS/MS fragmentation revealed that MBT was converted by Arabidopsis seedlings to multiple conjugated-MBT metabolites of differential polarity that accumulate in both the plant tissue and hydroponic medium; metabolite representation evolved temporally. Multiple novel MBT-derived plant metabolites were detected via LC-QTOF-MS analysis; proposed transformation products include glucose and amino acid conjugated MBT metabolites. Elucidating plant transformation products of trace organic contaminants has broad implications for water reuse because plant assimilation could be employed advantageously in engineered natural treatment systems, and plant metabolites in food crops could present an unintended exposure route to consumers. © 2015 American Chemical Society."
COMPENDEX,Journal article (JA),2022,Experimental investigation of water injection and spark timing effects on combustion and emissions of a hybrid hydrogen-gasoline engine,"Qian, Lijun (1, 2); Wan, Juye (1); Qian, Yejian (1); Sun, Yu (1); Zhuang, Yuan (1)",Gasoline - Direct injection - Timing circuits,,"This paper aimed to study the effects of water injection and spark timing on performance of a hybrid hydrogen-gasoline engine. For this aim, a modified four-cylinder turbocharged gasoline direct injection (GDI) engine equipped with hydrogen port injection and port water injection system was developed. In this study, the engine speed was maintained at 1300 rpm and the throttle opening of 30% with an excess air/fuel ratio of 1. The hydrogen energy percentage of 15%, water fuel mass ratio of 0.2 and 0.4 was added into the intake port. When the hydrogen energy percentage was changed, the gasoline fraction was also adjusted to keep the mixture at the stoichiometric. For all tested conditions, the spark timing was varied from 1 to 42°CA before top dead center (BTDC) with a fixed interval of 2°CA. Experimental results showed that maximum brake torque (MBT) spark timing varied when water and/or hydrogen is added. With hydrogen addition, the worsened combustion caused by water injection can be improved. Also, the variation of IMEP and COVIMEP versus spark timing became more insensitive with hydrogen addition. With water injection, the high NO emission caused by hydrogen addition can be largely reduced, however with side effect of higher HC and CO emissions. © 2022 Elsevier Ltd"
COMPENDEX,Journal article (JA),2015,"Effectiveness of 2-mercaptobenzothiazole, 8-hydroxyquinoline and benzotriazole as corrosion inhibitors on AA 2024-T3 assessed by electrochemical methods","Balaskas, Andronikos C. (1); Curioni, Michele (1); Thompson, George E. (1)",Aluminum alloys - Corrosion rate - Electrochemical impedance spectroscopy - Corrosion inhibitors - Corrosive effects - Reaction rates - Electrochemical corrosion - Corrosion protection - Polarization - Aluminum corrosion - Sodium chloride - Corrosion prevention - Dealloying - Potentiodynamic polarization,11,"In this study, the effectiveness of 2-mercaptobenzothiazole (2-MBT), 8-hydroxyquinoline and benzotriazole as corrosion inhibitors for AA 2024-T3 aluminium alloy was evaluated. The corrosion behaviour in the presence of each compound was investigated by image-assisted electrochemical noise analysis, electrochemical impedance spectroscopy, potentiodynamic polarization and the split cell technique. It was found that 2-MBT has superior inhibition properties compared with the other inhibitors. In particular, the specimens immersed in 3.5% NaCl in the presence of 2-MBT displayed high values of noise resistance that were maintained for over 400 h of testing, and high values of low-frequency impedance, measured after immersion for 24 h. The split cell technique and potentiodynamic polarization tests indicated that only 2-MBT decreases significantly both the anodic and the cathodic reaction rates. Scanning electron microscopy observations and energy dispersive X-ray measurements complement the findings from electrochemical measurements indicating that only 2-MBT protects the second phase particles, preventing dealloying, trenching and initiation of corrosion. © 2015 The Authors. Surface and Interface Analysis published by John Wiley & Sons Ltd."
COMPENDEX,Journal article (JA),2018,Effect of benzothiazole biocide on SRB-induced biocorrosion of hot-dip galvanized steel,"Eduok, Ubong (1); Faye, Omar (1); Szpunar, Jerzy (1)",Chlorine compounds - Microbial corrosion - Pitting - Sulfur compounds - Galvanizing - Steel corrosion - Biofilms,11,"In recent times, hot-dip galvanized steel (HDGS) products have been utilized in several engineering construction projects including architecture and structural fabrication due to their excellent durability and appearance. The galvanized Zn layer on steel is designed as a sacrificial anode against corrosion but it eventually fails due to biofouling and chloride-induced degradation. This work is designed to study the extent of damage caused by sulphate–reducing bacterial (SRB) colonization of HDGS surfaces, monitored within defined duration. The biocorrosion mechanism of the metal surface is elucidated by means of electrochemical assessments of associated liquid/metal interfacial phenomena evolved within the bacterial culture period and by monitoring the extent of surface pitting caused by associated biological activities of absorbed SRB cells. The rate of biocorrosion accompanying bacterial metabolic activities for test and control systems are further quantified by weight loss technique in the presence of a benzothiazole biocidal (MBT) additive capable of inhibiting biofilm growth at anaerobic conditions. MBT doped within the SRB-inoculated culture medium inhibited both SRB cellular growth and HDGS pitting, by forming passive antibiotic films on the metal surface. Since sustainable development is an important aspect of modern material designs and construction economics, this work provides a biofilm engineering background to safe monitoring of HDGS products. © 2018 Elsevier Ltd"
COMPENDEX,Journal article (JA),2015,Finger-vein recognition with modified binary tree model,"Liu, Tong (1); Xie, Jianbin (1); Yan, Wei (1); Li, Peiqin (1); Lu, Huanzhang (1)",Palmprint recognition - Anthropometry - Binary trees - Errors,9,"Finger-vein recognition is an increasingly promising biometric identification technology in terms of its high identification accuracy and prominent security performance. The main challenge faced by finger-vein recognition is the low recognition performance caused by segmentation error and local difference. To tackle this challenge, a finger-vein recognition method with modified binary tree (MBT) model is proposed in this paper. MBT model is used to describe the relationship and spatial structure of vein branches quantitatively. Based on the MBT model, four stages including rough selection, model correction, segment matching, and comprehensive judgment are presented to achieve a robust matching for finger-vein. Experiments demonstrate that the proposed method can boost the performance of finger-vein recognition that is degraded by segmentation error and local difference. While maintaining low complexity, the proposed method achieves 0.12 % equal error rate in the introduced dataset with 8,100 finger-vein images from 150 participants, which outperforms the state-of-the-art methods. © 2014, The Natural Computing Applications Forum."
COMPENDEX,Conference proceeding (CP),2019,"Proceedings - 13th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, ESEM 2019",,,,The proceedings contain 48 papers. The topics discussed include: framework code samples: how are they maintained and used by developers?; initial findings on the evaluation of a model-based testing tool in the test design process; do research and practice of code smell identification walk together? a social representations analysis; multivocal literature reviews in software engineering: preliminary findings from a tertiary study; software engineering research community viewpoints on rapid reviews; investigating the validity of ground truth in code reviewer recommendation studies; an evaluation of knowledge translation in software engineering; and on the relationship between coupling and refactoring: an empirical viewpoint.
COMPENDEX,Conference proceeding (CP),2018,"International Dagstuhl Seminar 16172 Machine Learning for Dynamic Software Analysis: Potentials and Limits, 2016",,,,The proceedings contain 9 papers. The special focus in this conference is on Dynamic Software Analysis: Potentials and Limits. The topics include: Model learning and model-based testing; testing functional black-box programs without a specification; active automata learning in practice: An annotated bibliography of the years 2011 to 2016; extending automata learning to extended finite state machines; Inferring FSM models of systems without reset; constraint-based behavioral consistency of evolving software systems; logic-based learning: Theory and application.
COMPENDEX,Journal article (JA),2023,Cycle-based LQG knock control using identified exhaust temperature model,"Tang, Jian (1); Dai, Wen (2); Archer, Chad (2); Yi, James (2); Zhu, Guoming (1)",Combustion knock - Feedback - Ignition - Religious buildings - Stochastic systems,14,"Spark ignition engines are often desired to be operated close to their knock borderline when MBT (maximum brake torque) cannot be achieved for optimizing combustion efficiency. Under this circumstance, a calibrated baseline spark timing, along with other control parameters such as intake and exhaust valve timings, is found for the engine control system to maximize fuel economy, and a stochastic scheme can be used for the control based on a large number of history data. However, cycle-to-cycle combustion variations still exist, resulting in a relatively conservative baseline control. To reduce cycle-to-cycle combustion variations, a real-time cycle-wised knock compensation is required. The correlation between exhaust temperature at the current cycle and knock intensity at the next cycle was found in our earlier research. In this paper, a cycle-to-cycle spark timing compensation scheme is developed based on the measured exhaust temperature when the engine is operated close to its knock borderline. To make model-based control possible, (Formula presented.) -Markov COVER (COVariance Equivalent Realization) system identification was used to obtain a linearized engine exhaust system model from incremental spark timing to associated exhaust temperature and knock intensity. Accordingly, a Linear–Quadratic–Gaussian (LQG) controller is designed, based on the identified model, to minimize the knock intensity fluctuations based on incremental exhaust temperature variation. The LQG control strategy was integrated with the existing entire knock control architecture, where the baseline spark timing is generated based on the offline machine training with an online updating scheme developed earlier, and demonstrated experimentally. Note that the cycle-based compensation only adds incremental spark timing to the baseline control so that knock combustion variations can be reduced. Three test scenarios are used to demonstrate the effectiveness of the proposed cycle-to-cycle compensation scheme when the engine is knock-limited. With the help of cycle-to-cycle based compensation, it was demonstrated that engine spark timing can be further advanced about one crank degree while maintaining the same knock intensity up-limit due to reduced knock combustion variations. Note that this is corresponding to 0.5%–1.0% fuel economy for this engine when it is operated under knock condition. © IMechE 2022."
COMPENDEX,Conference article (CA),2018,Comparative study on the performance of high temperature piezoelectric materials for structural health monitoring using ultrasonic guided waves,"Dhutti, A. (1); Tumin, S.A. (1); Gan, T.H. (1, 2); Kanfoud, J. (1); Balachandran, W. (1)",Guided electromagnetic wave propagation - Niobium compounds - Ultrasonic transducers - Defects - High temperature applications - Temperature - Ultrasonic testing - Frequency response - Lithium compounds - Piezoelectricity - Nondestructive examination - Piezoelectric materials - Piezoelectric transducers,11,"Focusing on predictive maintenance for optimised maintenance schedules, energy, aerospace, oil and gas industries are seeking technologies to enable in-service structural health monitoring (SHM) of their critical assets. Many of these critical assets such as turbine engine components and steamlines operate at elevated temperatures. For such high temperature (HT) applications, advanced piezoelectric materials are required for construction of ultrasonic transducers. Ultrasonic guided wave (UGW) technology has been widely used for pipeline inspection but HT ultrasonic transducers are required to enable in-service SHM of steamlines. The main criterion for HTUGW transducer design is an appropriate, temperature-stable ultrasonic response at target temperatures and a stable frequency response (in the range10-150 kHz for pipes of 2-48 inch diameter) to maintain defect sensitivity at HT. These transducers comprise piezoelectric materials of appropriate polarisation and dimensions, which, when excited with an electrical input, transmit the desired displacement patterns to the UGW modes in the structure being monitored. The detection of defects is indicated by changes in the received ultrasonic measurements. With temperature variations and over time, the dielectric, elastic and piezoelectric properties of the active material can diverge, leading to deviations in the ultrasonic response that may lead to false alarms. This comparative study investigates and compares the performance of four commercially available HT piezoelectric materials: PZT-5A, MBT, LiNbO3 and GaPO4. The maximum recommended operating temperatures for long-term use of these selected materials are 200°C, 400°C, 600°C and 720°C, respectively. Elastic, dielectric and material properties representing a figure of merit for piezo transducers are determined at increasing temperatures up to 600°C and over a period of 1000 hours. The findings from this work will enable transducer design to use the most appropriate piezoelectric material for the target temperature range. © APWSHM 2018. All rights reserved."
COMPENDEX,Conference article (CA),2018,"Understanding the Adverse Effects of Inlet Valve Deposits on SI Engine Operation, through a Novel Technique to Create Surrogate Deposits","Glawar, Andreas F. G. (1); Ziman, Pauline R. (2); Wu, Kaihua (3); Natarajan, Vinod (1); Wolgast, Eike J. (4); Dankers, Carolin (4); Groves, Adrian P. (2)",Efficiency - Combustion - Engine cylinders - Fuels,,"For gasoline spark ignition engines, port fuel injection (PFI) on a global basis remains the most common type of fuel delivery. When operated with lower quality fuels and lubricants, PFI engines are prone to suffering from the build-up of harmful deposits on critical engine parts including the inlet valves. High levels of inlet valve deposits (IVDs) have been associated with drivability issues like engine stumble and hesitation on sudden acceleration. Fuels formulated with the appropriate level of deposit control additive (DCA) can maintain engine cleanliness and even remove deposits from critical components. This study, involving a single cylinder research bench engine operated in PFI injection mode and heavily augmented with measurement equipment, aimed to gain a deeper understanding of the detrimental impacts of IVDs on engine efficiency and performance. Guided by 3D-scans of carbonaceous IVDs sourced from industry standard tests conducted per ASTM D5500, surrogate metal deposits were generated, utilizing the novel approach of powder-laser-cladding (PLC). The modified inlet valves were evaluated in the research engine across eight different speed load conditions including full-load. Using this approach and building on the results previously obtained on the industry standard Mercedes-Benz M111 bench engine, it was possible to quantify an increase of more than 3 crank angle degrees in combustion duration at a 95% level of statistical confidence, due to the presence of the simulated IVDs. Similarly, IVDs limited the quantity of air entering the cylinder which reduced power output of the engine for a given condition by 1.9% at a 99% level of statistical confidence. These effects were corroborated by supporting secondary metrics such as exhaust temperature increases and peak pressure reductions. Overall, it was shown that the presence of IVDs shifted the center of combustion away from the engine's optimum point for efficiency as defined by the maximum brake torque (MBT) spark timing. © 2018 Shell Global Solutions (US) Inc."
COMPENDEX,Conference article (CA),2015,"U-test: Evolving, modelling and testing realistic uncertain behaviours of cyber-physical systems","Ali, Shaukat (1); Yue, Tao (2)",Ability testing - Application programs - Risk assessment - Automation - Genetic algorithms - Cost effectiveness - Embedded systems - Model checking - Uncertainty analysis - Software testing,,"Uncertainty is intrinsic in Cyber-Physical Systems (CPSs) due to novel interactions of embedded systems, networking equipment, cloud infrastructures and humans. Our daily life has been increasing dependent on CPS applications in safety/mission critical domains such as healthcare, aerospace, oil/gas and maritime. For example, the National Institute of Standards and Technology (NIST) reported that direct CPS applications account for more than $32.3 trillions and expect to grow $82 trillions by 2025 (about half of the world economy). Expecting enormous dependence of our lives on CPSs in the future, dealing with uncertainty at an acceptable cost is vital to avoid posing undue threats to its users and environment. To ensure correct delivery of their functions at an acceptable cost even in the presence of uncertainty, CPSs must be reliable, robust, efficient, safe, and secure. All these properties are facets of a more general property often known as dependability. Improving system dependability first and foremost relies on the ability to verify and validate CPSs in a cost-effective manner and one way of achieving this is via systematic and automated Model-Based Testing (MBT): automated derivation of test cases from a behavioral model of a system. MBT supports rigorous, systematic, and automated testing, which eventually reduces the number of faults in the delivered systems and thus improves their quality. The goal of the U-Test project (a recently funded project under the EU Horizon2020 program (http://ec.europa.eu/programmes/horizon2020/) is to improve the dependability of CPSs, via cost-effective, model-based and search-based testing of CPSs under unknown risky uncertainty. Unknown uncertainty is the state of a CPS that can only be determined at the runtime as opposed to known uncertainty that is known at the design time and outcome from risky uncertainty is undesirable. To achieve our goal, we will advance the current state-of-art of testing CPSs by developing a novel solution based on sound theoretical foundation for uncertainty testing in the following steps: 1) Developing a light-weight modelling solution with rich formalism to support minimal modelling of known uncertainty with risk information; 2) Intelligently evolving known uncertainty models towards realistic and risky unknown uncertainty models (evolved models) using search algorithms (e.g., genetic algorithms mimicking natural selection); and 3) Automatically generating test cases from the evolved models to test a CPS under unknown uncertainty to ensure that the CPS continues to operate properly and possibly at a reduced quality of operation, rather than failing completely. © 2015 IEEE."
COMPENDEX,Journal article (JA),2015,Self healing coatings containing dual active agent loaded urea formaldehyde (UF) microcapsules,"Siva, T. (1); Sathiyanarayanan, S. (1)",Microstructure - Urea - Emulsification - Coremaking - Low carbon steel - Urea formaldehyde resins - Coatings - Emulsion polymerization - Formaldehyde - Encapsulation - Metabolism - Self-healing materials - Thermodynamic stability,11,Urea formaldehyde (UF) microcapsules loaded with linseed oil and mercaptobenzothiazole (MBT) as core materials have been synthesized by in situ emulsion polymerization. The capsules were characterized by FTIR. Surface morphology of microcapsules was analyzed using scanning electron microscope. The thermal stability of the microcapsules is in the temperature range around 600 °C as confirmed by TG analysis. The open circuit potential measurements have shown that the coatings with microcapsules maintain the potential in the noble range (-0.390 V vs. SCE) while the coating without microcapsules exhibit potentials in the active range. EIS studies at the artificial defect area have shown that the coating containing microcapsules is able to protect steel in neutral media since the impedance values remained at 107 Ω cm2 even after 15 days exposure where as the coatings without microcapsules have lost their protection ability. The self healing ability of the coating containing microcapsules was studied by SVET. © 2015 Elsevier B.V.
COMPENDEX,Conference proceeding (CP),2018,"Proceedings - International Symposium on Software Reliability Engineering, ISSRE",,,,The proceedings contain 23 papers. The topics discussed include: robust and rapid adaption for concept drift in software system anomaly detection; run-time reliability estimation of microservice architectures; online model-based testing under uncertainty; reliability evaluation of functionally equivalent Simulink implementations of a PID controller under silent data corruption; a natural language programming approach for requirements-based security testing; safe-AR: reducing risk while augmenting reality; worst-case execution time testing via evolutionary symbolic execution; evaluating regression test selection opportunities in a very large open-source ecosystem; and a study of regression test selection in continuous integration environments.
COMPENDEX,Conference article (CA),2016,Dependability verification of nanosatellite embedded software supported by a reusable test system,"Conceicao, Carlos A.P.L. (1); Mattiello-Francisco, Fatima (1); Batista, Carlos L.G. (1)",Interoperability - Nanosatellites - Computer software reusability - Software testing,7,"The use of CubeSats has increased tremendously over the 15 years since the standard creation because the low cost and reduced project development cycle. However, one of the most concerns in reducing a project delivery time is the collateral effect in test process, resulting in failures in the mission operation. This paper proposes the combined use of the Model-Driven Engineering (MDE) and Model-Base Testing (MBT) approaches in the Validation and Verification (V&V) process of a nanosatellite mission, focusing on an evolved way to measure the dependability requirements of the interoperable on-board software. The proposal counts on a reusable Test System (TS) based on Arduinos that are integrated in the engineering model of the Cubesat architecture via I2C bus. From the behavioral models of both the on-board computer and the satellite payloads, source code can be generated in order to be embedded in the Arduinos, prototyping in the TS the expected behavior of the interactions between the specified subsystems. These models can also be useful to derive test suites following a MBT approach. Thus the TS can support the execution of different test cases at different stages of development of the software intensive subsystems. The proposed V&V process is discussed in the context of a particular nanosatellite named NanosatC-Br2 under development at INPE. © 2016 IEEE."
COMPENDEX,Conference article (CA),2017,Cyclic Variations of Argon Power Cycle Engine with Fuel of Hydrogen,"Zhang, Erbao (1); Gong, Yinchun (1); Deng, Jun (1); Hu, Zongjie (1); Jiang, Chuanqian (1); Wu, Zhijun (1); Li, Liguang (1)",Diesel engines - Fuel injection - Mixtures - Fuels - Compression ratio (machinery) - Engine cylinders - Hydrogen,,"The work of this paper aimed at investigating the cyclic variations of argon power cycle engine with fuel of hydrogen at lean burn operating conditions. The engine had been modified based on a 0.402 L, single-cylinder diesel engine into spark ignition engine with a port fuel injection system. The influencing factors on the cyclic variations, such as ignition timing, engine speed and compression ratio, were tested in this study. In all tests, the throttle opened at 0%, and the excess oxygen coefficient was maintained at 2.3. The results showed that as the ignition timing retards, CoVPmax and CoV(dp/d)max of argon power cycle engine increased, while CoVIMEP decreased firstly and increased afterward. And there is an ignition timing to make the lowest CoVIMEP, which is not consistent with MBT. Under the condition of 900 rpm and MBT, when compression ratio increases from 5.6 to 6.9, both CoVIMEP and CoV(dp/d)max of argon power cycle engine were found to decrease, while CoVPmax was found to increase. The engine was also operated with Air-H2 mixtures and a compression ratio of 6.9 for comparison with the condition of argon cycle. For low speed and low load, it was found that Ar-O2-H2 mixtures result in higher IMEP, Pmax and (dp/d)max. The significant reduction in CoVIMEP, CoVPmax and CoV(dp/d)max indicated that better combustion stability could be achieved when running with Ar-O2-H2 mixtures. Moreover, for operation with Ar-O2-H2 mixtures, there was a very strong correlation between Pmax and its corresponding crank angle; and the absolute value of the correlation coefficient between the two was up to 0.926. Copyright © 2017 SAE International."
COMPENDEX,Conference article (CA),2014,Improving code coverage in android apps testing by exploiting patterns and automatic test case generation,"Amalfitano, Domenico (1); Amatucci, Nicola (1); Fasolino, Anna Rita (1); Gentile, Ugo (1); Mele, Gianluca (1); Nardone, Roberto (1); Vittorini, Valeria (1); Marrone, Stefano (2)",Reverse engineering - Automation - Model checking - Automatic test pattern generation - Software testing - Android (operating system) - Codes (symbols),6,"This work aims at defining a procedure and a set of mechanisms able to improve the quality of the code coverage in automated software reverse engineering processes, and specifically in automated GUI-driven testing of Android apps. Existing automated model-based testing techniques, based on reverse engineering, generate test cases which can be executed directly on the software's GUI. We propose to augment the code coverage of these techniques, by exploiting information from patterns, defined at different levels (application design, state-based model, interaction with Android services), and generating additional test cases that may in crease the coverage capability of GUI-Ripping based testing technique. The generation of the additional test cases is accomplished by defining an automatable procedure which exploits an existing GUI testing approach and a pattern based approach used in a different context. Copyright 2014 ACM."
COMPENDEX,Journal article (JA),2020,Stress tolerance assessment of dibenzyltoluene-based liquid organic hydrogen carriers,"Modisha, Phillimon (1); Bessarabov, Dmitri (1)",Economic and social effects - Hydrogen storage - Hydrogenation - Dehydrogenation - Hydrogen production - Molecules,9,"Hydrogen production from charged liquid organic hydrogen carrier (LOHC) systems is always a trade-off between the molecule's storage capacity and the stability over the numerous charging/discharging cycles. This is because deep dehydrogenation induces cracking of the molecule and thus the storage capacity could be compromised by partial dehydrogenation. It is crucial to optimize a hydrogenation system in order to avoid possible excessive exothermic temperature whilst maintaining a high degree of hydrogenation (doh). Pure dibenzyltoluene (H0-DBT) was hydrogenated up to 98% at a relatively low pressure of 15 barg (instead of at the frequently used 30-50 barg). We determined the number of cycles that a LOHC molecule can tolerate from the amount of by-products produced during each hydrogen charge/discharge cycle. If a limit of by-products is low such as in the case of toxic compounds if available, the LOHC duration of use will be short. A higher limit for LOHC based by-products suggests a long duration of usage. Furthermore, in the absence of any by-products, the LOHC molecule usage could be endless. This certainly depends on operating conditions, catalyst type and metal loading used. Accelerated stress tests were used to predict the time to failure of the LOHC molecule. Methane was obtained in the gas phase and the liquid by-products follow the increasing order: benzene © 2020 The Royal Society of Chemistry."
COMPENDEX,Journal article (JA),2015,A Structured Markov Chain Approach to Branching Processes,"Hautphenne, Sophie (1)",Chains - Probability distributions - Continuous time systems - Numerical methods - Markov processes,30,"Algorithmic methods developed for structured Markov chains are extended to solve questions about a class of continuous-time branching processes called Markovian binary trees (MBTs). This approach allows us to compute the extinction probability of an MBT, the distribution of its maximal size given extinction, the expected time until extinction, and the mean time until the tree reaches a given size. The resulting algorithms are efficient in practice for processes of relatively small dimension. The numerical methods are illustrated on MBTs evolving in a Markovian random environment. © 2015 Taylor and Francis Group, LLC."
COMPENDEX,Conference article (CA),2014,A heuristic-based approach to refactor crosscutting behaviors in UML state machines,"Khan, Muhammad Uzair (1); Iqbal, Muhamamd Zohaib (1, 2); Ali, Shaukat (3)",,4,"UML state machines are commonly used to model the state-based behavior of communication and control systems to support various activities such as test cases and code generation. Standard UML state machines are well suited to model functional behavior, however extra-functional behavior such as robustness and security can also be directly modeled on them, but this often results in cluttered models since extra-functional behaviors are often crosscutting. Such modeling crosscutting behavior directly on UML state machines is a common practice. Aspect-Oriented Modeling (AOM) allows systematically modeling of crosscutting behavior and has shown to provide a scalable solution in the recent years. However, due to lack of familiarity of AOM in both academic and industry, extra-functional behavior is often modeled directly on UML state machines and as a result those UML state machines are difficult to read and maintain. To improve the readability of already developed UML state machines and ease maintenance, we propose a set of heuristics, derived from two industrial cases studies, implemented in a tool to automatically identify commonly observed crosscutting behaviors in UML state machines and refactor them as Aspect State Machines. Such refactoring makes the state machines easier to maintain and comprehend. We present the results of applying our proposed heuristics to the existing UML state machines of two industrial case studies developed for model-based testing. © 2014 IEEE."
COMPENDEX,Conference article (CA),2014,Test process improvement with documentation driven integration testing,"Häser, Florian (1); Felderer, Michael (1); Breu, Ruth (1)",Process engineering - Iterative methods - Integration - Learning systems - Model checking - Problem oriented languages,6,"Improving the maturity of the test process in an organization, especially but not limited to integration testing, involves obstacles and risks, such as the additional work overhead of the new process. In addition, integration testing descriptions are often too technical not addressing the language needs of the domain. In research cooperations with companies from the insurance and banking domain it turned out that test descriptions and reports are one of the most useful testing artifacts, while doing adhoc testing. This paper presents a bottom up testing approach, which first helps the integration tester in producing a semi-formal test description and report, up to be an enabler for automatic model-based testing in the very end. The presented approach is based on a textual domain specific language that is able to evolve over time. This is done by analyzing the test descriptions and reports automatically with machine learning techniques as well as manually by integration testers. Often recurring test steps or used components are integrated into the test language, making it specially tailored for a specific organization. For each test step implementations can be attached, preparing it for the next iteration. In this paper the methodology and architecture of our integration testing approach are presented together with the underlying language concepts. © 2014 IEEE."
COMPENDEX,Conference article (CA),2017,"Impact of the Direct Injection of Liquid Propane on the Efficiency of a Light-Duty, Spark-Ignited Engine","Walls, Mark (1); Joo, Michael (1); Ross, Michael (1)",Brakes - Dynamometers - Temperature - Gasoline - Load testing - Propane - Thermal efficiency - Combustion,,"Liquefied petroleum gas (LPG) is commonly known as autogas when used as a fuel for internal combustion engines. In North America, autogas primarily consists of propane, but can contain small amounts of butane, methane and propylene. Autogas is not a new fuel for internal combustion engines, but as engine technology evolves, the properties of autogas can be utilized to improve engine and vehicle efficiency. With support from the Propane Education & Research Council (PERC), Southwest Research Institute (SwRI) performed testing to quantify efficiency differences with liquid autogas direct injection in a modern downsized and boosted direct-injected engine using the production gasoline fuel injection hardware. Engine dynamometer testing demonstrated that autogas produced similar performance characteristics to gasoline at part load, but could be used to improve brake thermal efficiency at loads above 9 bar Brake Mean Effective Pressure (BMEP). This improvement was attributed to the favorable octane rating of autogas. At higher loads, where the engine was knock limited on gasoline, autogas allowed operation at or near Minimum advance for Best Torque (MBT) timing and reduced the need for fuel enrichment to control exhaust temperature. At full load, the engine was capable of operating at a stoichiometric air-to-fuel ratio on autogas up to 4000 RPM, without exceeding the turbine inlet temperature limit. Copyright © 2017 SAE International."
COMPENDEX,Conference article (CA),2016,Design and evaluation of a grid reciprocation scheme for use in digital breast tomosynthesis,"Patel, Tushita (1); Sporkin, Helen (2); Peppard, Heather (3); Williams, Mark B. (1, 2, 3)",Image reconstruction - Power spectrum - Computerized tomography - X ray detectors - Scanning - Electric power transmission networks - Fourier transforms - Medical imaging,,"This work describes a methodology for efficient removal of scatter radiation during digital breast tomosynthesis (DBT). The goal of this approach is to enable grid image obscuration without a large increase in radiation dose by minimizing misalignment of the grid focal point (GFP) and x-ray focal spot (XFS) during grid reciprocation. Hardware for the motion scheme was built and tested on the dual modality breast tomosynthesis (DMT) scanner, which combines DBT and molecular breast tomosynthesis (MBT) on a single gantry. The DMT scanner uses fully isocentric rotation of tube and x-ray detector for maintaining a fixed tube-detector alignment during DBT imaging. A cellular focused copper prototype grid with 80 cm focal length, 3.85 mm height, 0.1 mm thick lamellae, and 1.1 mm hole pitch was tested. Primary transmission of the grid at 28 kV tube voltage was on average 74% with the grid stationary and aligned for maximum transmission. It fell to 72% during grid reciprocation by the proposed method. Residual grid line artifacts (GLAs) in projection views and reconstructed DBT images are characterized and methods for reducing the visibility of GLAs in the reconstructed volume through projection image flat-field correction and spatial frequency-based filtering of the DBT slices are described and evaluated. The software correction methods reduce the visibility of these artifacts in the reconstructed volume, making them imperceptible both in the reconstructed DBT images and their Fourier transforms. © 2016 SPIE."
COMPENDEX,Conference article (CA),2015,Characterization of High Efficiency Octane-On-Demand Fuels Requirement in a Modern Spark Ignition Engine with Dual Injection System,"Viollet, Yoann (1); Abdullah, Marwan (1); Alhajhouje, Abdullah (1); Chang, Junseok (1)",Carbon dioxide - Dual fuel engines - Ethers - Fuel economy - Fuels - Methanol - Naphthas - Refining,,"In a regulatory environment for spark ignition (SI) engines where the focus is continuously looking into improvements in fuel economy and reduction in noxious emissions, the challenges to achieve future requirements are utmost. To effectively reduce CO2 emissions on a well-to-wheel basis, future fuels enabling high efficiency SI engines will have to not only satisfy advanced engine requirements, i.e. high knock resistance, but also produce less CO2 emissions in the refinery. This paper describes how to characterize SI combustion's on-demand octane requirement with three different dual fuel configurations. Refinery naphtha was used for low octane component, and three oxygenates were used for high octane knock inhibiting component, such as, Methanol and Methyl tert-butyl ether (MTBE) and Ethyl tert-butyl ether (ETBE). Each low and high octane fuel was introduced via production gasoline direct injector (DI) and port fuel injector (PFI) in both configurations. It was found that benefits of the high RON component was amplified when it was introduced through DI while the low RON naphtha was injected in PFI. Methanol had been shown to be most effective through DI due to its high heat of evaporation and charge cooling. Consequently, the minimum methanol requirement to maintain MBT is less than MTBE or ETBE by volume. An optimum oxygenate map was found within a range of 1500 to 3500 rpm in speed and 1bar to 13bar Brake Mean Effective Pressure (BMEP) in load range conditions. As a result, the engine could operate solely with low octane naphtha, up to loads of 4-bar BMEP. At a high load condition, such as 1500 rpm, 13bar BMEP, minimum requirement of methanol was 43% of total dual fuel, while MTBE requirement was 74%. This was because methanol's charge cooling in the chamber had a dominant effect on knock suppression, although a RON of MTBE was higher than methanol. On the contrary, the total fuel consumption with naphtha-methanol was higher than one with naphtha-MTBE. This was due to the fact that methanol's lower energy value required more naphtha as the primary fuel source, while MTBE could contribute 1.5 times higher energy than methanol. Three fuels with both high and low octane properties could provide the optimum octane on an as-required basis. This can enable engine manufacturers to further downsize engines by means of an additional parameter to dynamically control the knock boundary. Copyright © 2015 SAE International."
COMPENDEX,Journal article (JA),2016,An experimental study on the potential usage of acetone as an oxygenate additive in PFI SI engines,"Meng, Lei (1, 3); Zeng, Chunnian (1); Li, Yuqiang (2); Nithyanandan, Karthik (3); Lee, Timothy H. (3); Lee, Chia-Fon (3, 4)",Byproducts - Fossil fuels - Ignition - Acetone - Fuel additives - Thermal efficiency - Alternative fuels - Ethanol fuels - Brakes - Gasoline - Internal combustion engines,,"To face the challenges of fossil fuel shortage and stringent emission norms, there is growing interest in the potential usage of alternative fuels such as bio-ethanol and bio-butanol in internal combustion engines. More recently, Acetone-Butanol-Ethanol (ABE), the intermediate product of bio-butanol fermentation, has been gaining a lot of attention as an alternative fuel. The literature shows that the acetone in the ABE blends plays an important part in improving the combustion performance and emissions, owing to its higher volatility. Acetone and ethanol are the low-value byproducts during bio-butanol production, so using acetone and ethanol as fuel additives may have both economic and environmental benefits. This study focuses on the differences in combustion, performance and emission characteristics of a port-injection spark-ignition engine fueled with pure gasoline (G100), ethanol-containing gasoline (E10 and E30) and acetone-ethanol-gasoline blends (AE10 and AE30 at A:E volumetric ratio of 3:1). The tests were conducted at 1200 RPM, under gasoline maximum brake torque (MBT) at 3 bar and 5 bar brake mean effective pressure (BMEP). Performance and emission data were measured under various equivalence ratios. Based on the comparison of combustion phasing, brake thermal efficiency, brake specific fuel consumption and various emissions of different fuels, it was found that using acetone as an oxygenate additive with the default ECU calibration (for gasoline) maintained the thermal efficiency and showed lower unburned HC emissions. © 2016 by the authors."
COMPENDEX,Conference proceeding (CP),2014,"Proceedings of the IEEE International Conference on Engineering of Complex Computer Systems, ICECCS",,,,The proceedings contain 29 papers. The topics discussed include: symbolic analysis of an electric vehicle charging protocol; an extended UML method for the verification of security protocols; DroidVault: a trusted data vault for Android devices; automatic defect categorization based on fault triggering conditions; design and analysis of security attacks against critical smart grid infrastructures; an adaptive auto-configuration tool for Hadoop; QScheduler: a tool for parallel query processing in database systems; deriving usage model variants for model-based testing: an industrial case study; a reference framework for the automated exploration of web applications; a thread behavior-based memory management framework on multi-core smartphone; evolving commitments for self-adaptive socio-technical systems; clause replication and reuse in incremental temporal induction; and generating SystemC implementations for clock constraints specified in UML/MARTE CCSL.
COMPENDEX,Conference article (CA),2016,Investigations on the effect of Piston Squish Area on Performance and Emission Characteristics of LPG fuelled Lean Burn SI Engine,"Krishnaiah, Ravi (1); Ekambaram, Porpatham (1); Jayapaul, Pradeep Bhasker (1)",Brakes - Liquefied petroleum gas - Gas emissions - Thermal efficiency - Compression ratio (machinery) - Engine cylinders - Engine pistons - Ignition,,"Experiments were conducted to study the effects of piston squish area on the performance, emissions and combustion characteristics of a Liquefied Petroleum Gas (LPG) fuelled lean burn Spark Ignition (SI) engine at a compression ratio of 10:1 under 25% throttle condition. A single cylinder diesel engine was modified to operate as LPG fuelled SI engine at a constant speed of 1500 rpm. The test was conducted at different squish areas of 25, 30, 35 and 40% on the total piston area at different equivalence ratios maintaining a constant squish velocity of 4 m/s. The ignition timing was set to MBT (Minimum advance for best Torque). It has been found that there is no significant change in lean limit in all the squish areas. An appreciable difference in brake power and brake thermal efficiency was noticed between equivalence ratios 0.7 and 0.9. The piston with 30% squish area showed good results followed by 25, 35 and 40%. The HC emission level at 30% squish area is less compared to other areas. At mid equivalence ratios the NO emission increased in 30% and 25% when compared to 35% and 40% due to increase in temperature and pressure. But NO emissions at maximum power in 25% and 30% were lower compared to 35% and 40% squish area. The Co-efficient of Variation (COV) of Indicated Mean Effective pressure (IMEP) increased sharply when the lean limit is reached. The heat release pattern shows that the rate of heat release was lowered at lean condition. On the whole it is concluded that 30% squish area is best suitable in terms of performance and emissions for LPG fuelled lean burn SI engine. Copyright © 2016 SAE International."
COMPENDEX,Conference proceeding (CP),2013,"Tests and Proofs - 7th International Conference, TAP 2013, Proceedings",,,,The proceedings contain 13 papers. The topics discussed include: incremental refinement checking for test case generation; time for mutants model-based mutation testing with timed automata; model-based testing for verification back-ends; a metric for testing program verification systems; test program generation for a microprocessor: a case-study; a declarative debugger for sequential Erlang programs; initiating a benchmark for UML and OCL analysis tools; speeding up algorithmic debugging using balanced execution trees; generating test suites with augmented dynamic symbolic execution; evaluation of ASLan mutation operators; solving constraints for generational search; and divergent quiescent transition systems.
COMPENDEX,Conference article (CA),2014,The effect of injection timing on the performance of natural gas with a high carbon dioxide (CO2) content in a Direct Injection (DI) gas engine,"Wasiu, Ayandotun B. (1); Aziz, A. Rashid A. (1); Heikal, Morgan R. (1)",Ignition - Proven reserves - Gases - Compressed natural gas - Engine cylinders - Timing circuits - Gas engines - Mixtures - Natural gas fields - Direct injection - Gas industry,,"This paper investigates the potential of utilizing raw natural gas from its reserves in Malaysia which are not harnessed because they are uneconomical due to the presence of large CO2 in it ranging from 25 to 89%. For this experimental work, the natural gas fields were simulated by adding CO 2 at 10%, 20%, 30%, and 40% to pure natural gas, and tested in a single-cylinder spark-ignition direct injection (DI) compressed natural gas (CNG) engine. Various injection timings were used, the injection duration was maintained, the ignition timing was adjusted to obtain the maximum brake torque (MBT), and at wide open throttle (WOT). The tests were carried out at a constant engine speed to study the effect of injection timings on performance and emission of the engine. Experimental results show that generally, the presence of high carbon dioxide content in the natural gas reduces the heating value of the mixture when compared with pure natural gas but however could be enhanced with injection timing in the range of 120 and 180 particularly for 20% CO 2 proportion in the mixture. There was a reduction in the NOX and CO emissions but an increase in the unburnt hydrocarbons (THC). © 2014 Owned by the authors, published by EDP Sciences."
COMPENDEX,Conference article (CA),2014,Ethanol optimized powertrain for medium duty trucks,"Perfetto, Anthony (1); Kameshwaran, Karthik (1); Geckler, Samuel C. (1); Zope, Rohit (1); Lana, Carlos (1); Kotharaman, Govindarajan (1)",Thermal efficiency - Trucks - Curve fitting - Diesel engines - Engine cylinders - Fuel consumption - Powertrains - Systems analysis - Brakes - Direct injection - Costs,,"This paper includes a detailed description of an optimized E85 concept engine developed for medium duty applications (Class 4-6 trucks) targeting ultra-low carbon emissions while maintaining power and delivering competitive cost of ownership. The engine is a light weight, downsized and boosted in-line 4 cylinder with air handling, fuel, and combustion systems designed specifically for E85 capability, producing high brake mean effective pressure (BMEP) at high thermal efficiency. It is integrated with a 12V start/stop system including a smart alternator for improved energy management. The present work demonstrates that even with the relative difference in the cost per heating value of fuel, using E85 can be upwards of 20% lower in cost while running middle to high loads. Combining high BMEP capability and a highly downsized engine displacement can ensure operation at high specific load where engine thermal efficiency is very good even in pickup-and-delivery type drive cycles. The performance characteristics of this engine were mapped using stoichiometric combustion and a three way catalyst for emissions control. The ability to perform at or close to Maximum Brake Torque (MBT) spark timing throughout the torque curve has been facilitated by an optimized combustion system design along with direct injection. The high engine thermal efficiency and knock tolerance of this combustion system eliminates the need for fuel enrichment anywhere in the engine map. © 2014 by ASME."
COMPENDEX,Journal article (JA),2015,Relating Knocking Combustions Effects to Measurable Data,"Corti, Enrico (1); Forte, Claudio (1); Bianchi, Gian Marco (1); Moro, Davide (1)",Combustion - Combustion knock - Computational fluid dynamics - Engine cylinders,12,"Knocking combustions heavily influence the efficiency of Spark Ignition engines, limiting the compression ratio and sometimes preventing the use of Maximum Brake Torque (MBT) Spark Advance (SA). A detailed analysis of knocking events can help in improving the engine performance and diagnostic strategies. An effective way is to use advanced 3D Computational Fluid Dynamics (CFD) simulation for the analysis and prediction of the combustion process. The standard 3D CFD approach based on RANS (Reynolds Averaged Navier Stokes) equations allows the analysis of the average engine cycle. However, the knocking phenomenon is heavily affected by the Cycle to Cycle Variation (CCV): the effects of CCV on knocking combustions are then taken into account, maintaining a RANS CFD approach, while representing a complex running condition, where knock intensity changes from cycle to cycle. The focus of the numerical methodology is the statistical evaluation of the local air-to-fuel and turbulence distribution at the spark plugs and their correlation with the variability of the initial stages of combustion. CFD simulations have been used to reproduce knock effect on the in-cylinder pressure trace. For this purpose, the CFD model has been validated, proving its ability to predict the combustion evolution with respect to SA variations, from non-knocking up to heavy knocking conditions. The CFD model allowed relating measurable data (i.e., the simulated cylinder pressure signal) to other factors, representative of the phenomena actually taking place during knocking combustions: for each cell used in the CFD simulation, information such as pressure, heat release, etc. are available and can be traced over the angular domain. Furthermore, the analysis refers to hundredths of engine cycles, leading to a comprehensive correlation between standard cylinder pressure-based knock indexes and other indexes (only available in a simulation environment), more representative of the actual knock intensity. Copyright © 2015 SAE International."
COMPENDEX,Conference article (CA),2014,Controlled assci with moderate auto-ignition for engine knock suppression in a GDI engine with high compression ratio,"A, Hui Liu (1); Wang, Zhi (1); Wang, Jianxin (1); Wang, Mengke (2); Yang, Wanli (2)",Fuel economy - Fuels - Ignition - Compression ratio (machinery) - Combustion knock - Direct injection - Diesel engines,,"This paper presents an experimental study on controlled ASSCI (Assisted Spark Stratified Compression Ignition) for engine knock suppression in a GDI engine with high compression ratio. The direct injection is used for forming desired stoichiometric stratified mixture at WOT condition without turbo-charging. The engine is filled with 20% cooled external EGR and the ignition timing is maintained at MBT point. The combustion characteristics of the desired stoichiometric stratified mixture show two-stage heat release, where the first stage is caused by spark ignition and the second stage is due to moderate auto-ignition. Compared with engine knock, the second stage heat release of controlled ASSCI shows smooth pressure curve without pressure oscillation. This is due to the low energy density mixture around the cylinder wall caused by cooled external EGR. The stratified mixture could suppress knock. Fuel economy and combustion characteristics of the baseline and the controlled ASSCI combustion were compared. The baseline GDI engine reaches a maximum of 8.9 bar BMEP with BSFC of 291 g/(kWh), the controlled ASSCI combustion achieves a maximum of 8.3 bar BMEP with BSFC of 256 g/(kWh), improving the fuel economy over 12% while maintaining approximately the same power. CA50 (the crank angle of 50% heat release) of the controlled ASSCI is detected at 8.4° CA ATDC, which is 17.4° CA advanced than that of the baseline while the combustion duration of the controlled ASSCI is 52.8 ° CA, 16.6° CA longer than that of the baseline caused by diluted mixture and two-stage heat release. The COV of the controlled ASSCI is 1.4%, 2.1% lower than that of the baseline. The peak pressure ( Pmax) and the maximum pressure rise rate (PRRmax) of the controlled ASSCI are 59.7 bar and 2.2 bar/° CA, 22.9 bar and 1.5 bar/ ° CA higher than that of the baseline respectively. The crank angle of P max and PRRmax of the controlled ASSCI are 11 ° CA ATDC and -1 ° CA ATDC, 15.4 ° CA and 17.2° CA earlier than that of the baseline. The results show that controlled ASSCI with two-stage heat releases is a potential combustion strategy to suppress engine knock while achieving high efficiency of the high compression ratio gasoline engine. © 2014 by ASME."
COMPENDEX,Journal article (JA),2021,An efficient assisted bidirectional glenn design with lowered superior vena cava pressure for stage-one single ventricle patients,"Jia, Dongjie (1); Peroni, Matthew (1); Khalapyan, Tigran (1); Esmaily, Mahdi (1)",Static Var compensators,,"Recently, the assisted bidirectional Glenn (ABG) procedure has been proposed as an alternative to the modified Blalock-Taussig shunt (mBTS) operation for neonates with single-ventricle physiology. Despite success in reducing heart workload and maintaining sufficient pulmonary flow, the ABG also raised the superior vena cava (SVC) pressure to a level that may not be tolerated by infants. To lower the SVC pressure, we propose a modified version of the ABG (mABG), in which a shunt with a slit-shaped nozzle exit is inserted at the junction of the right and left brachiocephalic veins. The proposed operation is compared against the ABG, the mBTS, and the bidirectional Glenn (BDG) operations using closed-loop multiscale simulations. Both normal (2.3 Wood units-m2) and high (7 Wood units-m2) pulmonary vascular resistance (PVR) values are simulated. The mABG provides the highest oxygen saturation, oxygen delivery, and pulmonary flow rate in comparison to the BDG and the ABG. At normal PVR, the SVC pressure is significantly reduced below that of the ABG and the BDG (mABG: 4; ABG: 8; BDG: 6; mBTS: 3 mmHg). However, the SVC pressure remains high at high PVR (mABG: 15; ABG: 16; BDG: 12; mBTS: 3 mmHg), motivating an optimization study to improve the ABG hemodynamics efficiency for a broader range of conditions in the future. Overall, the mABG preserves all advantages of the original ABG procedure while reducing the SVC pressure at normal PVR. Copyright © 2021 by ASME."
SCOPUS,Conference paper,2014,"Software paradigms, assessment types and non-functional requirements in model-based integration testing: A systematic literature review",Häser F.; Felderer M.; Breu R.,Assessment types; Model-based integration testing; Non-functional requirements; Systematic literature review,,"Context: In modern systems, like cyber-physical systems, where software and physical services are interacting, safety, security or performance play an important role. In order to guarantee the correct interoperability of such systems, with respect to functional and non-functional requirements, integration testing is an effective measure to achieve this. Model-based testing moreover not only enables early definition and validation, but also test automation. This makes it a good choice to overcome urgent challenges of integration testing. Objective: Many publications on model-based integration testing (MBIT) approaches can be found. Nevertheless, a study giving a systematic overview on the underlying software paradigms, measures for guiding the integration testing process as well as non-functional requirements they are suitable for, is missing. The aim of this paper is to find and synthesize the relevant primary studies to gain a comprehensive understanding of the current state of model-based integration testing. Method: For synthesizing the relevant studies, we conducted a systematic literature review (SLR) according to the guidelines of Kitchenham. Results: The systematic search and selection retrieved 83 relevant studies from which data has been extracted. Our review identified three assessment criteria for guiding the testing process, namely static metrics, dynamic metrics and stochastic &random. In addition it shows that just a small fraction considers non-functional requirements. Most approaches are for component-oriented systems. Conclusion: Results from the SLR show that there are two major research gaps. First, there is an accumulated need for approaches in the MBIT field that support non-functional requirements, as they are gaining importance. Second, means for steering the integration testing process, especially together with automation, need to evolve. Copyright 2014 ACM."
SCOPUS,Conference paper,2021,Model-Based Testing of Smart Home Systems Using EFSM and CEFSM,Albahli A.; Andrews A.,Black box testing; Communicating Extended Finite State Machines(CEFSM); Extended Finite State Machines(EFSM); Internet of Things(IoT); Model-Based Testing(MBT); Smart Homes,60,The Internet of Things (IoT) is the future of communication. The number of devices connected to the Internet has been growing dramatically and is expected to continue to grow. This increase causes a huge challenge for software quality. New testing approaches need to be developed and investigated to assure quality and efficiency of such systems. The main challenge with IoT devices is that their functionality varies greatly depending on the device type and how it is connected. In order to maintain feasibility of these functionality systems need to be modeled. This paper proposes a testing approach for a smart home system (SHS) modeled by Extended Finite State Machines (EFSMs) and Communicating Extended Finite State Machines (CEFSMs). We generate tests for individual devices in the SHS as well as the interaction between devices.
SCOPUS,Article,2022,ENHANCEMENT EFFICIENCY OF MICHELL-BANKI TURBINE USING NACA 6512 MODIFIED BLADE PROFILE VIA CFD,Galvis-Holguin S.; Sierra-Del Rio J.; Hincapié-Zuluaga D.,computational fluids dynamics; cross-flow turbine; efficiency; micro hydropower,130,"The small hydroelectric power plants (SHPP) are implemented in non-interconnected zones (NIZ) of developing countries. In which, the provision of electrical energy from the national interconnected system is not economically feasible. Therefore, in the literature, hydroelectric generation technologies have been implemented taking advantage of the energy available in the rivers. One of these technologies is the Michell-Banki type cross-flow turbines (MBT), which, despite having lower efficiencies than turbines such as Pelton and Francis, maintain their efficiency although fluctuations in site conditions. For this reason, different studies have been made to increase the efficiency of the MBT by making geometric modifications to both the nozzle and the rotor. The purpose of this study is to determine numerically the effect of the geometry of the blades that form the runner on the efficiency of Michell-Banki Turbine (MBT). For this, two (2) geometries were studied corresponding to a circular sector of a standard tubular profile and an airfoil NACA 6512 modified in curvature profile and chord length, according to the profile of the standard tubular blade. For this study, transient simulations for multiphase water-air flow were implemented using a k–ε turbulence model in the Ansys 2020R1® CFX software. The two (2) turbine models were configured to the same hydraulic conditions of head and volumetric flow corresponding to 0.5 m and 16.27 L/s, respectively. Variations in rotational speed were configured between 100 and 200 RPM with 20 RPM steps. It was found that using the modified 6512 hydrodynamic profile, at 140 RPM increased efficiency by 6 %, compared to the conventional tubular type blade geometry."
SCOPUS,Conference paper,2018,End-to-end Automatic Business Process Validation,Paiva A.C.R.; Flores N.H.; Faria J.P.; Marques J.M.G.,Business Process Testing; End-to-end Process Testing; Model Based Testing; Software Testing,60,"Business Process Testing is the act of validating that end-to-end transactions through enterprise systems continue to work correctly as the underlying packaged applications evolve. End-to-end automatic business process validation can be a challenging task, but an important way to check that business rules continue to work properly and that problems are detected and corrected as soon as possible. This paper presents the design of a test automation platform, ETAP-Pro, to test end-to-end business processes that aims to overcome some challenges in validating business processes."
SCOPUS,Conference paper,2019,The SAMBA approach for self-adaptive model-based online testing of services orchestrations,Leal L.; Ceccarelli A.; Martins E.,Model-based testing; Online testing; Self-adaptive; Service Oriented Architecture,60,"Service Oriented Architecture (SOA) is a popular design pattern that allows building applications composed of loosely-coupled and autonomous services. Such services may evolve and change at runtime, often outside the control of the owner of the application. Consequently, typical validation approaches, like offline testing performed before services deployment, are necessary but not sufficient: offline testing cannot assure the correct behavior of the SOA during its execution. To cope with the evolution of services and their orchestrations, in this paper we present a Self-Adaptive Model-BAsed online testing framework called SAMBA. SAMBA aims to assess the proper behavior of a SOA during its lifecycle executing model-based online testing at runtime, under the coordination of a MAPE-K control loop. SAMBA is assessed in a case study, where its detection capability are proved through functional, mutation and fault injection tests."
SCOPUS,Book chapter,2023,PLeTs: A software product line for testing tools,Rodrigues E.M.; Zorzo A.F.; Marchezan L.,,200,"Software testing is a fundamental activity to improve software quality. However, software testing is one of the most time-consuming and expensive activities of the software development process. Therefore, several testing tools have already been developed to support software testing, including tools for model-based testing (MBT), which is a testing technique to automatically generate testing artifacts from the system model. Some of the advantages of MBT include lower cost and less effort to generate test cases. Therefore, in the last years, a diversity of commercial, academic, and open-source tools to support MBT has been developed to better explore these advantages. Although several testing tools to support MBT were produced in the past years, most of them have been individually and independently developed based on a single architecture. Therefore, it is difficult to integrate, evolve, maintain, and reuse them. One strategy that could minimize those problems would be to use software product lines (SPL), which allows to systematically generating software products at lower costs, in a shorter time, and with higher quality. Therefore, this chapter presents an SPL for testing tools that support MBT (PLeTs (This chapter is an expanded version of previously published paper Rodrigues et al. (PLeTs - Test Automation using Software Product Lines and Model-Based Testing. In: Proceedings of the 22th International Conference on Software Engineering and Knowledge Engineering, pp. 483-488, 2010.))) and how we applied the Stereotype-based Management of Variability (SMarty) approach to manage and resolve the dependencies among components and to represent the variability in PLeTs architecture. PLeTs is a component-based SPL developed to automatically generate MBT tools. The PLeTs MBT tools aim to automate any of the test activities of MBT, for example, the generation of test cases and/or test scripts based on the system model. Basically, PLeTs MBT tools receive, as input, a system model, generate the test cases/scripts, execute the test scripts, and then compare the produced results. Since PLeTs can generate tools that connect to any commercial testing tool, a software testing team can incorporate their own testing tools, hence reducing effort and investment. In a nutshell, the main PLeTs goal is to reuse SPL artifacts and use existing testing tools to ease the development of new MBT tools."
SCOPUS,Conference paper,2023,Comparative study on model based test of automotive automatic control system,Gao Z.,CANoe; EUC; GraphWalker Tools; Maximum coverage,50,"In today's automotive industry, due to the increasingly complex nature of ECUs, there is a great need to create a model that can be tested early to maintain functional functioning. However, there are not many solutions that teach us how to organize and run these tests for maximum coverage. This article evaluates prototype CANoe+, which maximizes the coverage of test cases generated using the CANoe and GraphWalker tools from the perspective of software developers and software testers. CANoe+ was significantly more effective than CANOE alone when the Mann-Whitney Wilcoxon statistical test was used in the experiment. Such experimental results add to the existing evidence and demonstrate the irreplaceable advantages of using model-based testing techniques such as C.."
SCOPUS,Article,2017,Quasi dimensional numerical investigation of syngas fuelled engine operation: MBT operation and parametric sensitivity analysis,Shivapuji A.M.; Dasappa S.,Engine simulation; Non-regular fuel; Quasi-dimensional model; Syngas; Turbulent combustion; Williams-Klimov criterion,180,"The formulation, validation and application of a thermodynamic quasi dimensional SI engine simulation model for syngas fuelled operation is reported. The QD approach establishes the dependence of turbulent combustion on mixture thermo-physical properties and fluid domain average turbulent parameters, eliminating the need for domain discretization (unlike in multi-dimensional models). Turbulent combustion is formulated along the Eddy Entrainment Laminar Burn-up concept (Williams-Klimov criterion) with non-linear dependence of mixture burn rate on local laminar flame speed and turbulent intensity. Simulations are reported for syngas fuelled operation of a six cylinder engine and compared with experimental pressure and heat release traces. Maximum brake torque stoichiometric operation pressure and heat release simulation traces evolve closely with corresponding experimental traces. The simulation peak pressure and IMEP deviations remain within 5% and 2% of experimental traces respectively while the position of peak pressure overlaps within ±0.5 deg. Parametric sensitivity analysis for load, mixture quality and ignition timing are also addressed. Overall, the simulation results are in accordance within 5% of experimental results as long as the parametric variations are within the regimes of tuning of empirical correlations. In general, the versatility and robustness of quasi dimensional approach to simulate non-regular bio-derived alternative fuels is established."
SCOPUS,Conference paper,2019,A model-based approach to generate dynamic synthetic test data,Tan C.,Machine learning; Model-based testing; Test data generation,40,"Having access to high-quality test data is an important requirement to ensure effective cross-organizational integration testing in the Norwegian public sector. Evogent is a PhD project that aims to provide model-based solutions for generating synthetic test data that is statistically representative of real (reference) population, and is dynamic in the same way that the actual population is. This project is carried out in collaboration with the Modernization of the National Registry project (MF) within the Norwegian Tax Department, which serves as our case study. In this paper, we present a conceptual model and related algorithms for event generation."
SCOPUS,Conference paper,2018,Scrum and V lifecycle combined with model-based testing and model driven architecture to deal with evolutionary system issues,Essebaa I.; Chantit S.,Evolutionary system; Model Driven Architecture; Model transformations; Model-Based Testing; Scrum agile methodology; Test generation; V incremental lifecycle,150,"Model Driven Engineering (MDE) and Agile Methods (AM) are two principal domains that are in the way of improvement and evolution in order to facilitate the realisation of IT projects. However, these areas evolve separately despite the great number of researches that focus on improving realisation project’ techniques. Thus, our approach aims to provide an approach that combines two variants of MDE, Model Driven Architecture approach and Model-Based Testing with the V development lifecycle used in every scrum Agile Methodology sprint to deal with system evolution. In order to well illustrate this approach, we apply it on Rental Car Agency System realisation using Scrum methodology with some requirements’ evolution."
SCOPUS,Book chapter,2017,Challenges in communicating about defence research: Insight into defence research and development organisation's media strategy,Gupta R.K.,Defence research; DRDO; Electronic warfare; Guided missiles; MBT arjun; Media intervention; Public interaction,140,"Communicating nuances of defence science and technology to common man is not easy; communicating these and the challenges associated with the development of defence technologies to media was indeed a delicate and uphill task. In spite of numerous achievements and accomplishments that had been realised in the face of numerous stonewalling challenges, Defence Research and Development Organisation (DRDO) had to pass through a difficult phase marked by adverse publicity drawing flak from all quarters for a considerable period of time, damaging its reputation and denying its rightful place in the minds of masses and stakeholders. Insufficient and ineffective communication mainly due to absence of a single window agency with authorisation to interact with media was identified as the major cause for a widening perception gap resulting in the rapidly worsening situation. How creation of the Directorate of Public Interface, as the single window for interacting with media as well as public in general, and implementation of other well-planned communication strategies aimed at bridging perception gaps, particularly with media, helped in transforming DRDO's image to evolve into a major contributor to the nation building and a potential driver for national economy, attracting the country's best talent, is discussed along with a brief background of DRDO's evolution."
SCOPUS,Conference paper,2014,A heuristic-based approach to refactor crosscutting behaviors in UML state machines,Khan M.U.; Iqbal M.Z.; Ali S.,Aspect-Oriented Modeling; Heuristics; Model Refactoring; UML State machine,40,"UML state machines are commonly used to model the state-based behavior of communication and control systems to support various activities such as test cases and code generation. Standard UML state machines are well suited to model functional behavior, however extra-functional behavior such as robustness and security can also be directly modeled on them, but this often results in cluttered models since extra-functional behaviors are often crosscutting. Such modeling crosscutting behavior directly on UML state machines is a common practice. Aspect-Oriented Modeling (AOM) allows systematically modeling of crosscutting behavior and has shown to provide a scalable solution in the recent years. However, due to lack of familiarity of AOM in both academic and industry, extra-functional behavior is often modeled directly on UML state machines and as a result those UML state machines are difficult to read and maintain. To improve the readability of already developed UML state machines and ease maintenance, we propose a set of heuristics, derived from two industrial cases studies, implemented in a tool to automatically identify commonly observed crosscutting behaviors in UML state machines and refactor them as Aspect State Machines. Such refactoring makes the state machines easier to maintain and comprehend. We present the results of applying our proposed heuristics to the existing UML state machines of two industrial case studies developed for model-based testing."
SCOPUS,Article,2022,3D Finite Element Study of the Physiological Anchorage Control Concept on Anchorage Molars in Lingual Orthodontics,Zhao J.; Su M.; Zhao Q.; Liu J.; Wang J.; Wang J.; An X.,,,"Objective. To study the effect of the physiological anchorage control concept on anchorage molars in lingual and labial orthodontic techniques. Methods. Three-dimensional finite element models, including the right maxillary first molar, periodontal ligament, alveolar bone, and buccal tube, were established. The models were divided into the McLaughlin-Bennett-Trevisi (MBT™) straight-wire model with 0-degree maxillary first molar axial inclination and the physiologic anchorage Speewire system (PASS) model with -7-degree maxillary first molar axial inclination. Simulated sliding retraction forces (1 N, 1.5 N, and 2 N) were loaded on the buccal side and lingual side, and retraction forces (0.5 N, 0.75 N, and 1 N) were loaded on the buccal and lingual sides simultaneously. The displacements, principal stresses, and von Mises stresses of the periodontal ligament under different conditions were derived. Results. The anchorage molars showed different degrees of rotation, tipping, intrusion, and extrusion. As the force increased, these displacement trends also increased. The mesial displacement of the buccal + lingual force loading was less than that of the other two groups. Under the same force load method, the mesial displacement of the PASS group was less than that of the MBT group. Tilt movement increases the tensile stress of the distal cervical margin and root mesial apical third and the compressive stress of the mesial cervical margin and root distal apical third. The maximum stress of the periodontal ligament was less than that of the other two groups when the lingual force was loaded. Conclusion. The physiological anchorage control concept in lingual orthodontics provides better sagittal anchorage control than in labial orthodontics, but there is no significant difference numerically. Attention should be given to the control of torsion, torque, and arch width. Tilt movement increases the PDL stress of the cervical margin and root apical third. The sliding retraction force should be loaded lingually to maintain the force value of 1∼1.5 N. © 2022 Jiayuan Zhao et al."
SCOPUS,Conference paper,2018,Managing aircraft by trajectory: Literature review and lessons learned,Leiden K.; Fernandes A.; Atkins S.,,90,"In order to realize the full potential of the Next Generation Air Transportation System (NextGen), improved management along planned trajectories between air navigation service providers (ANSPs) and system users (e.g., pilots and airline dispatchers) is needed. Automation improvements and increased data communications between aircraft and ground automation would make the concept of Management by Trajectory (MBT) possible. Key components of the MBT concept include: • The ability for air traffic controllers and managers to quickly generate, evaluate and implement changes to an aircraft's trajectory. • Imposing constraints on flight operator-preferred trajectories only to the extent necessary to maintain safe and efficient traffic flows. • A method for the exchange of trajectory information between ground automation systems and the aircraft that allows for trajectory synchronization and trajectory negotiation. MBT addresses shortfalls that remain in the Trajectory Based Operations (TBO) solution set, despite years of research into various aspects of transitioning from the current airspace environment to TBO. This paper provides findings and insights from a literature survey of TBO-related concepts and technologies. These insights can be applied to improve the feasibility and ultimate adoption of MBT."
SCOPUS,Conference paper,2020,TesCaV: An Approach for Learning Model-Based Testing and Coverage in Practice,Marín B.; Alarcón S.; Giachetti G.; Snoeck M.,Coverage; Lessons learned; Model-Based Testing; Teaching/learning testing,160,"Academy and industry permanently remark the importance of software-testing techniques to improve software quality and to reduce development and maintenance costs. A testing method to be considered for this purpose is Model-Based Testing (MBT), which generates test cases from a model that represents the structure and the behavior of the system to be developed. The generated test suite is easier to maintain and adapt to changes in requirements or evolution of the developed system. However, teaching and learning MBT techniques are not easy tasks; students need to know the different testing techniques to assure that the requirements are fulfilled as well as to identify any failure in the software system modeled. In this work, we present TesCaV, an MBT teaching tool for university students, which is based on a model-driven technology for the automatic software generation from UML diagrams. TesCaV allows validating the test cases defined by students and graphically determines the level of testing coverage over the system modeled. Preliminary results show TesCaV as a promising approach for MBT teaching/learning processes."
SCOPUS,Article,2017,Uncertainty-wise evolution of test ready models,Zhang M.; Ali S.; Yue T.; Norgre R.,Belief model; Belief test ready model; Model evolution; Model-based testing; Uncertainty,200,"Context Cyber-Physical Systems (CPSs), when deployed for operation, are inherently prone to uncertainty. Considering their applications in critical domains (e.g., healthcare), it is important that such CPSs are tested sufficiently, with the explicit consideration of uncertainty. Model-based testing (MBT) involves creating test ready models capturing the expected behavior of a CPS and its operating environment. These test ready models are then used for generating executable test cases. It is, therefore, necessary to develop methods that can continuously evolve, based on real operational data collected during the operation of CPSs, test ready models and uncertainty captured in them, all together termed as Belief Test Ready Models (BMs) Objective Our objective is to propose a model evolution framework that can interactively improve the quality of BMs, based on operational data. Such BMs are developed by one or more test modelers (belief agents) with their assumptions about the expected behavior of a CPS, its expected physical environment, and potential future deployments. Thus, these models explicitly contain subjective uncertainty of the test modelers. Method We propose a framework (named as UncerTolve) for interactively evolving BMs (specified with extended UML notations) of CPSs with subjective uncertainty developed by test modelers. The key inputs of UncerTolve include initial BMs of CPSs with known subjective uncertainty and real data collected from the operation of CPSs. UncerTolve has three key features: 1) Validating the syntactic correctness and conformance of BMs against real operational data via model execution, 2) Evolving objective uncertainty measurements of BMs via model execution, and 3) Evolving state invariants (modeling test oracles) and guards of transitions (modeling constraints for test data generation) of BMs with a machine learning technique. Results As a proof-of-concept, we evaluated UncerTolve with one industrial CPS case study, i.e., GeoSports from the healthcare domain. Using UncerTolve, we managed to evolve 51% of belief elements, 18% of states, and 21% of transitions as compared to the initial BM developed in an industrial setting. Conclusion UncerTolve can successfully evolve model elements of the initial BM, in addition to objective uncertainty measurements using real operational data. The evolved model can be used to generate additional test cases covering evolved model elements and objective uncertainty. These additional test cases can be used to test the current and future deployments of a CPS to ensure that it will handle uncertainty gracefully during its operations."
SCOPUS,Conference paper,2019,Exploiting MDE for platform-independent testing of service orchestrations,Leal L.; Montecchi L.; Ceccarelli A.; Martins E.,Model-based testing; Model-driven engineering; Orchestration; SOA,40,"Service Oriented Architecture (SOA) is a common design pattern that allows building applications composed of several services. It promotes features as interoperability, scalability, and software reuse. Services composing a SOA system may evolve and change during runtime, often outside the control of the owner of the application, which makes the verification and validation processes complex. Among all the automated techniques to validate the behavior of an SOA application, is Model-Based Testing (MBT). MBT requires an accurate model of the application in order to generate suitable test cases. However, the intrinsic of a SOA application sets significant challenges to MBT effectiveness. In this paper we discuss the challenges in the testing of SOA applications, and we propose the use of Model-Driven Engineering (MDE) to improve the flexibility of testing tools. Finally, we outline our plan for realizing MDE-driven MBT within an existing online testing framework."
SCOPUS,Conference paper,2020,Tool Support for Refactoring Manual Tests,Bernard E.; Botella J.; Ambert F.; Legeard B.; Utting M.,Lightweight MBT; Machine Learning for Software Testing; Test suite minimisation; Test suite refactoring,110,"Manual test suites are typically described by natural language, and over time large manual test suites become disordered and harder to use and maintain. This paper focuses on the challenge of providing tool support for refactoring such test suites to make them more usable and maintainable. We describe how we have applied various machine-learning and NLP techniques and other algorithms to the refactoring of manual test suites, plus the tool support we have built to embody these techniques and to allow test suites to be explored and visualised. We evaluate our approach on several industry test suites, and report on the time savings that were obtained."
SCOPUS,Conference paper,2020,Model-based knock prediction and its stochastic feedforward compensation,Li R.C.; Zhu G.G.,,60,"This article studies the correlation between incylinder mixture temperature at intake valve closing and the engine knock, along with cycle-to-cycle knock variability based on a knock predictive model developed earlier. Based on the correlated stochastic relationship, a feedforward knock limit control strategy is developed to reduce the knock cycle-to-cycle variability and maintain the knock mean-intensity within a desired up bound while keeping spark timing close to engine MBT (maximum brake torque) timing as close as possible. The proposed feedforward control strategy is evaluated based on the knock predictive model in terms of knock mean-intensity and standard deviation and demonstrated its capability of reducing the knock cycle-to-cycle variability under the knock intensity constraint."
SCOPUS,Conference paper,2013,"Test generation for RTES from SysML models: Context, motivations and research proposal",Gauthier J.-M.,Model-Based Testing; Real-time systems; SysML,20,"This paper presents the context, motivations and perspectives of my PhD research about model-based testing for real-time and embedded systems using SysML. This work is based on an existing model-based approach which has been proposed during the VETESS project. This approach aims to generate tests for embedded systems. In this paper, we identify areas of improvement, which permit us to evolve the initial approach by taking into account real-time aspects. This will contribute to an automated Model-Based Testing toolchain for real-time and embedded systems. © 2013 IEEE."
SCOPUS,Conference paper,2020,Improving Heavy Duty Natural Gas Engine Efficiency: A Systematic Approach to Application of Dedicated EGR,Kocsis M.C.; Mitchell R.; Moiz A.A.; Kalaskar V.; Williams D.R.; Sjovall S.,,,"The worldwide trend of tightening CO2 emissions standards and desire for near zero emissions is driving development of high efficiency natural gas engines for a low CO2 replacement of traditional diesel engines. A Cummins Westport ISX12 G was previously converted to a Dedicated EGR® (D-EGR®) configuration with two out of the six cylinders acting as the EGR producing cylinders. Using a systems approach, the combustion and turbocharging systems were optimized for improved efficiency while maintaining the potential for achieving 0.02 g/bhp-hr NOX standards. A prototype variable nozzle turbocharger was selected to maintain the stock torque curve. The EGR delivery method enabled a reduction in pre-turbine pressure as the turbine was not required to be undersized to drive EGR. A high energy Dual Coil Offset (DCO®) ignition system was utilized to maintain stable combustion with increased EGR rates. High compression ratio, reduced squish pistons were designed to maintain MBT combustion phasing and fast burn rates along the torque curve. The final engine configuration was tested on the Heavy-Duty Supplemental Emissions Test (SET), a 13-mode steady-state engine dynamometer test. The engine was able to achieve a weighted average efficiency improvement of 12% over the baseline configuration with a peak BTE of 41.7%. © 2020 SAE International. All Rights Reserved."
SCOPUS,Conference paper,2018,"Understanding the Adverse Effects of Inlet Valve Deposits on SI Engine Operation, through a Novel Technique to Create Surrogate Deposits",Glawar A.F.G.; Ziman P.R.; Wu K.; Natarajan V.; Wolgast E.J.; Dankers C.; Groves A.P.,,,"For gasoline spark ignition engines, port fuel injection (PFI) on a global basis remains the most common type of fuel delivery. When operated with lower quality fuels and lubricants, PFI engines are prone to suffering from the build-up of harmful deposits on critical engine parts including the inlet valves. High levels of inlet valve deposits (IVDs) have been associated with drivability issues like engine stumble and hesitation on sudden acceleration. Fuels formulated with the appropriate level of deposit control additive (DCA) can maintain engine cleanliness and even remove deposits from critical components. This study, involving a single cylinder research bench engine operated in PFI injection mode and heavily augmented with measurement equipment, aimed to gain a deeper understanding of the detrimental impacts of IVDs on engine efficiency and performance. Guided by 3D-scans of carbonaceous IVDs sourced from industry standard tests conducted per ASTM D5500, surrogate metal deposits were generated, utilizing the novel approach of powder-laser-cladding (PLC). The modified inlet valves were evaluated in the research engine across eight different speed load conditions including full-load. Using this approach and building on the results previously obtained on the industry standard Mercedes-Benz M111 bench engine, it was possible to quantify an increase of more than 3 crank angle degrees in combustion duration at a 95% level of statistical confidence, due to the presence of the simulated IVDs. Similarly, IVDs limited the quantity of air entering the cylinder which reduced power output of the engine for a given condition by 1.9% at a 99% level of statistical confidence. These effects were corroborated by supporting secondary metrics such as exhaust temperature increases and peak pressure reductions. Overall, it was shown that the presence of IVDs shifted the center of combustion away from the engine's optimum point for efficiency as defined by the maximum brake torque (MBT) spark timing. © 2018 Shell Global Solutions (US) Inc."
SCOPUS,Conference paper,2014,Model-based testing of web service with EFSM,Sun F.; Liao L.; Zhang L.,Extended finite state machine (EFSM); Fault detection; Model-based testing; Web service,100,"Web services are becoming more and more widespread as an emerging technology; it is hard to test Web services because they are distributed applications with numerous aspects of runtime behavior that are different from typical applications. This paper presents a new approach to testing Web services based on Extended Finite State Machine (EFSM). Web Services Description Language (WSDL) file alone does not provide dynamic behavior information. This problem can be overcome by appending the formal model of EFSM to standard WSDL, we can generate a set of test cases which has a better test coverage than other methods. Moreover, a procedure for deriving an EFSM model from WSDL specification is provided to help a service provider augment, the EFSM model describing dynamic behaviors of the Web service. To show the efficacy of our approach, we applied our approach to Parlay-X Web services. In this way, we can test Web services with greater confidence in potential fault detection."
SCOPUS,Conference paper,2022,Testing Against Non-deterministic FSMs: A Probabilistic Approach for Test Suite Minimization,Kushik N.; Yevtushenko N.; López J.,Guaranteed fault coverage; Model based testing; Non-deterministic finite state machines; Probabilistic approach,70,"The paper is devoted to model based testing against non-deterministic specifications. Such test derivation strategies are well developed, for example against non-deterministic Finite State Machines, however the length of the corresponding test suite can be exponential w.r.t. the number of specification states. We therefore discuss how a test suite can be minimized or reduced when certain level of guarantee concerning its fault coverage is still preserved. The main idea behind the approach is to augment the specification by assigning probabilities for the non-deterministic transitions and later on evaluate the probability of each test sequence to detect the relevant faulty implementation. Given a probability P which is user-defined, we propose an approach for minimizing a given exhaustive test suite TS such that, it stays exhaustive with the probability no less than P."
SCOPUS,Conference paper,2015,Characterization of High Efficiency Octane-On-Demand Fuels Requirement in a Modern Spark Ignition Engine with Dual Injection System,Viollet Y.; Abdullah M.; Alhajhouje A.; Chang J.,,,"In a regulatory environment for spark ignition (SI) engines where the focus is continuously looking into improvements in fuel economy and reduction in noxious emissions, the challenges to achieve future requirements are utmost. To effectively reduce CO2 emissions on a well-to-wheel basis, future fuels enabling high efficiency SI engines will have to not only satisfy advanced engine requirements, i.e. high knock resistance, but also produce less CO2 emissions in the refinery. This paper describes how to characterize SI combustion's on-demand octane requirement with three different dual fuel configurations. Refinery naphtha was used for low octane component, and three oxygenates were used for high octane knock inhibiting component, such as, Methanol and Methyl tert-butyl ether (MTBE) and Ethyl tert-butyl ether (ETBE). Each low and high octane fuel was introduced via production gasoline direct injector (DI) and port fuel injector (PFI) in both configurations. It was found that benefits of the high RON component was amplified when it was introduced through DI while the low RON naphtha was injected in PFI. Methanol had been shown to be most effective through DI due to its high heat of evaporation and charge cooling. Consequently, the minimum methanol requirement to maintain MBT is less than MTBE or ETBE by volume. An optimum oxygenate map was found within a range of 1500 to 3500 rpm in speed and 1bar to 13bar Brake Mean Effective Pressure (BMEP) in load range conditions. As a result, the engine could operate solely with low octane naphtha, up to loads of 4-bar BMEP. At a high load condition, such as 1500 rpm, 13bar BMEP, minimum requirement of methanol was 43% of total dual fuel, while MTBE requirement was 74%. This was because methanol's charge cooling in the chamber had a dominant effect on knock suppression, although a RON of MTBE was higher than methanol. On the contrary, the total fuel consumption with naphtha-methanol was higher than one with naphtha-MTBE. This was due to the fact that methanol's lower energy value required more naphtha as the primary fuel source, while MTBE could contribute 1.5 times higher energy than methanol. Three fuels with both high and low octane properties could provide the optimum octane on an as-required basis. This can enable engine manufacturers to further downsize engines by means of an additional parameter to dynamically control the knock boundary. Copyright © 2015 SAE International."
SCOPUS,Conference paper,2014,Improving code coverage in android apps testing by exploiting patterns and automatic test case generation,Amalfitano D.; Amatucci N.; Fasolino A.R.; Gentile U.; Mele G.; Nardone R.; Vittorini V.; Marrone S.,Automatic test case generation; GUI testing; Mobile applications; Model driven engineering; Reverse engineering,60,"This work aims at defining a procedure and a set of mechanisms able to improve the quality of the code coverage in automated software reverse engineering processes, and specifically in automated GUI-driven testing of Android apps. Existing automated model-based testing techniques, based on reverse engineering, generate test cases which can be executed directly on the software's GUI. We propose to augment the code coverage of these techniques, by exploiting information from patterns, defined at different levels (application design, state-based model, interaction with Android services), and generating additional test cases that may in crease the coverage capability of GUI-Ripping based testing technique. The generation of the additional test cases is accomplished by defining an automatable procedure which exploits an existing GUI testing approach and a pattern based approach used in a different context. Copyright 2014 ACM."
SCOPUS,Conference paper,2016,Model-Based continuous verification,Fan L.; Chen S.; Xu L.; Yang Z.; Zhu H.,Consistency checking; Linear temporal logic; Model checking; Model-based testing,80,"Model-based engineering has emerged as a key set of technologies to engineer software systems. While system source code is expected to match with the designed model, legacy systems and workarounds during deployment would undoubtedly change the source code, making the actual running implementation mismatch with its model. Such mismatch poses a challenge of maintaining the conformance between the model and the corresponding implementation. Prior techniques, such as model checking and model-based testing, simply assumed the sole correctness of the model or the implementation, which is naive since they both could contain correct information (e.g. representing either the software requirements or the actual running environment).In this paper, we aim to address this problem through model-based continuous verification (ConV), an iterative verification process that links the traditional model checking phase with the software testing phase to a feedback loop, ensuring the conformance between the system model and its implementation. It allows to execute the abstract test cases over the implementation through a semi-automatic binding mechanism to guide the update of the code, and augments system properties from the actually running system to guide the update of the model through model checking. Based on these techniques, we implemented Eunomia, a conformance verification system, to support the continuous verification process. Experiments show that Eunomia can effectively detect and locate inconsistencies both in the model and the source code."
SCOPUS,Conference paper,2021,Towards an automatic model-based scrum methodology,Chantit S.; Essebaa I.,Agile methodologies; Model driven architecture; Model driven engineering; Model-based testing; Scrum; V development life cycle,60,"Software systems evolve continuously and must be developed quickly to fit user requirements and new advances in technology. This has led the software engineering to propose several methods and approaches to overcome the development and maintenance of these software systems. In this regard, Agile Methodologies and Model-Driven Engineering (MDE) are two main approaches that have emerged in recent years and suggest a solution to some of the issues associated with Software systems developments. MDE focuses on software reuse through models and on generative approaches based on separation of concerns whereas Agile Methods promote the use of simpler models and best practices for programming to achieve quick feedback from clients within a development process. However, these two approaches have evolved separately and there are only a few works related to their combination. This paper presents a customized V development life cycle based on models which combines the two MDE variants: The MDA approach in the V left branch with the MBT approach to generate tests of the V right branch. In addition, we integrate this customized V life cycle in the agile Scrum methodology to facilitate the management of each Scrum sprint."
SCOPUS,Conference paper,2018,SimEvo: A Toolset for Simulink Test Evolution & Maintenance,Rapos E.J.; Cordy J.R.,Model Based Testing; Simulink; Test Evolution; Test Harness Generation; Test Maintenance; Tool Development,60,"As Simulink models evolve and change during development, test evolution and maintenance can often be overlooked. SimEvo provides a toolset to assist Simulink developers in coevolving test harnesses and test cases alongside their source models. Primarily a collection of testing tools, SimEvo combines the impact analysis features of the SimPact impact analysis tool to identify instances of necessary test case changes and potentially affected blocks, with the SimTH test harness generator to automatically determine if changes need to be made to the test harness model, and automatically generate a new one if necessary. This paper examines the implementation of SimTH, its integration with SimPact into the workbench SimEvo, and an overall analysis of the contributions of the toolset."
SCOPUS,Conference paper,2018,Model based testing of cyber-physical systems,Khoo T.P.,Cyber-Physical Systems; Model Based Testing; Testing framework,130,"Black-box testing has been extensively applied to test models of Cyber-Physical systems (CPS) since these models are not often amenable to static and symbolic testing and verification. Black-box testing, however, requires to execute the model under test for a large number of candidate test inputs. This poses a challenge for a large and practically-important category of CPS models, known as compute-intensive CPS (CI-CPS) models, where a single simulation may take hours to complete. We propose a novel approach, namely ARIsTEO, to enable effective and efficient testing of CI-CPS models. Our approach embeds black-box testing into an iterative approximation-refinement loop. At the start, some sampled inputs and outputs of the CI-CPS model under test are used to generate a surrogate model that is faster to execute and can be subjected to black-box testing. Any failure-revealing test identified for the surrogate model is checked on the original model. If spurious, the test results are used to refine the surrogate model to be tested again. Otherwise, the test reveals a valid failure.We evaluated ARIsTEO by comparing it with S-Taliro, an open-source and industry-strength tool for testing CPS models. Our results, obtained based on five publicly-available CPS models, show that, on average, ARIsTEO is able to find 24% more requirements violations than S-Taliro and is 31% faster than S-Taliro in finding those violations. We further assessed the effectiveness and efficiency of ARIsTEO on a large industrial case study from the satellite domain. In contrast to S-Taliro, ARIsTEO successfully tested two different versions of this model and could identify three requirements violations, requiring four hours, on average, for each violation."
SCOPUS,Conference paper,2016,Model based testing of satellite on-board software - An industrial use case,Herpel H.J.; Kerep M.; Li J.; Xie J.; Johansen B.; Kvinnesland K.; Krueger S.; Barrios P.,,,"In this paper we describe a Model Based approach to testing of on-board software and compare it with traditional validation strategy currently applied to satellite software. The major problems that software engineering will face over at least the next two decades are increasing application complexity driven by the need for autonomy and serious application robustness. In other words, how do we actually get to declare success when trying to build applications one or two orders of magnitude more complex than today's applications. To solve the problems addressed above the software engineering process has to be improved at least for two aspects: 1) Software design and 2) Software testing. The software design process has to evolve towards model-based approaches with extensive use of code generators. Today, testing is an essential, but time and resource consuming activity in the software development process. Generating a short, but effective test suite usually requires a lot of manual work and expert knowledge. In a model-based process, among other subtasks, test construction and test execution can also be partially automated. The basic idea behind the presented study was to start from a formal model (e.g. State Machines), generate abstract test cases which are then converted to concrete executable test cases (input and expected output pairs). The generated concrete test cases were applied to an on-board software. Results were collected and evaluated wrt. applicability, cost-efficiency, effectiveness at fault finding, and scalability. © 2016 IEEE."
SCOPUS,Conference paper,2018,A model-based test case management approach for integrated sets of domain-specific models,Proll R.; Bauer B.,Model-Based Testing; Test Case Management; Test Model Scoping; Test Prioritization; Test Selection; Test Suite Reduction,100,"Due to rapid improvements in the area of embedded processing hardware, the complexity of developed systems constantly increases. In order to ensure a high quality level of such systems, related quality assurance concepts have to evolve. The introduction of Model-Based Testing (MBT) approaches has shown promising results by automating and abstracting multiple activities of the software testing life cycle. Nevertheless, there is a strong need for approaches supporting scoped test models, i.e. subsets of test cases, reflecting specific test purposes driven by risk-oriented development strategies. Therefore, we developed an integrated and model-based approach supporting test case management, which incorporates the beneficial aspects of abstract development methodologies with predominant research for test case management in non-model-based scenarios. Based on a new model artifact, the integration model, tasks like cross-domain information mapping and the integration of domain-specific KPIs derived by analyses favor the subsequently applied constraint-based mechanism for test case management. Further, a prototypical implementation of these concepts within the Architecture And Analysis Framework (A3F) is elaborated and further evaluated based on representative application scenarios. A comparative view on related work leads to a conclusive statement regarding our future work."
SCOPUS,Conference paper,2020,Supporting efficient test automation using lightweight MBT,Bernard E.; Ambert F.; Legeard B.,,110,"The Agile and DevOps transformation of software development practices enhances the need for increased automation of functional testing, especially for regression testing. This poses challenges both in the effort that needs to be devoted to the creation and maintenance of automated test scripts, and in their relevance (i.e. their alignment with business needs). Test automation is still difficult to implement and maintain and the return on investment comes late while projects tend to be short. In this context, we have experimented a lightweight model-based test automation approach to address both productivity and relevance challenges. It integrates test automation through a simple process and tool-chain experimented on large IT projects."
SCOPUS,Article,2022,High Moisture Stability for Enhanced Quality Perovskite Solar Cells Induced by Front and Back Layer Synergistic Passivation of Perovskite,Gong X.; Li H.; Liu X.; Wang H.; Ni Y.; Lei Y.; Zhou R.; Zou W.; Tang Y.; Liu S.,perovskite solar cells; porous PbI<sub>2</sub>; stability; synergistic passivation,,"Moisture stability is one of the key factors that hinders the commercialization of perovskite solar cells (PSCs). Herein, a new method of front and back layer synergistic passivation of perovskite is investigated. On the front layer, porous PbI2 nanostructures are induced by N-tert-butyl-2-benzothiazolesulfenamide (TBBS), which is added into PbI2 precursor solution and thermally decomposed to tert-butylamine (TBA) and 2-mercaptobenzothiazole (2-MBT) during annealing process. TBA volatilization leaves voids to induce porous PbI2, promoting diffusion of organic salts, facilitating crystallization of perovskite. Thickness of perovskite with TBBS doping increases from 527.7 to 561.2 nm, and the champion power conversion efficiency (PCE) increases from 19.71% to 20.97%. On the back layer, hydrophobic hole transport material PTAA is introduced onto perovskite surface to fill cation vacancies. Eventually, the highest efficiency of 22.35% with outstanding moisture stability is achieved after front and back layer synergistic passivation, which can maintain 71.14% of its initial efficiency after 7 days under high relative humidity (RH = 65 ± 2%) in ambient conditions without any encapsulation, while the control one can only remain 12.38%. © 2022 Wiley-VCH GmbH."
SCOPUS,Article,2018,An investigation on utilization of biogas and syngas produced from biomass waste in premixed spark ignition engine,Kan X.; Zhou D.; Yang W.; Zhai X.; Wang C.-H.,Biogas; Blended fuel; Experiment; KIVA-CHEMKIN; SI engine; Syngas,130,"Syngas and biogas are two typical biofuels generated from biomass wastes through gasification and anaerobic digestion processes, which are considered to be the future fuels for IC engines. In this work, the utilization of biogas and syngas produced from horticultural waste in a premixed spark ignition engine was investigated. An experimentally validated KIVA4-based CFD simulation integrated with CHEMKIN was performed to evaluate engine performance fuelled by syngas and biogas under both single and blended-fuel modes. Effects of ignition timing, hydrogen content in syngas and methane content in biogas on both energetic and environmental performance have been studied. The indicated thermal efficiency (ITE) of syngas fueled engine at wide open throttle (WOT) condition under maximum brake torque (MBT) operation was found to be higher than that of biogas fueled engine, meanwhile, with much lower NOx emission. In addition, a comparison of the engine performance between the single and blended-fuel modes under different syngas mixing ratios was conducted in terms of ITE and NOX emission. The results suggest that the utilization of syngas and biogas under blended-fuel mode can not only maintain the MBT energetic performance under single-fuel mode, but also show its potential in reducing NOx emission and lessening the tendency of knock onset."
SCOPUS,Article,2016,Petri net based test case generation for evolved specification,Ding Z.; Jiang M.; Chen H.; Jin Z.; Zhou M.,evolved specification; Petri net; reachability graph; regression testing; test case generation,,"Model-based testing can use a model to test a concrete program’s implementation. When the model is changed due to the evolution of the specification, it is important to maintain the test suites up to date, such that it can be used for regression testing. A complete regeneration of the whole test suite from the new model, although inefficient, is still frequently used in practice. To address this problem effectively, we propose a test case reusability analysis technique to identify reusable test cases of the original test suite based on graph analysis, such that we can generate new test cases to cover only the change-related parts of the new model. The Market Information System (MIS) is employed to demonstrate the feasibility and effectiveness of the proposed method. Our experimental results show that the use of our method saves about 31.5% test case generation cost. © 2016, Science China Press and Springer-Verlag Berlin Heidelberg."
SCOPUS,Conference paper,2013,Fifty shades of grey in SOA testing,Wotawa F.; Schulz M.; Pill I.; Jehan S.; Leitner P.; Hummer W.; Schulte S.; Hoenisch P.; Dustdar S.,Model-Based Testing; Service Oriented Architectures; Test Case Generation,40,"Testing is undisputedly a fundamental verification principle in the software landscape. Today's products require us to effectively handle and test huge, complex systems and in this context to tackle challenging traits like heterogeneity, distribution and controllability to name just a few. The advent of Service-Oriented Architectures with their inherent technological features like dynamics and heterogeneity exacerbated faced challenges, requiring us to evolve our technology. The traditional view of white or black box testing, for example, does not accommodate the multitude of shades of grey one should be able to exploit effectively for system-wide tests. Today, while there are a multitude of approaches for testing single services, there is still few work on methodological system tests for SOAs. In this paper we propose a corresponding workflow for tackling SOA testing and diagnosis, discuss SOA test case generation in more detail, and report preliminary research in that direction. © 2013 IEEE."
SCOPUS,Conference paper,2014,Test process improvement with documentation driven integration testing,Häser F.; Felderer M.; Breu R.,Model-Based Integration Testing; Regression Testing; Test Process Improvement,60,"Improving the maturity of the test process in an organization, especially but not limited to integration testing, involves obstacles and risks, such as the additional work overhead of the new process. In addition, integration testing descriptions are often too technical not addressing the language needs of the domain. In research cooperations with companies from the insurance and banking domain it turned out that test descriptions and reports are one of the most useful testing artifacts, while doing adhoc testing. This paper presents a bottom up testing approach, which first helps the integration tester in producing a semi-formal test description and report, up to be an enabler for automatic model-based testing in the very end. The presented approach is based on a textual domain specific language that is able to evolve over time. This is done by analyzing the test descriptions and reports automatically with machine learning techniques as well as manually by integration testers. Often recurring test steps or used components are integrated into the test language, making it specially tailored for a specific organization. For each test step implementations can be attached, preparing it for the next iteration. In this paper the methodology and architecture of our integration testing approach are presented together with the underlying language concepts."
SCOPUS,Article,2019,Learning and statistical model checking of system response times,Aichernig B.K.; Bauerstätter P.; Jöbstl E.; Kann S.; Korošec R.; Krenn W.; Mateis C.; Schlick R.; Schumi R.,Cost learning; FsCheck; Model-based testing; Performance testing; Property-based testing; Response time; Statistical model checking; User profiles,390,"Since computers have become increasingly more powerful, users are less willing to accept slow responses of systems. Hence, performance testing is important for interactive systems. However, it is still challenging to test if a system provides acceptable performance or can satisfy certain response-time limits, especially for different usage scenarios. On the one hand, there are performance-testing techniques that require numerous costly tests of the system. On the other hand, model-based performance analysis methods have a doubtful model quality. Hence, we propose a combined method to mitigate these issues. We learn response-time distributions from test data in order to augment existing behavioral models with timing aspects. Then, we perform statistical model checking with the resulting model for a performance prediction. Finally, we test the accuracy of our prediction with hypotheses testing of the real system. Our method is implemented with a property-based testing tool with integrated statistical model checking algorithms. We demonstrate the feasibility of our techniques in an industrial case study with a web-service application."
SCOPUS,Article,2019,Extension to Interaction Flow Modeling Language (IFML) for Android Application Modeling; [面向安卓应用建模的IFML扩展],Lu Y.-F.; Pan M.-X.; Zhang T.; Wang L.-Z.; Li X.-D.,Android application; Interaction flow modeling language; Model-based testing; Model-driven engineering,,
SCOPUS,Conference paper,2018,Toward a Constraint Based Test Case Generation of Parallel BPEL Process,Serbout S.; Benattou M.,constraint based testing; model based testing; parallel BPEL process; parallel control flow graph; test case generation,,"Business Process Execution Language (BPEL) offers the possibility to implement customized business processes in a record time. Testing is crucial to ensure the quality of BPEL process. The aim of this paper is to propose a constraint based approach to test parallel BPEL process. In our work, we propose an algorithm to transform a parallel BPEL process into a Parallel Control Flow Graph (PCFG), we augment PCFG with pre and post conditions, and we drive then a suite of feasible test cases. © 2018 IEEE."
SCOPUS,Article,2019,Hierarchical featured state machines,Fragal V.H.; Simao A.; Mousavi M.R.,Featured finite state machine; Hierarchical featured finite state machine; Model validation; Software product line,22,"Variants of the Finite State Machine (FSM) model have been extensively used to describe the behavior of reactive systems. In particular, several model-based testing techniques have been developed to support test case generation from FSMs and test case execution. Most of such techniques require several validation properties to hold for the underlying test models. Featured Finite State Machine (FFSM) is an extension of the FSM model proposed in our earlier publication that represents the abstract behavior of an entire Software Product Line (SPL). By validating an FFSM, we validate all valid products configurations of the SPL looking forward configurable test suites. However, modeling a large SPL using flat FFSMs may lead to a huge and hard-to-maintain specification. In this paper, we propose an extension of the FFSM model, named Hierarchical Featured State Machine (HFSM). Inspired by Statecharts and UML state machines, we introduce the HFSM model to improve model readability by grouping up FFSM conditional states and transitions into abstracted entities. Our ultimate goal is to use HFSMs as test models. To this end, we first define some syntactic and semantical validation criteria for HFSMs as prerequisites for using them as test models. Moreover, we implement an adapted graphical Eclipse-based editor from the Yakindu Project for modeling, derivation, and checking feature-oriented properties using Satisfiability Modulo Theory (SMT) solver tools. We investigate the applicability of our approach by applying it to an HFSM for a realistic case study (the Body Comfort System). The results indicate that HFSMs can be used to compactly represent and efficiently validate the behavior of parallel components in SPLs."
SCOPUS,Conference paper,2018,Uncovering Unknown System Behaviors in Uncertain Networks with Model and Search-Based Testing,Ji R.; Li Z.; Chen S.; Pan M.; Zhang T.; Ali S.; Yue T.; Li X.,Model-based Testing; Search-based Testing; Uncertain Networks; uncertainty,11,"Modern software systems rely on information networks for communication. Such information networks are inherently unpredictable and unreliable. Consequently, software systems behave in an unstipulated manner in uncertain network conditions. Discovering unknown behaviors of these software systems in uncertain network conditions is essential to ensure their correct behaviors. Such discovery requires the development of systematic and automated methods. We propose an online and iterative model-based testing approach to evolve test models with search algorithms. Our ultimate aim is to discover unknown expected behaviors that can only be observed in uncertain network conditions. Also, we have implemented an adaptive search-based test case generation strategy to generate test cases that are executed on the system under test. We evaluated our approach with an open source video conference application-Jitsi with three search algorithms in comparison with random search. Results show that our approach is efficient in discovering unknown system behaviors. In particular, (1+1) Evolutionary Algorithm outperformed the other algorithms."
SCOPUS,Conference paper,2019,From requirements to automated acceptance tests of interactive apps: An integrated model-based testing approach,Maciel D.; Paiva A.C.R.; Da Silva A.R.,Model-based Testing (MBT); Requirements Specification Language (RSL); Test Case Execution; Test Case Generation; Test Case Specification,8,"Frequently software testing tends to be neglected at the beginning of the projects, only performed on the late stage. However, it is possible to benefit from combining requirement with testing specification activities. On one hand, acceptance tests specification will require less manual effort since they are defined or generated automatically from the requirements specification. On the other hand, the requirements specification itself will end up having higher quality due to the use of a more structured language, reducing typical problems such as ambiguity, inconsistency and incorrectness. This research proposes an approach that promotes the practice of tests specification since the very beginning of projects, and its integration with the requirements specification itself. It is a model-driven approach that contributes to maintain the requirements and tests alignment, namely between requirements, test cases, and low-level automated test scripts. To show the applicability of the approach, two complementary languages are adopted: the ITLingo RSL that is particularly designed to support both requirements and tests specification; and the Robot language, which is a low-level keyword-based language for the specification of test scripts. The approach includes model-to-model transformation techniques, such as test cases into test scripts transformations. In addition, these test scripts are executed by the Robot test automation framework."
SCOPUS,Conference paper,2016,Matts - A step towards model based testing,Herpel H.-J.; Willich G.; Li J.; Xie J.; Johansen B.; Kvinnesland K.; Krueger S.; Barrios P.,,,"In this paper we describe a Model Based approach to testing of on-board software and compare it with traditional validation strategy currently applied to satellite software. The major problems that software engineering will face over at least the next two decades are increasing application complexity driven by the need for autonomy and serious application robustness. In other words, how do we actually get to declare success when trying to build applications one or two orders of magnitude more complex than today's applications. To solve the problems addressed above the software engineering process has to be improved at least for two aspects: 1) Software design and 2) Software testing. The software design process has to evolve towards model-based approaches with extensive use of code generators. Today, testing is an essential, but time and resource consuming activity in the software development process. Generating a short, but effective test suite usually requires a lot of manual work and expert knowledge. In a modelbased process, among other subtasks, test construction and test execution can also be partially automated. The basic idea behind the presented study was to start from a formal model (e.g. State Machines), generate abstract test cases which are then converted to concrete executable test cases (input and expected output pairs). The generated concrete test cases were applied to an on-board software. Results were collected and evaluated wrt. applicability, cost-efficiency, effectiveness at fault finding, and scalability."
SCOPUS,Conference paper,2018,Comparative study on the performance of high temperature piezoelectric materials for structural health monitoring using ultrasonic guided waves,Dhutti A.; Tumin S.A.; Gan T.H.; Kanfoud J.; Balachandran W.,Em impedance; Guided waves; High temperature piezoelectric; SHM; Thermal effects,11,"Focusing on predictive maintenance for optimised maintenance schedules, energy, aerospace, oil and gas industries are seeking technologies to enable in-service structural health monitoring (SHM) of their critical assets. Many of these critical assets such as turbine engine components and steamlines operate at elevated temperatures. For such high temperature (HT) applications, advanced piezoelectric materials are required for construction of ultrasonic transducers. Ultrasonic guided wave (UGW) technology has been widely used for pipeline inspection but HT ultrasonic transducers are required to enable in-service SHM of steamlines. The main criterion for HTUGW transducer design is an appropriate, temperature-stable ultrasonic response at target temperatures and a stable frequency response (in the range10-150 kHz for pipes of 2-48 inch diameter) to maintain defect sensitivity at HT. These transducers comprise piezoelectric materials of appropriate polarisation and dimensions, which, when excited with an electrical input, transmit the desired displacement patterns to the UGW modes in the structure being monitored. The detection of defects is indicated by changes in the received ultrasonic measurements. With temperature variations and over time, the dielectric, elastic and piezoelectric properties of the active material can diverge, leading to deviations in the ultrasonic response that may lead to false alarms. This comparative study investigates and compares the performance of four commercially available HT piezoelectric materials: PZT-5A, MBT, LiNbO3 and GaPO4. The maximum recommended operating temperatures for long-term use of these selected materials are 200°C, 400°C, 600°C and 720°C, respectively. Elastic, dielectric and material properties representing a figure of merit for piezo transducers are determined at increasing temperatures up to 600°C and over a period of 1000 hours. The findings from this work will enable transducer design to use the most appropriate piezoelectric material for the target temperature range."
SCOPUS,Conference paper,2018,A study on the impact of model evolution in MBT suites,Silva A.G.F.; Andrade W.L.; Alves E.L.G.,Model-based testing; Test suite maintenance; Use case evolution,8,"Software testing is known to be a key-factor for the success of a software development project. In this context, Model-Based Testing (MBT) plays an important role by providing an automated way for generating test cases from system models. However, although MBT can be helpful for creating sound test cases, its use can be very sensitive to model changes. Model edits often lead to a great number of obsolete test cases, as the software and its models evolve. This fact is even more evident in agile projects where requirement artifacts are very volatile. This paper presents an empirical study designed for investigating how model edits can impact MBT test suites. For that, we run a case study in the context of two industrial projects that apply agile methodologies combined with the use of MBT. We observed the evolution of specification models and their impact on generated MBT suites. Our results showed that 86% of the generated test cases were discarded due to model edits and their impact. However, a deeper analysis found that 52% of these tests were impacted only by syntactic model edits, which indicate they could be reused with little revision efforts."
SCOPUS,Conference paper,2013,Distributed online test generation for model-based testing,Kanstrén T.; Kekkonen T.,Algorithm; Distributed testing; Model-based testing; Online test generation; Optimization,8,"In online model-based testing, test execution is interleaved with test generation. Test cases should be generated and executed with minimal delay, while still achieving targeted coverage criteria quickly. Extensive model analysis in such case is not possible as any delays in choosing the next step will immediately impact the response times of test execution. The algorithms thus need to be as fast as possible, where a limiting factor is the available computing power. Experts working on the test models used for the generation often need to be able to quickly edit the models, generate test cases, and use the feedback to further evolve the models. Reserving large-scale computing resources while editing the model is unnecessary, but performing the analysis on them for test generation can improve the execution response time significantly. In this paper, we present an approach and algorithm for distributing the online test generation analysis part concurrently over the network, while enabling the expert to work on the models and execute the test cases locally at the same time."
SCOPUS,Article,2020,Calculation of Transient Torques on Motors during a Residual Voltage Motor Bus Transfer,Yalla M.V.V.S.; Vakili A.; Beckwith T.R.,Fast transfer; in-phase transfer; main-tie-main; motor bus transfer (MBT); residual voltage transfer,13,"To maintain a critical process upon loss of primary motor bus power, the petrochemical industry depends largely on residual voltage transfer, ignoring phase angle and closing the backup source when the motor bus residual voltage has decayed to 30%. To assess the consequences of out-of-phase residual voltage transfers, a transient simulation program models a bus with three motors of various sizes, inertias, and impedances. The three motors are loaded around 80% with fan, pump, and compressor loads to calculate the peak transient motor current and torque upon closure of the backup source breaker. Pre-transfer events and conditions produce an initial phase angle between the primary and backup sources, and the simulation reproduces the resultant residual voltage transfer closing angle and its effect on the peak transient current and torque. Individual motors exhibit positive and negative torques, oscillating from induction generator to motor, and the peak-to-peak torques are also recorded, as they can impact the motor shaft stress."
SCOPUS,Article,2018,Increasing test efficiency by risk-driven model-based testing,Şahin Gebizli C.; Kırkıcı A.; Sözer H.,Industrial case study; Model refinement; Model-based testing; Risk-based testing; Software test automation; Statistical usage testing,10,"We introduce an approach and a tool, RIMA, for adapting test models used for model-based testing to augment information regarding failure risk. We represent test models in the form of Markov chains. These models comprise a set of states and a set of state transitions that are annotated with probability values. These values steer the test case generation process, which aims at covering the most probable paths. RIMA refines these models in 3 steps. First, it updates transition probabilities based on a collected usage profile. Second, it updates the resulting models based on fault likelihood at each state, which is estimated based on static code analysis. Third, it performs updates based on error likelihood at each state, which is estimated with dynamic analysis. The approach is evaluated with two industrial case studies for testing digital TVs and smart phones. Results show that the approach increases test efficiency by revealing more faults in less testing time."
SPRINGERLINK,Chapter,2023,Efficient Dynamic Model Based Testing,P. H. M. van Spaendonck,"efficient testing, model based testing, test case selection",10,"Model-based testing (MBT) provides an automated approach for finding discrepancies between software models and their implementation. If we want to incorporate MBT into the fast and iterative software development process that is Continuous Integration Continuous Deployment, then MBT must be able to test the entire model in as little time as possible. However, current academic MBT tools either traverse models at random, which we show to be ineffective for this purpose, or use precalculated optimal paths which can not be efficiently calculated for large industrial models. We provide a new traversal strategy that provides an improvement in error-detection rate comparable to using precalculated paths. We show that the new strategy is able to be applied efficiently to large models. The benchmarks are performed on a mix of real-world and pseudo-randomly generated models. We observe no significant difference between these two types of models."
SPRINGERLINK,Chapter,2023,Compositionality in Model-Based Testing,Gijs van CuyckLars van ArragonJan Tretmans,"component-based testing, compositional testing, labelled transition systems, model-based testing, uioco",10,"Model-based testing (MBT) promises a scalable solution to testing large systems, if a model is available. Creating these models for large systems, however, has proven to be difficult. Composing larger models from smaller ones could solve this, but our current MBT conformance relation $$\mathrel {{\textbf {uioco}}}$$ uioco is not compositional, i.e. correctly tested components, when composed into a system, can still lead to a faulty system. To catch these integration problems, we introduce a new relation over component models called mutual acceptance . Mutually accepting components are guaranteed to communicate correctly, which makes MBT compositional. In addition to providing compositionality, mutual acceptance has benefits when retesting systems with updated components, and when diagnosing systems consisting of components."
SPRINGERLINK,Chapter,2023,Model-based Player Experience Testing with Emotion Pattern Verification,Saba Gholizadeh AnsariI. S. W. B. PrasetyaDavide PrandiFitsum Meshesha KifetewMehdi DastaniFrank DignumGabriele Keller,"agent-based testing, automated player experience testing, model-based testing, models of emotion",10,"Player eXperience (PX) testing has attracted attention in the game industry as video games become more complex and widespread. Understanding players’ desires and their experience are key elements to guarantee the success of a game in the highly competitive market. Although a number of techniques have been introduced to measure the emotional aspect of the experience, automated testing of player experience still needs to be explored. This paper presents a framework for automated player experience testing by formulating emotion patterns’ requirements and utilizing a computational model of players’ emotions developed based on a psychological theory of emotions along with a model-based testing approach for test suite generation. We evaluate the strength of our framework by performing mutation test. The paper also evaluates the performance of a search-based generated test suite and LTL model checking-based test suite in revealing various variations of temporal and spatial emotion patterns. Results show the contribution of both algorithms in generating complementary test cases for revealing various emotions in different locations of a game level."
SPRINGERLINK,Chapter,2023,Towards a Dynamic Testing Approach for Checking the Correctness of Ethereum Smart Contracts,Mohamed Amin HammamiMariam LahamiAfef Jmal Maâlej,"Blockchain, Dynamic Testing, Ethereum, Model-based testing, Smart contracts, UPPAAL Timed automata, Validation, Verification",10,"One of the most essential concepts related to the development of Blockchain oriented software is smart contracts. Once deployed on the blockchain, these pieces of code cannot be altered due to the immutability feature of the blockchain technology. Therefore, it is necessary to verify and validate smart contracts before their deployment. This paper presents a model-based testing approach for validating and checking the correctness of Ethereum smart contracts. The adopted process comprises essentially four steps: (1) modelling the smart contract and its blockchain environment as UPPAAL Timed Automata, (2) generating abstract test cases by UPPAAL CO $$\surd $$ √ ER tool, (3) executing in a dynamic manner the generated test cases, and finally (4) analyzing the obtained test results and generating test reports. To illustrate our proposal, we apply it on Ethereum Blockchain and especially on the electronic voting case study."
SPRINGERLINK,Chapter,2023,Towards Online Testing Under Uncertainty Using Model-Based Reinforcement Learning,Matteo CamilliRaffaela MirandolaPatrizia ScandurraCatia Trubiani,"Bayesian Reinforcement Learning, Markov Decision Processes, Model-based Testing, Uncertainty quantification",10,"Modern software operates in complex ecosystems and is exposed to multiple sources of uncertainty that emerge in different phases of the development lifecycle, such as early requirement analysis or late testing and in-field monitoring. This paper envisions a novel methodology to deal with uncertainty in online model-based testing. We make use of model-based reinforcement learning to gather runtime evidence, spot and quantify existing uncertainties of the system under test. Preliminary experiments show that our novel testing approach has the potential of overcoming the major weaknesses of existing online testing techniques tailored to uncertainty quantification."
SPRINGERLINK,Chapter,2023,Conformance in the Railway Industry: Single-Input-Change Testing a EULYNX Controller,Djurre van der WalMarcus GerholdMariëlle Stoelinga,"Conformance testing, Model-based testing, Programmable logic controllers, Railways, Safety-critical systems, Single-Input-Change",10,"We propose a novel framework for model-based testing against specifications from EULYNX , a SysML-based standard from the railway industry for the controllers of systems such as points, signals, sensors, and crossings. The main challenge here is the sheer complexity: with state spaces exceeding $$10^{10}$$ states, it is hard to derive test suites that achieve a meaningful type of coverage. We tackle this problem by moving away from the traditional interleaving semantics for SysML. Instead, we propose a synchronous semantics in terms of Finite State Machines (FSMs), leveraging the fact that EULYNX is implemented on Programmable Logic Controllers (PLCs). Then, we deploy Single-Input-Change Deterministic Finite State Machines (SIC-DFSMs), which ensures fully deterministic tests thus minimizing scalability issues. Our focus lies on the EULYNX specification for point controllers . The generated test suite achieves maximal transition coverage, but test execution time remains substantial. We introduce an additional test suite that achieves maximal transition label coverage. Remarkably, this smaller suite successfully identifies the same four faults as the larger suite."
SPRINGERLINK,Chapter,2023,Towards Automated Load Testing Through the User Interface,Bruno TeixeiraJosé Creissac Campos,"capture and replay, load testing, Model-based testing",10,"Slight variations in user interface response times can significantly impact the user experience provided by an interface. Load testing is used to evaluate how an application behaves under increasing loads. For interactive applications, load testing can be done by directly calling services at the business logic or through the user interface. In modern web applications, there is a considerable amount of control logic on the browser side. The impact of this logic on applications’ behaviour is only fully considered if the tests are done through the user interface. Capture reply tools are used for this, but their use can become costly. Leveraging an existing model-based testing tool, we propose an approach to automate load testing done through the user interface."
SPRINGERLINK,Chapter,2023,A Systematic Literature Review on Prioritizing Software Test Cases Using Markov Chains,G. BarbosaÉ. SouzaL. RebeloM. SilvaJ. BaleraN. Vijaykumar,,10,"Software Testing is a costly activity since the size of the test case set tends to increase as the construction of the software evolves. Test Case Prioritization (TCP) can reduce the effort and cost of software testing. TCP is an activity where a subset of the existing test cases is selected in order to maximize the possibility of finding defects. On the other hand, Markov chains representing a system, when solved, can present the occupation time of each of their states. The idea is to use such information and associate priority to those test cases that consist of states with the highest probabilities. This journal-first paper provides an overview of a systematic survey of the state-of-the-art to identify and understand key initiatives for using Markov chains in TCP."
SPRINGERLINK,Chapter,2023,Using GUI Change Detection for Delta Testing,Fernando Pastor RicósRick NeeftBeatriz MarínTanja E. J. VosPekka Aho,"Delta testing, GUI change detection, Scriptless testing, State-model inference",10,"Current software development processes in the industry are designed to respond to rapid modification or changes in software features. Delta testing is a technique used to check that the identified changes are deliberate and neither compromise existing functionality nor result in introducing new defects. This paper proposes a technique for delta testing at the Graphical User Interface (GUI) level. We employ scriptless testing and state-model inference to automatically detect and visualize GUI changes between different versions of the same application. Our proposed offline change detection algorithm compares two existing GUI state models to detect changes. We present a proof of concept experiment with the open-source application Notepad ++ , which allows automatic inference and highlights GUI changes. The results show that our technique is a valuable amplification of scriptless testing tools for delta testing."
SPRINGERLINK,Chapter,2023,Protocol Conformance with Choreographic PlusCal,Darius FooAndreea CosteaWei-Ngan Chin,,10,"Distributed protocols, an essential part of modern computing infrastructure, are well-known to be difficult to implement correctly. While lightweight formal methods such as TLA $$^{+}$$ +  can be effectively used to verify abstract protocols, end-to-end validation of real-world protocol implementations remains challenging due to their complexity. To address this problem, we extend the TLA $$^{+}$$ +  toolset along two fronts. We propose several extensions to PlusCal – an algorithm language which compiles to TLA $$^{+}$$ +  – to allow writing distributed protocols as choreographies. This enables more structured and succinct specifications for role-based protocols. We also provide a methodology and toolchain for compiling TLA $$^{+}$$ +  models into monitors, allowing them to be used to test existing systems for conformance. The result is a lightweight testing method that bridges specification and implementation. We demonstrate its benefits with case studies of both classic and recent protocols and show it to be readily applicable to existing systems with low runtime overhead."
SPRINGERLINK,Chapter,2023,A Modulatory Elongated Model for Delineating Retinal Microvasculature in OCTA Images,Mohsin ChalloobYongsheng GaoAndrew BuschWeichuan Zhang,"Contextual information, Elongated responses, Modulatory influences, OCTA, Retinal vasculature, Vessel features",10,"Robust delineation of retinal microvasculature in optical coherence tomography angiography (OCTA) images remains a challenging task, particularly in handling the weak continuity of vessels, low visibility of capillaries, and significant noise interferences. This paper introduces a modulatory elongated model to overcome these difficulties by exploiting the facilitatory and inhibitory interactions exhibited by the contextual influences for neurons in the primary visual cortex. We construct the receptive field of the neurons by an elongated representation, which encodes the underlying profile of vasculature structures, elongated-like patterns, in an anisotropic neighborhood. An annular function is formed to capture the contextual influences presented in the surrounding region outside the neuron support and provide an automatic tuning of contextual information. The proposed modulatory method incorporates the elongated responses with the contextual influences to produce spatial coherent responses for delineating microvasculature features more distinctively from their background regions. Experimental evaluation on clinical retinal OCTA images shows the effectiveness of the proposed model in attaining a promising performance, outperforming the state-of-the-art vessel delineation methods."
SPRINGERLINK,Chapter,2023,Performance Evaluation of Global Trust Management in MANETs Routing Protocols,Hassan JariNigel Thomas,"AODV, Direct trust, Global trust, Indirect trust, MANETs, NS-3, Routing protocol",10,"This paper presents a comprehensive trust management strategy for MANETs, concentrating on developing, assessing, and comparing global trust management mechanisms for the Ad-hoc On-demand Distance Vector (AODV) routing protocol. The research introduces a novel trust-based routing protocol called GTAODV, which builds upon the standard AODV protocol. GTAODV incorporates direct, indirect, and global trust mechanisms to evaluate the reliability of nodes when forwarding packets. This study aims to contribute to ongoing efforts in creating more secure, robust, and efficient ad-hoc networking solutions by focusing on the performance of MANET routing protocols when subjected to black hole attacks. Using Network Simulator 3 (NS-3), the performance of AODV and GTAODV is evaluated and compared. The experimental results demonstrate the effectiveness of the GTAODV protocol in countering black hole attacks, highlighting its potential to enhance the security and reliability of MANETs."
SPRINGERLINK,Chapter,2023,Verifying Open Data Portals Completeness in Compliance to a Grounding Framework,Flavia BernardiniCatherine Fortes Thedim CostaShaiana PereiraVictor Antunes VieiraDaniela TrevisanJosé Viterbo,"Completeness Evaluation, Compliance Assessment, Open Data Reference Framework, Open Government Data",10,"Open Government Data Portals (OGDPs) are a way of keeping up the information about government’s actions, including how the collected taxes are used in favor of its citizens. However, one difficult in some of these portals is guaranteeing accountability on OGDP completeness according to different instruments specifying legal requirements and good practices, especially when they may reinforce some requirements or may be even contradictory. This problem leads to the need for a comprehensive methodology to assess completeness of OGDPs related to data and information availability. This work presents a process for constructing a reference guide, aiming to help analyzing completeness of an OGDP content, in compliance to legal requirements and good practices, presented by textual instruments. We conducted an experimental analysis for evaluating the completeness of Transparency OGDPs (TOGDPs) requirements using our process. We evaluated, as (T)OGDP experts, the constructed reference guide on three different TOGDPs. We also used the output guide to interview managers and users of the Niterói TOGDP, in order to both evaluate the quality of the guide and the Niterói TOGDP completeness. We could observe which items of our guide were well understood and which need to be improved. These results are of interest to the OGD research community as they provide a tool for constructing a reference guide that facilitates the systematic assessment of OGDPs completeness, in compliance to a given legal framework. Future research includes testing our approach on different contexts for various OGDP types and exploring automation possibilities."
SPRINGERLINK,Chapter,2023,"Relating Reversible Petri Nets and Reversible Event Structures, Categorically",Hernán MelgrattiClaudio Antares MezzinaG. Michele Pinna,,10,"Causal nets (CNs) are Petri nets where causal dependencies are modelled via inhibitor arcs. They play the role of occurrence nets when representing the behaviour of a concurrent and distributed system, even when reversibility is considered. In this paper we extend CNs to account also for asymmetric conflicts and study (i) how this kind of nets, and their reversible versions, can be turned into a category; and (ii) their relation with the categories of reversible asymmetric event structures."
SPRINGERLINK,Chapter,2023,Research on Feature Picking of Domestic Waste Sorting Based on Neural Network Training,Yufei HuangZhengjie LuJixin SunBo WangShude Liao,"Domestic waste, GUI, MATLAB, Neural network",10,"Through the analysis of the status quo of domestic waste treatment, three common and recyclable domestic wastes of plastic bottles, cardboard and cans are selected as the classification samples to study the classification of the overall domestic waste. Based on MATLAB, a nerve that can be used for domestic waste sorting is designed. The network model realizes the effective classification of the domestic garbage images after real-time acquisition of the images by the camera, and borrows the MATLAB GUI toolbox to design a GUI that is easy to operate and has strong practicability. The research provides an implementation method for the effective sorting and treatment of domestic waste."
SPRINGERLINK,Chapter,2023,Spanning Trees with Few Branch Vertices in Graphs of Bounded Neighborhood Diversity,Luisa GarganoAdele A. Rescigno,"Fixed parameterized algorithms, Neighborhood diversity, Spanning tree",10,"A branch vertex in a tree is a vertex of degree at least three. We study the NP -hard problem of constructing spanning trees with as few branch vertices as possible. This problem generalizes the famous Hamiltonian Path problem which corresponds to the case of no vertices having degree three or more. It has been extensively studied in the literature and has important applications in network design and optimization. In this paper, we study the problem of finding a spanning tree with the minimum number of branch vertices in graphs of bounded neighborhood diversity. Neighborhood diversity, a generalization of vertex cover to dense graphs, plays an important role in the design of algorithms for such graphs."
SPRINGERLINK,Chapter,2023,Minimal Generating Sets for Semiflows,Gerard Memmi,"Formal verification, generating set, invariant, linear algebra, Petri Nets, semiflow",10,"We discuss important characteristics of finite generating sets for $$\mathcal {F^{+}}$$ F + , the set of all semiflows with non-negative coordinates of a Petri Net. We endeavor to regroup a number of algebraic results dispersed throughout the Petri Nets literature and also to better position the results while considering semirings such as $$\mathbb {N}$$ N or $$\mathbb {Q^+}$$ Q + then fields such as $$\mathbb {Q}$$ Q . As accurately as possible, we provide a range of new algebraic results on minimal semiflows, minimal supports, and finite minimal generating sets for a given family of semiflows. Minimality of semiflows and of support are critical to develop effective analysis of invariants and behavioral properties of Petri Nets. Main results are concisely presented in a table and our contribution is highlighted. We conclude with the analysis of an example drawn from the telecommunication industry underlining the efficiency brought by using minimal semiflows of minimal supports."
SPRINGERLINK,Chapter,2022,Model-Based Testing of Internet of Things Protocols,Xavier Manuel van DommelenMachiel van der BijlAndy Pimentel,"Bluetooth Low Energy, Communication Protocol, Embedded Systems, Internet of Things, Model-Based Testing",10,"Internet of Things (IoT) is a popular term to describe systems/devices that connect and interact with each other through a network, e.g., the Internet. These devices communicate with each other via a communication protocol, such as Zigbee or Bluetooth Low Energy (BLE), the subject of this paper. Communication protocols are notoriously hard to implement correctly and a large set of test-cases is needed to check for conformance to the standard. Many of us have encountered communication problems in practice, such as random mobile phone disconnects, difficulty obtaining a Bluetooth connection, etc. In this paper, we research the application of industry strength Model-Based Testing (MBT) within the IoT domain. This technique contributes to higher quality specifications and more efficient and more thorough conformance testing. We show how we can model part of the BLE protocol specification using the Axini Modeling Platform (AMP). Based on the model, AMP is then able to automatically test the conformance of a BLE device. With this approach, we found specification flaws in the official BLE specifications as well as conformance errors on a certified BLE system."
SPRINGERLINK,Chapter,2022,Investigating The Effectiveness of Model-Based Testing on Testing Skill Acquisition,Felix CammaertsCharlotte VerbruggenMonique Snoeck,"Model-based testing, TesCaV, Testing skill acquisition",10,"Software does not only need to be developed but also needs to get tested. Testing of software reduces the development and maintenance costs and increases software quality. Unfortunately, few software development courses focus on good testing practices. Some prior work has nevertheless researched possible ways of teaching software testing techniques to students. Unfortunately, all these approaches are code-oriented approaches, implying that a strong technical background is needed to effectively use them. They are also mostly focused on improving students’ knowledge on basic testing techniques. In contrast, TesCaV, a software tool used for teaching testing skills to university students, focuses on teaching testing to novice users with limited technical skills by providing a model-based testing (MBT) approach. MBT is a black-box testing technique in which the tests are automatically generated from a software model. This automatic generation allows for easy maintenance of the test suite when the software changes. These tests can be automatically generated by using a.o. Finite State Machines (FSMs), Markov Chains and Logic Programming. TesCaV is mainly based on Finite State Machines. The effect of using TesCaV on testing coverage is quantitatively analysed in this research. The preliminary results of TesCaV show that it is a promising tool for the teaching of MBT."
SPRINGERLINK,Chapter,2022,libfsmtest An Open Source Library for FSM-Based Testing,Moritz BergenthalNiklas KrafczykJan PeleskaRobert Sachtleben,,10,"In this paper, the open source library libfsmtest is presented. It has been developed to support model-based testing with finite state machine (FSM) models. The library is provided as a collection of $$\mathtt{C}^{++}$$ C + + classes, each class supporting specific aspects of FSM creation and transformation, and test generation from FSM models. Additionally, the library provides main programs for test generation with the methods realised in the library and for testing ‘implementation FSMs’ with suites generated from ‘reference FSMs’. Moreover, a generic test harness is provided for running test suites against $$\mathtt{C}^{++}$$ C + + libraries. We explain the unique selling points of this library and compare it to competing approaches."
SPRINGERLINK,Chapter,2022,Towards Substructural Property-Based Testing,Marco MantovaniAlberto Momigliano,"Focusing, Linear logic, Property-based testing, Semantics of programming languages",10,We propose to extend property-based testing to substructural logics to overcome the current lack of reasoning tools in the field. We take the first step by implementing a property-based testing system for specifications written in the linear logic programming language Lolli. We employ the foundational proof certificates architecture to model various data generation strategies. We validate our approach by encoding a model of a simple imperative programming language and its compilation and by testing its meta-theory via mutation analysis.
SPRINGERLINK,Chapter,2022,Towards Causal Model-Based Engineering in Automotive System Safety,Robert MaierLisa GrabingerDavid UrlhartJürgen Mottok,"Causality, Model-based engineering, Probabilistic reasoning, Scenario identification, SOTIF",10,"Engineering is based on the understanding of causes and effects. Thus, causality should also guide the safety assessment of complex systems such as autonomous driving cars. To ensure the safety of the intended functionality of these systems, normative regulations like ISO 21448 recommend scenario-based testing. An important task here is to identify critical scenarios, so-called edge and corner cases. Data-driven approaches to this task (e.g. based on machine learning) cannot adequately address a constantly changing operational design domain. Model-based approaches offer a remedy – they allow including different sources of knowledge (e.g. data, human experts) into safety considerations. With this paper, we outline a novel approach for ensuring automotive system safety. We propose to use structural causal models as a probabilistic modelling language to combine knowledge about an open-context environment from different sources. Based on these models, we investigate parameter configurations that are candidates for critical scenarios. In this paper, we first discuss some aspects of scenario-based testing. We then provide an informal introduction to causal models and relate their development lifecycle to the established V-model. Finally, we outline a generic workflow for using causal models to identify critical scenarios and highlight some challenges that arise in the process."
SPRINGERLINK,Chapter,2022,Locality-Based Test Selection for Autonomous Agents,Sina EntekhabiWojciech MostowskiMohammad Reza MousaviThomas Arts,"Autonomous agents, Domain specific languages, Model-based testing, Scenario-based testing, Test input generation, Test selection",10,"Automated random testing is useful in finding faulty corner cases that are difficult to find by using manually-defined fixed test suites. However, random test inputs can be inefficient in finding faults, particularly in systems where test execution is time- and resource-consuming. Hence, filtering out less-effective test cases by applying domain knowledge constraints can contribute to test effectiveness and efficiency. In this paper, we provide a domain specific language (DSL) for formalising locality-based test selection constraints for autonomous agents. We use this DSL for filtering randomly generated test inputs. To evaluate our approach, we use a simple case study of autonomous agents and evaluate our approach using the QuickCheck tool. The results of our experiments show that using domain knowledge and applying test selection filters significantly reduce the required number of potentially expensive test executions to discover still existing faults. We have also identified the need for applying filters earlier during the test data generation. This observation shows the need to make a more formal connection between the data generation and the DSL-based filtering, which will be addressed in future work."
SPRINGERLINK,Chapter,2022,Temporal Multi-view Contracts for Efficient Test Models,Jishu GuinJüri VainLeonidas TsiopoulosGert Valdek,"Contract-based design, Model-based testing, Model-checking",10,"In this work we focus on practical aspects of test automation, namely reducing the model creation effort for model-based testing by exploiting the multi-view contract paradigm. We take into account explicitly the design views of the system and develop dedicated system test models by views in an incremental manner. The test models formalized as Uppaal Timed Automata refine the requirements of the views and are verified against the view contracts specified in Timed Computation Tree logic. As a novel theoretical contribution we extend the notion of assume/guarantee contracts by introducing temporal modalities. As a second contribution, we demonstrate the feasibility of the approach on an industrial climate control system testing case study. The improvement of testing process productivity is compared to that of developing a monolithic model empirically without extracting views. Finally, we discuss the usability aspects of the method in test development and outline the challenges."
SPRINGERLINK,Chapter,2022,Is NLP-based Test Automation Cheaper Than Programmable and Capture &Replay?,Maurizio LeottaFilippo RiccaSimone StoppaAlessandro Marchetto,"Artificial intelligence, NLP, Test automation, Web testing",10,"Nowadays, there is a growing interest in the use of Natural-Language Processing (NLP) for supporting software test automation. This paper investigates the adoption of NLP in web testing. To this aim, a case study has been conducted to compare the cost of the adoption of a NLP testing approach, with respect to more consolidated approaches, i.e., programmable testing and capture and replay testing, in two testing tasks: test cases development and test case evolution/maintenance. Even if preliminary, results show that NLP testing is quite competitive with respect to the more consolidated approaches since the cumulative testing effort of a NLP testing approach, computed considering both development and evolution efforts, is almost always lower than the one of programmable testing and capture &replay testing."
SPRINGERLINK,Chapter,2022,Testing Against Non-deterministic FSMs: A Probabilistic Approach for Test Suite Minimization,Natalia KushikNina YevtushenkoJorge López,"Guaranteed fault coverage, Model based testing, Non-deterministic finite state machines, Probabilistic approach",10,"The paper is devoted to model based testing against non-deterministic specifications. Such test derivation strategies are well developed, for example against non-deterministic Finite State Machines, however the length of the corresponding test suite can be exponential w.r.t. the number of specification states. We therefore discuss how a test suite can be minimized or reduced when certain level of guarantee concerning its fault coverage is still preserved. The main idea behind the approach is to augment the specification by assigning probabilities for the non-deterministic transitions and later on evaluate the probability of each test sequence to detect the relevant faulty implementation. Given a probability P which is user-defined, we propose an approach for minimizing a given exhaustive test suite TS such that, it stays exhaustive with the probability no less than P ."
SPRINGERLINK,Chapter,2022,Learning Deterministic One-Clock Timed Automata via Mutation Testing,Xiaochen TangWei ShenMiaomiao ZhangJie AnBohua ZhanNaijun Zhan,"Active learning, Model-based mutation testing, Timed automata",10,"In active learning, an equivalence oracle is supposed to answer whether a hypothesis model is equivalent to the system under learning. Its implementation in real applications is considered a major bottleneck for active automata learning. The problem is especially difficult in the context of learning timed automata due to the infinitely large state space involved. In this paper, following the framework of combining mutation analysis and random testing, we propose an implementation of equivalence oracle in the context of learning deterministic one-clock timed automata (DOTAs). This includes two learning-friendly mutation operators, a heuristic test-case generation method, and a score-based test-case selection method. We implemented a prototype applying our approach by extending an existing tool on active learning of DOTAs and conducted extensive experiments. The results indicate that our method improves upon existing methods on the rate of learning correct models, the number of test cases required, and accumulated delay time in test cases."
SPRINGERLINK,Chapter,2022,Towards Continuous Quality Control in the Context of Language-Driven Engineering,Alexander BainczykSteve BoßelmannMarvin KrauseMarco KrumreyDominic WirknerBernhard Steffen,"Active automata learning, Continuous quality control, Domain-specific languages, Generation, Language-driven engineering, Migration, Model/learning-based testing",10,"In this paper, we illustrate the role of quality assurance in Language-Driven Engineering (LDE) which exploits the observation that the more specific a programming/modeling language is, the better it can be controlled . In fact, well-tailored domain-specific languages (DSLs) allow one to (1) syntactically express a number of semantic properties with the effect that they can be verified during syntax analysis or using more involved static verification techniques like model checking, and (2), combined with a concept of design for testability, to automatically validate run-time properties using, in our case, learning-based testing technology. To ensure practicality and scalability, the LDE approach must be supported by language definition technology, powerful enough to ensure that corresponding Integrated Modeling Environments (IMEs) can be generated on demand. Our LDE ecosystem provides such means in a fashion where the dependencies between the various modeling environments and their corresponding meta-modeling environments are systematically addressed in a path-up/tree-down fashion: application-level requests are stepwise moved up to the meta hierarchy, far enough to fully address the issue at hand. The resulting meta-level changes are then propagated down the meta hierarchy to ensure the adequate migration of all involved IMEs and their corresponding modeled artifacts."
SPRINGERLINK,Chapter,2022,A Survey-driven Feature Model for Software Traceability Approaches,Edouard Romari BatotSebastien GérardJordi Cabot,,10,"Traceability is the capability to represent, understand and analyze the relationships between software artefacts. Traceability is at the core of many software engineering activities. This is a blessing in disguise as traceability research is scattered among various research subfields, which impairs a global view and integration of the different innovations around the recording, identification, evaluation and management of traces. This also limits the adoption of traceability solutions in industry. In this sense, the goal of this paper is to present a characterization of the traceability mechanism as a feature model depicting the shared and variable elements in any traceability proposal. The features in the model are derived from a survey of papers related to traceability published in the literature. We believe this feature model is useful to assess and compare different proposals and provide a common terminology and background. Beyond the feature model, the survey we conducted also help us to identify a number of challenges to be solved in order to move traceability forward, especially in a context where, due to the increasing importance of AI techniques in Software Engineering, traces are more important than ever in order to be able to reproduce and explain AI decisions."
SPRINGERLINK,Chapter,2022,Modeling and Model Transformation as a Service: Towards an Agile Approach to Model-Driven Development,Adel VahdatiRaman Ramsin,"Agile methods, Model-Driven Development, Service-oriented architecture",10,"Scalability has always been a challenge in software development, and agile methods have faced their own ordeal in this regard. The classic solution is to use modeling to manage the complexities of the system while facilitating intra-team and inter-team communication; however, agile methods tend to shy away from modeling to avoid its adverse effect on productivity. Model-driven development (MDD) has shown great potential for automatic code generation, thereby enhancing productivity, but the agile community seems unconvinced that this gain in productivity justifies the extra effort required for modeling. The challenge that the MDD community faces today is to incorporate MDD in agile development methodologies in such a way that agility is tangibly and convincingly preserved. In this paper, we address this challenge by using a service-oriented approach to modeling and model transformation that pays special attention to abiding by agile values and principles."
SPRINGERLINK,Chapter,2022,A New Approach for Active Automata Learning Based on Apartness,Frits VaandragerBharat GarhewalJurriaan RotThorsten Wißmann,"L#, algorithm, active automata learning, adaptive distinguishing sequence, apartness relation, conformance testing, Mealy machine, observation tree",10,"We present $$L^{\#}$$ L # , a new and simple approach to active automata learning. Instead of focusing on equivalence of observations, like the $$L^{*}$$ L ∗ algorithm and its descendants, $$L^{\#}$$ L # takes a different perspective: it tries to establish apartness , a constructive form of inequality. $$L^{\#}$$ L # does not require auxiliary notions such as observation tables or discrimination trees, but operates directly on tree-shaped automata. $$L^{\#}$$ L # has the same asymptotic query and symbol complexities as the best existing learning algorithms, but we show that adaptive distinguishing sequences can be naturally integrated to boost the performance of $$L^{\#}$$ L # in practice. Experiments with a prototype implementation, written in Rust, suggest that $$L^{\#}$$ L # is competitive with existing algorithms."
SPRINGERLINK,Chapter,2022,Algebraic Virtual Machine Project,Oleksandr LetychevskyiVolodymyr PeschanenkoVladislav Volkov,"Behavior algebra, Formal methods, Model-based testing, Symbolic modeling, Verification",10,"T his paper presents a program system called an algebraic virtual machine (AVM), which handles industrial hardware specifications, programs in different languages, and models in algebraic language. It uses the formal algebraic methods that were developed in the scope of behavior algebra and help to resolve the problems of verification, analysis, testing, and cybersecurity. It permits the possibility of creating your own methods and theories and trying them with industrial examples with minimal efforts. The machine learning technique is used for the definition of formal method efficiency, and the classification model is trained during algebraic processing. The formalization and checking for resistance of blockchain attack is considered."
SPRINGERLINK,Chapter,2022,Algebraic Virtual Machine and Its Applications,Oleksandr LetychevskyiVolodymyr PeschanenkoVlad Volkov,"Behavior algebra, Formal methods, Model-based testing, Symbolic modeling, Verification",10,"This paper presents a software system called “Algebraic Virtual Machine (AVM), which handles industrial hardware specifications, programs in different languages, and models in algebraic language. It uses the formal algebraic methods that were developed in the scope of behavior algebra and help to resolve the problems of verification, analysis, testing, and cybersecurity. The new version of AVM will include the possibilities to formalize continuous process and significantly extends the usage of formal methods. It permits the possibility of creating your own methods and theories and trying them with industrial examples with minimal efforts. The machine learning technique is used for the definition of formal method efficiency, and the classification model is trained during algebraic processing. The formalization and checking for resistance of blockchain attack is considered as case study."
SPRINGERLINK,Chapter,2022,Digital Twin for IoT Environments: A Testing and Simulation Tool,Luong NguyenMariana SegoviaWissam MallouliEdgardo Montes de OcaAna R. Cavalli,"Actuators, Digital Twins, Gateway, IoT, Sensors, Simulation, Testing",10,"Digital Twin (DT) is one of the pillars of modern information technologies that plays an important role on industry’s digitalization. A DT is composed of a real physical object, a virtual abstraction of the object and a bidirectional data flow between the physical and virtual components. This paper presents a DT-based tool, called TaS, to easily test and simulate IoT environments. The objective is to improve the testing methodologies in IoT systems to evaluate the possible impact of it on the physical world. We provide the conditions to test, predict errors and stress application depending on hardware, software and real world physical process. The tool is based on the DT concept in order to detect and predict failures in evolving IoT environments. In particular, the way to prepare the DT to support fault injection and cybersecurity threats is analyzed. The TaS tool is tested through an industrial case study, the Intelligent Transport System (ITS) provided by the INDRA company. Results of experiments are presented that show that our DT is closely linked to the real world."
SPRINGERLINK,Chapter,2022,Safe and Secure Future AI-Driven Railway Technologies: Challenges for Formal Methods in Railway,Monika SeisenbergerMaurice H. ter BeekXiuyi FanAlessio FerrariAnne E. HaxthausenPhillip JamesAndrew LawrenceBas LuttikJaco van de PolSimon Wimmer,,10,"In 2020, the EU launched its sustainable and smart mobility strategy, outlining how it plans to have a 90% reduction in transport emission by 2050. Central to achieving this goal will be the improvement of rail technology, with many new data-driven visionary systems being proposed. AI will be the enabling technology for many of those systems. However, safety and security guarantees will be key for wide-spread acceptance and uptake by Industry and Society. Therefore, suitable verification and validation techniques are needed. In this article, we argue how formal methods research can contribute to the development of modern Railway systems—which may or may not make use of AI techniques—and present several research problems and techniques worth to be further considered."
SPRINGERLINK,Chapter,2022,State Model Inference Through the GUI Using Run-Time Test Generation,Ad MuldersOlivia Rodriguez ValdesFernando Pastor RicósPekka AhoBeatriz MarínTanja E. J. Vos,"Automated GUI testing, Model inference, TESTAR tool",10,"Software testing is an important part of engineering trustworthy information systems. End-to-end testing through Graphical User Interface (GUI) can be done manually, but it is a very time consuming and costly process. There are tools to capture or manually define scripts for automating regression testing through a GUI, but the main challenge is the high maintenance cost of the scripts when the GUI changes. In addition, GUIs tend to have a large state space, so creating scripts to cover all the possible paths and defining test oracles to check all the elements of all the states would be an enormous effort. This paper presents an approach to automatically explore a GUI while inferring state models that are used for action selection in run-time GUI test generation, implemented as an extension to the open source TESTAR tool. As an initial validation, we experiment on the impact of using various state abstraction mechanisms on the model inference and the performance of the implemented action selection algorithm based on the inferred model. Later, we analyse the challenges and provide future research directions on model inference and scriptless GUI testing."
SPRINGERLINK,Chapter,2022,Visual Smart Contracts for DAML,Reiko HeckelZobia ErumNitia RahmiAlbert Pul,"DAML, graph transformation, Groove, model-based development, smart contracts, UML, visual contracts",10,"The Digital Asset Modelling Language (DAML) enables low-code development of smart contract applications. Starting from a high-level but textual notation, DAML thus implements the lower end of a model-driven development process, from a platform-specific level to implementations on a range of blockchain platforms. Existing approaches for modelling smart contracts support a domain-oriented, conceptual view but do not link to the same technology-specific level. We develop a notation based on class diagrams and visual contracts that map directly to DAML smart contracts. The approach is grounded in an operational semantics in terms of graph transformation that accounts for the more complex behavioural features of DAML, such as its role-based access control and the order of contract execution and archival. The models, with their mappings to DAML and their operational semantics, are introduced via the Doodle case study from a DAML tutorial and validated through testing the graph transformation system against the DAML code using the Groove model checker."
SPRINGERLINK,Chapter,2022,Scriptless Testing for Extended Reality Systems,Fernando Pastor Ricós,"Extended reality, Scriptless testing, State model inference",10,"Extended Reality ( XR ) systems are complex applications that have emerged in a wide variety of domains, such as computer games and medical practice. Testing XR software is mainly done manually by human testers, which implies a high cost in terms of time and money. Current automated testing approaches for XR systems consist of rudimentary capture and replay of scripts. However, this approach only works for simple test scenarios. Moreover, it is well-known that the scripts break easily each time the XR system is changed. There are research projects aimed at using autonomous agents that will follow scripted instructions to test XR functionalities. Nonetheless, using only scripted testing techniques, it is difficult and expensive to tackle the challenges of testing XR systems. This thesis is focus on the use of automated scriptless testing for XR systems. This way we help to reduce part of the manual testing effort and complement the scripted techniques."
SPRINGERLINK,Chapter,2022,Computational Discovery of Transaction-Based Financial Crime via Grammatical Evolution: The Case of Ponzi Schemes,Peter FratričGiovanni SilenoTom van EngersSander Klous,,10,"The financial sector continues to experience wide digitalization; the resulting transactional activity creates large amounts of data, in principle enabling public and private actors to better understand the social domain they operate on, possibly facilitating the design of interventions to reduce illegal activity. However, the adversarial nature of frauds and the relatively low amount of observed instances make the problem especially challenging with standard statistical-based methods. To address such fundamental issues to non-compliance detection, this paper presents a proof-of-concept of a methodological framework based on automated discovery of instances of non-compliant behaviour in a simulation environment via grammatical evolution. We illustrate the methodology with an experiment capable of discovering two known types of Ponzi schemes from a modest set of assumptions."
SPRINGERLINK,Chapter,2022,Verified Security for the Morello Capability-enhanced Prototype Arm Architecture,Thomas BauereissBrian CampbellThomas SewellAlasdair ArmstrongLawrence EsswoodIan StarkGraeme BarnesRobert N. M. WatsonPeter Sewell,,10,"Memory safety bugs continue to be a major source of security vulnerabilities in our critical infrastructure. The CHERI project has proposed extending conventional architectures with hardware-supported capabilities to enable fine-grained memory protection and scalable compartmentalisation, allowing historically memory-unsafe C and C++ to be adapted to deterministically mitigate large classes of vulnerabilities, while requiring only minor changes to existing system software sources. Arm is currently designing and building Morello, a CHERI-enabled prototype architecture, processor, SoC, and board, extending the high-performance Neoverse N1, to enable industrial evaluation of CHERI and pave the way for potential mass-market adoption. However, for such a major new security-oriented architecture feature, it is important to establish high confidence that it does provide the intended protections, and that cannot be done with conventional engineering techniques. In this paper we put the Morello architecture on a solid mathematical footing from the outset. We define the fundamental security property that Morello aims to provide, reachable capability monotonicity, and prove that the architecture definition satisfies it. This proof is mechanised in Isabelle/HOL, and applies to a translation of the official Arm specification of the Morello instruction-set architecture (ISA) into Isabelle. The main challenge is handling the complexity and scale of a production architecture: 62,000 lines of specification, translated to 210,000 lines of Isabelle. We do so by factoring the proof via a narrow abstraction capturing essential properties of arbitrary CHERI ISAs, expressed above a monadic intra-instruction semantics. We also develop a model-based test generator, which generates instruction-sequence tests that give good specification coverage, used in early testing of the Morello implementation and in Morello QEMU development, and we use Arm’s internal test suite to validate our model. This gives us machine-checked mathematical proofs of whole-ISA security properties of a full-scale industry architecture, at design-time. To the best of our knowledge, this is the first demonstration that that is feasible, and it significantly increases confidence in Morello."
SPRINGERLINK,Chapter,2022,Designing Functional Prototypes Combining BCI and AR for Home Automation,Hakim Si-MohammedCoralie HaumontAlexandre SanchezCyril PlapousFoued BouchnakJean-Philippe JavaudinAnatole Lécuyer,"Augmented Reality (AR), Brain-Computer Interface (BCI), Home automation, Smart home, Steady-State Visual Evoked Potentials (SSVEP)",10,"In this technology report we present how to design functional prototypes of smart home systems, based on Augmented Reality (AR) and Brain-Computer Interfaces (BCI). A prototype was designed and integrated into a home automation platform, aiming to illustrate the potential of combining EEG-based interaction with Augmented Reality interfaces for operating home appliances. Our proposed solution enables users to interact with different types of appliances from “on-off”-based objects like lamps, to multiple command objects like televisions. This technology report presents the different steps of the design and implementation of the system, and proposes general guidelines regarding the future development of such solutions. These guidelines start with the description of the functional and technical specifications that should be met, before the introduction of a generic and modular software architecture that can be maintained and adapted for different types of BCI, AR displays and connected objects. Overall this technology report paves the way to the development of a new generation of smart home systems, exploiting brain activity and Augmented Reality for direct interaction with multiple home appliances."
SPRINGERLINK,Chapter,2022,Bi-directional Contrastive Learning for Domain Adaptive Semantic Segmentation,Geon LeeChanho EomWonkyung LeeHyekang ParkBumsub Ham,"Bi-directional contrastive learning, Domain adaptive semantic segmentation, Dynamic pseudo label",10,"We present a novel unsupervised domain adaptation method for semantic segmentation that generalizes a model trained with source images and corresponding ground-truth labels to a target domain. A key to domain adaptive semantic segmentation is to learn domain-invariant and discriminative features without target ground-truth labels. To this end, we propose a bi-directional pixel-prototype contrastive learning framework that minimizes intra-class variations of features for the same object class, while maximizing inter-class variations for different ones, regardless of domains. Specifically, our framework aligns pixel-level features and a prototype of the same object class in target and source images (i.e., positive pairs), respectively, sets them apart for different classes (i.e., negative pairs), and performs the alignment and separation processes toward the other direction with pixel-level features in the source image and a prototype in the target image. The cross-domain matching encourages domain-invariant feature representations, while the bidirectional pixel-prototype correspondences aggregate features for the same object class, providing discriminative features. To establish training pairs for contrastive learning, we propose to generate dynamic pseudo labels of target images using a non-parametric label transfer, that is, pixel-prototype correspondences across different domains. We also present a calibration method compensating class-wise domain biases of prototypes gradually during training. Experimental results on standard benchmarks including GTA5 $$\rightarrow $$ → Cityscapes and SYNTHIA $$\rightarrow $$ → Cityscapes demonstrate the effectiveness of our framework."
SPRINGERLINK,Chapter,2022,Learning Audio-Video Modalities from Image Captions,Arsha NagraniPaul Hongsuck SeoBryan SeyboldAnja HauthSantiago ManenChen SunCordelia Schmid,"Captioning, Data mining, Video retrieval",10,"There has been a recent explosion of large-scale image-text datasets, as images with alt-text captions can be easily obtained online. Obtaining large-scale, high quality data for video in the form of text-video and text-audio pairs however, is more challenging. To close this gap we propose a new video mining pipeline which involves transferring captions from image captioning datasets to video clips with no additional manual effort. Using this pipeline, we create a new large-scale, weakly labelled audio-video captioning dataset consisting of millions of paired clips and captions. We show that training a multimodal transformer based model on this data achieves competitive performance on video retrieval and video captioning, matching or even outperforming HowTo100M pretraining with 20x fewer clips. We also show that our mined clips are suitable for text-audio pretraining, and achieve state of the art results for the task of audio retrieval."
SPRINGERLINK,Chapter,2022,"Specification and Verification with the TLA+ Trifecta: TLC, Apalache, and TLAPS",Igor KonnovMarkus KuppeStephan Merz,"Model checking, Specification, Theorem proving, TLA+",10,"Using an algorithm due to Safra for distributed termination detection as a running example, we present the main tools for verifying specifications written in TLA + . Examining their complementary strengths and weaknesses, we suggest a workflow that supports different types of analysis and that can be adapted to the desired degree of confidence."
SPRINGERLINK,Chapter,2022,A Model-Based Approach for Quality Assessment of Insulin Infusion Pump Systems,Tássio Fernandes CostaÁlvaro SobrinhoLenardo Chaves e SilvaLeandro Dias da SilvaAngelo Perkusich,"Access/CPN, ASK-CTL, Coloured Petri Nets, Formal specifications, Modeling, Quality assessment, Simulation, Web-based application",10,"Insulin infusion pumps are safety-critical systems that require the approval of regulatory agencies before commercialization to prevent hazard situations. Nowadays, many recalls are reported for insulin infusion pump systems, motivating the usage of a formal model-based approach to improve quality. However, the usage of such approaches increases costs and development time. Thus, this study aims to assist the quality assessment of such systems cost-effectively and time-efficient. We defined a coloured Petri nets model-based approach and conducted a case study on the ACCU-CHEK Spirit system to verify and validate a reference model, describing quality assessment scenarios. We also conducted an empirical evaluation of the approach with 12 modelers to verify productivity and reusability. Using the approach, 66.7% of the modelers stated no effort, while 8.3%, stated low effort, 16.7% medium effort, and 8.3% considerable effort. Given such results, we developed a web-based application to assist modelers in re-using the proposed approach. The usage of the approach can decrease development time and thus costs, increasing confidence in quality attributes such as safety and effectiveness."
SPRINGERLINK,Chapter,2022,Exploring Fine-Grained Audiovisual Categorization with the SSW60 Dataset,Grant Van HornRui QianKimberly WilberHartwig AdamOisin Mac AodhaSerge Belongie,"Audio, Fine-grained, Multi-modal learning, Video",10,"We present a new benchmark dataset, Sapsucker Woods 60 (SSW60), for advancing research on audiovisual fine-grained categorization. While our community has made great strides in fine-grained visual categorization on images, the counterparts in audio and video fine-grained categorization are relatively unexplored. To encourage advancements in this space, we have carefully constructed the SSW60 dataset to enable researchers to experiment with classifying the same set of categories in three different modalities: images, audio, and video. The dataset covers 60 species of birds and is comprised of images from existing datasets, and brand new, expert curated audio and video datasets. We thoroughly benchmark audiovisual classification performance and modality fusion experiments through the use of state-of-the-art transformer methods. Our findings show that performance of audiovisual fusion methods is better than using exclusively image or audio based methods for the task of video classification. We also present interesting modality transfer experiments, enabled by the unique construction of SSW60 to encompass three different modalities. We hope the SSW60 dataset and accompanying baselines spur research in this fascinating area."
SPRINGERLINK,Chapter,2021,Data Quality Model-Based Testing of Information Systems: Two-Level Testing of the Insurance System,Anastasija NikiforovaJanis BicevskisZane BicevskaIvo Oditis,"Complete test set, Data quality model, Information system, Model-Based testing, Post-condition, Pre-condition",10,"In order to develop reliable software, its operating must be verified for all possible cases of use. This can be achieved, at least partly, by means of a model-based testing (MBT), by establishing tests that check all conditions covered by the model. This paper presents a Data Quality Model-based Testing (DQMBT) using the data quality model (DQ-model) as a testing model. The DQ-model contains definitions and conditions for data objects to consider the data object as correct. The proposed testing approach allows complete testing of the conformity of the data to be entered and the data already stored in the database. The data to be entered shall be verified by means of predefined pre-conditions, while post-conditions verify the allocation of the data into the database. The paper demonstrates the application of the proposed solution to the insurance system, concluding that it is able to identify previously undetected defects even after years of operating the IS. Therefore, the proposed solution can be considered as an effective complementary testing approach capable to improve the quality of an information system significantly. In the context of this study, we also address the MBT approach and the main factors affecting its popularity and identify the most popular ways of classifying MBT approaches."
SPRINGERLINK,Chapter,2021,Aspect-Oriented Model-Based Testing with UPPAAL Timed Automata,Jüri VainLeonidas TsiopoulosGert Kanter,"Aspect-Oriented Modeling, Model-Based Testing, Offline test generation, Test coverage, UPPAAL Timed Automata",10,This paper presents a method for offline test derivation from formal aspect-oriented models so that the tests provide coverage in terms of aspects related metrics. A test purpose specification method in temporal logic TCTL is proposed that enables referring to the attributes of aspect models symbolically. The method is exemplified on a health monitoring system and the quantitative evidence of the advantages provided by the method are evaluated in terms of work effort put into the test development and by analytical reasoning on the complexity.
SPRINGERLINK,Chapter,2021,Search-Based Automated Play Testing of Computer Games: A Model-Based Approach,Raihana FerdousFitsum KifetewDavide PrandiI. S. W. B. PrasetyaSamira ShirzadehhajimahmoodAngelo Susi,"Game play testing, Model-based testing, Search-based testing",10,"Computer game technology is increasingly more complex and applied in a wide variety of domains, beyond entertainment, such as training and educational scenarios. Testing games is a difficult task requiring a lot of manual effort since the interaction space in the game is very fine grained and requires a certain level of intelligence that cannot be easily automated. This makes testing a costly activity in the overall development of games. This paper presents a model-based formulation of game play testing in such a way that search-based testing can be applied for test generation. An abstraction of the desired game behaviour is captured in an extended finite state machine (EFSM) and search-based algorithms are used to derive abstract tests from the model, which are then concretised into action sequences that are executed on the game under test. The approach is implemented in a prototype tool EvoMBT . We carried out experiments on a 3D game to assess the suitability of the approach in general, and search-based test generation in particular. We applied 5 search algorithms for test generation on three different models of the game. Results show that search algorithms are able to achieve reasonable coverage on models: between 75% and 100% for the small and medium sized models, and between 29% and 56% for the bigger model. Mutation analysis shows that on the actual game application tests kill up to 99% of mutants. Tests have also revealed previously unknown faults."
SPRINGERLINK,Chapter,2021,Towards a Model-Based Approach to Support Physical Test Process of Aircraft Hydraulic Systems,Ouissem Mesli-KesraouiYassine OuhammouOlga GoubaliPascal BerruetPatrick GirardEmmanuel Grolleau,"Avionic test, DSML, Flushing, Hydraulic system, MBT",10,"The physical integration of an aircraft consists of the assembly of several complex subsystems (including hydraulic systems) developed by different stakeholders. The cleanliness of the developed hydraulic subsystems is ensured by performing several decontamination and flushing tests. This testing phase is very tedious as it is mainly performed by SCADA (Supervisory Control and Data Acquisition) systems and depends on chemical substances. However, as the design is mainly expressed in informal textual languages and synoptic diagrams, this testing is currently done manually and is determined by the experience of the testers. This makes it error-prone and time-consuming. In this paper, we propose to capitalize the effort for physical testing of hydraulic systems by proposing a model-based system engineering approach that allows: (i) to graphically specify the systems under test and (ii) to automatically generate the corresponding test cases. A proof of concept is proposed as well as a case study."
SPRINGERLINK,Chapter,2021,"A Proposal for the Classification of Methods for Verification and Validation of Safety, Cybersecurity, and Privacy of Automated Systems",Jose Luis de la VaraThomas BauerBernhard FischerMustafa KaracaHenrique MadeiraMartin MatschnigSilvia MazziniGiann Spilere NandiFabio PatroneDavid PereiraJosé ProençaRupert SchlickStefano TonettaUgur YayanBehrooz Sangchoolie,"Automated system, Classification, Cybersecurity, Method, Privacy, Safety, V&V, Verification and validation",10,"As our dependence on automated systems grows, so does the need for guaranteeing their safety, cybersecurity, and privacy (SCP). Dedicated methods for verification and validation (V&V) must be used to this end and it is necessary that the methods and their characteristics can be clearly differentiated. This can be achieved via method classifications. However, we have experienced that existing classifications are not suitable to categorise V&V methods for SCP of automated systems. They do not pay enough attention to the distinguishing characteristics of this system type and of these quality concerns. As a solution, we present a new classification developed in the scope of a large-scale industry-academia project. The classification considers both the method type, e.g., testing, and the concern addressed, e.g., safety. Over 70 people have successfully used the classification on 53 methods. We argue that the classification is a more suitable means to categorise V&V methods for SCP of automated systems and that it can help other researchers and practitioners."
SPRINGERLINK,Chapter,2021,An OWASP Top Ten Driven Survey on Web Application Protection Methods,Ouissem Ben FredjOmar CheikhrouhouMoez KrichenHabib HamamAbdelouahid Derhab,"Attacks, Countermeasures, OWASP top ten, Security, Survey, Web",10,"Web applications (WAs) are constantly evolving and deployed at broad scale. However, they are exposed to a variety of attacks. The biggest challenge facing organizations is how to develop a WA that fulfills their requirements with respect to sensitive data exchange, E-commerce, and secure workflows. This paper identifies the most critical web vulnerabilities according to OWASP Top Ten, their corresponding attacks, and their countermeasures. The application of these countermeasures will guarantee the protection of the WAs against the most severe attacks and prevent several unknown exploits."
SPRINGERLINK,Chapter,2021,Relation Between Test Coverage and Timed Automata Model Structure,Lukáš KrejčíJan SobotkaJiří Novák,"Automotive, Coverage, Hardware-in-the-Loop, HiL, Model-Based, Structure, Testing, Timed Automata",10,"This paper deals with problematics of structure of Timed Automata models suitable for Model-Based Testing of automotive systems. Previous experiments, primarily focused on the environmental models, have shown that their structure does not significantly affect the coverage speed of testing process. However, similar questions regarding the observer part of the system model remained open. This paper analyzes those remaining questions and focuses on uncovering possible relation between an observer model structure and the quality of generated test sequences according to multiple criteria. Goal of presented experiments is to compare multiple modeling approaches and discover which one is most suitable for automotive systems."
SPRINGERLINK,Chapter,2021,Realizing Digital Systems Engineering—Aerospace and Defence Use Case,Eran Gery,,10,The aerospace and defense industry have always been in the forefront of designing and developing complex systems. Mission challenges combined with technological advances are both contributing factors in how quickly the pace of complexity and sophistication is evolving in this industry. Being able to successfully navigate these challenges will define which companies are most competitive in this market.
SPRINGERLINK,Chapter,2021,Abstract Test Execution for Early Testing Activities in Model-Driven Scenarios,Reinhard PröllNoël HagemannBernhard Bauer,"Domain-specific modeling, Integrated model basis, Model-based testing, Model-driven software development, Test execution",10,"The continuous improvement of the performance of computing units makes it possible to cope with increasingly complex tasks. This results in more complex software systems. However, the development of such highly complex systems is difficult to achieve using traditional approaches. Concepts like model-driven software development can weaken this problem in these constructive phases. However, new challenges arise for the testing of development artifacts. In order to be able to perform a real shift left of verification and validation tasks towards early phases of development, we present a semi-formal approach that enables users to execute test cases against the system under development (SUD) on the model-level. Grounded on an Integrated Model Basis which is created and maintained during development, test reports are automatically derived. This opens up a wide range of possibilities for early and targeted troubleshooting."
SPRINGERLINK,Chapter,2021,30 Years of Automated GUI Testing: A Bibliometric Analysis,Olivia Rodríguez-ValdésTanja E. J. VosPekka AhoBeatriz Marín,"Automated testing, Bibliometric analysis, Graphical user interface, Secondary study",10,"Context: Over the last 30 years, GUIs have changed considerably, becoming everyday part of our lives through smart phones and other devices. More complex GUIs and multitude of platforms have increased the challenges when testing software through the GUI. Objective: To visualise how the field of automated GUI testing has evolved by studying the growth of the field; types of publications; influential events, papers and authors; collaboration among authors; and trends on GUI testing. Method: To conduct a bibliometric analysis of automated GUI testing by performing a systematic search of primary studies in Scopus from 1990 to 2020. Results: 744 publications were selected as primary studies. The majority of them were conference papers, the most cited paper was published on 2013, and the most published author has 53 papers. Conclusions: Automated GUI testing has continuously grown. Keywords show that testing applied to mobile interfaces will be the trend in next years, along with the integration of Artificial Intelligence and automated exploration techniques."
SPRINGERLINK,Chapter,2021,A Formalisation of SysML State Machines in mCRL2,Mark BouwmanBas LuttikDjurre van der Wal,,10,"This paper reports on a formalisation of the semi-formal modelling language SysML in the formal language mCRL2, in order to unlock formal verification and model-based testing using the mCRL2 toolset for SysML models. The formalisation focuses on a fragment of SysML used in the railway standardisation project EULYNX. It comprises the semantics of state machines, communication between objects via ports, and an action language called ASAL. It turns out that the generic execution model of SysML state machines can be elegantly specified using the rich data and process languages of mCRL2. This is a big step towards an automated translation as the generic model can be configured with a formal description of a specific set of state machines in a straightforward manner."
SPRINGERLINK,Chapter,2021,Formal Analysis of the UNISIG Safety Application Intermediate Sub-layer,Davide BasileAlessandro FantechiIrene Rosadi,,10,"The combined use of standard interfaces and formal methods is currently under investigation by Shift2Rail, a joint undertaking between railway stakeholders and the EU. Standard interfaces are useful to increase market competition and standardization whilst reducing long-term life cycle costs. Formal methods are needed to achieve interoperability and safety of standard interfaces and are one of the targets of the 4SECURail project funded by Shift2Rail. This paper presents the modelling and analysis of the selected case study of the 4SECURail project: the Safe Application Intermediate sub-layer of the UNISIG RBC/RBC Safe Communication Interface. The adopted formal method is Statistical Model Checking of a network of Stochastic Priced Timed Automata, as provided by the Uppaal SMC tool. The main contributions are: (i) rigorous complete and publicly available models of an official interface specification already in operation, (ii) identification of safety and interoperability issues in the original specification using Statistical Model Checking, (iii) quantification of costs for learning the adopted formal method and developing the carried out analysis."
SPRINGERLINK,Chapter,2021,Ontology-Driven Audit Using the REA-Ontology,Graham GalMonique SnoeckWim Laurier,"Model-driven engineering, Ontology, Smart contracts, Software audit",10,"While blockchains are not yet ubiquitous in business practice, they are expected to serve as a platform to handle an increasing number of business transactions in a not-too-distant future. Smart contracts can be used to code and to enforce agreements between business parties. A significant difference between traditional and smart contracts is that once the actual events of the smart contract become part of a block in the blockchain, they are almost impossible to undo. Therefore, it is important that critical validity aspects of these smart contracts are explicitly represented. As smart contracts are software products too, it is therefore also critical that the coding of these critical validity aspects guarantees a faithful implementation of the validity checks. This paper suggests applying a combination of two approaches (i.e., ontology engineering and model-driven engineering) to the design and the implementation of smart contracts, in order to facilitate their audit through a clear separation of concerns. More precisely, this paper discusses the example of the REA ontology to provide the ontological commitment of the critical validity aspects of a contract, while MDE provides a tool to unambiguously translate the REA ontology’s contracting terms into a well-designed Smart Contract. This paper suggests that the resulting Smart Contract can support auditors’ assertions regarding exchanges between business partners and support the audit process."
SPRINGERLINK,Chapter,2021,An Automated Modeling Method and Visualization Implementation of Smart Contracts,Jie MengZheng LiRuiliang ZhaoYing Shang,"Blockchain, EFSM, EFSMSolid, Formal definition, Smart contracts",10,"Smart contracts are one of the core components of the block-chain system and have been widely used across various fields. Since a smart contract cannot be easily changed or updated once instantiated, one has to be absolutely sure that the program code works as expected. However, there are no uniform definitions for smart contracts, and the programming of smart contracts requires professional developers with expert domain knowledge. This paper proposed a formal modeling method for start contracts. First, the formal definition of smart contracts is proposed. Second, we introduce an EFSM based modeling method for smart contracts. Finally, we design a visual modeling tool EFSMSolid for creating EFSM on an easy-to-use graphical platform. To verify the effectiveness of the method, we conduct experiments on smart contracts of five blockchain applications, and the experimental results show that the proposed method can automatically and effectively create smart contracts models."
SPRINGERLINK,Chapter,2021,Understanding Digital Twins for Cyber-Physical Systems: A Conceptual Model,Tao YuePaolo ArcainiShaukat Ali,"Conceptual model, Cyber-physical systems, Digital twins",10,"Digital Twins (DTs) are revolutionizing Cyber-Physical Systems (CPSs) in many ways, including their development and operation. The significant interest of industry and academia in DTs has led to various definitions of DTs and related concepts, as seen in many recently published papers. Thus, there is a need for precisely defining different DT concepts and their relationships. To this end, we present a conceptual model that captures various DT concepts and their relationships, some of which are from the published literature, to provide a unified understanding of these concepts in the context of CPSs. The conceptual model is implemented as a set of Unified Modeling Language (UML) class diagrams and the concepts in the conceptual model are explained with a running example of an automated warehouse case study from published literature and based on the authors’ experience of working with the real CPS case study in previous projects."
SPRINGERLINK,Chapter,2021,On Education and Training in Formal Methods for Industrial Critical Systems,Bernd Westphal,,10,"The 2020 expert survey on formal methods has put one topic into the focus of the formal methods for industrial critical systems community: education and training. Of three overall conclusions, the first one finds the survey to indicate “a consensus about the essential role of education”. At the same time, survey results and individual expert statements indicate largely open challenges. In this work, we analyse the 2020 expert survey results from an education and training perspective, and we discuss the proposal of an integrative approach with respect to these challenges. A central enabler for the integrated approach is the modern, inclusive interpretation of formal methods as put forth in the survey report and a differentiated understanding of roles (or stakeholders) in formal methods for industrial critical systems."
SPRINGERLINK,Chapter,2021,Privacy Design Strategies and the GDPR: A Systematic Literature Review,Marco SaltarellaGiuseppe DesoldaRosa Lanzilotti,"GDPR, Privacy by design, Usable privacy",10,"Article 25 of the GDPR states that data collection, processing and management measures should be implemented following tṇhe privacy by design and privacy by default paradigms. This paper presents a systematic literature review to identify useful guidelines to support the development of GDPR-compliant software. Selected papers are categorized under 8 different data-oriented and process-oriented strategies and their contributions are reported. Future activities will highlight the HCI community’s attitude towards these new technical and organizational approaches in order to bridge the identified gaps and shortcomings."
SPRINGERLINK,Chapter,2021,Testing Autogenerated OPC UA NodeSet Models for Product Variants in Industry,Claus KlammerThomas WetzlmaierMichael PfeifferThomas SteinerMatthias Konnerth,"Integration testing, Middleware, OPC UA, Test case generation",10,"Product line management activities have to ensure that offered product options are valid and compatible. With the arise of the Internet of Things (IoT) movement not only the own product compatibility has to be managed by the vendors anymore, but also the compliance and openness to standardized interfaces has to be supported as well. The Machine to Machine (M2M) communication protocol standard Open Platform Communications Unified Architecture (OPC UA) has received great attention in the field of mechanical engineering recently. In this industrial experience report we describe our approach how to support the testing of automatically generated models for OPC UA, by applying test case generation at the integration level. We show the feasibility of our approach and report about found issues, discuss some general findings and provide an outlook for future work."
SPRINGERLINK,Chapter,2020,Model-Based Testing Under Parametric Variability of Uncertain Beliefs,Matteo CamilliBarbara Russo,"Bayesian inference, Model-based Testing, Parametric Markov Decision Processes, Uncertainty analysis",10,"Modern software systems operate in complex and changing environments and are exposed to multiple sources of uncertainty. Considering uncertainty as a first-class concern in software testing is currently on an uptrend. This paper introduces a novel methodology to deal with testing under uncertainty. Our proposal combines the usage of parametric model checking at design-time and online model-based testing algorithms to gather runtime evidence and detect requirements violations. As modeling formalism, we adopt parametric Markov Decision Processes where transition probabilities are not fixed, but are possibly given as a set of uncertain parameters. The design-time phase aims at analyzing the parameter space to identify the constraints for requirements satisfaction. Then, the testing activity applies a Bayesian inference process to identify violations of pre-computed constraints. An extensive empirical evaluation shows that the proposed technique is effective in discovering violations and is cheaper than existing testing under uncertainty methods."
SPRINGERLINK,Chapter,2020,TesCaV: An Approach for Learning Model-Based Testing and Coverage in Practice,Beatriz MarínSofía AlarcónGiovanni GiachettiMonique Snoeck,"Coverage, Lessons learned, Model-Based Testing, Teaching/learning testing",10,"Academy and industry permanently remark the importance of software-testing techniques to improve software quality and to reduce development and maintenance costs. A testing method to be considered for this purpose is Model-Based Testing (MBT), which generates test cases from a model that represents the structure and the behavior of the system to be developed. The generated test suite is easier to maintain and adapt to changes in requirements or evolution of the developed system. However, teaching and learning MBT techniques are not easy tasks; students need to know the different testing techniques to assure that the requirements are fulfilled as well as to identify any failure in the software system modeled. In this work, we present TesCaV , an MBT teaching tool for university students, which is based on a model-driven technology for the automatic software generation from UML diagrams. TesCaV allows validating the test cases defined by students and graphically determines the level of testing coverage over the system modeled. Preliminary results show TesCaV as a promising approach for MBT teaching/learning processes."
SPRINGERLINK,Chapter,2020,Multi-path Coverage of All Final States for Model-Based Testing Theory Using Spark In-memory Design,Wilfried Yves Hamilton AdoniMoez KrichenTarik NahhalAbdeltif Elbyed,"Apache hadoop, Apache spark, Big data, Big graphs, Coverage, Model-based testing, Parallel and distributed computing",10,"This paper deals with an efficient and robust distributed framework for finite state machine coverage in the field model based testing theory. All final states coverage in large-scale automaton is inherently computing-intensive and memory exhausting with impractical time complexity because of an explosion of the number of states. Thus, it is important to propose a faster solution that reduces the time complexity by exploiting big data concept based on Spark RDD computation. To cope with this situation, we propose a parallel and distributed approach based on Spark in-memory design which exploits A* algorithm for optimal coverage. The experiments performed on multi-node cluster prove that the proposed framework achieves significant gain of the computation time."
SPRINGERLINK,Chapter,2020,Giving a Model-Based Testing Language a Formal Semantics via Partial MAX-SAT,Bernhard K. AichernigChristian Burghard,"Consistency checking, Formal semantics, Frame problem, Model transformation, Partial MAX-SAT, Partial moore machines",10,"Domain-specific Languages (DSLs) are widely used in model-based testing to make the benefits of modeling available to test engineers while avoiding the problem of excessive learning effort. Complex DSLs benefit from a formal definition of their semantics for model processing as well as consistency checking. A formal semantics can be established by mapping the model domain to a well-known formalism. In this paper, we present an industrial use case which includes a mapping from domain-specific models to Moore Machines, based on a Partial MAX-SAT problem, encoding a predicative semantics for the model-to-model mapping. We show how Partial MAX-SAT solves the frame problem for a non-trivial DSL in which the non-effect on variables cannot be determined statically. We evaluated the performance of our model-transformation algorithm based on models from our industrial use case."
SPRINGERLINK,Chapter,2020,Model-Based Testing for MQTT Applications,Kotaro TanabeYoshinori TanabeMasami Hagiya,,10,"Model-based testing is a widely-used vital technique for testing software running in a complex environment. In this paper, we propose extensions to existing model-based tools to apply this technique to software that employs the MQ Telemetry Transport (MQTT) protocol for transmitting messages, commonly used in the Internet of Things (IoT) environment. First, in the finite state machine used for generating test cases in a model-based testing framework, we introduce a type of transition that is triggered when receiving MQTT messages. Second, we extend the finite-state machine so that it produces test cases that reflect the characteristics of IoT software – a large number of relatively simple devices communicate with servers. Third, the concept of time is introduced into the finite state machine. Naturally, this is necessary for verifying the properties of software that runs for a long time. Moreover, to facilitate such verification, both real-time and virtual time are introduced. We implemented these extensions into a model-based testing tool, Modbat, and conducted a small experiment to confirm the feasibility, gaining positive results."
SPRINGERLINK,Chapter,2020,Automated Requirements-Based Testing of Black-Box Reactive Systems,Massimo NarizzanoLuca PulinaArmando TacchellaSimone Vuotto,"Automated testing and verification, Black-box conformance testing, Runtime verification",10,"We present a new approach to conformance testing of black-box reactive systems. We consider system specifications written as linear temporal logic formulas to generate tests as sequences of input/output pairs: inputs are extracted from the Büchi automata corresponding to the specifications, and outputs are obtained by feeding the inputs to the systems. Conformance is checked by comparing input/output sequences with automata traces to detect violations of the specifications. We consider several criteria for extracting tests and for stopping generation, and we compare them experimentally using both indicators of coverage and error-detection. The results show that our methodology can generate test suites with good system coverage and error-detection capability."
SPRINGERLINK,Chapter,2020,Interoperability and Integration Testing Methods for IoT Systems: A Systematic Mapping Study,Miroslav BuresMatej KlimaVaclav RechtbergerXavier BellekensChristos TachtatzisRobert AtkinsonBestoun S. Ahmed,"Automated testing, Integration, Internet of Things, Interoperability, Testing, Verification",10,"The recent active development of Internet of Things (IoT) solutions in various domains has led to an increased demand for security, safety, and reliability of these systems. Security and data privacy are currently the most frequently discussed topics; however, other reliability aspects also need to be focused on to maintain smooth and safe operation of IoT systems. Until now, there has been no systematic mapping study dedicated to the topic of interoperability and integration testing of IoT systems specifically; therefore, we present such an overview in this study. We analyze 803 papers from four major primary databases and perform detailed assessment and quality check to find 115 relevant papers. In addition, recently published testing techniques and approaches are analyzed and classified; the challenges and limitations in the field are also identified and discussed. Research trends related to publication time, active researchers, and publication media are presented in this study. The results suggest that studies mainly focus only on general testing methods, which can be applied to integration and interoperability testing of IoT systems; thus, there are research opportunities to develop additional testing methods focused specifically on IoT systems, so that they are more effective in the IoT context."
SPRINGERLINK,Chapter,2020,Improving and Optimizing Verification and Testing Techniques for Distributed Information Systems,Moez Krichen,"Distributed, Formal verification, Information systems, Model based testing, Optimization, Test component placement",10,"In this paper, we deal with two validation techniques which may be adopted for improving the quality and ensuring the correctness of Distributed Information Systems. These two techniques are Formal Verification and Model Based Techniques. The first one consists in checking the correctness of a mathematical model used to describe the behavior of the considered system before its implementation. The second technique consists in deriving tests suites from the adopted model, executing them and finally deducing verdicts about the correctness of this system under test. In both cases, we need to tackle the explosion state challenge which corresponds to the fact of reaching a very large space of states and consuming a very long time during the validation process. To solve this problem we propose a set of appropriate techniques taken from the literature. We also identify a set of techniques which may be used for the optimization of the test component placement procedure."
SPRINGERLINK,Chapter,2020,On the Automation of Security Testing for IoT Constrained Scenarios,Sara N. MatheuSalvador PérezJosé L. Hernández RamosAntonio Skarmeta,"IoT, Model-Based Testing (MBT), Security risk assessment, Security testing",10,"Due to the high increase of IoT technologies and devices, analyzing their security is crucial for their acceptance. Towards this end, an automated security testing approach should be considered as a cornerstone to cope with the business interests and the high fragmentation of new approaches. In particular, this work analyses the use of the Model-Based Testing (MBT) approach and specific technologies and tools to automate the generation of security tests. Then, we provide a detailed description of its application to the Elliptic Curve Diffie-Hellman over COSE (EDHOC) protocol, which is being defined within the scope of the Internet Engineering Task Force (IETF)."
SPRINGERLINK,Chapter,2020,Teaching Software Testing to Industrial Practitioners Using Distance and Web-Based Learning,Eduard Paul Enoiu,"Industrial practitioners, Online education, Software engineering education, Software testing education, Web-based learning",10,"Software testing is a business-critical process used by private and public organizations and an important source of market competitiveness. Employees of these organizations are facing tough competition and are required to be able to maintain and develop their skills and knowledge in software testing. In the education market, many commercial courses and certifications are available for industrial engineers who wish to improve their skills in software development. Nevertheless, there is a lack of access to world-leading research within the software testing field in these commercial courses that supports the companies’ innovation in software testing. As an alternative, universities are approaching this challenge by developing academic courses on software testing that can suit professionals who need to be able to combine work and studies. This study highlights several good approaches and challenges in developing and teaching three distance web-based software testing courses targeting test practitioners. The proposed approaches for enhancing teaching of software testing in an online setting for industrial practitioners are: active participation at the student’s pace, inclusion of software testing artifacts from the student’s organization as part of assignments, continuous access to online materials, the use of short video materials on testing theory, and setting clear expectations for performing online test design assignments. Finally, several challenges have been identified: poor feedback on assignments, distances between students and teachers, the use of non-realistic assignments and the difficulty for industrial practitioners to complete academic assignments each week. Future work is needed to explore these results in practice, for example on how to shorten distances between students and teachers, as well as how to enhance the inclusion of real-world testing artifacts in course assignments."
SPRINGERLINK,Chapter,2020,Benchmarking Combinations of Learning and Testing Algorithms for Active Automata Learning,Bernhard K. AichernigMartin TapplerFelix Wallner,"Active automata learning, Conformance testing, LearnLib, Model learning, Model-based testing",10,"Active automata learning comprises techniques for learning automata models of black-box systems by testing such systems. While this form of learning enables model-based analysis and verification, it may also require a substantial amount of interactions with considered systems to learn adequate models, which capture the systems’ behaviour. The test cases executed during learning can be divided into two categories: (1) test cases to gain knowledge about a system and (2) test cases to falsify a learned hypothesis automaton. The former are selected by learning algorithms, whereas the latter are selected by conformance-testing algorithms. There exist various options for both types of algorithms and there are dependencies between them. In this paper, we investigate the performance of combinations of four different learning algorithms and seven different testing algorithms. For this purpose, we perform learning experiments using 39 benchmark models. Based on experimental results, we discuss insights regarding the performance of different configurations for various types of systems. These insights may serve as guidance for future users of active automata learning."
SPRINGERLINK,Chapter,2020,Flexible Formality Practical Experience with Agile Formal Methods,Philipp KantKevin HammondDuncan CouttsJames ChapmanNicholas ClarkeJared CorduanNeil DaviesJavier DíazMatthias GüdemannWolfgang JeltschMarcin SzamotulskiPolina Vinogradova,,10,"Agile software development and Formal Methods are traditionally seen as being in conflict. From an Agile perspective, there is pressure to deliver quickly , building vertical prototypes and doing many iterations/sprints, refining the requirements; from a Formal Methods perspective, there is pressure to deliver correctly and any change in requirements often necessitates changes in the formal specification and might even impact all arguments of correctness. Over the years, the need to “be agile” has become a kind of mantra in software development management, and there is a prevalent prejudice that using formal methods was an impediment to being agile. In this paper, we contribute to the refutation of this stereotype, by providing a real-world example of using good practices from formal methods and agile software engineering to deliver software that is simultaneously reliable, effective, testable, and that can also be iterated and delivered rapidly. We thus present how a lightweight software engineering methodology, drawing from appropriate formal methods techniques and providing the benefits of agile software development, can look like. Our methodology is informed and motivated by practical experience. We have devised and adapted it in the light of experience in delivering a large-scale software system that needs to meet complex real-world requirements: the Cardano blockchain and its cryptocurrency ada. The cryptocurrency domain is a rather new application area for which no clear engineering habit exists, so it is fitting well for agile methods. At the same time, there is a lot of real monetary value at stake, making it a good fit for using formal methods to ensure high quality and correctness. This paper reports on the issues that have been faced and overcome, and provides a number of real-world lessons that can be used to leverage the benefits of both agile and formal methods in other situations."
SPRINGERLINK,Chapter,2020,From Requirements to Automated Acceptance Tests with the RSL Language,Ana C. R. PaivaDaniel MacielAlberto Rodrigues da Silva,"Model-based Testing (MBT), Requirements Specification Language (RSL), Test case execution, Test case generation, Test case specification",10,"Software testing can promote software quality. However, this activity is often performed at the end of projects where failures are most difficult to correct. Combining requirements specification activities with test design at an early stage of the software development process can be beneficial. One way to do this is to use a more structured requirements specification language. This allow to reduce typical problems such as ambiguity, inconsistency, and incorrectness in requirements and may allow the automatic generation of (parts of) acceptance test cases reducing the test design effort. In this paper we discuss an approach that promotes the practice of requirements specification combined with testing specification. This is a model-based approach that promotes the alignment between requirements and tests, namely, test cases and also low-level automated test scripts. To show the applicability of this approach, we integrate two complementary languages: (i) the ITLingo RSL (Requirements Specification Language) that is specially designed to support both requirements and tests rigorously and consistently specified; and (ii) the Robot language, which is a low-level keyword-based language for specifying test scripts. This approach includes model-to-model transformation processes, namely a transformation process from requirements (defined in RSL) into test cases (defined in RSL), and a second transformation process from test cases (in RSL) into test scripts (defined according the Robot framework). This approach was applied in a fictitious online store that illustrates the various phases of the proposal."
SPRINGERLINK,Chapter,2020,From Passive to Active: Learning Timed Automata Efficiently,Bernhard K. AichernigAndrea PferscherMartin Tappler,"Active automata learning, Genetic programming, Model inference, Model learning, Timed automata",10,"Model-based testing is a promising technique for quality assurance. In practice, however, a model is not always present. Hence, model learning techniques attain increasing interest. Still, many learning approaches can only learn relatively simple types of models and advanced properties like time are ignored in many cases. In this paper we present an active model learning technique for timed automata. For this, we build upon an existing passive learning technique for real-timed systems. Our goal is to efficiently learn a timed system while simultaneously minimizing the set of training data. For evaluation we compared our active to the passive learning technique based on 43 timed systems with up to 20 locations and multiple clock variables. The results of $$18\,060$$ 18 060 experiments show that we require only 100 timed traces to adequately learn a timed system. The new approach is up to 755 times faster."
SPRINGERLINK,Chapter,2020,Aplib: Tactical Agents for Testing Computer Games,I. S. W. B. PrasetyaMehdi DastaniRui PradaTanja E. J. VosFrank DignumFitsum Kifetew,"Agents tactical programming, AI for automated testing, Automated game testing, Intelligent agent programming, Intelligent agents for testing",10,"Modern interactive software, such as computer games, employ complex user interfaces. Although these user interfaces make the games attractive and powerful, unfortunately they also make them extremely difficult to test. Not only do we have to deal with their functional complexity, but also the fine grained interactivity of their user interface blows up their interaction space, so that traditional automated testing techniques have trouble handling it. An agent-based testing approach offers an alternative solution: agents’ goal driven planning, adaptivity, and reasoning ability can provide an extra edge towards effective navigation in complex interaction space. This paper presents aplib , a Java library for programming intelligent test agents, featuring novel tactical programming as an abstract way to exert control over agents’ underlying reasoning-based behavior. This type of control is suitable for programming testing tasks. Aplib is implemented in such a way to provide the fluency of a Domain Specific Language (DSL). Its embedded DSL approach also means that aplib programmers will get al.l the advantages that Java programmers get: rich language features and a whole array of development tools ."
SPRINGERLINK,Chapter,2020,Test Automation with the Gauge Framework: Experience and Best Practices,Vahid GarousiAlper Buğra KeleşYunus BalamanZeynep Özdemir Güler,"Best practices, Gauge framework, Industrial experience, Software testing, Test automation",10,"While Behavior-driven development (BDD) tools such as Cucumber are powerful tools for automated testing, they have certain limitations. For example, they often enforce strict syntax for test cases, like the “Given-When-Then” format, which may not always be easy to write for a given test case. A new test automation framework named Gauge ( gauge.org ) addresses that limitation since it does not prescribe the BDD testing process with a strict syntax. In Gauge, writing a test case is as easy as writing down the flow of test cases in several itemized sentences in a natural language, like English. In the context of Testinium ( testinium.com ), a large software testing company which provides software testing services, tools and solutions to a large number of clients, we have actively used the Gauge framework since 2018 to develop large automated front-end test suites for several large web applications. In this paper/talk, the speakers will share several examples and best practices of developing automated tests in natural-language requirements using the Gauge framework. By learning from the ideas presented in the talk, readers (attendees) will be able to consider applying the Gauge framework in their own test automation projects."
SPRINGERLINK,Chapter,2020,"A Model-Based Approach to the Design, Verification and Deployment of Railway Interlocking System",Arturo AmendolaAnna BecchiRoberto CavadaAlessandro CimattiAlberto GriggioGiuseppe ScaglioneAngelo SusiAlberto TacchellaMatteo Tessi,"Code generation, Formal verification, Functional specifications, Interlocking Systems, Model-based design",10,"This paper describes a model-based flow for the development of Interlocking Systems. The flow starts from a set of specifications in Controlled Natural Language (CNL), that are close to the jargon adopted in by domain experts, but fully formal. From the CNL, a complete SysML specification is extracted, leveraging various forms of diagrams, and enabling automated code generation. Several formal verification methods are supported. A complementary part of the flow supports the extraction of formal properties from legacy Interlocking Systems designed as Relay circuits. The flow is implemented in a comprehensive toolset, and is currently used by railway experts."
SPRINGERLINK,Chapter,2020,Test4Enforcers: Test Case Generation for Software Enforcers,Michell GuzmanOliviero RiganelliDaniela MicucciLeonardo Mariani,"Android apps, Runtime enforcement, Test case generation, Testing enforcers",10,"Software enforcers can be used to modify the runtime behavior of software applications to guarantee that relevant correctness policies are satisfied. Indeed, the implementation of software enforcers can be tricky, due to the heterogeneity of the situations that they must be able to handle. Assessing their ability to steer the behavior of the target system without introducing any side effect is an important challenge to fully trust the resulting system. To address this challenge, this paper presents Test4Enforcers, the first approach to derive thorough test suites that can validate the impact of enforcers on a target system. The paper also shows how to implement the Test4Enforcers approach in the DroidBot test generator to validate enforcers for Android apps."
SPRINGERLINK,Chapter,2020,Trace Analysis Using an Event-Driven Interval Temporal Logic,María-del-Mar GallardoLaura Panizo,,10,"Nowadays, many critical systems can be characterized as hybrid ones, combining continuous and discrete behaviours that are closely related. Changes in the continuous dynamics are usually fired by internal or external discrete events. Due to their inherent complexity, it is a crucial but not trivial task to ensure that these systems satisfy some desirable properties. An approach to analyze them consists of the combination of model-based testing and run-time verification techniques. In this paper, we present an interval logic to specify properties of event-driven hybrid systems and an automatic transformation of the logic formulae into networks of finite-state machines. Currently, we use Promela / Spin to implement the network of finite-state machines, and analyze non-functional properties of mobile applications. We use the TRIANGLE testbed, which implements a controllable network environment for testing, to obtain the application traces and monitor network parameters."
SPRINGERLINK,Chapter,2020,The 2020 Expert Survey on Formal Methods,Hubert GaravelMaurice H. ter BeekJaco van de Pol,"Cybersecurity, Education, Formal method, Modelling, Safety, Software engineering, Software tool, Specification, Survey, Technology transfer, Verification",10,"Organised to celebrate the 25th anniversary of the FMICS international conference, the present survey addresses 30 questions on the past, present, and future of formal methods in research, industry, and education. Not less than 130 high-profile experts in formal methods (among whom three Turing award winners and many recipients of other prizes and distinctions) accepted to participate in this survey. We analyse their answers and comments, and present a collection of 111 position statements provided by these experts. The survey is both an exercise in collective thinking and a family picture of key actors in formal methods."
SPRINGERLINK,Chapter,2020,A General Framework for Decentralized Combinatorial Testing of Access Control Engine: Examples of Application,Said DaoudaghFrancesca LonettiEda Marchetti,"Access control systems, Oracle, Testing, Web service, XACML",10,"Access control mechanisms aim to assure data protection in modern software systems. Testing of such mechanisms is a key activity to avoid security flaws and violations inside the systems or applications. In this paper, we introduce the general architecture of a new decentralized framework for testing of XACML-based access control engines. The proposed framework is composed of different web services and can be instantiated for different testing purposes: i) generation of test cases based on combinatorial testing strategies; ii) distributed test cases execution; iii) decentralized oracle derivation able to associate the expected authorization decision to a given XACML request. The effectiveness of the framework has been proven into two different experiments. The former addressed the evaluation of the distributed vs non distributed testing solution. The latter focused on the performance comparison of two distributed oracle approaches."
SPRINGERLINK,Chapter,2020,An Architecture for Automated Security Test Case Generation for MQTT Systems,Hannes SochorFlavio FerrarottiRudolf Ramler,"Automated testing, IoT, MQTT, Security testing",10,"Message Queuing Telemetry Transport (MQTT) protocol is among the preferred publish/subscribe protocols used for Machine-to-Machine (M2M) communication and Internet of Things (IoT). Although the MQTT protocol itself is quite simple, the concurrent iteration of brokers and clients and its intrinsic non-determinism, coupled with the diversity of platforms and programming languages in which the protocol is implemented and run, makes the necessary task of security testing challenging. We address precisely this problem by proposing an architecture for security test generation for systems relying on the MQTT protocol. This architecture enables automated test case generation to reveal vulnerabilities and discrepancies between different implementations. As a desired consequence, when implemented, our architectural design can be used to uncover erroneous behaviours that entail latent security risks in MQTT broker and client implementations. In this paper we describe the key components of our architecture, our prototypical implementation using a random test case generator, core design decisions and the use of security attacks in testing. Moreover, we present first evaluations of the architectural design and the prototypical implementation with encouraging initial results."
SPRINGERLINK,Chapter,2020,"Uncertainty, Modeling and Safety Assurance: Towards a Unified Framework",Marsha ChechikSahar KokalyMona RahimiRick SalayTorin Viger,,10,"Uncertainty occurs naturally in software systems, including those that are model-based. When such systems are safety-critical, they need to be assured, e.g., by arguing that the system satisfies its safety goals. But how can we rigorously reason about assurance in the presence of uncertainty? In this paper, we propose a vision for a framework for managing uncertainty in assurance cases for software systems, and in particular, for model-based software systems, by systematically identifying , assessing and addressing it. We also discuss a set of challenges that need to be addressed to realize this framework."
SPRINGERLINK,Chapter,2020,Learning Abstracted Non-deterministic Finite State Machines,Andrea PferscherBernhard K. Aichernig,"Active automata learning, Model inference, MQTT, Non-deterministic finite state machines",10,"Active automata learning gains increasing interest since it gives an insight into the behavior of a black-box system. A crucial drawback of the frequently used learning algorithms based on Angluin’s $$L^*$$ L ∗ is that they become impractical if systems with a large input/output alphabet are learned. Previous work suggested to circumvent this problem by abstracting the input alphabet and the observed outputs. However, abstraction could introduce non-deterministic behavior. Already existing active automata learning algorithms for observable non-deterministic systems learn larger models if outputs are only observable after certain input/output sequences. In this paper, we introduce an abstraction scheme that merges akin states. Hence, we learn a more generic behavioral model of a black-box system. Furthermore, we evaluate our algorithm in a practical case study. In this case study, we learn the behavior of five different Message Queuing Telemetry Transport (mqtt) brokers interacting with multiple clients."
SPRINGERLINK,Chapter,2020,Language Inclusion for Finite Prime Event Structures,Andreas FellnerThorsten TarrachGeorg Weissenbacher,"Concurrency, Event structures, Language inclusion, Mutation-based test case generation",10,"We study the problem of language inclusion between finite, labeled prime event structures. Prime event structures are a formalism to compactly represent concurrent behavior of discrete systems. A labeled prime event structure induces a language of sequences of labels produced by the represented system. We study the problem of deciding inclusion and membership for languages encoded by finite prime event structures and provide complexity results for both problems. We provide a family of examples where prime event structures are exponentially more succinct than formalisms that do not take concurrency into account. We provide a decision algorithm for language inclusion that exploits this succinctness. Furthermore, we provide an implementation of the algorithm and an evaluation on a series of benchmarks. Finally, we demonstrate how our results can be applied to mutation-based test case generation."
SPRINGERLINK,Chapter,2020,Interrogating Virtual Agents: In Quest of Security Vulnerabilities,Josip BozicFranz Wotawa,"Chatbots, Model-based testing, Security testing, Web applications",10,"Chatbots, i.e., systems that communicate in natural language, have been of increasing importance over the last few years. These virtual agents provide specific services or products to clients on a 24/7 basis. Chatbots provide a simple and intuitive interface, i.e., natural language processing, which makes them increasingly attractive for various applications. In fact, chatbots are used as substitutes for repetitive tasks or user inquiries that can be automated. However, these advantages always are accompanied with concerns, e.g., whether security and privacy can be assured. These concerns become more and more important, because in contrast to simple requests, more sophisticated chatbots are able to utilize personalized services to users. In such cases, sensitive user data are processed and exchanged. Hence, such systems become natural targets for cyber-attacks with unforeseen consequences. For this reason, assuring information security of chatbots is an important challenge in practice. In this paper, we contribute to this challenge and introduce an automated security testing approach for chatbots. The presented framework is able to generate and run tests in order to detect intrinsic software weaknesses leading to the XSS vulnerability. We assume a vulnerability to be triggered when obtaining critical information from or crashing the virtual agent, regardless of its purpose. We discuss the underlying basic foundations and demonstrate the testing approach using several real-world chatbots."
SPRINGERLINK,Chapter,2020,A Modular SystemC RTOS Model for Uncertainty Analysis,Lorenzo LazzaraGiulio Mosé MancusoFabio CremonaAlessandro Ulisse,"Real-time operating system model, Statistical model checking, SystemC, Uncertainty quantification",10,"Nowadays the complexity of embedded systems is constantly increasing and several different types of applications concurrently execute on the same computational platform. Hence these systems have to satisfy real-time constraints and support real-time communication. The design and verification of these systems is very complex, full formal verification is not always possible and the run-time verification is the only feasible path to follow. In this context, the possibility to simulate their behavior becomes a crucial aspect. This paper proposes a SystemC modular RTOS model to assist the design and the verification of real-time embedded systems. The model architecture has been designed to capture all the typical functionalities that every RTOS owns, in order to easily reproduce the behavior of a large class of RTOS. The RTOS model can support functional simulation for design space exploration to rapidly evaluate the impact of different RTOS configurations (such as scheduling policies) on the overall system performances. Moreover the model can be used for software verification by implementing specific RTOS APIs over the generic services provided by the model, allowing the simulation of a real application without changing any instruction. The proposed approach enables the user to model non-deterministic behaviors at architectural and application level by means of probabilistic distributions. This allows to assess system performances of complex embedded systems under uncertain behavior (e.g. execution time). A use case is proposed considering an instance of the model compliant with the ARINC 653 specification, which requires spatial and temporal segregation, and where typical RTOS performances are assessed given the probability distributions of execution time and aperiodic task activation."
SPRINGERLINK,Chapter,2020,Model-Driven Chatbot Development,Sara Pérez-SolerEsther GuerraJuan de Lara,"Chatbots, DSLs, Migration, Model-driven engineering",10,"Chatbots are software services accessed via conversation in natural language. They are increasingly used to help in all kinds of procedures like booking flights, querying visa information or assigning tasks to developers. They can be embedded in webs and social networks, and be used from mobile devices without installing dedicated apps. While many frameworks and platforms have emerged for their development, identifying the most appropriate one for building a particular chatbot requires a high investment of time. Moreover, some of them are closed – resulting in customer lock-in – or require deep technical knowledge. To tackle these issues, we propose a model-driven engineering approach to chatbot development. It comprises a neutral meta-model and a domain-specific language (DSL) for chatbot description; code generators and parsers for several chatbot platforms; and a platform recommender. Our approach supports forward and reverse engineering, and model-based analysis. We demonstrate its feasibility presenting a prototype tool and an evaluation based on migrating third party Dialogflow bots to Rasa."
SPRINGERLINK,Chapter,2020,Coverage Analysis of Net Inscriptions in Coloured Petri Net Models,Faustin AhishakiyeJosé Ignacio Requeno JaraboLars Michael KristensenVolker Stolz,,10,"High-level Petri nets such as Coloured Petri Nets (CPNs) are characterised by the combination of Petri nets and a high-level programming language. In the context of CPNs and CPN Tools, the inscriptions (e.g., arc expressions and guards) are specified using Standard ML (SML). The application of simulation and state space exploration (SSE) for validating CPN models traditionally focusses on behavioural properties related to net structure, i.e., places and transitions. This means that the net inscriptions are only implicitly validated, and the extent to which their sub-expressions have been covered is not made explicit. The contribution of this paper is an approach that establishes a link between coverage analysis known from programming languages and net inscriptions of CPN models. Specifically, we consider Modified Condition/Decision Coverage (MC/DC) of Boolean SML decisions, which cannot be measured within CPN Tools neither through state space exploration nor model checking directly. We have implemented our approach in a library for CPN Tools comprised of an annotation and instrumentation mechanism that transparently intercepts and collects evaluation of boolean conditions, and a post-processing tool that, for a set of model executions (runs), determines whether each decision is MC/DC-covered. We evaluate our approach on four large publicly available CPN models."
SPRINGERLINK,Chapter,2020,Inspecting Code Churns to Prioritize Test Cases,Francesco AltieroAnna CorazzaSergio Di MartinoAdriano PeronLuigi Libero Lucio Starace,"Code churn., Regression testing, Test prioritization",10,"Within the context of software evolution, due to time-to-market pressure, it is not uncommon that a company has not enough time and/or resources to re-execute the whole test suite on the new software version, to check for non-regression. To face this issue, many Regression Test Prioritization techniques have been proposed, aimed at ranking test cases in a way that tests more likely to expose faults have higher priority. Some of these techniques exploit code churn metrics, i.e. some quantification of code changes between two subsequent versions of a software artifact, which have been proven to be effective indicators of defect-prone components. In this paper, we first present three new Regression Test Prioritization strategies, based on a novel code churn metric, that we empirically assessed on an open source software system. Results highlighted that the proposal is promising, but that it might be further improved by a more detailed analysis on the nature of the changes introduced between two subsequent code versions. To this aim, in this paper we also sketch a more refined approach we are currently investigating, that quantifies changes in a code base at a finer grained level. Intuitively, we seek to prioritize tests that stress more fault-prone changes (e.g., structural changes in the control flow), w.r.t. those that are less likely to introduce errors (e.g., the renaming of a variable). To do so, we propose the exploitation of the Abstract Syntax Tree (AST) representation of source code, and to quantify differences between ASTs by means of specifically designed Tree Kernel functions, a type of similarity measure for tree-based data structures, which have shown to be very effective in other domains, thanks to their customizability."
SPRINGERLINK,Chapter,2020,Continuous Optimization Benchmarks by Simulation,Martin ZaeffererFrederik Rehbach,"Benchmarking, Continuous optimization, Gaussian process regression, Kriging, Simulation, Test function",10,"Benchmark experiments are required to test, compare, tune, and understand optimization algorithms. Ideally, benchmark problems closely reflect real-world problem behavior. Yet, real-world problems are not always readily available for benchmarking. For example, evaluation costs may be too high, or resources are unavailable (e.g., software or equipment). As a solution, data from previous evaluations can be used to train surrogate models which are then used for benchmarking. The goal is to generate test functions on which the performance of an algorithm is similar to that on the real-world objective function. However, predictions from data-driven models tend to be smoother than the ground-truth from which the training data is derived. This is especially problematic when the training data becomes sparse. The resulting benchmarks may not reflect the landscape features of the ground-truth, are too easy, and may lead to biased conclusions. To resolve this, we use simulation of Gaussian processes instead of estimation (or prediction). This retains the covariance properties estimated during model training. While previous research suggested a decomposition-based approach for a small-scale, discrete problem, we show that the spectral simulation method enables simulation for continuous optimization problems. In a set of experiments with an artificial ground-truth, we demonstrate that this yields more accurate benchmarks than simply predicting with the Gaussian process model."
SPRINGERLINK,Chapter,2020,Statistical Model Checking for Variability-Intensive Systems,Maxime CordyMike PapadakisAxel Legay,,10,"We propose a new Statistical Model Checking (SMC) method to discover bugs in variability-intensive systems (VIS). The state-space of such systems is exponential in the number of variants, which makes the verification problem harder than for classical systems. To reduce verification time, we sample executions from a featured transition system – a model that represents jointly the state spaces of all variants. The combination of this compact representation and the inherent efficiency of SMC allows us to find bugs much faster (up to 16 times according to our experiments) than other methods. As any simulation-based approach, however, the risk of Type-1 error exists. We provide a lower bound and an upper bound for the number of simulations to perform to achieve the desired level of confidence. Our empirical study involving 59 properties over three case studies reveals that our method manages to discover all variants violating 41 of the properties. This indicates that SMC can act as a low-cost-high-reward method for verifying VIS."
SPRINGERLINK,Chapter,2020,Safety Patterns for SysML: What Does OMG Specify?,Nan NiuLogan JohnsonChristopher Diltz,"Grounded theory, Semantic roles, Specification patterns, Systems Modeling Language (SysML), Systems reuse, Temporal constraints",10,"The Systems Modeling Language (SysML) represents a significant and increasing segment of industrial support for building critical systems. The Object Management Group (OMG) has been releasing and revising the formal specification of SysML since 2007, with version 1.6 recently formalized in November 2019. However, little is known about what OMG specifies and how the official specification influences model-driven engineering (MDE). To fill the gap, we present a new way of analyzing the OMG SysML specification (version 1.6) to uncover reusable guidelines and constraints for safe MDE practice. We illustrate our approach with the discovery of the recurring “Asset Leakage” safety pattern and the development of a semantic-role-based theory to support practitioners’ identification, formulation, and verification of critical properties in their modeling contexts."
SPRINGERLINK,Chapter,2020,Systematic Approach to Engineer Decentralized Self-adaptive Systems,Federico Quin,"Architecture-based adaptation, Decentralization, Formal techniques, Machine learning, Self-adaptation",10,"Self-adaptation is a widely accepted approach to deal with uncertainties that are difficult to anticipate before deployment. We focus on architecture-based adaptation that relies on a feedback loop that reasons over architectural models of the system at runtime to make adaptation decisions. In particular, we study decentralized self-adaptive systems where self-adaptation is realized through multiple coordinating feedback loops. Such decentralization is crucial for systems where adaptation decisions cannot be made in a centralized way, such as in large scale Internet of Things (IoT). State of the art in this area is limited to either conceptual ideas or solutions dedicated to particular settings. This paper outlines a research project targeting the research question: “how to model and realize decentralized feedback loops that are capable to guarantee compliance of system goals in an efficient way despite uncertainties the system faces?” We plan to answer this question in two stage. First, we study commonalities and variability of decentralized self-adaptive systems leveraging on patterns and coordination mechanisms, and reify our insights in a framework. Second, we study language support for the design and implementation of decentralized self-adaptation, capitalizing on the outcome of the first stage. To ensure guarantees for the qualities we will found our work on formal techniques. To ensure efficiency, we will combine statistical techniques with machine learning. We plan to validate the research results in two domains: IoT and multi-cloud systems."
SPRINGERLINK,Chapter,2020,Formal Verification of OIL Component Specifications using mCRL2,Olav BunteLouis C. M. van GoolTim A. C. Willemse,,10,"To aid in making software bug-free, several high-tech companies are moving from coding to modelling. In some cases model checking techniques are explored or have already been adopted to get more value from these models. This also holds for Canon Production Printing, where the language OIL was developed for modelling control-software components. In this paper we present OIL and give its semantics. We define a translation from OIL to mCRL2 to enable the use of model checking techniques. Moreover, we discuss informal validity requirements on OIL component specifications and show how these can be formalised and verified using model checking. To test the feasibility of these techniques, we apply them to two models of systems used in production."
SPRINGERLINK,Chapter,2020,Continuous Formal Verification of Microservice-Based Process Flows,Matteo Camilli,"DevOps, Formal verification, Microservices, Petri nets",10,"The microservice architectural style is often used to implement modern cloud, IoT, and large-scale distributed applications. Here software development processes are characterized by short incremental iterations, where several updates and new functionalities are continuously integrated many times a day in a agile fashion. Such a paradigm shift calls for new formal approaches to systematic (design-time and runtime) verification. This paper introduces a formal framework to apply continuous verification of microservice based applications built on top of Conductor , i.e., an open source orchestration engine of microservices workflows in use at Netflix, Inc. for their production environment. Our proposal adopts a model-driven paradigm and it leverages solid foundation from Petri nets to specify and verify the behavior of time-dependent workflows. This paper describes our approach, the current implementation, and evaluation activity conducted on a taxi-hailing application example."
SPRINGERLINK,Chapter,2020,Declarative Stream Runtime Verification (hLola),Martín CeresaFelipe GorostiagaCésar Sánchez,,10,"Stream Runtime Verification (SRV) is a formal dynamic analysis technique that generalizes runtime verification algorithms from temporal logics like LTL to stream monitoring, allowing the computation of richer verdicts than Booleans (quantitative values or even arbitrary data). The core of SRV algorithms is a clean separation between temporal dependencies and data computations. In spite of this theoretical separation previous engines include ad-hoc implementations of just a few data types, requiring complex changes in the tools to incorporate new data types. In this paper we present a solution as a Haskell embedded domain specific language that is easily extensible to arbitrary data types. The solution is enabled by a technique, which we call lift deep embedding , that consists in borrowing general Haskell types and embedding them transparently into an eDSL. This allows for example the use of higher-order functions to implement static stream parametrization. We describe the Haskell implementation called hLola and illustrate simple extensions implemented using libraries, which would require long and error-prone additions in other ad-hoc SRV formalisms."
SPRINGERLINK,Chapter,2020,Quantifying the Similarity of Non-bisimilar Labelled Transition Systems,Gwen Salaün,,10,"Equivalence checking is an established technique for automatically verifying that two behavioural models (Labelled Transition Systems, LTSs) are equivalent from the point of view of an external observer. When these models are not equivalent, the checker returns a Boolean result with a counterexample, which is a sequence of actions leading to a state where the equivalence relation is not satisfied. However, this counterexample does not give any indication of how far the two LTSs are one from another. One can wonder whether they are almost identical or totally different, which is quite different from a design or debugging point of view. In this paper, we present an approach for measuring the similarity between two LTS models. The set of metrics is computed automatically using a tool we implemented. Beyond presenting the foundations of the proposed solution, we will show how it can be applied to a concrete application domain for supporting the construction of IoT applications by composition of existing devices."
SPRINGERLINK,Chapter,2020,Optimistic and Pessimistic On-the-fly Analysis for Metric Temporal Graph Logic,Sven SchneiderLucas SakizloglouMaria MaximovaHolger Giese,"Graph logic with binding, Nonpropositional metric temporal logic, Runtime monitoring, Three-valued logic",10,"The nonpropositional Metric Temporal Graph Logic (MTGL) specifies the behavior of timed dynamic systems given by timed graph sequences (TGSs), which contain typed attributed graphs representing system states and the elapsed time between states. MTGL satisfaction can be analyzed for finite TGSs by translating its satisfaction problem to the satisfaction problem of nested graph conditions using a folding operation (aggregating a TGS into a graph with history ) and a reduction operation (translating an MTGL condition into a nested graph condition). In this paper, we introduce an analysis procedure for MTGL to allow for an on-the-fly analysis of finite/infinite TGSs. To this end, we introduce a further (optimistic) reduction of MTGL conditions, which leads to violations during the on-the-fly analysis only when non-satisfaction is guaranteed in the future whereas the former (pessimistic) reduction leads to violations when satisfaction is not guaranteed in the future. We motivate the relevance of our analysis procedure, which uses both reduction operations, by means of a running example. Finally, we discuss prototypical support in the tool AutoGraph ."
SPRINGERLINK,Chapter,2020,On Testing Message-Passing Components,Alex CotoRoberto GuancialeEmilio Tuosto,,10,"We instantiate and apply a recently proposed abstract framework featuring an algorithm for the automatic generation of tests for component testing of message-passing systems. We demonstrate the application of a top-down mechanism for test generation. More precisely, we reduce the problem of generating tests for components of message-passing applications to the projection of global views of choreographies. The application of the framework to some examples gives us the pretext to make some considerations about our approach."
SPRINGERLINK,Chapter,2020,Modelling an Automotive Software-Intensive System with Adaptive Features Using ASMETA,Paolo ArcainiSilvia BonfantiAngelo GargantiniElvinia RiccobenePatrizia Scandurra,,10,"In the context of automotive domain, modern control systems are software-intensive and have adaptive features to provide safety and comfort. These software-based features demand software engineering approaches and formal methods that are able to guarantee correct operation, since malfunctions may cause harm/damage. Adaptive Exterior Light and the Speed Control Systems are examples of software-intensive systems that equip modern cars. We have used the Abstract State Machines to model the behaviour of both control systems. Each model has been developed through model refinement, following the incremental way in which functional requirements are given. We used the ASMETA tool-set to support the simulation of the abstract models, their validation against the informal requirements, and the verification of behavioural properties. In this paper, we discuss our modelling, validation and verification strategies, and the results (in terms of features addressed and not) of our activities. In particular, we provide insights on how we addressed the adaptive features (the adaptive high beam headlights and the adaptive cruise control) by explicitly modelling their software control loops according to the MAPE-K (Monitor-Analyse-Plan-Execute over a shared Knowledge) reference control model for self-adaptive systems."
SPRINGERLINK,Chapter,2020,Tendermint Blockchain Synchronization: Formal Specification and Model Checking,Sean BraithwaiteEthan BuchmanIgor KonnovZarko MilosevicIlina StoilkovskaJosef WidderAnca Zamfir,,10,"Blockchain synchronization is one of the core protocols of Tendermint blockchains. We describe our recent efforts on formal specification of the protocol and its implementation, and present model checking results for small parameters. We demonstrate that the protocol quality and understanding can be improved by writing specifications and applying model checking to verify their properties."
SPRINGERLINK,Chapter,2020,Towards a Formally Verified Implementation of the MimbleWimble Cryptocurrency Protocol,Gustavo BetarteMaximiliano CristiáCarlos LunaAdrián SilveiraDante Zanarini,"Cryptocurrency, Formal verification, Idealized model, MimbleWimble, Security",10,MimbleWimble is a privacy-oriented cryptocurrency technology which provides security and scalability properties that distinguish it from other protocols of its kind. We present and briefly discuss those properties and outline the basis of a model-driven verification approach to address the certification of the correctness of an implementation of the protocol.
SPRINGERLINK,Chapter,2020,Using Model Learning for the Generation of Mock Components,Sébastien SalvaElliott Blot,"Communicating systems, Mock, Model learning, Quality metrics",10,"Mocking objects is a common technique that substitutes parts of a program to simplify the test case development, to increase test coverage or to speed up performance. Today, mocks are almost exclusively used with object oriented programs. But mocks could offer the same benefits with communicating systems to make them more reliable. This paper proposes a model-based approach to help developers generate mocks for this kind of system, i.e. systems made up of components interacting with each other by data networks and whose communications can be monitored. The approach combines model learning to infer models from event logs, quality metric measurements to help chose the components that may be replaced by mocks, and mock generation and execution algorithms to reduce the mock development time. The approach has been implemented as a tool chain with which we performed experimentations to evaluate its benefits in terms of usability and efficiency."
SPRINGERLINK,Chapter,2020,"The Impact of Social-Support, Self-efficacy and APP on MBI",Shu-Mei LinLiang-Ming LoChia-Yi LiuChao LiuWen-Ko Chiou,"APP, MBI, Self-efficacy, Social-support",10,"Social-support, self-efficacy and APP were one of the advanced MBI. This article presents a structured literature review of 44 articles to elucidate the impacts of social support, self-efficacy, APP. We discuss (1) the MBIs in which social-support, self-efficacy, and APP operate; (2) social-support, self-efficacy, and APP as MBI design choices and (3) the implycations of MBI design choices on MBI performance output. The structure of this article is based on the MBI-PPD-APP model. Results of our literature review revealed that, social-support, self-efficacy, and APP are employed in a variety of applications. We also found that MBI design involves choices pertaining to MBI configurations, MBI relationship, social-support, self-efficacy, and the APP process. The MBI performance outputs which were found to be most influenced by social-support, self-efficacy, and APP included PPD (reduce), MBI phenomena (reduced), and MBI responsiveness (improved). We used the findings of our literature review to develop a conceptual framework, which includes 18 propositions and an agenda for research. Specifically, the goal of this research agenda is to existing knowledge about how social-support, self-efficacy, and APP impact MBI design. We expect that social-support and self-efficacy and APP will eventually lead to improve."
SPRINGERLINK,Chapter,2020,Initial Pose Estimation of 3D Object with Severe Occlusion Using Deep Learning,Jean-Pierre LomalizaHanhoon Park,"Deep learning, Initial camera pose estimation, Mobile augmented reality, Model-based tracking, Partially visible object, Severe occlusion, Subpart detection",10,"During the last decade, augmented reality (AR) has gained explosive attention and demonstrated high potential on educational and training applications. As a core technique, AR requires a tracking method to get 3D poses of a camera or an object. Hence, providing fast, accurate, robust, and consistent tracking methods have been a main research topic in the AR field. Fortunately, tracking the camera pose using a relatively small and less-textured known object placed on the scene has been successfully mastered through various types of model-based tracking (MBT) methods. However, MBT methods requires a good initial camera pose estimator and estimating an initial camera pose from partially visible objects remains an open problem. Moreover, severe occlusions are also challenging problems for initial camera pose estimation. Thus, in this paper, we propose a deep learning method to estimate an initial camera pose from a partially visible object that may also be severely occluded. The proposed method handles such challenging scenarios by relying on the information of detected subparts of a target object to be tracked. Specifically, we first detect subparts of the target object using a state-of-the-art convolutional neural networks (CNN). The object detector returns two dimensional bounding boxes, associated classes, and confidence scores. We then use the bounding boxes and classes information to train a deep neural network (DNN) that regresses to camera’s 6-DoF pose. After initial pose estimation, we attempt to use a tweaked version of an existing MBT method to keep tracking the target object in real time on mobile platform. Experimental results demonstrate that the proposed method can estimate accurately initial camera poses from objects that are partially visible or/and severely occluded. Finally, we analyze the performance of the proposed method in more detail by comparing the estimation errors when different number of subparts are detected."
SPRINGERLINK,Chapter,2020,STAMP S&S: Layered Modeling for the Complexed System in the Society of AI/IoT,Tomoko KanekoNobukazu Yoshioka,"ISO15288, ISO21207, Layered modeling, Risk analysis, Safety, Security, Socio-technical system, STAMP",10,"Systems, including AI/IoT, have complex relationships. It is necessary to analyze risks from various perspectives to build a system that can be used safely and securely throughout society, including people and organizations. Object modeling is desirable for risk analysis from multiple viewpoints. An accident model based on system theory called STAMP and its hazard analysis method STPA has attracted attention recently. The basis of this theory is the Control Structure diagram (CS) that captures the entire system. The authors use CS as a structural diagram that captures the requirements of the whole system, including humans and society, and clarifies the relationship by the software lifecycle process standard and the system-life cycle process standard. Therefore, it is proposed to explain the specifications hierarchically for each software, system, service, and stakeholder, and to standardize it for the social layer. In order to model a complex system hierarchically, we propose to model the control structure diagram of STAMP into five layers according to the life cycle of software and system requirements. In addition, we present a case study of safety and security analysis based on the above-mentioned model, considering the case of level 3 autonomous driving."
SPRINGERLINK,Chapter,2020,The First Twenty-Five Years of Industrial Use of the B-Method,Michael ButlerPhilipp KörnerSebastian KringsThierry LecomteMichael LeuschelLuis-Fernando MejiaLaurent Voisin,,10,"The B-Method has an interesting history, where language and tools have evolved over the years. This not only led to considerable research and progress in the area of formal methods, but also to numerous industrial applications, in particular in the railway domain. We present a survey of the industrial usage of the B-Method since the first toolset in 1993 and the inauguration of the driverless metro line 14 in Paris in 1999. We discuss the various areas of applications, from software development to data validation and on to systems modelling. The evolution of the tooling landscape is also analysed, and we present an assessment of the current situation, lessons learned and possible new directions."
SPRINGERLINK,Chapter,2020,Families of Monotonic Trees: Combinatorial Enumeration and Asymptotics,Olivier BodiniAntoine GenitriniMehdi NaimaAlexandros Singh,"Analytic Combinatorics, Asymptotic enumeration, Borel transform, Evolution process, Increasing trees, Monotonic trees",10,"There exists a wealth of literature concerning families of increasing trees, particularly suitable for representing the evolution of either data structures in computer science, or probabilistic urns in mathematics, but are also adapted to model evolutionary trees in biology. The classical notion of increasing trees corresponds to labeled trees such that, along paths from the root to any leaf, node labels are strictly increasing; in addition nodes have distinct labels. In this paper we introduce new families of increasingly labeled trees relaxing the constraint of unicity of each label. Such models are especially useful to characterize processes evolving in discrete time whose nodes evolve simultaneously. In particular, we obtain growth processes for biology much more adequate than the previous increasing models. The families of monotonic trees we introduce are much more delicate to deal with, since they are not decomposable in the sense of Analytic Combinatorics. New tools are required to study the quantitative statistics of such families. In this paper, we first present a way to combinatorially specify such families through evolution processes, then, we study the tree enumerations."
SPRINGERLINK,Chapter,2020,A Study of Mechanism Design for C2C Service Based on Multi-agent Simulation,Takuya IzumisawaYuki KatsumataAkira Yamada,"Evolutionary game, Mechanism design, Multi-agent simulation",10,"In Consumer-to-Consumer (C2C) services where individuals provide their own idle assets to other individuals, the number of trouble incidents between individuals is increasing. These incidents arise because individuals act inappropriately (defection strategy) when providing or using assets against the will of the counterpart. One goal for C2C services is to activate the market by increasing the number of individuals who take appropriate action (cooperation strategy). Toward this end, we propose a mechanism that achieves the desired cooperation rate. The number of individuals who follow the cooperation strategy will increase as incentives are increased, and there is a trade-off between the achievable cooperation rate and incentives. The purpose of this study is to clarify the conditions that achieve the desired cooperation rate with fewer incentives. Simulation results show that the proposed mechanism increases the number of individuals who follow the cooperation strategy and that incentives contribute to achieving the desired cooperation rate rather than penalties."
SPRINGERLINK,Chapter,2020,Quantitative Analysis of Goal Oriented Requirements Models,Haruhiko Kaiya,"Goal Oriented Requirements Analysis, Metrics, Quality requirements",10,"An information system is developed and embedded into a dairy activity to satisfy requirements of people in the activity. Because the system is expected to improve the activity, we have to predict the extent of such improvement. Goal oriented requirements models are useful to represent the relationships among systems and people in a business or life activity. We have been proposed extended goal oriented requirements models to predict how well the system improves the activity of the people. In this talk, we briefly introduce typical goal oriented requirements models, and their extensions suitable for quantitative analysis. Finally, we show several issues of future challenges."
SPRINGERLINK,Chapter,2020,Revisiting Principles and Challenges in Natural Language Programming,Juliano Efson SalesAndré FreitasDouglas OliveiraAdamantios KoumpisSiegfried Handschuh,"Natural language interfaces, Natural language programming, Very high-level languages",10,"Automation has faced the risk of reducing its pace due to the shortage of information technology professionals. Although part of the programming demand can be addressed by simple compositions of high-level functions and data flows, non-technical professionals are still unable to build their own software given the intrinsic complexity of coding. Among other types of end-user development, natural language programming has emerged as a strong candidate to fill this gap by developing methods and tools to allow end users to program. The paper revisits some principles of evaluation of traditional programming languages and analyses the new challenges to deliver an effective end-user development platform based on aspects of natural language processing, human-computer interaction, software engineering, and programming education. We advocate that an effective end-user platform is essentially hybrid, combining features from different branches of the end-user development research, having, however, a search mechanism with semantic capabilities at its centre ."
SPRINGERLINK,Chapter,2020,Experimental Evaluation of Traceability Checking Tool for Goal Dependency Modeling,Haruhiko KaiyaWataru FujitaRyotaro YamadaAtsuo HazeyamaShinpei OgataTakao OkuboNobukazu YoshiokaHironori Washizaki,"Experimental evaluation, Goal oriented requirements analysis, Istar, Modeling tool, Traceability",10,"In a complex socio-technical system, a human’s goal is delegated to many actors such as human and machines. Because the delegated goal can be decomposed into several sub-goals by each actor, goals are delegated recursively until an actor provides the means to achieve each sub-goal. We have already proposed a notation and a method called GDMA to represent and analyze the issues above. Because GDMA can be represented in a class diagram, software engineers do not have to use specific tools of GDMA models. To confirm whether a goal is properly achieved by suitable means, we have to trace such delegation and decomposition relationships. However, it is not easy to confirm it in a real-world system because of the system’s complexity. In this paper, we present a tool to check such traceability. The tool is implemented as a plugin of an existing UML modeling editor, and goal dependencies and decompositions are depicted using color. We also evaluate the tool through a comparative experiment. As a result, the tool enables an analyst to check the traceability without omission although it does not improve efficiency of the traceability checking task."
SPRINGERLINK,Chapter,2020,State Identification for Labeled Transition Systems with Inputs and Outputs,Petra van den BosFrits Vaandrager,,10,"For Finite State Machines (FSMs) a rich testing theory has been developed to discover aspects of their behavior and ensure their correct functioning. Although this theory is widely used, e.g., to check conformance of protocol implementations, its applicability is limited by restrictions of the FSM framework: the fact that inputs and outputs alternate in an FSM, and outputs are fully determined by the previous input and state. Labeled Transition Systems with inputs and outputs (LTSs), as studied in ioco testing theory, provide a richer framework for testing component oriented systems, but lack the algorithms for test generation from FSM theory. In this article, we propose an algorithm for the fundamental problem of state identification during testing of LTSs. Our algorithm is a direct generalization of the well-known algorithm for computing adaptive distinguishing sequences for FSMs proposed by Lee & Yannakakis. Our algorithm has to deal with so-called compatible states, states that cannot be distinguished in case of an adversarial system-under-test. Analogous to the result of Lee & Yannakakis, we prove that if an (adaptive) test exists that distinguishes all pairs of incompatible states of an LTS, our algorithm will find one. In practice, such adaptive tests typically do not exist. However, in experiments with an implementation of our algorithm on an industrial benchmark, we find that tests produced by our algorithm still distinguish more than 99% of the incompatible state pairs."
SPRINGERLINK,Chapter,2020,How the Apriori Algorithm Can Help to Find Semantic Duplicates in Ontology,Irina AstrovaArne KoschelSu Ling Lee,"Apriori algorithm, Market basket analysis, Ontolgy, OntoLife, Semantic heterogeneity, Similar attributes",10,"Ontology-based data integration attempts to overcome the semantic heterogeneity problem in data integration. Semantic heterogeneity refers to an ambiguous interpretation of terms that describes the meaning of data in heterogeneous resources. However, the presence of semantic duplicates such as similar attributes in the integrated ontologies can lead to incomplete query results. This paper proposes to use the Apriori algorithm from market basket analysis to find similar attributes in an ontology."
SPRINGERLINK,Chapter,2019,Learning-Based Testing of an Industrial Measurement Device,Bernhard K. AichernigChristian BurghardRobert Korošec,"Active learning, Automata learning, Automotive case study, Model inference, Mutation analysis, Testbed, Testing",10,"Active automata learning algorithms have gained increasing importance in the field of model-based system verification. For some classes of systems - especially deterministic systems, like Mealy machines, a variety of learning algorithm implementations is readily available. In this paper, we apply this technique to a measurement device from the automotive industry in order to systematically test its behaviour. However, our system under learning shows sparse non-deterministic behaviour, preventing the direct application of the available learning tools. We propose an implementation of the active automata learning framework which masks this non-determinism. We repeat a previous model-based testing experiment with faulty devices and show that we can detect all injected faults. Most importantly, our technique was also able to find unknown bugs."
SPRINGERLINK,Chapter,2019,A Model-Driven Approach for Simplified Cluster Based Test Suite Optimization of Industrial Systems – An Introduction to UMLTSO,Ayesha KiranFarooque AzamMuhammad Waseem AnwarIqra QasimHanny Tufail,"Clustering, Model-based optimization, Optimization, Test case, Testing",10,"Software testing is a significant but costly activity of software development life cycle, because it accounts for more than fifty-two percent (>52%) of entire development cost. Testing requires the execution of all possible test cases in order to find defects in software. However, the selection and implementation of right test cases is always challenging for large scale industrial systems. In this context, clustering is a renowned approach for achieving optimization. However, it is difficult to optimize test cases through clustering due to its implementation complexity and time-consuming nature. Hence, a model based simple mechanism is strongly needed for optimization of generated test cases while preserving the coverage criterion. In this paper, a Unified Modeling Language profile for Test Suite Optimization (UMLTSO) is presented that models the optimization process for test case generated from java source code. Particularly, UMLTSO is capable of modeling test case generation, coverage criteria application and optimization using clustering approaches. This offers the rationale for converting the UMLTSO source code into target test cases for optimization based on different coverage criteria e.g. code coverage. The applicability of UMLTSO is validated through two industrial case studies."
SPRINGERLINK,Chapter,2019,"Challenges for Automated, Model-Based Test Scenario Generation",Alexander KolchinStepan PotiyenkoThomas Weigert,"Data flow, Model-based testing, Tests quality",10,"This paper focuses on challenges to automatic test suite generation from formal models of software systems. Popular tools and methods and their limitations are discussed. Data cohesion, meaningfulness of derived behavior, usefulness for debugging, coverage evenness, coverage overlap, fault detection ability, and size of the generated test suite are considered as quality indicators for generated tests. A novel composite weight-based heuristic method for improving the quality of automatically generated test scenarios is proposed."
SPRINGERLINK,Chapter,2019,Visualization and Abstractions for Execution Paths in Model-Based Software Testing,Rui WangCyrille ArthoLars Michael KristensenVolker Stolz,,10,"This paper presents a technique to measure and visualize execution-path coverage of test cases in the context of model-based software systems testing. Our technique provides visual feedback of the tests, their coverage, and their diversity. We provide two types of visualizations for path coverage based on so-called state-based graphs and path-based graphs. Our approach is implemented by extending the Modbat tool for model-based testing and experimentally evaluated on a collection of examples, including the ZooKeeper distributed coordination service. Our experimental results show that the state-based visualization is good at relating the tests to the model structure, while the path-based visualization shows distinct paths well, in particular linearly independent paths. Furthermore, our graph abstractions retain the characteristics of distinct execution paths, while removing some of the complexity of the graph."
SPRINGERLINK,Chapter,2019,Automatic Generation of Test Oracles from Component Based Software Architectures,Maxime SamsonThomas Vergnaud,"Component Based Software Engineering, Model based testing, UCM",10,"In a software development process, the integration and verification of the different parts of the application under development often require a lot of effort. Component Based Software Engineering (CBSE) approaches help cut software integration costs by enabling the automatic generation of data types, method signatures and middleware configuration from a model of the application structure. Model Based Testing (MBT) techniques help cut software verification costs by enabling the automatic generation of test oracles from a model of the expected application behaviour. Models for CBSE and MBT are usually separate. This may result in discrepancies between them, especially when the application architecture is updated, which always happens. In this paper, we describe how to rely on a single CBSE model to produce both code generation and oracles for some tests, thus ensuring consistency between them. Our work is based on existing OMG standards, mainly UCM and UML."
SPRINGERLINK,Chapter,2019,VERCORS: Hardware and Software Complex for Intelligent Round-Trip Formalized Verification of Dependable Cyber-Physical Systems in a Digital Twin Environment (Position Paper),Alexandr NaumchevAndrey SadovykhVladimir Ivanov,"Co-simulation, Cyber-physical systems (CPS), Digital twin, Formal specification, Language processing, Model-based testing, Multi-modelling, Natural, Traceability, Verification",10,"Formal specification, model checking and model-based testing are recommended techniques for engineering of mission-critical systems. In the meantime, those techniques struggle to obtain wide adoption due to inherent learning barrier, i.e. it is considered difficult to use those methods. There is also a common difficulty in translating the specifications in natural language, a common practice nowadays, to formal specifications. In this position paper we discuss the concept of an end-to-end methodology that helps identify specifications from various sources, automatically create formal specifications and apply them to verification of cyber-physical systems. Thus, we intent to address the challenges of creation of formal specifications in an efficient automated and tool-supported manner. The novelty of the approach is analyzed through a survey of state of the art. It is currently planned to implement this concept and evaluate it with industrial case studies."
SPRINGERLINK,Chapter,2019,Formal Modelling and Verification of an Interlocking Using mCRL2,Mark BouwmanBob JanssenBas Luttik,,10,"This paper presents an application of the formal modelling and model checking toolkit mCRL2 and the model-based testing tool JTorX in the signalling domain. The mCRL2 toolkit is used to formally model the behaviour of a system at the core of signalling solutions: the interlocking. The model of the interlocking is validated through model-based testing. We use the mCRL2 toolkit to verify high-level safety properties of the interlocking software. The suitability of mCRL2, JTorX and our modelling approach is evaluated and suggestions are given for future research to improve the applicability of mCRL2 in the signalling domain."
SPRINGERLINK,Chapter,2019,A Search-Based Approach to Generate MC/DC Test Data for OCL Constraints,Hassan SartajMuhammad Zohaib IqbalAtif Aftab Ahmed JilaniMuhammad Uzair Khan,"MC/DC, Model-based testing, OCL, SBSE, Test data generation",10,"Automated generation of test data is an important and challenging activity in Model-based Testing. This typically requires solving of constraints, written in Object Constraint Language (OCL), specified on models in order to obtain solutions that can be used as test data. Test data generation techniques in the literature discuss various coverage criteria for test generation to achieve a sufficient level of coverage. One of the recommended criteria is modified condition/decision coverage (MC/DC) that is a requirement of different safety standards, such as DO-178C. In this paper, we propose a search-based strategy that utilizes case-based reasoning (CBR) to reuse the already generated test data and generate new test data that provides MC/DC coverage of OCL constraints. To evaluate the performance of the proposed approach in solving MC/DC constraints, we perform an empirical evaluation using AVM without CBR, AVM with CBR, and use Random Search (RS) as a baseline for comparison. We use 84 OCL constraints from four case studies belonging to different domains with varying size and complexity. The experimental results show that our proposed strategy of reusing already generated test data is better as compared to generating test data without using previous test data."
SPRINGERLINK,Chapter,2019,"A Test Specification Language for Information Systems Based on Data Entities, Use Cases and State Machines",Alberto Rodrigues da SilvaAna C. R. PaivaValter E. R. da Silva,"Model based Testing (MBT), Test case generation, Test case specification, Test Specification Language (TSL)",10,"Testing is one of the most important activities to ensure the quality of a software system. This paper proposes and discusses the TSL (Test Specification Language) that adopts a model-based testing approach for both human-readable and computer-executable specifications of test cases. TSL is strongly inspired on the grammar, nomenclature and writing style as defined by the RSLingo RSL, which is a rigorous requirements specification language. Both RSL and TSL are controlled natural languages that share common concepts such as data entities, use cases and state machines. However, by applying black-box functional testing design techniques, TSL includes and supports four complementary testing strategies, namely: domain analysis testing; use case tests; state machine testing; and acceptance criteria. This paper focuses on the first three testing strategies of TSL. Finally, a simple but effective case study illustrates the overall approach and supports the discussion."
SPRINGERLINK,Chapter,2019,Component-aware Input-Output Conformance,Alexander Graf-BrillHolger Hermanns,"Compositionality, Input-output conformance, Model-based testing",10,"Black-box conformance testing based on a compositional model of the intended behaviour is a very attractive approach to validate the correctness of an implementation. In this context, input-output conformance is a scientifically well-established formalisation of the testing process. This paper discusses peculiar problems arising in situations where the implementation is a monolithic black box, for instance for reasons of intellectual property restrictions, while the specification is compositional. In essence, tests need to be enabled to observe progress in individual specification-level components. For that, we will reconsider input-output conformance so that it can faithfully deal with such situations. Refined notions of quiescence play a central role in a proper treatment of the problem. We focus on the scenario of parallel components with fully asynchronous communication covering very many notorious practical examples. We finally illustrate the practical implications of component-aware conformance testing in the context of a prominent example, namely networked embedded software."
SPRINGERLINK,Chapter,2019,Property-Based Test Case Generators for Free,Emanuele De AngelisFabio FioravantiAdrián PalaciosAlberto PettorossiMaurizio Proietti,,10,"Property-Based Testing requires the programmer to write suitable generators , i.e., programs that generate (possibly in a random way) input values for which the program under test should be run. However, the process of writing generators is quite a costly, error-prone activity. In the context of Property-Based Testing of Erlang programs, we propose an approach to relieve the programmer from the task of writing generators. Our approach allows the automatic, efficient generation of input test values that satisfy a given specification. In particular, we have considered the case when the input values are data structures satisfying complex constraints. That generation is performed via the symbolic execution of the specification using constraint logic programming."
SPRINGERLINK,Chapter,2019,Testing Real-Time Systems Using Determinization Techniques for Automata over Timed Domains,Moez Krichen,"Automaton over timed domains, Conformance relation, Correctness, Determinization, Model-Based Testing, Real-time systems",10,"In this work, we are interested in Model-Based Testing for Real-Time Systems. The proposed approach is based on the use of the model of Automata over Timed Domains (ATD) which corresponds to an extension of the classical Timed Automaton Model. First, we explain the main advantages of adopting this new formalism. Then, we propose a testing framework based on ATD and which is an extension of our initial framework presented in previous contributions. We extend the notion of correctness requirements (soundness and completeness) along with the notion of timed input-output conformance relation (tioco) used to compare between implementations and specifications. Moreover we propose a determinization technique used to generate test cases. Finally, several possible extensions of the present work are proposed."
SPRINGERLINK,Chapter,2019,Directed Multi-target Search Based Unit Tests Generation,Greta RudžionienėŠarūnas PackevičiusEduardas Bareiša,"Search based software testing, Unit testing, Unit tests generation",10,"Software testing costs are reduced by employing test automation. One of the automation activities is tests generation. The goal of tests generation is to generate tests with large code coverage with the efficient faults detection ability. Search-based tests generation methods are analysed and their experimental comparison is provided in this paper. The novel search-based unit tests generation approach directed by multiple search targets to generate unit tests is presented. Introduced method allows generating test data and oracles using static code analysis and code instrumentation. Oracles are created as assertions based on system state after tests execution phase, thus making tests suitable for regression testing. The method was implemented as an experimental tool. It was evaluated and compared against other search-based tests generation tools/methods by using code coverage and mutation score metrics. The experimental evaluation was performed on 124 classes from 3 open source libraries."
SPRINGERLINK,Chapter,2019,Generating Test Data for Blackbox Testing from UML-Based Web Engineering Content and Presentation Models,Quyet-Thang HuynhDinh-Dien TranDuc-Man NguyenNhu-Hang HaThi-Mai-Anh BuiPhi-Le Nguyen,"Model-based testing, Test case generation, UML-based Web Engineering, Web application testing",10,"Software testing is a process that produces and consumes huge amounts of data. Thus, the test data is usually either gathered manually by the testers or randomly generated by tools. The manual method consumes lot of time and highly depends on the testers’ experience while the random approach faces the problem of redundant test data caused by identical use cases. By leveraging the concept of Model-based testing, this paper provides a novel method of testing to save the cost of manual testing and to increase the reliability of the testing processes. In Model-based testing, test cases and test data can be derived from different models. In this paper, we present a technique to generate test data from UML-based Web Engineering (UWE) presentation model for web application testing by using formal specification and Z3 SMT solver. We also build a model-based testing Eclipse Plug-in tool called TESTGER-UWE that generates test data based on the model of UWE for the web application. We evaluate the proposed methods by applying them to generate test data for an Address Book project of UWE. Experimental results show that our proposed methods can reduce the time significantly when generating test data for automation test tools such as Selenium, Katalon, Unit test, etc."
SPRINGERLINK,Chapter,2019,Multi-objective Search for Effective Testing of Cyber-Physical Systems,Hugo AraujoGustavo CarvalhoMohammad Reza MousaviAugusto Sampaio,"Cyber-Physical Systems, Input selection, Search based",10,"We propose a multi-objective strategy for finding effective inputs for fault detection in Cyber Physical Systems (CPSs). The main goal is to provide input signals for a system in such a way that they maximise the distance between the system’s output and an ideal target, thus leading the system towards a fault; this is based on Genetic Algorithm and Simulated Annealing heuristics. Additionally, we take into consideration the discrete locations (of hybrid system models) and a notion of input diversity to increase coverage. We implement our strategy and present an empirical analysis to estimate its effectiveness."
SPRINGERLINK,Chapter,2019,A Methodology for Generating Tests for Evaluating User-Centric Performance of Mobile Streaming Applications,Mustafa Al-tekreetiKshirasagar NaikAtef AbdrabouMarzia ZamanPradeep Srivastava,"Coverage criteria, Performance, Software, Testing",10,"Compared to other platforms, mobile apps’ quality assurance is more challenging, since their functionality is affected by the surrounding environment. In literature, a considerable volume of research has been devoted to develop frameworks that facilitate conducting performance analysis during the development life cycle. However, less attention has been given to test generation and test selection criteria for performance evaluation. In this work, a model based test generation methodology is proposed to evaluate the impact of the interaction of the environment, the wireless network, and the app configurations on the performance of a mobile streaming app and thereby on the experience of the end user. The methodology steps, inputs, and outputs are explained using an app example. The methodology assumes that the app has a network access through a WiFi access point. We evaluate the effectiveness of the methodology by comparing the time cost to design a test suite with random testing. The obtained results are very promising."
SPRINGERLINK,Chapter,2019,Does Diversity Improve the Test Suite Generation for Mobile Applications?,Thomas VogelChinh TranLars Grunske,"Diversity, Fitness landscape analysis, Test generation",10,"In search-based software engineering we often use popular heuristics with default configurations, which typically lead to suboptimal results, or we perform experiments to identify configurations on a trial-and-error basis, which may lead to better results for a specific problem. To obtain better results while avoiding trial-and-error experiments, a fitness landscape analysis is helpful in understanding the search problem, and making an informed decision about the heuristics. In this paper, we investigate the search problem of test suite generation for mobile applications (apps) using Sapienz whose heuristic is a default NSGA-II. We analyze the fitness landscape of Sapienz with respect to genotypic diversity and use the gained insights to adapt the heuristic of Sapienz . These adaptations result in Sapienz $$^{div}$$ that aims for preserving the diversity of test suites during the search. To evaluate Sapienz $$^{div}$$ , we perform a head-to-head comparison with Sapienz on 76 open-source apps."
SPRINGERLINK,Chapter,2019,Research Review on Web Service Composition Testing,Zhoujie DuHuaikou Miao,"Testing methods, Testing techniques, Web service, Web service combination",10,"Web services composition is designed to achieve a more powerful and large-grained services with organic synthesis of different Web services. In order to guarantee the quality of the Web services composition, comprehensive and adequate testing of the Web services composition is required. However, the dynamic and distributed characteristics of Web services combination make its testing technology and method have big difference with the traditional software testing and bring a large of challenges. In this paper, we summarize and analyze the definition, architecture, testing methods and testing techniques of Web service composition. In addition, we also analyze and prospect the progress of Web services combination testing."
SPRINGERLINK,Chapter,2019,Conformance Testing of Schedulers for DSL-based Model Checking,Nhat-Hoa TranToshiaki Aoki,"Conformance testing, Domain-specific language, Model checking, Model-based testing, Scheduling policy, Test generation",10,"When we verify concurrent systems executed under a real operating system (OS), we should take the scheduling policy of the OS into account. However, with a specific implementation of an OS, the description of the scheduling policy does not exist or not clear to describe the behaviors of the real scheduler. In this case, we need to make assumptions in the specification by ourselves. Therefore, checking the correctness of the specification of the scheduling policy is important because it affects the verification result. In this paper, we propose a method to validate the correspondence between the specification of the scheduling policy and the implementation of the scheduler using testing techniques. The overall approach can be regarded as conformance testing. As a result, we can find the inconsistency between the implementation and the specification. That indicates the incorrectness of the specification. To deal with testing, we propose a domain-specific language (DSL) to specify the test generation with the scheduling policy. A search algorithm is introduced to determine the executions of the processes. The tests are generated automatically and exhaustively by applying model-based testing (MBT) techniques. Based on this method, we develop a tool for generating the tests. We demonstrate our method with Linux FIFO scheduling policy. The experiments show that we can facilitate the test generation and check the specification of the scheduling policy easily."
SPRINGERLINK,Chapter,2019,Mutation Testing with Hyperproperties,Andreas FellnerMitra Tabaei BefroueiGeorg Weissenbacher,,10,"We present a new method for model-based mutation-driven test case generation. Mutants are generated by making small syntactical modifications to the model or source code of the system under test. A test case kills a mutant if the behavior of the mutant deviates from the original system when running the test. In this work, we use hyperproperties—which allow to express relations between multiple executions—to formalize different notions of killing for both deterministic as well as non-deterministic models. The resulting hyperproperties are universal in the sense that they apply to arbitrary reactive models and mutants. Moreover, an off-the-shelf model checking tool for hyperproperties can be used to generate test cases. We evaluate our approach on a number of models expressed in two different modeling languages by generating tests using a state-of-the-art mutation testing tool."
SPRINGERLINK,Chapter,2019,Mutation-Based Web Test Case Generation,Sérgio AlmeidaAna C. R. PaivaAndré Restivo,"Mutation testing, Software testing, Test case generation, Web testing",10,"Regression testing is of paramount importance to ensure that the quality of software does not suffer when code changes are implemented. However, having a large set of tests is mostly done by hand and is time-consuming. Regression tests are written to test functionality that is already implemented and thus are a prime target for automatic test generation. Mutation testing is a technique that evaluates the quality of tests by applying simple changes to source code and checking if any test detects those changes. This paper presents an approach focused on GUI Testing that takes the idea behind mutation testing and applies it, not to the source code, but the actual tests. Generated tests are then analyzed, and those that generate different outcomes are chosen. The set of initial test cases is obtained from the interactions of the actual users of the service under analysis. In the end, an evaluation of the approach is presented."
SPRINGERLINK,Chapter,2019,A Lightweight Multilevel Markup Language for Connecting Software Requirements and Simulations,Florian PudlitzAndreas VogelsangFlorian Brokhausen,"Markup language, Requirements modeling, Simulation, Test evaluation",10,"[ Context ] Simulation is a powerful tool to validate specified requirements especially for complex systems that constantly monitor and react to characteristics of their environment. The simulators for such systems are complex themselves as they simulate multiple actors with multiple interacting functions in a number of different scenarios. To validate requirements in such simulations, the requirements must be related to the simulation runs. [ Problem ] In practice, engineers are reluctant to state their requirements in terms of structured languages or models that would allow for a straightforward relation of requirements to simulation runs. Instead, the requirements are expressed as unstructured natural language text that is hard to assess in a set of complex simulation runs. Therefore, the feedback loop between requirements and simulation is very long or non-existent at all. [ Principal idea ] We aim to close the gap between requirements specifications and simulation by proposing a lightweight markup language for requirements. Our markup language provides a set of annotations on different levels that can be applied to natural language requirements. The annotations are mapped to simulation events. As a result, meaningful information from a set of simulation runs is shown directly in the requirements specification. [ Contribution ] Instead of forcing the engineer to write requirements in a specific way just for the purpose of relating them to a simulator, the markup language allows annotating the already specified requirements up to a level that is interesting for the engineer. We evaluate our approach by analyzing 8 original requirements of an automotive system in a set of 100 simulation runs."
SPRINGERLINK,Chapter,2019,Time to Learn – Learning Timed Automata from Tests,Martin TapplerBernhard K. AichernigKim Guldstrand LarsenFlorian Lorber,,10,"Model learning has gained increasing interest in recent years. It derives behavioural models from test data of black-box systems. The main advantage offered by such techniques is that they enable model-based analysis without access to the internals of a system. Applications range from fully automated testing over model checking to system understanding. Current work focuses on learning variations of finite state machines. However, most techniques consider discrete time. In this paper, we present a novel method for learning timed automata, finite state machines extended with real-valued clocks. The learning method generates a model consistent with a set of timed traces collected via testing. This generation is based on genetic programming, a search-based technique for automatic program creation. We evaluate our approach on $$\mathbf {44}$$ timed systems, comprised of four systems from the literature (two industrial and two academic) and $$\mathbf {40}$$ randomly generated examples."
SPRINGERLINK,Chapter,2019,Rationalizing the Need of Architecture-Driven Testing of Interactive Systems,Alexandre CannyElodie BouzekriCélia MartiniePhilippe Palanque,"Architecture-driven testing, Interactive system testing",10,"Testing interactive systems is known to be a complex task that cannot be exhaustive. Indeed, the infinite number of combination of user input and the complexity of information presentation exceed the practical limits of exhaustive and analytical approach to testing [ 31 ]. Most interactive software testing techniques are produced by applying and tuning techniques from the field of software testing to try to address the specificities of interactive applications. When some elements cannot be taken into account by the software testing technique, they are usually ignored. In this paper we propose to follow an opposite approach, starting from a generic architecture for interactive systems (including both software and hardware elements) for identifying in a systematic way, testing problems and testing needs. This architecture-driven approach makes it possible to identify how software testing knowledge and techniques can support interactive systems testing but also where the interactive systems engineering community should invest in order to test their idiosyncrasies too."
SPRINGERLINK,Chapter,2019,A Modular Hybrid Learning Approach for Black-Box Security Testing of CPS,John Henry CastellanosJianying Zhou,"Black-box security testing, Cyber-Physical Systems security, Model-based attack detection",10,"Evaluating the security of Cyber-Physical Systems (CPS) is challenging, mainly because it brings risks that are not acceptable in mission-critical systems like Industrial Control Systems (ICS). Model-based approaches help to address such challenges by keeping the risk associated with testing low. This paper presents a novel modelling framework and methodology that can easily be adapted to different CPS. Based on our experiments, HybLearner takes less than 140 s to build a model from historical data of a real-world water treatment testbed, and HybTester can simulate accurately about 60 min ahead of normal behaviour of the system including transitions of control strategies. We also introduce a security metrics ( time-to-critical-state ) that gives a measurement of how fast the system might reach a critical state, which is one of the use cases of the proposed framework to build a model-based attack detection mechanism."
SPRINGERLINK,Chapter,2019,A Fault-Driven Combinatorial Process for Model Evolution in XSS Vulnerability Detection,Bernhard GarnMarco RadavelliAngelo GargantiniManuel LeithnerDimitris E. Simos,"Combinatorial testing, Model evolution, Security testing, XSS vulnerability",10,"We consider the case where a knowledge base consists of interactions among parameter values in an input parameter model for web application security testing. The input model gives rise to attack strings to be used for exploiting XSS vulnerabilities, a critical threat towards the security of web applications. Testing results are then annotated with a vulnerability triggering or non-triggering classification, and such security knowledge findings are added back to the knowledge base, making the resulting attack capabilities superior for newly requested input models. We present our approach as an iterative process that evolves an input model for security testing. Empirical evaluation on six real-world web application shows that the process effectively evolves a knowledge base for XSS vulnerability detection, achieving on average 78.8% accuracy."
SPRINGERLINK,Chapter,2019,Survey on Formal Methods and Tools in Railways: The ASTRail Approach,Alessio FerrariMaurice H. ter BeekFranco MazzantiDavide BasileAlessandro FantechiStefania GnesiAndrea PiattinoDaniele Trentini,"Formal methods, Model-based development, Railways",10,"Formal methods and tools have been widely applied to the development of railway systems during the last decades. However, no universally accepted formal framework has emerged, and railway companies wishing to introduce formal methods have little guidance for the selection of the most appropriate methods and tools to adopt. A work package (WP) of the European project ASTRail, funded under the Shift2Rail initiative, addresses this problem, by performing a survey that considers scientific literature, international projects, and practitioners’ perspectives to identify a collection of formal methods and tools to be applied in railways. This paper summarises the current results of this WP. We surveyed 114 scientific publications, 44 practitioners, and 8 projects to come to a shortlist of 14 methods considered suitable for system modelling and verification in railways. The methods and tools were reviewed according to a set of functional, language-related, and quality features. The current paper extends the body of knowledge with a set of publicly available documents that can be leveraged by companies for guidance on formal methods selection in railway system development."
SPRINGERLINK,Chapter,2019,SoTesTeR: Software Testing Techniques’ Recommender System Using a Collaborative Approach,Ronald IbarraGlen Rodriguez,"Collaborative repository, Content-based reasoning, k-Nearest Neighbors, Recommender system, Software testing techniques",10,"Software testing is a key factor on any software project; testing costs are significant in relation to development costs. Therefore, it is essential to select the most suitable testing techniques for a given project to find defects at the lower cost possible in the different testing levels. However, in several projects, testing practitioners do not have a deep understanding of the full array of techniques available, and they adopt the same techniques that were used in prior projects or any available technique without taking into consideration the attributes of each testing technique. Currently, there are researches oriented to support selection of software testing techniques; nevertheless, they are based on static catalogues, whose adaptation to any niche software application may be slow and expensive. In this work, we introduce a content-based recommender system that offer a ranking of software testing techniques based on a target project characterization and evaluation of testing techniques in similar projects. The repository of projects and techniques was completed through the collaborative effort of a community of practitioners. It has been found that the difference between recommendations of SoTesTeR and recommendations of a human expert are similar to the difference between recommendations of two different human experts."
SPRINGERLINK,Chapter,2019,Empowering Continuous Delivery in Software Development: The DevOps Strategy,Clauirton SiebraRosberg LacerdaItalo CerqueiraJonysberg P. QuintinoFabiana FlorentinFabio B. Q. da SilvaAndre L. M. Santos,"Continuous delivery, DevOps, Software deployment",10,"Continuous Delivery refers to a software development practice where members of a team frequently integrate their work, so that the process of delivery can be easily conducted. However, this continuous integration and delivery requires a reliable collaboration between development and IT operation teams. The DevOps practices support this collaboration since they enable that the operation staff making use of the same infrastructure as developers for their systems work. Our study aims at presenting a practical DevOps implementation and analyzing how the process of software delivery and infrastructure changes was automated. Our approach follows the principles of infrastructure as code, where a configuration platform – PowerShell DSC – was used to automatically define reliable environments for continuous software delivery. In this context, we defined the concept of “stage for dev”, also using the Docker technology, which involves all the elements that enable members of a team to have the same production environment, locally configured in their personal machines and thus empowering the continuous integration and delivery of system releases."
SPRINGERLINK,Chapter,2019,Local Observability and Controllability Enforcement in Distributed Testing,Bruno LimaJoão Pascoal FariaRobert Hierons,"Controllability, Distributed systems, Integration testing, Model-based testing, Observability, UML",10,"To ensure interoperability and the correct end-to-end behavior of heterogenous distributed systems, it is important to conduct integration tests that verify the interactions with the environment and between the system components in key scenarios. The automation of such integration tests requires that test components are also distributed, with local testers deployed close to the system components, coordinated by a central tester. In such a test architecture, it is important to maximize the autonomy of the local testers to minimize the communication overhead and maximize the fault detection capability. A test scenario is called locally observable and locally controllable, if conformance errors can be detected locally and test inputs can be decided locally, respectively, by the local testers, without the need for exchanging coordination messages between the test components during test execution (i.e., without any communication overhead). For test scenarios specified by means of UML sequence diagrams that don’t exhibit those properties, we present in this paper an approach with tool support to automatically find coordination messages that, added to the given scenario, make it locally controllable and locally observable."
SPRINGERLINK,Chapter,2019,Automatic Test Data Generation for a Given Set of Applications Using Recurrent Neural Networks,Ciprian PaduraruMarius-Constantin MelemciucMiruna Paduraru,"Fuzz testing, LSTM Tensorflow, Pipeline, Recurrent neural networks, Taint analysis",10,"To address the problem of automatic software testing against vulnerabilities, our work focuses on creating a tool capable in assisting users to generate automatic test sets for multiple programs under test at the same time. Starting with an initial set of inputs in a corpus folder, the tool works by clustering the inputs depending on their application target type, then produces a generative model for each of these clusters. The architecture of the models is falling in the recurrent neural network architecture class, and for training and inferencing the models we used the Tensorflow framework. Online-learning is supported by the tool, thus models can get better as long as new inputs for each application cluster are added to the corpus folder. Users can interact with the tool similar to the interface used in expert systems: customize various parameters exposed per cluster, or override various function hooks for learning and inferencing the model, with the purpose of getting finer control over the tool’s backend. As the evaluation section shows, the tool can be useful for creating important sets of new inputs, with good code coverage quality and less resources consumed."
SPRINGERLINK,Chapter,2019,Incorporating Data into EFSM Inference,Michael FosterAchim D. BruckerRamsay G. TaylorSiobhán NorthJohn Derrick,"EFSM inference, Model inference, Reverse engineering",10,"Models are an important way of understanding software systems. If they do not already exist, then we need to infer them from system behaviour. Most current approaches infer classical FSM models that do not consider data, thus limiting applicability. EFSMs provide a way to concisely model systems with an internal state but existing inference techniques either do not infer models which allow outputs to be computed from inputs, or rely heavily on comprehensive white-box traces to reveal the internal program state, which are often unavailable. In this paper, we present an approach for inferring EFSM models, including functions that modify the internal state. Our technique uses black-box traces which only contain information visible to an external observer of the system. We implemented our approach as a prototype."
SPRINGERLINK,Chapter,2019,Why Software Testing Fails: Common Pitfalls Observed in a Critical Smart Metering Project,Stefan MohacsiRudolf Ramler,"Common testing pitfalls, Smart metering, Software testing, System testing, Test management, Testing Anti-Patterns",10,"Over the last decades a considerable share of software engineering research has been dedicated to the area of software testing. Still, however, testing often fails or causes major problems in practice. In this paper we present insights and experiences from a large project in the energy sector. The obligatory switch from analog energy meters to smart metering technology poses a big challenge for many energy providers. Apart from technical issues concerning meters and transmission technology, the adaption of the internal business processes together with the development of backend software can turn out to be more difficult than expected. The criticality, size and complexity of the analyzed project are reflected in software and system testing, where the underestimated effort, mistakes, and wrong decisions caused serious difficulties. In our work we describe the observed testing problems and the underlying causes. Subsequently, we compare the identified problems with a catalogue of commonly known testing pitfalls and anti-patterns. The results show that the majority of the observed problems are not new or specific to the studied project. Furthermore, additional candidates for extending the list of common pitfalls are identified. Besides recommendations on how to mitigate the problems in the studied project, we conclude with the general insight that there is a great potential to improve software testing practice by developing measures for early recognition, communication, and avoiding of common mistakes."
SPRINGERLINK,Chapter,2019,TOOLympics 2019: An Overview of Competitions in Formal Methods,Ezio BartocciDirk BeyerPaul E. BlackGrigory FedyukovichHubert GaravelArnd HartmannsMarieke HuismanFabrice KordonJulian NageleMihaela SighireanuBernhard SteffenMartin SudaGeoff SutcliffeTjark WeberAkihisa Yamada,,10,"Evaluation of scientific contributions can be done in many different ways. For the various research communities working on the verification of systems (software, hardware, or the underlying involved mechanisms), it is important to bring together the community and to compare the state of the art, in order to identify progress of and new challenges in the research area. Competitions are a suitable way to do that. The first verification competition was created in 1992 (SAT competition), shortly followed by the CASC competition in 1996. Since the year 2000, the number of dedicated verification competitions is steadily increasing. Many of these events now happen regularly, gathering researchers that would like to understand how well their research prototypes work in practice. Scientific results have to be reproducible, and powerful computers are becoming cheaper and cheaper, thus, these competitions are becoming an important means for advancing research in verification technology. TOOLympics 2019 is an event to celebrate the achievements of the various competitions, and to understand their commonalities and differences. This volume is dedicated to the presentation of the 16 competitions that joined TOOLympics as part of the celebration of the $$25^{ th }$$ anniversary of the TACAS conference."
SPRINGERLINK,Chapter,2019,Ensuring the Consistency Between User Requirements and GUI Prototypes: A Behavior-Based Automated Approach,Thiago Rocha SilvaMarco WincklerHallvard Trætteberg,"Behavior-Driven Development (BDD), GUI Prototypes, User Requirements Assessment, User Stories",10,"In a user-centered design process, graphical user interface (GUI) prototypes may be seen as an important early artifact to design and validate user requirements before making strong commitments with a full-fledged version of the user interface. Ensuring the consistency of GUI prototypes with other representations of the user requirements is then a critical aspect of the design process. This paper presents an approach which extends Behavior-Driven Development (BDD) by employing an ontology in order to provide automated assessment for GUI prototypes as design artifacts. The approach has been evaluated by exploiting user requirements described by a group of experts in the flight tickets e-commerce domain. Such requirements gave rise to a set of User Stories that have been used to automatically check the consistency of Balsamiq prototypes which were reengineered from an existing web system for booking business trips. The results have shown our approach was able to identify different types of inconsistencies in the set of analyzed artifacts, allowing to build an effective correspondence between user requirements and their representation in GUI prototypes."
SPRINGERLINK,Chapter,2019,Formal Model Validation Through Acceptance Tests,Tomas FischerDana Dghyam,"Acceptance tests, Cucumber, Event-B, Formal methods, Gherkin, iUML-B, Validation",10,"When formal systems modelling is used as part of the development process, modellers need to understand the requirements in order to create appropriate models, and domain experts need to validate the final models to ensure they fit the needs of stakeholders. A suitable mechanism for such a validation are acceptance tests. In this paper we discuss how the principles of Behaviour-Driven Development (BDD) can be applied to (i) formal modelling and (ii) validation of behaviour specifications, thus coupling those two tasks. We show how to close the gap between the informal domain specification and the formal model, thus enabling the domain expert to write acceptance tests in a high-level language matching the formal specification. We analyse the applicability of this approach by providing the Gherkin scenarios for an formal model of a ‘fixed virtual block’ approach to train movement control, developed according to the Hybrid ERTMS/ETCS Level 3 principles specified by the EEIG ERTMS Users Group and presented as a case study on the 6. International ABZ Conference 2018."
SPRINGERLINK,Chapter,2019,Repairing Timed Automata Clock Guards through Abstraction and Testing,Étienne AndréPaolo ArcainiAngelo GargantiniMarco Radavelli,,10,"Timed automata (TAs) are a widely used formalism to specify systems having temporal requirements. However, exactly specifying the system may be difficult, as the user may not know the exact clock constraints triggering state transitions. In this work, we assume the user already specified a TA, and (s)he wants to validate it against an oracle that can be queried for acceptance. Under the assumption that the user only wrote wrong guard transitions (i.e., the structure of the TA is correct), the search space for the correct TA can be represented by a Parametric Timed Automaton (PTA), i.e., a TA in which some constants are parametrized. The paper presents a process that (i) abstracts the initial (faulty) TA $$ ta_{init} $$ t a init in a PTA $$ pta $$ pta ; (ii) generates some test data (i.e., timed traces) from $$ pta $$ pta ; (iii) assesses the correct evaluation of the traces with the oracle; (iv) uses the IMITATOR tool for synthesizing some constraints $$\varphi $$ φ on the parameters of $$ pta $$ pta ; (v) instantiate from $$\varphi $$ φ a TA $$ ta_{rep} $$ t a rep as final repaired model. Experiments show that the approach is successfully able to partially repair the initial design of the user."
SPRINGERLINK,Chapter,2019,Software Assurance in an Uncertain World,Marsha ChechikRick SalayTorin VigerSahar KokalyMona Rahimi,,10,"From financial services platforms to social networks to vehicle control, software has come to mediate many activities of daily life. Governing bodies and standards organizations have responded to this trend by creating regulations and standards to address issues such as safety, security and privacy. In this environment, the compliance of software development to standards and regulations has emerged as a key requirement. Compliance claims and arguments are often captured in assurance cases, with linked evidence of compliance. Evidence can come from testcases, verification proofs, human judgment, or a combination of these. That is, experts try to build (safety-critical) systems carefully according to well justified methods and articulate these justifications in an assurance case that is ultimately judged by a human. Yet software is deeply rooted in uncertainty; most complex open-world functionality (e.g., perception of the state of the world by a self-driving vehicle), is either not completely specifiable or it is not cost-effective to do so; software systems are often to be placed into uncertain environments, and there can be uncertainties that need to be We argue that the role of assurance cases is to be the grand unifier for software development, focusing on capturing and managing uncertainty. We discuss three approaches for arguing about safety and security of software under uncertainty, in the absence of fully sound and complete methods: assurance argument rigor, semantic evidence composition and applicability to new kinds of systems, specifically those relying on ML."
SPRINGERLINK,Chapter,2019,Adaptation and Implementation of the ISO42010 Standard to Software Design and Modeling Tools,Maged ElaasarFlorian NoyritOmar BadreddinSébastien Gérard,"Architecture description language, Architecture framework, ISO 42010, Model driven architecture, Model driven development, Software design, Software modeling, SysML, UML",10,"Model cantered software development practices adoption remains limited to small niche domains. The broad development practices remain code centric. Modeling tool complexity is often cited as a significant factor limiting the adoption and negatively affecting user experience. Modeling and design tools complexity are due to multiple factors including complexity of the underlying language, weak support for methodologies, and insensitivity to users’ concerns. This results in modeling and design tools that expose all or most of their capabilities and elements at once, often overwhelming users and negatively affecting user experience. The problem is further exacerbated when a tool supports multiple domain-specific modeling languages that are defined on top of a base language such as UML. In this case, the tool customizations and visual elements necessary to support each language often interfere with each other and further exacerbate the modeling tool complexity. In this paper, we present a novel and systematic approach to reduce the complexity of design and modeling tools by introducing an interpretation and adaptation of the ISO42010 standard on architecture description specific to the software domain. We demonstrate this approach by providing a working implementation as part of the Papyrus opensource modeling framework. In this approach, we leverage the notions of Architecture Contexts and Architecture Viewpoints to enable heterogeneous UML-based languages to be independently supported and help contextualize the exposed tool capabilities. This paper presents the ISO42010 interpretation and adaptation to software design and architecture and a case study with several definitions of architecture contexts. The implementation of this novel approach demonstrates the ability for multiple modeling languages and notations to coexist without interference and provides significant reduction in the exposed capabilities in the UI. Reducing design and modeling tool complexity has a potential to significantly broaden the adoption of modeling and design practices in the software engineering sphere."
SPRINGERLINK,Chapter,2019,Testing for Integrity Flaws in Web Sessions,Stefano CalzavaraAlvise RabittiAlessio RagazzoMichele Bugliesi,"CSRF, Session fixation, Session hijacking, Web sessions",10,"Web sessions are fragile and can be attacked at many different levels. Classic attacks like session hijacking, session fixation and cross-site request forgery are particularly dangerous for web session security, because they allow the attacker to breach the integrity of honest users’ sessions by forging requests which get authenticated on the victim’s behalf. In this paper, we systematize current countermeasures against these attacks and the shortcomings thereof, which may completely void protection under specific assumptions on the attacker’s capabilities. We then build on our security analysis to introduce black-box testing strategies to discover insecure session implementation practices on existing websites, which we implement in a browser extension called Dredd. Finally, we use Dredd to assess the security of 20 popular websites from Alexa, exposing a number of session integrity flaws."
SPRINGERLINK,Chapter,2019,Extracting High-Level System Specifications from Source Code via Abstract State Machines,Flavio FerrarottiJosef PichlerMichael MoserGeorg Buchgeher,,10,"We are interested in specifications which provide a consistent high-level view of systems. They should abstract irrelevant details and provide a precise and complete description of the behaviour of the system. This view of software specification can naturally be expressed by means of Gurevich’s Abstract State Machines (ASMs). There are many known benefits of such an approach to system specifications for software engineering and testing. In practice however, such specifications are rarely generated and/or maintained during software development. Addressing this problem, we present an exploratory study on (semi) automated extraction of high-level software specifications by means of ASMs. We describe, in the form of examples, an abstraction process which starts by extracting an initial ground-level ASM specification from Java source code (with the same core functionality), and ends in a high-level ASM specification at the desired level of abstraction. We argue that this process can be done in a (semi) automated way, resulting in a valuable tool to improve the current software engineering practices."
SPRINGERLINK,Chapter,2019,An Implementation Relation for Cyclic Systems with Refusals and Discrete Time,Raluca LefticaruRobert M. HieronsManuel Núñez,,10,"This paper explores a particular type of model, a cyclic model, in which there are sequences of observable actions separated by discrete time intervals, introduces a novel implementation relation and studies some properties of this relation. Implementation relations formalise what it means for an unknown model of the system under test (SUT) to be a correct implementation of a specification. Many implementation relations are variants of the well known ioco implementation relation, and this includes several timed versions of ioco. It transpires that the timed variants of ioco are not suitable for cyclic models. Our implementation relation encapsulates the discrete nature of time in cyclic models and takes into account not only the actions that models can perform but also the ones that they can refuse at each point of time. We prove that our implementation relation is a conservative extension of trace containment and present two alternative characterisations."
SPRINGERLINK,Chapter,2018,A Survey on Model-Based Testing Tools for Test Case Generation,Wenbin LiFranck Le GallNaum Spaseski,"Model specification, Model-Based Testing, Survey, Test case, Test description, Test generation, Tool",10,"Compared to traditional testing methods, Model-Based Testing (MBT) is able to manage and accomplish testing tasks in a cheaper and more efficient way. A number of MBT tools are developed to support MBT activities in the past few years, whereas the characteristics of these tools largely vary from one to another and users without prior knowledge can hardly choose appropriate tools. This paper aims at providing a survey on the emerging MBT tools following a list of criteria emphasizing on test case generation while illustrating aspects of test data and test script generation. Firstly, we introduce the general MBT process for a common understanding; we then present a list of criteria oriented to test case generation covering fours dimensions i.e., model specification, test generation, test description and overall support; following our proposed criteria, we survey and characterize the emerging MBT tools; at last we summarize the current limitations based on our survey and shed light on further directions of MBT tool development."
SPRINGERLINK,Chapter,2018,Model Based Testing of Cyber-Physical Systems,Teck Ping Khoo,"Cyber-Physical Systems, Model Based Testing, Testing framework",10,"Testing, inspection, and certification (TIC) are essential activities on consumer and industrial systems. The conformance to system specifications and standards can then provide assurances on system safety, security, reliability, and interoperability. TIC needs to evolve in tandem with growing system size and complexity. Common modern systems such as autonomous vehicles and smart health-care systems take the form of Cyber Physical Systems (CPSs). Model Based Testing (MBT) is one promising approach to test CPSs. An MBT framework for testing CPSs will be useful to systems testers and can raise the standard of systems testing as a whole."
SPRINGERLINK,Chapter,2018,Model-Based Testing for Avionic Systems Proven Benefits and Further Challenges,Jan PeleskaJörg BrauerWen-ling Huang,"Avionic systems, HW/SW integration testing, Model-based testing, Scenario-based testing",10,"In this article, we report on the transition of model-based testing (MBT) from a widely discussed research discipline to an accepted technology that is currently becoming state of the art in industry; in particular, in the field of safety-critical systems testing. It is reviewed how focal points of MBT-related research in the past have found their way into today’s commercial MBT products. We describe the benefits of MBT that are – from our experience – most appreciated by practitioners. Moreover, some interesting open challenges are described, and potential future solutions are presented. The material presented in this paper is based on our practical experience with recent MBT campaigns performed for Airbus in Germany."
SPRINGERLINK,Chapter,2018,Scrum and V Lifecycle Combined with Model-Based Testing and Model Driven Architecture to Deal with Evolutionary System Issues,Imane EssebaaSalima Chantit,"Evolutionary system, Model Driven Architecture, Model transformations, Model-Based Testing, Scrum agile methodology, Test generation, V incremental lifecycle",10,"Model Driven Engineering (MDE) and Agile Methods (AM) are two principal domains that are in the way of improvement and evolution in order to facilitate the realisation of IT projects. However, these areas evolve separately despite the great number of researches that focus on improving realisation project’ techniques. Thus, our approach aims to provide an approach that combines two variants of MDE, Model Driven Architecture approach and Model-Based Testing with the V development lifecycle used in every scrum Agile Methodology sprint to deal with system evolution. In order to well illustrate this approach, we apply it on Rental Car Agency System realisation using Scrum methodology with some requirements’ evolution."
SPRINGERLINK,Chapter,2018,Model-Based Testing for Avionics Systems,Jörg BrauerUwe Schulze,"Application Parameters, Model-based Development Techniques, Model-based Testing, Tension Panel, Voiding Function",10,"Model-based testing is considered state-of-the-art in verification and validation of safety-critical systems. This paper discusses some experiences of applying the model-based testing tool RTT-MBT for the evacuation function of an aircraft cabin controller. One challenge of this project was the parametric design of the software, which allows to tailor the software to a certain aircraft configuration via application parameters. Further challenges consisted of connecting hardware signals of the system under test to abstract model variables, and handling incremental test model development during an ongoing test campaign. We discuss solutions that we developed to successfully conduct this test campaign."
SPRINGERLINK,Chapter,2018,Model-Based Testing for General Stochastic Time,Marcus GerholdArnd HartmannsMariëlle Stoelinga,,10,"Many systems are inherently stochastic: they interact with unpredictable environments or use randomised algorithms. Then classical model-based testing is insufficient: it only covers functional correctness. In this paper, we present a new model-based testing framework that additionally covers the stochastic aspects in hard and soft real-time systems. Using the theory of stochastic automata for specifications, test cases and a formal notion of conformance, it provides clean mechanisms to represent underspecification, randomisation, and stochastic timing. Supporting arbitrary continuous and discrete probability distributions, the framework generalises previous work based on purely Markovian models. We cleanly define its theoretical foundations, and then outline a practical algorithm for statistical conformance testing based on the Kolmogorov-Smirnov test. We exemplify the framework’s capabilities and tradeoffs by testing timing aspects of the Bluetooth device discovery protocol."
SPRINGERLINK,Chapter,2018,An Extension of TRIANGLE Testbed with Model-Based Testing,Laura PanizoAlmudena DíazBruno García,"Mobile network testbed, Model checking, Model-based testing",10,"Traditional testing methods for mobile apps focus on detecting execution errors. However, the evolution of mobile networks towards 5G will require additional support for app developers to ensure also the performance and user-experience. Manual testing in a number of scenarios is not enough to satisfy the expectations of the apps final users. This paper presents the testing framework developed in the TRIANGLE project ( https://www.triangle-project.eu/ ) that integrates a complete mobile network testbed and a model-based testing approach, which is based on model checking, to automatically evaluate the apps performance in different network scenarios."
SPRINGERLINK,Chapter,2018,Towards a Model-Based Testing Framework for the Security of Internet of Things for Smart City Applications,Moez KrichenOmar CheikhrouhouMariam LahamiRoobaea AlroobaeaAfef Jmal Maâlej,"Coverage, Generation, Internet of Things, Security, Security models, Smart cities, Test, Verdicts",10,This is a work in progress in which we are interested in testing security aspects of Internet of Things for Smart Cities. For this purpose we follow a Model-Based approach which consists in: modeling the system under investigation with an appropriate formalism; deriving test suites from the obtained model; applying some coverage criteria to select suitable tests; executing the obtained tests; and finally collecting verdicts and analyzing them in order to detect errors and repair them.
SPRINGERLINK,Chapter,2018,MBT/CPN: A Tool for Model-Based Software Testing of Distributed Systems Protocols Using Coloured Petri Nets,Rui WangLars Michael KristensenVolker Stolz,,10,"Model-based testing is an approach to software testing based on generating test cases from models. The test cases are then executed against a system under test. Coloured Petri Nets (CPNs) have been widely used for modeling, validation, and verification of concurrent software systems, but their application for model-based testing has only been explored to a limited extent. The contribution of this paper is to present the MBT/CPN tool, implemented through CPN Tools, to support test case generation from CPN models. We illustrate the application of our approach by showing how it can be used for model-based testing of a Go implementation of the coordinator in a two-phase commit protocol. In addition, we report on experimental results for Go-based implementations of a distributed storage protocol and the Paxos distributed consensus protocol. The experiments demonstrate that the generated test cases yield a high statement coverage."
SPRINGERLINK,Chapter,2018,Model Based Approach for Testing: Distributed Real-Time Systems Augmented with Online Monitors,Deepak PalJüri Vain,"Distributed systems, Low-latency systems, Model-based testing, Real-time database systems",10,"Testing distributed systems requires an integration of computation, communication and control in the test architecture. This may pose number of issues that may not be suitably addressed by traditional centralized test architectures. In this paper, a distributed test framework for testing distributed real-time systems is presented, where online monitors (executable code as annotations) are integrated to systems to record relevant events. The proposed test architecture is more scalable than centralized architectures in the sense of timing constraints and geographical distribution. By assuming the existence of a coverage correct centralized remote tester, we give a partitioning algorithm of it to produce distributed local testers which enables to meet more flexible performance constraints while preserving the remote tester’s functionality. The proposed approach not only preserves the correctness of the centralized tester but also allows to meet stronger timing constraints for solving test controllability and observability issues. The effectiveness of the proposed architecture is demonstrated by an illustrative example."
SPRINGERLINK,Chapter,2018,Applying Integrated Domain-Specific Modeling for Multi-concerns Development of Complex Systems,Reinhard PröllAdrian RumpoldBernhard Bauer,"Domain-specific modeling, Model transformation, Model-based analysis, Model-based testing",10,"Current systems engineering efforts are increasingly driven by trade-offs and limitations imposed by multiple factors: Growing product complexity as well as stricter regulatory requirements in domains such as automotive or aviation necessitate advanced design and development methods. At the core of these influencing factors lies a consideration of competing non-functional concerns, such as safety and reliability, performance, and the fulfillment of quality requirements. In an attempt to cope with these aspects, incremental evolution of model-based engineering practice has produced heterogeneous tool environments without proper integration and exchange of design artifacts. In order to overcome these shortcomings of current engineering practice, we propose a holistic, model-based architecture and analysis framework for seamless design, analysis, and evolution of integrated system models. We describe how heterogeneous domain-specific modeling languages can be embedded into a common general-purpose model in order to facilitate the integration between previously disjoint design artifacts. A case study demonstrates the suitability of this methodology for the design of a safety-critical embedded system, a hypothetical gas heating, with respect to reliability engineering and further quality assurance activities."
SPRINGERLINK,Chapter,2018,Effective Test Suite Design for Detecting Concurrency Control Faults in Distributed Transaction Systems,Simin CaiBarbara GallinaDag NyströmCristina Seceleanu,,10,"Concurrency control faults may lead to unwanted interleavings, and breach data consistency in distributed transaction systems. However, due to the unpredictable delays between sites, detecting concurrency control faults in distributed transaction systems is difficult. In this paper, we propose a methodology, relying on model-based testing and mutation testing, for designing test cases in order to detect such faults. The generated test inputs are designated delays between distributed operations, while the outputs are the occurrence of unwanted interleavings that are consequences of the concurrency control faults. We mutate the distributed transaction specification with common concurrency control faults, and model them as UPPAAL timed automata, in which designated delays are encoded as stopwatches. Test cases are generated via reachability analysis using UPPAAL Model Checker, and are selected to form an effective test suite. Our methodology can reduce redundant test cases, and find the appropriate delays to detect concurrency control faults effectively."
SPRINGERLINK,Chapter,2018,20 Years of UPPAAL Enabled Industrial Model-Based Validation and Beyond,Kim G. LarsenFlorian LorberBrian Nielsen,,10,"In this paper we review how the Uppaal Tool Suite served in industrial projects and was both driven and improved by them throughout the last 20 years. We show how the need of industry for model-based validation, performance evaluation and synthesis shaped the tool suite and how the tool suite aided the use cases it was applied in. The paper highlights a number of selected cases, including success stories and pitfalls, and we discuss the important roles of both basic research and industrial projects."
SPRINGERLINK,Chapter,2018,Lessons Learned Using FMI Co-simulation for Model-Based Design of Cyber Physical Systems,Luís Diogo CoutoStylianos BasagiannisEl Hassan RidouaneErica ZavaglioPasquale AntonanteHajer SaadaSara Falleni,,10,"Model-Based Design is an effective way to carry out Cyber-Physical Systems (CPS) development. One of the main sets of challenges in CPS projects is dealing with the highly heterogeneous nature of the development teams. These challenges can be brought to the forefront by focusing on model integration through standards, such as the Functional Mockup Interface (FMI). We report on a case study of the application of an FMI-based workflow to the development of a Heat Ventilation and Air Conditioning (HVAC) system of a building. We report on ten challenges and lessons learned when using the FMI standard, focusing on collaborative aspects and model integration. As a conclusion we provide recommendations and examples for dealing with the CPS development challenges assessing to that end the importance of the FMI standard."
SPRINGERLINK,Chapter,2018,The Miles Before Formal Methods - A Case Study on Modeling and Analyzing a Passenger Lift System,Teck Ping KhooJun Sun,,10,"Cyber-Physical Systems (CPS) pervade our everyday lives. As users, we need assurances that such systems satisfy requirements on safety, reliability, security and interoperability. CPS presents a major challenge for formal analysis because of their complexity, physical dependencies and non-linearity, and for smart CPS - the ability to improve their behavior over time. Existing approaches on analyzing CPS (e.g., model checking and model-based testing) often assume the existence of a system model. Such approaches have limited application in practice as the models often do not exist. In this work, we report our experience on applying a three-step approach to analyzing a practical CPS: a passenger lift system in a commercial building. The three steps are (1) determining the right level of system abstraction, (2) building the model automatically using grammatical inference, and (3) analyzing the model. The inferred model is in the form of a probabilistic deterministic real time automaton, which allows us to verify the system against properties demanded by the lift requirement. The resulting models form the basis of formal analysis and potentially other approaches. We believe that our approach and experience are applicable to other CPSs."
SPRINGERLINK,Chapter,2018,"Life Sciences-Inspired Test Case Similarity Measures for Search-Based, FSM-Based Software Testing",Nesa AsoudehYvan Labiche,"Fault detection, FSM, State-based testing, Test suite diversity",10,"Researchers and practitioners alike have the intuition that test cases diversity is positively correlated to fault detection. Empirical results already show that some measurement of diversity within a pre-existing state-based test suite (i.e., a test suite not necessarily created to have diverse tests in the first place) indeed relates to fault detection. In this paper we show how our procedure, based on a genetic algorithm, to construct an entire (all-transition) adequate test suite with as diverse tests as possible fares in terms of fault detection. We experimentally compare on a case study nine different ways of computing test suite diversity, including measures already used by others in software testing as well as measures inspired by the notion of diversity in the life sciences. Although our results confirm a positive correlation between diversity and fault detection, we believe our results raise more questions than they answer about the notion and measurement of test suite diversity, which leads us to argue that more work needs to be dedicated to this topic."
SPRINGERLINK,Chapter,2018,QuickChecking Patricia Trees,Jan Midtgaard,"Functional Data Structures, Integer Keys, Okasaki, Patricia Tree, QuickCheck",10,"Patricia trees are a space-efficient, purely functional data structure, useful for efficiently implementing both integer sets and dictionaries with integer keys. In this paper we illustrate how to build a QuickCheck model of the data structure for the purpose of testing a mature OCaml library implementing it. In doing so, we encounter a subtle bug, initially inherited from a paper by Okasaki and Gill, and since then flying under the radar for almost two decades."
SPRINGERLINK,Chapter,2018,Randomized Event Sequence Generation Strategies for Automated Testing of Android Apps,David AdamoRenée BryceTariq M. King,"Android, Automated testing, GUI testing, Mobile apps",10,"Mobile apps are often tested with automatically generated sequences of Graphical User Interface (GUI) events. Dynamic GUI testing algorithms construct event sequences by selecting and executing events from GUI states at runtime. The event selection strategy used in a dynamic GUI testing algorithm may directly influence the quality of the test suites it produces. Existing algorithms use a uniform probability distribution to randomly select events from each GUI state and they are often not directly applicable to mobile apps. In this paper, we develop a randomized algorithm to dynamically construct test suites with event sequences for Android apps. We develop two frequency-based event selection strategies as alternatives to uniform random event selection. Our event selection algorithms construct event sequences by dynamically altering event selection probabilities based on the prior selection frequency of events in each GUI state. We compare the frequency-based strategies to uniform random selection across nine Android apps. The results of our experiments show that the frequency-based event selection strategies tend to produce test suites that achieve better code coverage and fault detection than test suites constructed with uniform random event selection."
SPRINGERLINK,Chapter,2018,MoDeS3: Model-Based Demonstrator for Smart and Safe Cyber-Physical Systems,András VörösMárton BúrIstván RáthÁkos HorváthZoltán MicskeiLászló BaloghBálint HegyiBenedek HorváthZsolt MázlóDániel Varró,"Demonstrator, Education, Formal methods, Model-driven engineering, Smart cyber-physical systems",10,"We present MoDeS3, a complex research demonstrator illustrating the combined use of model-driven development, formal verification, safety engineering and IoT technologies for smart and safe cyber-physical systems. MoDeS3 represents a smart transportation system-of-systems composed of a model railway and a crane which may automatically load and unload cargo from trains where both subsystems need to fulfill functional and safety requirements. The demonstrator is built by using the model-based software engineering principle, while the system level safety is ensured by the combined use of design-time and runtime verification and validation techniques."
SPRINGERLINK,Chapter,2018,Model-Driven Engineering for Design-Runtime Interaction in Complex Systems: Scientific Challenges and Roadmap,Hugo BruneliereRomina EramoAbel GómezValentin BesnardJean Michel BruelMartin GogollaAndreas KästnerAdrian Rutle,"Correspondences, Design time modeling, Feedback, Interactions, Runtime modeling, Traceability",10,"This paper reports on the first Workshop on Model-Driven Engineering for Design-Runtime Interaction in Complex Systems (also called MDE@DeRun 2018) that took place during the STAF 2018 week. It explains the main objectives, content and results of the event. Based on these, the paper also proposes initial directions to explore for further research in the workshop area."
SPRINGERLINK,Chapter,2018,Extending Automated Protocol State Learning for the 802.11 4-Way Handshake,Chris McMahon StoneTom ChothiaJoeri de Ruiter,,10,"We show how state machine learning can be extended to handle time out behaviour and unreliable communication mediums. This enables us to carry out the first fully automated analysis of 802.11 4-Way Handshake implementations. We develop a tool that uses our learning method and apply this to 7 widely used Wi-Fi routers, finding 3 new security critical vulnerabilities: two distinct downgrade attacks and one router that can be made to leak some encrypted data to an attacker before authentication."
SPRINGERLINK,Chapter,2018,A Proposal of an Example and Experiments Repository to Foster Industrial Adoption of Formal Methods,Rupert SchlickMichael FeldererIstvan MajzikRoberto NardoneAlexander RaschkeColin SnookValeria Vittorini,"Benchmarks, Formal methods, Formal models, Industrial adoption",10,"Formal methods (in a broad sense) have been around almost since the beginning of computer science. Nonetheless, there is a perception in the formal methods community that take-up by industry is low considering the potential benefits. We take a look at possible reasons and give candidate explanations for this effect. To address the issue, we propose a repository of industry-relevant example problems with an accompanying open data storage for experiment results in order to document, disseminate and compare exemplary solutions from formal model based methods. This would allow potential users from industry to better understand the available solutions and to more easily select and adopt a formal method that fits their needs. At the same time, it would foster the adoption of open data and good scientific practice in this research field."
SPRINGERLINK,Chapter,2018,Injecting Formal Verification in FMI-Based Co-simulations of Cyber-Physical Systems,Luís Diogo CoutoStylianos BasagiannisEl Hassan RidouaneAlie El-Din MadyMiran HasanagicPeter Gorm Larsen,,10,"Model-based design tools supporting the Functional Mockup Interface (FMI) standard, often employ specification languages ideal for modelling specific domain problems without capturing the overall behavior of a Cyber-Physical System (CPS). These tools tend to handle some important CPS characteristics implicitly, such as network communication handshakes. At the same time, formal verification although a powerful approach, is still decoupled to FMI co-simulation processes, as it can easily lead to infeasible explorations due to state space explosion of continuous or discrete representations. In this paper we exploit co-modelling and co-simulation concepts combined with the injection of formal verification results indirectly in a model-based design workflow that will enable verification engineering benefits in a heterogeneous, multi-disciplinary design process for CPSs. We demonstrate the approach using a Heating, Ventilation and Air Conditioning (HVAC) case study where communication delays may affect the CPS system’s analysis. We model discrete events based on the Vienna Development Method Real-Time dialect, Continuous Time phenomena using Modelica, and communications using PROMELA. Results are considered and inspected both at the level of constituent models and the overall co-simulation."
SPRINGERLINK,Chapter,2018,Automatic Test Case Generation for Concurrent Features from Natural Language Descriptions,Rafaela AlmeidaSidney NogueiraAugusto Sampaio,"Concurrent feature, CSP, Software testing",10,"Contemporary computing applications have an increasing level of concurrency; new techniques are demanded to tackle the challenge of testing the plentiful interactions that arise from concurrent behaviour. Current approaches for automatic test generation from natural language models do not allow the explicit specification of concurrent behaviour. This paper extends our previous test case generation approach to support concurrent mobile device features. A natural language notation is proposed to express the composition of sequential and concurrent behaviour. The notation can be automatically translated to a CSP model, from which tests are automatically produced using the FDR refinement checker. The approach is illustrated with a mobile application that includes concurrent features."
SPRINGERLINK,Chapter,2018,Applying Model-Driven Web Engineering to the Testing Phase of the ADAGIO Project,L. MoralesS. Moreno-LeonardoM. A. OliveroA. Jiménez-RamírezM. Mejías,"Early Testing, Model-Driven Web Engineering, NDT, Web application",10,"The Model-Driven Engineering (MDE) has been used in recent years to promote better results in the development of Web Applications, in the field that has been called Model-Driven Web Engineering (MDWE). One of the advantages of applying MDWE is that it offers a solution to reduce the cost of the tests without affecting their quality execution. This paper presents the application of a MDWE methodology (Navigational Development Techniques, NDT) that provides support for all the phases of the lifecycle of a software project development proposing transformations between these phases, to manage the test phase of a real-world case study named ADAGIO. This project, among other goals, proposes the development of a web application whose main objective is to offer researchers the possibility of integrating and consolidating heterogeneous data sources, showing a unified vision of them, allowing to simplify the search task in different repositories as well as the relationship between the sources found."
SPRINGERLINK,Chapter,2018,Property-Aware Unit Testing of UML-RT Models in the Context of MDE,Reza AhmadiNicolas HiliJuergen Dingel,,10,"Modern cyber-physical systems are complex to model due, among other things, to timing constraints and complex communications between components of such systems. Therefore, testing models of these systems is not straightforward. This paper presents an approach for automatically testing components of UML-RT models with respect to a set of formally defined properties. Compared to existing model-based techniques where abstract test cases are complemented with their concrete counterparts, our approach solely leverages on constructs provided by the modeling language to express all artifacts (component to test, test harness, the property of interest) and existing code generator to generate test cases. This helps to reduce the cost of ensuring the consistency between code- and model-level tests. Moreover, to reduce the number of test cases and the associated cost, our approach integrates our test case generators with slicing techniques to reduce the size of the components. A prototype implementation has been sketched and our approach has been evaluated over two case studies."
SPRINGERLINK,Chapter,2018,Modelling and Validating an Engineering Application in Kernel P Systems,Raluca LefticaruMehmet Emin BakirSavas KonurMike StannettFlorentin Ipate,"Bicycle, Cruise control, Electric bike, Kernel P systems, Membrane computing, Testing, Verification",10,"This paper illustrates how kernel P systems ( kP systems ) can be used for modelling and validating an engineering application, in this case a cruise control system of an electric bike. The validity of the system is demonstrated via formal verification, carried out using the k PWorkbench tool. Furthermore, we show how the kernel P system model can be tested using automata and X-machine based techniques."
SPRINGERLINK,Chapter,2018,Formal Modelling of Environment Restrictions from Natural-Language Requirements,Tainã SantosGustavo CarvalhoAugusto Sampaio,"Case grammar, Communicating Sequential Processes, Environment restrictions, Linear temporal logic, Natural language",10,"When creating system models, further to system behaviour one should take into account properties of the environment in order to achieve more meaningful models. Here, we extend a strategy that formalises data-flow reactive systems as CSP processes to take into account environment restrictions. Initially, these restrictions are written in natural language. Afterwards, with the aid of case-grammar theory, they are formalised by deriving LTL formulae automatically. Finally, these formulae are used to prune infeasible scenarios from the CSP-based system specification, in the light of the environment restrictions. Considering examples from the literature, and from the aerospace (Embraer) and the automotive (Mercedes) industry, we show the efficacy of our proposal in terms of state space reduction, up to 61% in some cases."
SPRINGERLINK,Chapter,2018,Sound Black-Box Checking in the LearnLib,Jeroen MeijerJaco van de Pol,,10,"In Black-Box Checking (BBC) incremental hypotheses of a system are learned in the form of finite automata. On these automata LTL formulae are verified, or their counterexamples validated on the actual system. We extend the LearnLib’s system-under-learning API for sound BBC, by means of state equivalence, that contrasts the original proposal where an upper-bound on the number of states in the system is assumed. We will show how LearnLib’s new BBC algorithms can be used in practice, as well as how one could experiment with different model checkers and BBC algorithms. Using the RERS 2017 challenge we provide experimental results on the performance of all LearnLib’s active learning algorithms when applied in a BBC setting. The performance of learning algorithms was unknown for this setting. We will show that the novel incremental algorithms TTT, and ADT perform the best."
SPRINGERLINK,Chapter,2018,Consumer-Driven API Testing with Performance Contracts,Johannes StählinSebastian LangFabian KajzarChristian Zirpins,"Application reuse, Cloud migration, Non-functional consumer-driven contract testing, RESTful web services and APIs",10,"Modern software applications are often based on a modular structure where services expose functions and data via an API. In an enterprise context, such APIs may be reused in varying contexts with alternative frontends and on different platforms. E.g., an intranet application may be reused by another department or as part of a public portal thereby migrating between different private clouds. When migrating services, it is imperative to assure their qualitative characteristics. Expectations of application users need to be satisfied despite of changes in service usage context and provisioning platform. The problem is (a) to adequately verify qualitative expectations after migration and (b) to optimize service provisioning respectively. In this position paper we discuss an adaptive API testing approach for reusable application services and APIs. Our work builds on a case study of application service reuse and migration at SAP SE. Subsequently, we propose performance contracts as a means to capture non-functional application requirements on user level. We utilize these contracts for consumer-driven API testing in order to verify and optimize the migration of services to different application contexts."
SPRINGERLINK,Chapter,2018,Deterministic High-Level Executable Models Allowing Efficient Runtime Verification,Vladimir Estivill-CastroRené Hexel,"Logic-labeled finite state machines, Model-driven software development, Run-time verification",10,"We present an architecture that enables run-time verification with executable models of behaviour. Our uniform modelling paradigm is logic-labelled finite-state machines (LLFSMs). Behaviours are constructed by parameterizable, loadable, and suspendable LLFSMs executed in predictable sequential schedules, but they are also verified at run-time by LLFSMs as well. Our architecture enables runtime verification (to monitor the quality of software during execution) as well as set up, tear down, and enforcement of quality behaviour during runtime. The LLFSMs models are executable and efficient because they are compiled (not interpreted). The LLFSMs can be derived from requirement engineering approaches such as behaviour trees, and also validated using test-driven development. However, in situations where software evolves incorporating elements of adaptive systems or machine learning, the software in execution may have never existed during development. We demonstrate the features of the architecture with illustrative case studies from robotics and embedded systems."
SPRINGERLINK,Chapter,2018,Test Derivation for SDN-Enabled Switches: A Logic Circuit Based Approach,Jorge LópezNatalia KushikAsma BerririNina YevtushenkoDjamal Zeghlache,"Logic circuits, Mutation testing, Run-time verification, SDN-enabled switches, Software Defined Networking (SDN)",10,"The paper is devoted to testing critical Software Defined Networking (SDN) components and in particular, SDN-enabled switches. A switch can be seen as a forwarding device with a set of configured rules and thus, can be modelled and analyzed as a ‘stateless’ system. Correspondingly, in this paper we propose to use appropriate logic circuits or networks to model the switch behavior. Both active and passive testing modes can benefit from such representation. First, this allows applying well-known test generation strategies such as for example, test derivation techniques targeting Single Stuck-at Faults (SSFs). We also specify a number of mutation operators for switch rules and propose an algorithm for eliminating equivalent mutants via SAT solving. Logic circuits simulating the behavior of the switches can be effectively utilized for run-time verification, and such logic circuit based approach is also discussed in the paper. Preliminary experimental results with Open vSwitch, on one hand, demonstrate the necessity of considering new fault models for logic circuits (apart from, for example well established SSFs) and on the other hand, confirm the efficiency of the proposed test generation and verification techniques."
SPRINGERLINK,Chapter,2018,Towards ‘Verifying’ a Water Treatment System,Jingyi WangJun SunYifan JiaShengchao QinZhiwu Xu,,10,"Modeling and verifying real-world cyber-physical systems is challenging, which is especially so for complex systems where manually modeling is infeasible. In this work, we report our experience on combining model learning and abstraction refinement to analyze a challenging system, i.e., a real-world Secure Water Treatment system (SWaT). Given a set of safety requirements, the objective is to either show that the system is safe with a high probability (so that a system shutdown is rarely triggered due to safety violation) or not. As the system is too complicated to be manually modeled, we apply latest automatic model learning techniques to construct a set of Markov chains through abstraction and refinement, based on two long system execution logs (one for training and the other for testing). For each probabilistic safety property, we either report it does not hold with a certain level of probabilistic confidence, or report that it holds by showing the evidence in the form of an abstract Markov chain. The Markov chains can subsequently be implemented as runtime monitors in SWaT."
SPRINGERLINK,Chapter,2018,Leveraging Smart Environments for Runtime Resources Management,Paolo BarsocchiAntonello CalabróFrancesca LonettiEda MarchettiFilippo Palumbo,"Access control policy, Monitoring, Sensors, Smart environment",10,"Smart environments (SE) have gained widespread attention due to their flexible integration into everyday life. Applications leveraging the smart environments rely on regular exchange of critical information and need accurate models for monitoring and controlling the SE behavior. Different rules are usually specified and centralized for correlating sensor data, as well as managing the resources and regulating the access to them, thus avoiding security flaws. In this paper, we propose a dynamic and flexible infrastructure able to perform runtime resources’ management by decoupling the different levels of SE control rules. This allows to simplify their continuous updating and improvement, thus reducing the maintenance effort. The proposed solution integrates low cost wireless technologies and can be easily extended to include other possible existing equipments. A first validation of the proposed infrastructure on a case study is also presented."
SPRINGERLINK,Chapter,2018,Are Your Requirements Covered?,Richard Mordinyi,"Coverage, Issue tracking system, Requirement, Test scenario, Testing, Version control system",10,"The coverage of requirements is a fundamental need throughout the software life cycle. It gives project managers an indication how well the software meets expected requirements. A precondition for the process is to link requirements with project artifacts, like test cases. There are various (semi-) automated methods deriving traceable relations between requirements and test scenarios aiming to counteract time consuming and error-prone manual approaches. However, even if traceability links are correctly established coverage is calculated based on passed test scenarios without taking into account the overall code base written to realize the requirement in the first place. In this paper the “Requirements-Testing-Coverage” (ReTeCo) approach is described that establishes links between requirements and test cases by making use of knowledge available in software tools supporting the software engineering process and are part of the software engineering tool environment. In contrast to traditional approaches ReTeCo generates traceability links indirectly by gathering and analyzing information from version control system, ticketing system and test coverage tools. Since the approach takes into account a larger information base it is able to calculate coverage reports on a fine-grained contextual level rather than on the result of high-level artifacts."
SPRINGERLINK,Chapter,2018,Developers’ Initial Perceptions on TDD Practice: A Thematic Analysis with Distinct Domains and Languages,Joelma ChomaEduardo M. GuerraTiago Silva da Silva,"Qualitative study, TDD, Test-driven development, Test-first programming, Thematic analysis",10,"Test-Driven Development (TDD) is one of the most popular agile practices among software developers. To investigate the software developers’ initial perceptions when applying TDD, we have performed an exploratory study. This study was carried out with participants who had about ten years of professional experience (on average), the majority of whom with no experience using TDD. The study is in the context of an agile project course at the postgraduate level of a research institute. Participants individually developed medium size projects addressed to different domains and using different programming languages. Through a structured questionnaire with open and semi-open questions, we collected information on TDD effects such as the perceived benefits, encountered difficulties, and developer’s opinion about the quality improvement of the software. Afterward, we conducted a thematic analysis of the qualitative data. Most participants noticed improvements in code quality, but few have a more comprehensive view of the effects of TDD on software design. Our findings suggest that after overcoming the initial difficulties to understand where to start, and know how to create a test for a feature that does not yet exist, participants gain greater confidence to implement new features and make changes due to broad test coverage."
SPRINGERLINK,Chapter,2018,Theoretical Aspects of Consumer Metrics for Safety & Privacy,Thomas FehlmannEberhard Kranich,"Functional size, Software metrics, Software testing, Test coverage, Test goals, Test intensity, Test size",10,"Software metrics are a matter of academic interest. Consumers, software developers, and other practitioners seem less interested in functional size than, maybe, in quality metrics. Functional size is useful for predicting cost of development; however, with today’s software development techniques and wide availability of open software, its size has become less important. Today, compliance, usability, and connectivity, are the most important cost drivers when developing software-intense products. However, functional size is essential for software testing. This is not yet widely accepted because today’s best practices in testing focus on code coverage. However, software must be tested against functionality. Code is usually not available for cloud functionality such as map services. Software-intense products, for instance when driving autonomous vehicles, or powering robots for daily life, rely on functionality from various origins, not on embedded software alone. This paper sketches the theoretical framework for software metrics that help consumers assessing the level of safety and privacy of their software."
SPRINGERLINK,Chapter,2018,Towards Minimizing the Impact of Changes Using Search-Based Approach,Bogdan KorelNada AlmasriLuay Tahat,"Extended finite state machine, Impact analysis, Model transformation, Search-based software engineering",10,"Software maintenance is becoming more challenging with the increased complexity of the software and the frequently applied modifications. To manage this complexity, systems development is headed towards Model-driven engineering (MDE) and search-based software engineering (SBSE). Additionally, prior to applying a change to these complex systems, change impact analysis is usually performed in order to determine the scope of the change, its feasibility, and the time and resources required to implement the change. The bigger the scope, the riskier the change is on the system. In this paper, we introduce a set of transformation rules for Extended Finite State Machine (EFSM) models of state-based systems. These transformation rules can be used as the basis for search-based model optimization in order to reduce the average impact of a potential change applied to an EFSM model. Assuming that Model-driven development is adopted for the implementation of a state-based system, reducing the change impact at the model level will lead to reducing the impact at the system level. An exploratory study is performed to measure the impact reduction for a given EFSM model when the transformation rules are applied by a search-based algorithm. The initial results show a promising usage of the transformation rules which can lead to a reduction of more than 50% of the initial average change impact of the model."
SPRINGERLINK,Chapter,2018,Under-Approximation Generation Driven by Relevance Predicates and Variants,J. JulliandO. KouchnarenkoP.-A. MassonG. Voiron,"Loop variant, Predicate abstraction, Relevance predicate, Under-approximation generation",10,"In test generation, when computing a reachable concrete under-approximation of an event system’s predicate abstraction, we aim at covering each reachable abstract transition with at least one reachable concrete instance. As this is in general undecidable, an algorithm must finitely instantiate the abstract transitions for it to terminate. The approach defended in this paper is to first concretely explore the abstract graph, while concretizing the abstract transitions met at most once. However, some abstract transitions would require that loops were taken previously for them to become reached. To this end, in a second phase, a test engineer guides the exploration by describing a relevance predicate able to travel such loops. We give hints on how to design and express a relevance predicate, and provide a method for automatically extracting a variant out of it. A relevance guided concretization algorithm is given, whose termination is ensured by using this variant. Experimental results are provided that show the interest of the approach."
SPRINGERLINK,Chapter,2018,Conformance Testing and Inference of Embedded Components,Alexandre PetrenkoFlorent Avellaneda,"Active inference, Component-based systems, Conformance testing, Embedded testing, FSM learning, SAT solving, Testing in context",10,"The problems of active inference (learning) and conformance testing of a system modelled by an automaton have actively been studied for decades, however, much less attention has been paid to modular systems, modelled by communicating automata. In this paper, we consider a system of two communicating FSMs, one machine represents an embedded component and another the remaining part of the system, the context. Assuming that the context FSM is known, we want to learn the embedded FSM without directly interacting with it. This problem can be viewed as a generalization of the classical automata inference in isolation, i.e., it is the grey box learning problem. The proposed approach to solve this problem relies on a SAT-solving method for FSM inference from traces. It does not depend on the composition topology and allows at the same time to solve a related problem of conformance testing in context. The latter is to test whether an embedded implementation FSM composed with the given context is equivalent to the embedded specification FSM also composed with the context. The novelty of the conformance testing method is that it directly generates a complete test suite for the embedded machine and avoids using nondeterministic approximations with their tests, eliminating thus several sources of test redundancy inherent in the existing methods."
SPRINGERLINK,Chapter,2018,PIAnalyzer: A Precise Approach for PendingIntent Vulnerability Analysis,Sascha GroßAbhishek TiwariChristian Hammer,"Android, Information flow control, Intent analysis, Static analysis",10,"PendingIntents are a powerful and universal feature of Android for inter-component communication. A PendingIntent holds a base intent to be executed by another application with the creator’s permissions and identity without the creator necessarily residing in memory. While PendingIntents are useful for many scenarios, e.g., for setting an alarm or getting notified at some point in the future, insecure usage of PendingIntents causes severe security threats in the form of denial-of-service, identity theft, and privilege escalation attacks. An attacker may gain up to SYSTEM privileges to perform the most sensitive operations, e.g., deleting user’s data on the device. However, so far no tool can detect these PendingIntent vulnerabilities. In this work we propose PIAnalyzer, a novel approach to analyze PendingIntent related vulnerabilities. We empirically evaluate PIAnalyzer on a set of 1000 randomly selected applications from the Google Play Store and find 1358 insecure usages of PendingIntents, including 70 severe vulnerabilities. We manually inspected ten reported vulnerabilities out of which nine correctly reported vulnerabilities, indicating a high precision. The evaluation shows that PIAnalyzer is efficient with an average execution time of 13 seconds per application."
SPRINGERLINK,Chapter,2018,Measuring and Evaluating the Performance of Self-Organization Mechanisms Within Collective Adaptive Systems,Benedikt EberhardingerHella PonsarDominik KlumppWolfgang Reif,,10,"By restructuring and reconfiguring itself at run-time, a collective adaptive system (CAS) is able to fulfill its requirements under uncertain, ever-changing environmental conditions. Indeed, this process of self-organization (SO) is of utmost importance for the ability of the CAS to perform. However, it is hard to design high-performing SO mechanisms, because the environmental conditions are partially unpredictable at design time. Thus, a crucial aid for the development of SO mechanisms is a tool set enabling performance evaluations at design time in order to select the best-fitting mechanism and parametrize it. We present a metric for measuring the performance of an SO mechanism as well as a framework that enables evaluation of this metric. The proposed metric is evaluated for different kinds of SO mechanisms in two case studies: a smart energy management system and a self-organizing production cell."
SPRINGERLINK,Chapter,2018,Test Case Generation with PathCrawler/LTest: How to Automate an Industrial Testing Process,Sébastien BardinNikolai KosmatovBruno MarreDavid MentréNicky Williams,,10,"Automatic white-box testing based on formal methods is now a relatively mature technology and operational tools are available. Despite this, and the cost of manual testing, the technology is still rarely applied in an industrial setting. This paper describes how the specific needs of the user can be taken into account in order to build the necessary interface with a generic test tool. We present P ath C rawler /LT est , a generator of test inputs for structural coverage of C functions, recently extended to support labels. Labels offer a generic mechanism for specification of code coverage criteria and make it possible to prototype and implement new criteria for specific industrial needs. We describe the essential participation of the research branch of an industrial user in bridging the gap between the tool developers and their business unit and adapting P ath C rawler /LT est to the needs of the latter. We present the excellent results so far of their ongoing adoption and finish by mentioning possible improvements."
SPRINGERLINK,Chapter,2018,Effective Analysis of Attack Trees: A Model-Driven Approach,Rajesh KumarStefano SchivoEnno RuijtersBuǧra Mehmet YildizDavid HuistraJacco BrandtArend RensinkMariëlle Stoelinga,,10,"Attack trees (ATs) are a popular formalism for security analysis, and numerous variations and tools have been developed around them. These were mostly developed independently, and offer little interoperability or ability to combine various AT features. We present ATTop, a software bridging tool that enables automated analysis of ATs using a model-driven engineering approach. ATTop fulfills two purposes: 1. It facilitates interoperation between several AT analysis methodologies and resulting tools (e.g., ATE, ATCalc, ADTool 2.0), 2. it can perform a comprehensive analysis of attack trees by translating them into timed automata and analyzing them using the popular model checker Uppaal , and translating the analysis results back to the original ATs. Technically, our approach uses various metamodels to provide a unified description of AT variants. Based on these metamodels, we perform model transformations that allow to apply various analysis methods to an AT and trace the results back to the AT domain. We illustrate our approach on the basis of a case study from the AT literature."
SPRINGERLINK,Chapter,2018,Design-Time to Run-Time Verification of Microservices Based Applications,Matteo CamilliCarlo BellettiniLorenzo Capra,"Cloud applications, Formal methods @ runtime, Formal verification, Microservices, Petri nets",10,"Microservice based architectures have started to gain in popularity and are often adopted in the implementation of modern cloud, IoT, and large-scale distributed applications. Software life cycles, in this context, are characterized by short iterations, where several updates and new functionalities are continuously integrated many times a day. This paradigm shift calls for new formal approaches to systematic verification and testing of applications in production infrastructures. We introduce an approach to continuous, design- to run-time verification , of microservice based applications. This paper describes our envisioned approach, the current stage of this ongoing work, and the challenges ahead."
SPRINGERLINK,Chapter,2018,xR-Based Systems for Mindfulness Based Training in Clinical Settings,Mark R. CostaDessa Bergen-CicoRocio HererroJessica NavarroRachel RazzaQiu Wang,"Meditation, Mindfulness, Mixed reality, Virtual reality, Wellness",10,"Chronic and acute stress are persistent and troubling health concerns for many people and military veterans in particular. Clinicians are increasingly turning to mindfulness techniques to provide people with the skills they need to self-manage that stress. However, training and getting people to adhere to the practice is difficult. In this paper, we talk about a virtual reality based system designed specifically to help veterans learn mindfulness-based stress reduction techniques."
SPRINGERLINK,Chapter,2018,Design Approaches for Critical Embedded Systems: A Systematic Mapping Study,Daniel FeitosaApostolos AmpatzoglouParis AvgeriouFrank J. AffonsoHugo AndradeKatia R. FelizardoElisa Y. Nakagawa,"Critical embedded system, Design, Systematic mapping study",10,"Critical Embedded Systems (CES) are systems in which failures are potentially catastrophic and, therefore, hard constraints are imposed on them. In the last years the amount of software accommodated within CES has considerably changed. For example, in smart cars the amount of software has grown about 100 times compared to previous years. This change means that software design for these systems is also bounded to hard constraints (e.g., high security and performance). Along the evolution of CES, the approaches for designing them are also changing rapidly, so as to fit the specialized needs of CES. Thus, a broad understanding of such approaches is missing. Therefore, this study aims to establish a fair overview on CESs design approaches. For that, we conducted a Systematic Mapping Study (SMS), in which we collected 1,673 papers from five digital libraries, filtered 269 primary studies, and analyzed five facets: design approaches, applications domains, critical quality attributes, tools, and type of evidence. Our findings show that the body of knowledge is vast and overlaps with other types of systems (e.g., real-time or cyber-physical systems). In addition, we have observed that some critical quality attributes are common among various application domains, as well as approaches and tools are oftentimes generic to CES."
SPRINGERLINK,Chapter,2018,Using a Formal B Model at Runtime in a Demonstration of the ETCS Hybrid Level 3 Concept with Real Trains,Dominik HansenMichael LeuschelDavid SchneiderSebastian KringsPhilipp KörnerThomas NaulinNader NayeriFrank Skowron,"Animation, B-method, ETCS, Model-based testing",10,"In this article, we present a concrete realisation of the ETCS Hybrid Level 3 concept, whose practical viability was evaluated in a field demonstration in 2017. Hybrid Level 3 (HL3) introduces Virtual Sub-Sections (VSS) as sub-divisions of classical track sections with Trackside Train Detection (TTD). Our approach introduces an add-on for the Radio Block Centre (RBC) of Thales, called Virtual Block Function (VBF), which computes the occupation states of the VSSs according to the HL3 concept using the train position reports, train integrity information, and the TTD occupation states. From the perspective of the RBC, the VBF behaves as an Interlocking (IXL) that transmits all signal aspects for virtual signals introduced for each VSS to the RBC. We report on the development of the VBF, implemented as a formal B model executed at runtime using ProB and successfully used in a field demonstration to control real trains."
SPRINGERLINK,Chapter,2018,Robotics and Integrated Formal Methods: Necessity Meets Opportunity,Marie FarrellMatt LuckcuckMichael Fisher,"Agent Programming Language, Probabilistic Temporal Logic (PTL), Robot Swarm, Robotic Systems, Safety Case",10,"Robotic systems are multi-dimensional entities, combining both hardware and software, that are heavily dependent on, and influenced by, interactions with the real world. They can be variously categorised as embedded, cyber-physical, real-time, hybrid, adaptive and even autonomous systems, with a typical robotic system being likely to contain all of these aspects. The techniques for developing and verifying each of these system varieties are often quite distinct. This, together with the sheer complexity of robotic systems, leads us to argue that diverse formal techniques must be integrated in order to develop, verify, and provide certification evidence for, robotic systems. Furthermore, we propose the fast evolving field of robotics as an ideal catalyst for the advancement of integrated formal methods research, helping to drive the field in new and exciting directions and shedding light on the development of large-scale, dynamic, complex systems."
SPRINGERLINK,Chapter,2018,Android Stack Machine,Taolue ChenJinlong HeFu SongGuozhen WangZhilin WuJun Yan,,10,"In this paper, we propose Android Stack Machine (ASM), a formal model to capture key mechanisms of Android multi-tasking such as activities, back stacks, launch modes, as well as task affinities. The model is based on pushdown systems with multiple stacks, and focuses on the evolution of the back stack of the Android system when interacting with activities carrying specific launch modes and task affinities. For formal analysis, we study the reachability problem of ASM. While the general problem is shown to be undecidable, we identify expressive fragments for which various verification techniques for pushdown systems or their extensions are harnessed to show decidability of the problem."
SPRINGERLINK,Chapter,2018,Foundation of a Framework to Support Compliance Checking in Construction Industry,Wuwei ShenGuangyuan LiChung-Ling LinHongliang Liang,"Class diagram, Compliance checking, Conformance checking, Instance diagram, International codes",10,"Computer use is pervasive in our daily life and the increasing demand for computer applications has penetrated into various domains. Construction industry has become one of domains which are more reliable on the application of computer to implement regulatory compliance checking. Like many safety critical domains, the construction domain has its own set of international building codes on construction projects which must comply with. With the increasing complexity of construction projects, many manual compliance checking techniques have shown some serious issues. First, the manual techniques are error-prone due to human errors. Second, the complexity of a construction project exceeds the human limit to deal with. Third, the evolution of a construction project is inevitable and the human maintenance of a construction project is almost impossible because either the memory of the original project design has faked away or some development team members are gone. So, it has become a new trend to employ computers to support automatic regulatory compliance checking in construction industry. In this paper, we propose a novel framework to support compliance checking with the emphasis on the foundation of automatic regulatory compliance checking to certify whether a construction project complies with some international building codes. An example is illustrated how compliance checking is performed in the framework."
SPRINGERLINK,Chapter,2018,Towards a Runtime Verification Approach for Internet of Things Systems,Maurizio LeottaDavide AnconaLuca FranceschiniDario OlianasMarina RibaudoFilippo Ricca,"Input Scenarios, Mobile Health, Runtime Veriﬁcation, Things Systems, Trace Expression",10,"Internet of Things systems are evolving at a rapid pace and their impact on our society grows every day. In this context developing IoT systems that are reliable and compliant with the requirements is of paramount importance. Unfortunately, few proposals for assuring the quality of these complex and often safety-critical systems are present in the literature. To this aim, runtime verification can be a valuable support to tackle such a complex task and to complement other software verification techniques based on static analysis and testing. This paper is a first step towards the application of runtime verification to IoT systems. In particular, we describe our approach based on a Prolog monitor, the definition of a formal specification (using trace expressions) describing the expected behaviour of the system, and the definition of appropriate input scenarios. Furthermore, we describe its application and preliminary evaluation using a simplified mobile health IoT system for the management of diabetic patients composed by sensors, actuators, Node-RED logic on the cloud, and smartphones."
SPRINGERLINK,Chapter,2018,Generative Model Driven Design for Agile System Design and Evolution: A Tale of Two Worlds,Tiziana Margaria,,10,"In order to mainstream the production and evolution of IT at the levels of speed, scale, affordability and collaborative effort needed to truly make IT enter the fabric of every economical and societal endeavour, as is the projected future of our society in the next decade, the ease of learning, understanding, and applying new disruptive technologies must drastically improve. We argue that the needs of the people, the economical sectors, and the large-scale trends can only be met if the IT professions embrace and adopt a new way of producing and consuming IT, based on more formal descriptions, more models, more reasoning and analysis before expensive implementations are incurred, coupled with automatic transformations, generations, and analyses that take advantage of the models and formalized knowledge. We analyse briefly the various dimensions, derive a specification for the new IT and IT platforms, and provide a few examples of how the new thinking can disrupt the status quo but empower a better understanding, a more efficient organization, and a more automatic management of the many cross-dimensional issues that future connected software and systems will depend upon."
SPRINGERLINK,Chapter,2018,Using Abstraction with Interaction Sequences for Interactive System Modelling,Jessica TurnerJudy BowenSteve Reeves,"Formal methods, Interaction sequences, Interactive system testing",10,"Interaction sequences can be used as an abstraction of an interactive system. We can use such models to consider or verify properties of a system for testing purposes. However, interaction sequences have the potential to become unfeasibly long, leading to models which are intractable. We propose a method of reducing the state space of such sequences using the self-containment property. This allows us to hide (and subsequently expand) some of the model describing parts of the system not currently under consideration. Interaction sequences and their models can therefore be used to control the state space size of the models we create as an abstraction of an interactive system."
SPRINGERLINK,Chapter,2018,A Vision for Enhancing Security of Cryptography in Executables,Otto BrechelmacherWillibald KrennThorsten Tarrach,"Binary Rewriting, Crypto Functions, DynamoRIO, Runtime Manipulation, Symbolic Analysis Framework",10,"This paper proposes an idea on how to use existing techniques from late stage software customization to improve the security of software employing cryptographic functions. In our vision, we can verify an implemented algorithm and replace it with a faster or more trusted implementation if necessary. We also want to be able to add encryption to binaries that currently do not employ any, or gain access to unencrypted data if an application depends on encryption. To corroborate the feasibility of our vision, we developed a prototype that is able to identify cryptographic functions in highly optimized binary code and tests the identified functions for functional correctness, potentially also revealing backdoors."
SPRINGERLINK,Chapter,2018,Lightweight Verifiable Auditing for Outsourced Database in Cloud Computing,Mayank KumarSyam Kumar Pasupuleti,"Cloud computing, Database, Embedded Merkle B tree, Lightweight homomorhic encryption",10,"Database outsourcing in Cloud Computing enables the data owner to store the data on cloud and assign the management to a cloud service provider (CSP), which provides various cloud services to the users. However, outsourcing database to cloud poses many challenges. One of the major concerns is confidentiality of the data. The general approach to tackle this issue is by encrypting the database before outsourcing, this helps in protecting confidentiality but poses a new problem of verifying the search results. We propose a lightweight verifiable auditing scheme for secure outsourcing of database, which encrypts the database and verifies search results with both parameters of correctness and completeness. We design our scheme based on a lightweight homomorphic encryption scheme (LHE) and efficient authenticated data structures to ensure the confidentiality and integrity of the database respectively."
SPRINGERLINK,Chapter,2017,A Model-Based Testing Method for Dynamic Aspect-Oriented Software,Maria Laura Pires SouzaFábio Fagundes Silveira,"Dynamic aspect-oriented, Model-based testing, Mutation testing",10,"Aspect-oriented programming (AOP) is used to implement crosscutting concerns such as persistence and safety in program units called aspects. To ensure that these concerns behave as specified and do not introduce faults into the application, rigorous software testing practices should be applied. Even though there are statements in the literature that the adoption of AOP takes a software to get better quality, it does not provide correctness by itself. Therefore, the test remains an important activity to ensure aspects are correctly integrated into the main system. Additionally, in a dynamic environment: new aspects may be incompatible with aspects already woven; and aspects to be removed can hold the system to an inconsistent state. Available approaches in the literature do not directly investigate the problem of testing dynamic aspects within the context of a target application. This paper presents a method to apply tests in dynamic aspects that verify the interactions between aspects and classes, as well as among aspects. Aiming to support the method, we also introduce a model to represent the dynamic behavior of aspects and a new strategy to derive testing cases. To evaluate the effectiveness of the test cases generated by the method, mutation operators were applied to the model and simulated with a model checker. Results showed that the approach is capable of detecting faults in dynamic aspects interactions into a target application."
SPRINGERLINK,Chapter,2017,Model-Based Testing for Asynchronous Systems,Alexander Graf-BrillHolger Hermanns,,10,"Model-based testing is a prominent validation technique, integrating well with other formal approaches to verification, such as model checking. Automated test derivation and execution approaches often struggle with asynchrony in communication between the implementation under test (IUT) and tester, a phenomenon present in most networked systems. Earlier attacks on this problem came with different restrictions on the specification model side. This paper presents a new and effective approach to model-based testing under asynchrony. By waiving the need to guess the possible output state of the IUT, we reduce the computational effort of the test generation algorithm while preserving soundness and conceptual completeness of the testing procedures. In addition, no restrictions on the specification model need to be imposed. We define a suitable conformance relation and we report on empirical results obtained from an industrial case study from the domain of electric mobility."
SPRINGERLINK,Chapter,2017,WSCLim: A Tool for Model-Based Testing of WS-BPEL Compositions Under Load Conditions,Afef Jmal MaâlejMoez KrichenMohamed Jmaïel,"Load testing, Log analysis, Performance monitoring, Timed Automata, Web services composition",10,"Web services compositions must provide different utilities to hundreds even thousands of users simultaneously. An important challenge of testing these applications is load testing. For this purpose, we proposed in a previous work a test architecture aiming to study the limitations of WS-BPEL compositions under load conditions. We also concretized our solution by implementing a tool support (WSCLim). We introduce in this paper a case study on Hospital Blood Ordering for Transfusion Purposes in order to best illustrate our solution."
SPRINGERLINK,Chapter,2017,Learning-Based Testing for Safety Critical Automotive Applications,Hojat KhosrowjerdiKarl MeinkeAndreas Rasmusson,"Automotive software, Black-box testing, Learning-based testing, Machine learning, Model-based testing, Requirements testing, Temporal logic",10,"Learning-based testing (LBT) is an emerging paradigm for fully automated requirements testing. This approach combines machine learning and model-checking techniques for test case generation and verdict construction. LBT is well suited to requirements testing of low-latency safety critical embedded systems, such as can be found in the automotive sector. We evaluate the feasibility and effectiveness of applying LBT to two safety critical industrial automotive applications. We also benchmark our LBT tool against an existing industrial test tool that executes manually written test cases."
SPRINGERLINK,Chapter,2017,Fault-Based Testing for Refinement in CSP,Ana CavalcantiAdenilso Simao,,10,"The process algebra CSP has been studied as a modeling notation for test derivation. Work has been developed using its trace and failure semantics, and their refinement notions as conformance relations. In this paper, we propose a procedure for online test generation for selection of finite test sets for traces refinement from CSP models, based on the notion of fault domains, that is, focusing on the set of faulty implementations of interest. We investigate scenarios where the verdict of a test campaign can be reached after a finite number of test executions. We illustrate the usage of the procedure with a small case study."
SPRINGERLINK,Chapter,2017,Learning-Based Testing the Sliding Window Behavior of TCP Implementations,Paul Fiterău-BroşteanFalk Howar,"Learning-based Testing, Register Automata, System Under Test (SUT), Tree Oracle, Window Behavior",10,"We develop a learning-based testing framework for register automaton models that can express the windowing behavior of TCP, thereby presenting the first significant application of register automata learning to realistic software for a class of automata with Boolean-arithmetic constraints over data values. We have applied our framework to TCP implementations belonging to different operating systems and have found a violation of the TCP specification in Linux and Windows. The violation has been confirmed by Linux developers."
SPRINGERLINK,Chapter,2017,Learning-Based Testing of Cyber-Physical Systems-of-Systems: A Platooning Study,Karl Meinke,"Cyber-physical system, Learning-based testing, Machine learning, Model-based testing, Platooning, Requirements testing, System-of-systems",10,"Learning-based testing (LBT) is a paradigm for fully automated requirements testing that combines machine learning with model-checking techniques. LBT has been shown to be effective for unit and integration testing of safety critical components in cyber-physical systems, e.g. automotive ECU software. We consider the challenges faced, and some initial results obtained in an effort to scale up LBT to testing co-operative open cyber-physical systems-of-systems (CO-CPS). For this we focus on a case study of testing safety and performance properties of multi-vehicle platoons."
SPRINGERLINK,Chapter,2017,A Comparative Study of Software Testing Techniques,Meriem AtifiAbdelaziz MamouniAbdelaziz Marzak,"Model-based testing, Risk-based testing, Software systems, Software testing, Software testing approaches",10,"Nowadays, software systems have become an essential element in our daily life. To ensure the quality and operation of software, testing activities have become primordial in the software development life cycle (SDLC). Indeed, software bugs can potentially cause dramatic consequences if the product is released to the end user without testing. The software testing role is to verify that the actual result and the expected result are consistent and ensure that the system is delivered without bugs. Many techniques, approaches and tools have been proposed to help check that the system is defect free. In this paper, we highlight two software testing techniques considered among the most used techniques to perform software tests, and then we perform a comparative study of these techniques, the approaches that supports studied techniques, and the tools used for each technique. We have selected the first technique based on the 2014 survey [ 62 ] that heighted the motivations for using the Model-based-testing, and by analyzing the survey results we have found that some MBT limits are benefits in Risk based testing, the second technique in our study."
SPRINGERLINK,Chapter,2017,Security of Web Application: State of the Art,Habib ur RehmanMohammed NazirKhurram Mustafa,"Security testing approaches, Security testing limitations, Testing in industrial practices, Testing techniques, Web application security, Web testing",10,"As complexity inherent in web application is growing rapidly. Testing web applications with more sophisticated approaches is essentially needed. Several approaches for security testing are available, but only a few of them are appreciated in common IT industries and hence in practice. The paper recapitulates the current approaches, considering the limitations of real world applications. An effort has been made in the direction of bridging the gaps with the study of foremost web security concerns and the current web testing techniques, including their strengths and weaknesses. The paper highlights the security issues pertinent to web applications, along with actual practices in industries related to these issues. It also includes gap between practices and theories in the industry."
SPRINGERLINK,Chapter,2017,How is Security Testing Done in Agile Teams? A Cross-Case Analysis of Four Software Teams,Daniela Soares CruzesMichael FeldererTosin Daniel OyetoyanMatthias GanderIrdin Pekaric,"Agile testing, Case study research, Security testing",10,"Security testing can broadly be described as (1) the testing of security requirements that concerns confidentiality, integrity, availability, authentication, authorization, nonrepudiation and (2) the testing of the software to validate how much it can withstand an attack. Agile testing involves immediately integrating changes into the main system, continuously testing all changes and updating test cases to be able to run a regression test at any time to verify that changes have not broken existing functionality. Software companies have a challenge to systematically apply security testing in their processes nowadays. There is a lack of guidelines in practice as well as empirical studies in real-world projects on agile security testing; industry in general needs a more systematic approach to security. The findings of this research are not surprising, but at the same time are alarming. The lack of knowledge on security by agile teams in general, the large dependency on incidental pen-testers, and the ignorance in static testing for security are indicators that security testing is highly under addressed and that more efforts should be addressed to security testing in agile teams."
SPRINGERLINK,Chapter,2017,A Survey on Testing Distributed and Heterogeneous Systems: The State of the Practice,Bruno LimaJoão Pascoal Faria,"Distributed systems, Heterogeneous systems, Software testing, State of the practice, Systems of systems",10,"Distributed and heterogeneous systems (DHS), running over interconnected mobile and cloud-based platforms, are used in a growing number of domains for provisioning end-to-end services to users. Testing DHS is particularly important and challenging, with little support being provided by current tools. In order to assess the current state of the practice regarding the testing of DHS and identify opportunities and priorities for research and innovation initiatives, we conducted an exploratory survey that was responded by 147 software testing professionals that attended industry-oriented software testing conferences. The survey allowed us to assess the relevance of DHS in software testing practice, the most important features to be tested in DHS, the current status of test automation and tool sourcing for testing DHS, and the most desired features in test automation solutions for DHS. Some follow up interviews allowed us to further investigate drivers and barriers for DHS test automation. We expect that the results presented in the paper are of interest to researchers, tool vendors and service providers in this field."
SPRINGERLINK,Chapter,2017,Exploratory Testing of Large-Scale Systems – Testing in the Continuous Integration and Delivery Pipeline,Torvald MårtenssonDaniel StåhlJan Bosch,"Continuous delivery, Continuous integration, Exploratory testing, Large-scale systems, Software testing",10,"In this paper, we show how exploratory testing plays a role as part of a continuous integration and delivery pipeline for large-scale and complex software products. We propose a test method that incorporates exploratory testing as an activity in the continuous integration and delivery pipeline, and is based on elements from other testing techniques such as scenario-based testing, testing in teams and testing in time-boxed sessions. The test method has been validated during ten months by 28 individuals (21 engineers and 7 flight test pilots) in a case study where the system under test is a fighter aircraft. Quantitative data from the case study company shows that the exploratory test teams produced more problem reports than other test teams. The interview results show that both engineers and test pilots were generally positive or very positive when they described their experiences from the case study, and consider the test method to be an efficient way of testing the system in the case study."
SPRINGERLINK,Chapter,2017,Test Case/Step Minimization for Visual Programming Language Models and Its Application to Space Systems,Paulo Nolberto dos Santos AlarconValdivino Alexandre de Santiago Júnior,"Model Checking, Model-Based Testing, Specification patterns, Test case/step minimization",10,"Visual Programming Languages have been widely used in the context of Model-Based Development, and they find a particular appeal for the design of satellite subsystems, such as the Attitude and Orbit Control Subsystem (AOCS) which is an extremely complex part of a spacecraft. The software testing community has been trying to ensure high quality products with as few defects as possible. Given that exhaustive generation and execution of software test cases are unfeasible in practice, one of the initiatives is to reduce the sets of test cases required to test a Software/System Under Test, while still maintaining the efficiency (ability to find product defects, code coverage). This paper presents a new methodology to generate test cases for Visual Programming Language models, aiming at minimizing the set of test cases/steps but maintaining efficiency. The approach, called specification Patterns, modified Condition/Decision coverage, and formal Verification to support Testing (PCDVT), combines the Modified Decision/Condition Coverage (MC/DC) criterion, Model Checking, specification patterns, and a minimization approach by identifying irreplaceable tests in a single method, taking advantage of the benefits of all these efforts in a unified strategy. Results showed that two instances of PCDVT presented a lower cost (smaller number of test steps) and, basically, the same efficiency (model coverage) if compared with a specialist ad hoc approach. We used the AOCS model of a Brazilian satellite in order to make the comparison between the methods."
SPRINGERLINK,Chapter,2017,Design Decisions in the Development of a Graphical Language for Risk-Driven Security Testing,Gencer ErdoganKetil Stølen,"Domain-specific modeling language, Model-based testing, Risk-driven security testing, Security risk assessment",10,"We have developed a domain-specific modeling language named CORAL that employs risk assessment to help security testers select and design test cases based on the available risk picture. In this paper, we present CORAL and then discuss why the language is designed the way it is, and what we could have done differently."
SPRINGERLINK,Chapter,2017,Formal Verification of Financial Algorithms,Grant Olney PassmoreDenis Ignatovich,,10,"Many deep issues plaguing today’s financial markets are symptoms of a fundamental problem: The complexity of algorithms underlying modern finance has significantly outpaced the power of traditional tools used to design and regulate them. At Aesthetic Integration, we have pioneered the use of formal verification for analysing the safety and fairness of financial algorithms. With a focus on financial infrastructure (e.g., the matching logics of exchanges and dark pools and FIX connectivity between trading systems), we describe the landscape, and illustrate our Imandra formal verification system on a number of real-world examples. We sketch many open problems and future directions along the way."
SPRINGERLINK,Chapter,2017,An Approach for Isolated Testing of Self-Organization Algorithms,Benedikt EberhardingerGerrit AndersHella SeebachFlorian SiefertAlexander KnappWolfgang Reif,"Adaptive systems, Quality assurance, Self-organization algorithms, Self-organizing systems, Software engineering, Software test",10,"We provide a systematic approach for testing self-organization (SO) algorithms. The main challenges for such a testing domain are the strongly ramified state space, the possible error masking, the interleaving of mechanisms, and the oracle problem resulting from the main characteristics of SO algorithms: their inherent non-deterministic behavior on the one hand, and their dynamic environment on the other. A key to success for our SO algorithm testing framework is automation, since it is rarely possible to cope with the ramified state space manually. The test automation is based on a model-based testing approach where probabilistic environment profiles are used to derive test cases that are performed and evaluated on isolated SO algorithms. Besides isolation, we are able to achieve representative test results with respect to a specific application. For illustration purposes, we apply the concepts of our framework to partitioning-based SO algorithms and provide an evaluation in the context of an existing smart-grid application."
SPRINGERLINK,Chapter,2017,Mutation Analysis of Stateflow to Improve the Modelling Analysis,Prachi GoyalManju NandaJ. Jayanthi,"Formal methods, Mutation analysis, Safety critical systems, Stateflow integration",10,Formal methods possess great analyzing capability that has led to an increasing use by engineers in the development and verification-validation life-cycle of hardware and software critical systems. Mutation Analysis has been very effective in model design and safety analysis. In this paper primary idea is to integrate the mutation analysis of stateflow to the Integrated Mutation Analysis Tool. This enhanced property of the IMAT tool after integration will be able to analyze the functionalities of stateflow models of the highly critical systems. The effectiveness of the Stateflow mutation analysis can be validated using the case-study of Autopilot Mode Transition Logic.
SPRINGERLINK,Chapter,2017,Should We Learn Probabilistic Models for Model Checking? A New Approach and An Empirical Study,Jingyi WangJun SunQixia YuanJun Pang,"Genetic algorithm, Model learning, Probabilistic model checking",10,"Many automated system analysis techniques (e.g., model checking, model-based testing) rely on first obtaining a model of the system under analysis. System modeling is often done manually, which is often considered as a hindrance to adopt model-based system analysis and development techniques. To overcome this problem, researchers have proposed to automatically “learn” models based on sample system executions and shown that the learned models can be useful sometimes. There are however many questions to be answered. For instance, how much shall we generalize from the observed samples and how fast would learning converge? Or, would the analysis result based on the learned model be more accurate than the estimation we could have obtained by sampling many system executions within the same amount of time? In this work, we investigate existing algorithms for learning probabilistic models for model checking, propose an evolution-based approach for better controlling the degree of generalization and conduct an empirical study in order to answer the questions. One of our findings is that the effectiveness of learning may sometimes be limited."
SPRINGERLINK,Chapter,2017,Hardness of Deriving Invertible Sequences from Finite State Machines,Robert M. HieronsMohammad Reza MousaviMichael Kirkedal ThomsenUraz Cengiz Türker,"Finite Automaton, Finite State Machine, Generate Test Case, Input Sequence, System Under Test",10,"Many test generation algorithms use unique input/output sequences (UIOs) that identify states of the finite state machine specification M . However, it is known that UIO checking the existence of UIO sequences is PSPACE-complete. As a result, some UIO generation algorithms utilise what are called invertible sequences; these allow one to construct additional UIOs once a UIO has been found. We consider three optimisation problems associated with invertible sequences: deciding whether there is a (proper) invertible sequence of length at least K ; deciding whether there is a set of invertible sequences for state set $$S'$$ that contains at most K input sequences; and deciding whether there is a single input sequence that defines invertible sequences that take state set $$S''$$ to state set $$S'$$ . We prove that the first two problems are NP-complete and the third is PSPACE-complete. These results imply that we should investigate heuristics for these problems."
SPRINGERLINK,Chapter,2017,From Passive to Active FSM Inference via Checking Sequence Construction,Alexandre PetrenkoFlorent AvellanedaRoland GrozCatherine Oriat,"Active learning, Checking experiments, Checking sequences, FSM testing, Machine identification, Machine inference",10,"The paper focuses on the problems of passive and active FSM inference as well as checking sequence generation. We consider the setting where an FSM cannot be reset so that its inference is constrained to a single trace either given a priori in passive inference scenario or to be constructed in active inference scenario or aiming at obtaining checking sequence for a given FSM. In each of the last two cases, the expected result is a trace representing a checking sequence for an inferred machine, if it was not given. We demonstrate that this can be achieved by a repetitive use of a procedure that infers an FSM from a given trace (identifying a minimal machine consistent with a trace) avoiding equivalent conjectures. We thus show that FSM inference and checking sequence construction can be seen as two sides of the same coin. Following an existing approach of constructing conjectures by SAT solving, we elaborate first such a procedure and then based on it the methods for obtaining checking sequence for a given FSM and inferring a machine from a black box. The novelty of our approach is that it does not use any state identification facilities. We only assume that we know initially the input set and a bound on the number of states of the machine. Experiments with a prototype implementation of the developed approach using as a backend an existing SAT solver indicate that it scales for FSMs with up to a dozen of states and requires relatively short sequences to identify the machine."
SPRINGERLINK,Chapter,2017,Multiple Mutation Testing from Finite State Machines with Symbolic Inputs,Omer Nguena TimoAlexandre PetrenkoS. Ramesh,"Conformance testing, Constraint solving, Extended FSM, Fault model-based test generation, Mutation testing fault modelling, Symbolic inputs",10,"Recently, we proposed a mutation-testing approach from a classical finite state machine (FSM) for detecting nonconforming mutants in a given fault domain specified with a so-called mutation machine. In this paper, we lift this approach to a particular type of extended finite state machines called symbolic input finite state machine (SIFSM), where transitions are labeled with symbolic inputs, which are predicates on input variables possibly having infinite domains. We define a well-formed mutation SIFSM for describing various types of faults. Given a mutation SIFSM, we develop a method for evaluating the adequacy of a test suite and a method for generating tests detecting all nonconforming mutants. Experimental results with the prototype tool we have developed indicate that the approach is applicable to industrial-like systems."
SPRINGERLINK,Chapter,2017,Challenges in Composing and Decomposing Assurances for Self-Adaptive Systems,Bradley SchmerlJesper AnderssonThomas VogelMyra B. CohenCecilia M. F. RubiraYuriy BrunAlessandra GorlaFranco ZambonelliLuciano Baresi,"Assurance Case, Goal Structuring Notation (GSN), Response Time Goals, Safety Case, Self-adaptive Systems",10,"Self-adaptive software systems adapt to changes in the environment, in the system itself, in their requirements, or in their business objectives. Typically, these systems attempt to maintain system goals at run time and often provide assurance that they will meet their goals under dynamic and uncertain circumstances. While significant research has focused on ways to engineer self-adaptive capabilities into both new and legacy software systems, less work has been conducted on how to assure that self-adaptation maintains system goals. For traditional, especially safety-critical software systems, assurance techniques decompose assurances into sub-goals and evidence that can be provided by parts of the system. Existing approaches also exist for composing assurances, in terms of composing multiple goals and composing assurances in systems of systems. While some of these techniques may be applied to self-adaptive systems, we argue that several significant challenges remain in applying them to self-adaptive systems in this chapter. We discuss how existing assurance techniques can be applied to composing and decomposing assurances for self-adaptive systems, highlight the challenges in applying them, summarize existing research to address some of these challenges, and identify gaps and opportunities to be addressed by future research."
SPRINGERLINK,Chapter,2017,Supporting the Integration of New Security Features in Embedded Control Devices Through the Digitalization of Production,Tobias RauterJohannes IberMichael KrisperChristian Kreiner,,10,"Security is a vital property of Industrial Control Systems (ICS), especially in the context of critical infrastructure. In this work, we focus on distributed control devices for hydro-electric power plants. Much work has been done for specific lifecylce phases of distributed control devices such as development or operational phase. Our aim here is to consider the entire product lifecycle and the consequences of security feature implementations for a single lifecycle stage on other stages. At the same time, recent trends such as the digitization of production is an enabler of production process extensions that support the integration of such security features during the operational phase of a control devices. In particular, we propose a security concept that enables assurance of the integrity of software components and product configuration of other control devices in the same network. Moreover, we show how these concepts result in additional requirements for the production stages. We show how we meet these requirements and focus on a production process by extending previously proposed methods that enable the commissioning of secrets such as private keys during the manufacturing phase. We extend this process by extracting information about the configurations of the actually produced devices during production. Based on this information, the proposed security techniques can be integrated without considerable overhead for bootstrapping."
SPRINGERLINK,Chapter,2017,SysML to NuSMV Model Transformation via Object-Orientation,Georgiana CaltaisFlorian Leitner-FischerStefan LeueJannis  Weiser,,10,This paper proposes a transformation of SysML models into the NuSMV input language. The transformation is performed automatically using SysMV-Ja and relies on a notion of intermediate model structuring the relevant SysML components in an object-oriented fashion.
SPRINGERLINK,Chapter,2017,Event-Based Runtime Verification of Temporal Properties Using Time Basic Petri Nets,Matteo CamilliAngelo GargantiniPatrizia ScandurraCarlo Bellettini,"Formal methods @ runtime, Petri nets, Runtime verification, Temporal properties, Timing analysis",10,"We introduce a formal framework to provide an efficient event-based monitoring technique, and we describe its current implementation as the MahaRAJA software tool. The framework enables the quantitative runtime verification of temporal properties extracted from occurring events on Java programs. The monitor continuously evaluates the conformance of the concrete implementation with respect to its formal specification given in terms of Time Basic Petri nets, a particular timed extension of Petri nets. The system under test is instrumented by using simple Java annotations on methods to link the implementation to its formal model. This allows a separation between implementation and specification that can be used for other purposes such as formal verification, simulation, and model-based testing. The tool has been successfully used to monitor at runtime and test a number of benchmarking case-studies. Experiments show that our approach introduces bounded overhead and effectively reduces the involvement of the monitor at run time by using negligible auxiliary memory. A comparison with a number of state-of-the-art runtime verification tools is also presented."
SPRINGERLINK,Chapter,2017,Abstraction Refinement for the Analysis of Software Product Lines,Ferruccio DamianiReiner HähnleMichael Lienhardt,,10,"We generalize the principle of counter example-guided data abstraction refinement (CEGAR) to guided refinement of Software Product Lines (SPL) and of analysis tools. We also add a problem decomposition step. The result is a framework for formal SPL analysis via guided refinement and divide-and-conquer, through sound orchestration of multiple tools."
SPRINGERLINK,Chapter,2017,A New Evolutionary Algorithm for Synchronization,Jakub KowalskiAdam Roman,"Automata synchronization, Genetic algorithm, Knowledge-based evolution",10,"A synchronizing word brings all states of a finite automaton to the one particular state. From practical reasons the synchronizing words should be as short as possible. Unfortunately, the decision version of the problem is NP-complete. In this paper we present a new evolutionary approach for finding possibly short synchronizing words for a given automaton. As the optimization problem has two contradicting goals (the word’s length and the word’s rank) we use a 2 population feasible-infeasible approach. It is based on the knowledge on words’ ranks of all prefixes of a given word. This knowledge makes the genetic operators more efficient than in case of the standard letter-based operators."
SPRINGERLINK,Chapter,2017,Test Suite Reduction in Idempotence Testing of Infrastructure as Code,Katsuhiko IkeshitaFuyuki IshikawaShinichi Honiden,,10,"Infrastructure as Code, which uses machine-processable code for managing, provisioning, and configuring computing infrastructure, has been attracting wide attention. In its application, the idempotence of the code is essential: the system should converge to the desired state even if the code is repeatedly executed possibly with failures or interruptions. Previous studies have used testing or static verification techniques to check whether the code is idempotent or not. The testing approach is impractically time-consuming, whereas the static verification approach is not applicable in many practical cases in which external scripts are used. In this paper, we present a method for efficiently checking idempotence by combining the testing and static verification approaches. The method dramatically decreases the number of test cases used to check code including external scripts by applying the static verification approach."
SPRINGERLINK,Chapter,2017,A Novel Learning Algorithm for Büchi Automata Based on Family of DFAs and Classification Trees,Yong LiYu-Fang ChenLijun ZhangDepeng Liu,"Buchi Automata (BA), Deterministic Finite Automaton (DFA), Observation Table, Solving Learning Tasks, Tree-structured Classification",10,"In this paper, we propose a novel algorithm to learn a Büchi automaton from a teacher who knows an $$\omega $$ -regular language. The algorithm is based on learning a formalism named family of DFAs (FDFAs) recently proposed by Angluin and Fisman [ 10 ]. The main catch is that we use a classification tree structure instead of the standard observation table structure. The worst case storage space required by our algorithm is quadratically better than the table-based algorithm proposed in [ 10 ]. We implement the first publicly available library ROLL (Regular Omega Language Learning), which consists of all $$\omega $$ -regular learning algorithms available in the literature and the new algorithms proposed in this paper. Experimental results show that our tree-based algorithms have the best performance among others regarding the number of solved learning tasks."
SPRINGERLINK,Chapter,2017,Asm2C++: A Tool for Code Generation from Abstract State Machines to Arduino,Silvia BonfantiMarco CarissoniAngelo GargantiniAtif Mashkoor,,10,"This paper presents Asm2C++ , a tool that automatically generates executable C++ code for Arduino from a formal specification given as Abstract State Machines (ASMs). The code generation process follows the model-driven engineering approach, where the code is obtained from a formal abstract model by applying certain transformation rules. The translation process is highly configurable in order to correctly integrate the underlying hardware. The advantage of the Asm2C++ tool is that it is part of the Asmeta framework that allows to analyze, verify, and validate the correctness of a formal model."
SPRINGERLINK,Chapter,2017,Towards a Model-Driven Security Assurance of Open Source Components,Irum RaufElena Troubitsyna,,10,"Open Source software is increasingly used in a wide spectrum of applications. While the benefits of the open source components are unquestionable now, there is a great concern over security assurance provided by such components. Often open source software is a subject of frequent updates. The updates might introduce or remove a diverse range of features and hence violate security properties of the previous releases. Obviously, a manual inspection of security would be prohibitively slow and inefficient. Therefore, there is a great demand for the techniques that would allow the developers to automate the process of security assurance in the presence of frequent releases. The problem of security assurance is especially challenging because to ensure scalability, such main open source initiatives, as OpenStack adopt RESTful architecture. This requires new security assurance techniques to cater to stateless nature of the system. In this paper, we propose a model-driven framework that would allow the designers to model the security concerns and facilitate verification and validation of them in an automated manner. It enables a regular monitoring of the security features even in the presence of frequent updates. We exemplify our approach with the Keystone component of OpenStack."
SPRINGERLINK,Chapter,2017,Formal Analysis of Predictable Data Flow in Fault-Tolerant Multicore Systems,Boris MadzarJalil BoudjadarJuergen DingelThomas E. FuhrmanS. Ramesh,,10,"The need to integrate large and complex functions into today’s vehicle electronic control systems requires high performance computing platforms, while at the same time the manufacturers try to reduce cost, power consumption and ensure safety. Traditionally, safety isolation and fault containment of software tasks have been achieved by either physically or temporally segregating them. This approach is reliable but inefficient in terms of processor utilization. Dynamic approaches that achieve better utilization without sacrificing safety isolation and fault containment appear to be of increasing interest. One of these approaches relies on predictable data flow introduced in PharOS and Giotto. In this paper, we extend the work on leveraging predictable data flow by addressing the problem of how the predictability of data flow can be proved formally for mixed criticality systems that run on multicore platforms and are subject to failures. We consider dynamic tasks where the timing attributes vary from one period to another. Our setting also allows for sporadic deadline overruns and accounts for criticality during fault handling. A user interface was created to allow automatic generation of the models as well as visualization of the analysis results, whereas predictability is verified using the Spin model checker."
SPRINGERLINK,Chapter,2016,Model-Based Testing as a Service for IoT Platforms,Abbas AhmadFabrice BouquetElizabeta FourneretFranck Le GallBruno Legeard,"Internet of Things, Model Based Testing, Standard compliance, Testing As A Service",10,"The Internet of Things (IoT) has increased its footprint becoming globally a ‘must have’ for today’s most innovative companies. Applications extend to multitude of domains, such as smart cities, healthcare, logistics, manufacturing, etc. Gartner Group estimates an increase up to 21 billion connected things by 2020. To manage ‘things’ heterogeneity and data streams over large scale and secured deployments, IoT and data platforms are becoming a central part of the IoT. To respond to this fast growing demand we see more and more platforms being developed, requiring systematic testing. Combining Model-Based Testing (MBT) technique and a service-oriented solution, we present Model-Based Testing As A Service (MBTAAS) for testing data and IoT platforms. In this paper, we present a first step towards MBTAAS for data and IoT Platforms, with experimentation on FIWARE, one of the EU most emerging IoT enabled platforms."
SPRINGERLINK,Chapter,2016,Model-Based Testing of Real-Time Distributed Systems,Jüri VainEvelin HallingGert KanterAivo AnierDeepak Pal,"Distributed systems, Low-latency systems, Model-based testing",10,"Modern financial systems have grown to the scale of global geographic distribution and latency requirements are measured in nanoseconds. Low-latency systems where reaction time is primary success factor and design consideration, are serious challenge to existing integration and system level testing techniques. While existing tools support prescribed input profiles they seldom provide enough reactivity to run the tests with simultaneous and interdependent input profiles at remote frontends. Additional complexities emerge due to severe timing constraints the tests have to meet when test navigation decision time ranges near the message propagation time. Sufficient timing conditions for remote online testing have been proven by Larsen et al. and implemented in $$\varDelta $$ Δ -testing method recently. We extend the $$\varDelta $$ Δ -testing by deploying testers on fully distributed test architecture. This approach reduces the test reaction time by almost a factor of two. We validate the method on a distributed time-sensitive global financial system case study."
SPRINGERLINK,Chapter,2016,Model-Based Testing of Probabilistic Systems,Marcus GerholdMariëlle Stoelinga,"False Rejection, Finite Path, Probabilistic Automaton, Statistical Hypothesis Testing, Trace Distribution",10,"This paper presents a model-based testing framework for probabilistic systems. We provide algorithms to generate, execute and evaluate test cases from a probabilistic requirements model. In doing so, we connect ioco -theory for model-based testing and statistical hypothesis testing: our ioco -style algorithms handle the functional aspects, while statistical methods, using $$\chi ^2$$ χ 2 tests and fitting functions, assess if the frequencies observed during test execution correspond to the probabilities specified in the requirements. Key results of our paper are the classical soundness and completeness properties, establishing the mathematical correctness of our framework; Soundness states that each test case is assigned the right verdict. Completeness states that the framework is powerful enough to discover each probabilistic deviation from the specification, with arbitrary precision. We illustrate the use of our framework via two case studies."
SPRINGERLINK,Chapter,2016,Evolving the ETSI Test Description Language,Philip MakedonskiGusztáv AdamisMartti KäärikFinn KristoffersenXavier Zeitoun,"Domain-specific modeling, Model-based testing, Test description language",10,"Increasing software and system complexity due to the integration of more and more diverse sub-systems presents new testing challenges. Standardisation and certification requirements in certain domains such as telecommunication, automotive, aerospace, and health-care contribute further challenges for testing systems operating in these domains. Consequently, there is a need for suitable methodologies, processes, languages, and tools to address these testing challenges. To address some of these challenges, the Test Description Language (TDL) has been developed at the European Telecommunications Standards Institute (ETSI) over the past three years. TDL bridges the gap between declarative test purposes and imperative test cases by offering a standardised language for the specification of test descriptions. TDL started as a standardised meta-model, subsequently enriched with a graphical syntax, exchange format, and a UML profile. A reference implementation of TDL has been developed as a common platform to accelerate the adoption of TDL and lower the barrier to entry for both end-users and tool-vendors. This article tells the story of the evolution of TDL from its conception."
SPRINGERLINK,Chapter,2016,Learning-Based Cross-Platform Conformance Testing,Johannes NeubauerBernhard Steffen,"Automata learning conformance testing, Higher-order test-block integration, User-level modeling",10,"In this paper we present learning-based cross-platform conformance testing (LCCT), an approach specifically designed to validate successful system migration. Key to our approach is the combination of (1) adequate user-level system abstraction, (2) higher-order integration of executable test-blocks, and (3) learning-based automatic model inference and comparison. The impact of LCCT will be illustrated along the migration of Springer’s Online Conference Service (OCS) from a browser-based implementation to using a RESTful web service API. Continuous LCCT allowed us in particular to systematically pinpoint spots where the original OCS depended on browser-based access control mechanisms, to eliminate them, and thus to maintain the OCS access control policy for the RESTFul API."
SPRINGERLINK,Chapter,2016,Systematic and Realistic Testing in Simulation of Control Code for Robots in Collaborative Human-Robot Interactions,Dejanira Araiza-IllanDavid WesternAnthony G. PipeKerstin Eder,,10,"Industries such as flexible manufacturing and home care will be transformed by the presence of robotic assistants. Assurance of safety and functional soundness for these robotic systems will require rigorous verification and validation. We propose testing in simulation using Coverage-Driven Verification (CDV) to guide the testing process in an automatic and systematic way. We use a two-tiered test generation approach, where abstract test sequences are computed first and then concretized (e.g., data and variables are instantiated), to reduce the complexity of the test generation problem. To demonstrate the effectiveness of our approach, we developed a testbench for robotic code, running in ROS-Gazebo, that implements an object handover as part of a human-robot interaction (HRI) task. Tests are generated to stimulate the robot’s code in a realistic manner, through stimulating the human, environment, sensors, and actuators in simulation. We compare the merits of unconstrained, constrained and model-based test generation in achieving thorough exploration of the code under test, and interesting combinations of human-robot interactions. Our results show that CDV combined with systematic test generation achieves a very high degree of automation in simulation-based verification of control code for robots in HRI."
SPRINGERLINK,Chapter,2016,Automated Support to Capture and Validate Security Requirements for Mobile Apps,Noorrezam YusopMassila KamalrudinSafiah SidekJohn Grundy,"EUC, EUI, Mobile apps, Model based testing strategy, Security attributes, Security requirements, Test driven development, Validation",10,"Mobile application usage has become widespread and significant as it allows interactions between people and services anywhere and anytime. However, issues related to security have become a major concern among mobile users as insecure applications may lead to security vulnerabilities that make them easily compromised by hackers. Thus, it is important for mobile application developers to validate security requirements of mobile apps at the earliest stage to prevent potential security problems. In this paper, we describe our automated approach and tool, called MobiMEReq that helps to capture and validate the security attributes requirements of mobile apps. We employed the concept of Test Driven Development (TDD) with a model-based testing strategy using Essential Use Cases (EUCs) and Essential User Interface (EUI) models. We also conducted an evaluation to compare the performance and correctness of our tool in various application domains. The results of the study showed that our tool is able to help requirements engineers to easily capture and validate security-related requirements of mobile applications."
SPRINGERLINK,Chapter,2016,Towards Model Construction Based on Test Cases and GUI Extraction,Antti Jääskeläinen,"Model extraction, Model-based testing, Software testing",10,"The adoption of model-based testing techniques is hindered by the difficulty of creating a test model. Various techniques to automate the modelling process have been proposed, based on software process artefacts or an existing product. This paper outlines a hybrid approach to model construction, based on two previously proposed methods. The presented approach combines information in pre-existing test cases with a model extracted from the graphical user interface of the product."
SPRINGERLINK,Chapter,2016,On Generating Test Cases from EDT Specifications,R. VenkateshUlka ShrotriAmey ZareSupriya Agrawal,"Functional test generation, Random test case generation, Reactive systems",10,"In an earlier work we presented a cost-effective approach to generate test cases that cover functional requirements of reactive systems. The approach involved specifying requirements in EDT (Expressive Decision Tables) and generating test cases from them using RGRaF, a Row-Guided Random algorithm with Fuzzing. In this paper we propose DRAFT, a novel Dependency driven Random Algorithm with Fuzzing at Time boundaries, to improve requirement coverage. DRAFT is an enhancement over RGRaF in its ability to exploit dependencies between requirements. To compare DRAFT and other test case generation approaches - manual, pure random and RGRaF, we conducted experiments on four real-world applications. The experiments indicated that DRAFT achieves better coverage than RGRaF and its variants. When compared with the manual approach, our test cases subsumed all manual test cases and achieved up to $$60\,\%$$ reduction in effort."
SPRINGERLINK,Chapter,2016,Formal Model-Based Constraint Solving and Document Generation,Michael Leuschel,,10,"Constraint solving technology for formal models has made considerable progress in the last years, and has lead to many applications such as animation of high-level specifications, test case generation, or symbolic model checking. In this article we discuss the idea to use formal models themselves to express constraint satisfaction problems and to embed formal models as executable artefacts at runtime. As part of our work, we have developed a document generation feature, whose output is derived from such executable models. This present article has been generated using this feature, and we use the feature to showcase the suitability of formal modelling to express and solve various constraint solving benchmark examples. We conclude with current limitations and open challenges of formal model-based constraint solving."
SPRINGERLINK,Chapter,2016,Towards a Standardized Quality Assessment Framework for OCCI-Controlled Cloud Infrastructures,Yongzheng Liang,"Cloud quality assessment, Cloud Standards, Industrie 4.0, Network Functions Virtualization, OCCI, Software Defined Network, Standardized testing, TTCN-3",10,"Considering standardized testing methodologies and related tool infrastructures as key elements of software quality assessment frameworks, for Clouds controlled by the Open Cloud Computing Interface OCCI this paper is going to present related first work based on the ETSI standardized test specification language TTCN-3. Initially motivated by studying the NIST Cloud Computing Program and the ETSI Cloud Standards Coordination (CSC) effort this approach is further stimulated by the recent evolution of the Cloud-oriented ETSI Network Functions Virtualization (NFV) and related projects such as the German Industrie 4.0."
SPRINGERLINK,Chapter,2016,Automatic Generation of Test Cases and Test Purposes from Natural Language,Sidney NogueiraHugo L. S. AraujoRenata B. S. AraujoJuliano IyodaAugusto Sampaio,"Editing, Prefix",10,"Use cases are widely used for requirements description in the software engineering practice. As a use case event flow is often written in natural language, it lacks tools for automatic analysis or processing. In this paper, we extend previous work that proposes an automatic strategy for generating test cases from use cases written in a Controlled Natural Language (CNL), which is a subset of English that can be processed and translated into a formal representation. Here we propose a state-based CNL for describing use cases. We translate state-based use case descriptions into CSP processes from which test cases can be automatically generated. In addition, we show how a similar notation can be used to specify test selection via the definition of state-based test purposes, which are also translated into CSP processes. Test generation and selection are mechanised by running refinement checking verifications using the CSP processes for use cases and test purposes. All the steps of the strategy are integrated into a tool that provides a GUI for authoring use cases and test purposes described in the proposed CNL, so the formal CSP notation is totally hidden from the test designer. We illustrate our tool and techniques with a running example."
SPRINGERLINK,Chapter,2016,Functional Testing of Java Programs,Clara Benac EarleLars-Åke Fredlund,"Erlang, Java, Software testing",10,"This paper describes an approach to testing Java code using a functional programming language. Models for Java programs are expressed as Quviq Erlang QuickCheck properties, from which random tests are generated and executed. To remove the need for writing boilerplate code to interface Java and Erlang, a new library, JavaErlang, has been developed. The library provides a number of interesting features, e.g., it supports automatic garbage collection of Java objects communicated to Erlang, and permits Java classes to be written entirely in Erlang. Moreover, as the library is built on top of the Erlang distributed node concept, the Java program under test runs in isolation from the Erlang testing code. The chief advantage of this testing approach is that a functional programming language, with expressive data types and side-effect free libraries, is very suited to formulating models for imperative programs. The resulting testing methodology has been applied extensively to evaluate student Java exercises."
SPRINGERLINK,Chapter,2016,Model-Driven Active Automata Learning with LearnLib Studio,Oliver BauerJohannes NeubauerMalte Isberner,,10,"We present our reboot of LearnLib Studio , formerly being a part of the Next Generation LearnLib (NGLL) framework for model-based construction of automata learning solutions. The new version of LearnLib Studio is a from-scratch re-implementation, which is based on an improved open-source realization of LearnLib as well as our latest version of the jABC framework ( jABC4 ) for model-driven, service-oriented development of applications with recently added support for type-safe higher-order process modeling. Our all new version of LearnLib Studio provides an easy way to enable even users who do not necessarily have programming expertise to use and extend dedicated learning solutions with minimal manual effort. We illustrate the tool by applying automata learning to a concrete web service following the Representational State Transfer (REST) paradigm."
SPRINGERLINK,Chapter,2016,Risk-Based Interoperability Testing Using Reinforcement Learning,André ReichstallerBenedikt EberhardingerAlexander KnappWolfgang ReifMarcel Gehlen,"Generate Test Case, Model Checker, Reinforcement Learning, System Under Test, Test Suite",10,"Risk-based test strategies enable the tester to harmonize the number of specified test cases with imposed time and cost constraints. However, the risk assessment itself often requires a considerable effort of cost and time, since it is rarely automated. Especially for complex tasks such as testing the interoperability of different components it is expensive to manually assess the criticality of possible faults. We present a method that operationalizes the risk assessment for interoperability testing. This method uses behavior models of the system under test and reinforcement learning techniques to break down the criticality of given failure situations to the relevance of single system actions for being tested. Based on this risk assessment, a desired number of test cases is generated which covers as much relevance as possible. Risk models and test cases have been generated for a mobile payment system within an industrial case study."
SPRINGERLINK,Chapter,2016,How to Assure Correctness and Safety of Medical Software: The Hemodialysis Machine Case Study,Paolo ArcainiSilvia BonfantiAngelo GargantiniElvinia Riccobene,,10,"Medical devices are nowadays more and more software dependent, and software malfunctioning can lead to injuries or death for patients. Several standards have been proposed for the development and the validation of medical devices, but they establish general guidelines on the use of common software engineering activities without any indication regarding methods and techniques to assure safety and reliability. This paper takes advantage of the Hemodialysis machine case study to present a formal development process supporting most of the engineering activities required by the standards, and provides rigorous approaches for system validation and verification. The process is based on the Abstract State Machine formal method and its model refinement principle."
SPRINGERLINK,Chapter,2016,Test Generation by Constraint Solving and FSM Mutant Killing,Alexandre PetrenkoOmer Nguena TimoS. Ramesh,"Conformance testing, Fault coverage analysis, Fault model-based test generation, Fault modelling, FSM, Mutation testing, Test coverage",10,"The problem of fault model-based test generation from formal models, in this case Finite State Machines, is addressed. We consider a general fault model which is a tuple of a specification, conformance relation and fault domain. The specification is a deterministic FSM which can be partially specified and not reduced. The conformance relation is quasi-equivalence, as all implementations in the fault domain are assumed to be completely specified FSMs. The fault domain is a set of all possible deterministic submachines of a given nondeterministic FSM, called a mutation machine. The mutation machine contains a specification machine and extends it with mutated transitions modelling potential faults. An approach for deriving a test suite which is complete (sound and exhaustive) for the given fault model is elaborated. It is based on our previously proposed method for analyzing the test completeness by logical encoding and SMT-solving. The preliminary experiments performed on an industrial controller indicate that the approach scales sufficiently well."
SPRINGERLINK,Chapter,2016,Web Service Test Evolution,Harry M. Sneed,"Automated web service testing, Data reverse engineering, Regression testing, Requirement-based testing, Test automation, Test maintenance, Test script evolution, Test-driven development, Web services",10,"In order to remain useful test scripts must evolve parallel to the test objects they are intended to test. In the approach described here the test objects are web services whose test script is derived from the web service interface definition. The test script structure is automatically generated from the WSDL structure with tags and attributes, however, the content, i.e. the test data has to be inserted by hand. From this script service requests are automatically generated and service responses automatically validated. As with other generated software artifacts, once the structure of the interface or the logic of the targeted service is changed, the content of the test script is no longer valid. It has to be altered and/or enhanced to fit the new interface structure and/or the altered service logic. In this paper the author proposes a semi-automated approach to solving this test maintenance problem and explains how it has been implemented in a web service testing tool by employing data reverse engineering techniques. The author also report on his experience with the approach when maintaining a test in the field."
SPRINGERLINK,Chapter,2016,Software that Meets Its Intent,Marieke HuismanHerbert BosSjaak BrinkkemperArie van DeursenJan Friso GrootePatricia LagoJaco van de PolEelco Visser,"Intended Behavior, Model Checker, Program Verifier, Proof Checker, Satisfiability Modulo Theory",10,"Software is widely used, and society increasingly depends on its reliability. However, software has become so complex and it evolves so quickly that we fail to keep it under control. Therefore, we propose intents : fundamental laws that capture a software systems’ intended behavior (resilient, secure, safe, sustainable, etc.). The realization of this idea requires novel theories, algorithms, tools, and techniques to discover, express, verify, and evolve software intents. Thus, future software systems will be able to verify themselves that they meet their intents. Moreover, they will be able to respond to deviations from intents through self-correction. In this article we propose a research agenda, outlining which novel theories, algorithms and tools are required."
SPRINGERLINK,Chapter,2016,A Model Interpreter for Timed Automata,M. Usman IftikharJonas LundbergDanny Weyns,"Model interpretation, Model-driven development, Timed automata, Virtual machine",10,"In the model-centric approach to model-driven development, the models used are sufficiently detailed to be executed. Being able to execute the model directly, without any intermediate model-to-code translation, has a number of advantages. The model is always up-to-date and runtime updates of the model are possible. This paper presents a model interpreter for timed automata, a formalism often used for modeling and verification of real-time systems. The model interpreter supports real-time system features like simultaneous execution, system wide signals, a ticking clock, and time constraints. Many existing formal representations can be verified, and many existing DSMLs can be executed. It is the combination of being both verifiable and executable that makes our approach rather unique."
SPRINGERLINK,Chapter,2016,Cost-Benefit Analysis of Using Dependency Knowledge at Integration Testing,Sahar TahviliMarkus BohlinMehrdad SaadatmandStig LarssonWasif AfzalDaniel Sundmark,"Decision support system, Integration testing, Optimization, Prioritization, Process improvement, Return on investment, Software testing, Test case selection",10,"In software system development, testing can take considerable time and resources, and there are numerous examples in the literature of how to improve the testing process. In particular, methods for selection and prioritization of test cases can play a critical role in efficient use of testing resources. This paper focuses on the problem of selection and ordering of integration-level test cases. Integration testing is performed to evaluate the correctness of several units in composition. Further, for reasons of both effectiveness and safety, many embedded systems are still tested manually. To this end, we propose a process, supported by an online decision support system, for ordering and selection of test cases based on the test result of previously executed test cases. To analyze the economic efficiency of such a system, a customized return on investment (ROI) metric tailored for system integration testing is introduced. Using data collected from the development process of a large-scale safety-critical embedded system, we perform Monte Carlo simulations to evaluate the expected ROI of three variants of the proposed new process. The results show that our proposed decision support system is beneficial in terms of ROI at system integration testing and thus qualifies as an important element in improving the integration testing process."
SPRINGERLINK,Chapter,2016,Temporal Test Generation for Embedded System Based on Correlation Analysis of Timing Constraints,Bo WangXiaoying BaiWenguang ChenXiaoyu Song,"Correlation analysis, Embedded software, Temporal testing, Test generation, Timing constraint",10,"Timing constraints are critical to real-time embedded software. However, it is hard to verify and validate system temporal correctness when there exist multiple timing constraints with complex inter-dependencies. To facilitate temporal testing, the paper systematically analyzes the characteristics of timing constraints and their correlation patterns, using a modeling technique called Extended Semantic Interface Automata (ESIA). A Correlation-Based Partition Testing (CBPT) approach is proposed to generate temporal test cases. The value of time variables are sampled from equivalent partitions of test domain, which are identified by taking constraints and constraint correlations into considerations. Each partition of test vectors represents a typical timing scenario, such that the sampled test cases can validate both the correctness of system normal functionalities and system robustness in reaction to timing exceptions. The strategies to search and calculate test data are designed. Experiments are exercised on a Satellite Positioning System (SPS) software. The results show that the proposed approach can effectively reduce test cost, enhance test coverage, and efficiently detect various temporal defects."
SPRINGERLINK,Chapter,2016,Cyber-Physical Systems Engineering,Bernd-Holger Schlingloff,"Block diagrams, Code generation, Cyber-physical systems, Embedded systems, Model-based design, Requirements analysis, State-transition systems, Systems analysis, Systems modeling",10,Building complex embedded- and cyber-physical systems requires a holistic view on both product and process. The constructed system must interact with its physical environment and its human users in a smooth way. The development processes must provide a seamless transition between stages and views. Different modeling techniques and methods have been proposed to achieve this goal. In this chapter we present the fundamentals of cyber-physical systems engineering: identification and quantification of system goals; requirements elicitation and management; modeling and simulation in different views; and validation to ensure that the system meets its original design goals. A special focus is on the model-based design process. All techniques are demonstrated with appropriate examples and engineering tools.
SPRINGERLINK,Chapter,2016,Combining Model Learning and Model Checking to Analyze TCP Implementations,Paul Fiterău-BroşteanRamon JanssenFrits Vaandrager,"Abstraction Function, Automaton Learning, Equivalence Query, Membership Query, Model Check",10,"We combine model learning and model checking in a challenging case study involving Linux, Windows and FreeBSD implementations of TCP. We use model learning to infer models of different software components and then apply model checking to fully explore what may happen when these components (e.g. a Linux client and a Windows server) interact. Our analysis reveals several instances in which TCP implementations do not conform to their RFC specifications."
SPRINGERLINK,Chapter,2016,A Case Study for a Bidirectional Transformation Between Heterogeneous Metamodels in QVT Relations,Bernhard Westfechtel,"Bidirectional Transformation, Ecore Model, Heterogeneous Metamodels, Object-relational Mapping, Unidirectional Transformations",10,"Model transformations constitute a key technology for model-driven software engineering. In additional to unidirectional transformations, bidirectional transformations may be required e.g. for round-trip engineering or bidirectional data conversion. Bidirectional transformations may be difficult to perform if the metamodels of source and target models differ significantly from each other, as it is the case for object-relational mappings. In this paper, we present a bidirectional transformation between Ecore models and relational schemata written in QVT Relations. The case study demonstrates that it is possible to encode a bidirectional transformation between heterogeneous metamodels in a single relational specification. Simultaneously, the case study also shows some inherent limitations of what can be achieved by bidirectional transformations."
SPRINGERLINK,Chapter,2016,Applying Abstract Interpretation to Verify EN-50128 Software Safety Requirements,Daniel KästnerChristian Ferdinand,"Abstract Interpretation-based Static Analysis, Data Races, Potential Runtime Errors, Stack Overflow, Worst-case Execution Time (WCET)",10,"Like other contemporary safety standards EN-50128 requires to identify potential functional and non-functional hazards and to demonstrate that the software does not violate the relevant safety goals. Examples of safety-relevant non-functional hazards are violations of resource bounds, especially stack overflows and deadline violations, as well as run-time errors and data races. They can cause erroneous and erratic program behavior, invalidate separation mechanisms in mixed-criticality software, and even trigger software crashes. Classical software verification methods like code review and testing with measurements cannot really guarantee the absence of errors. Abstract interpretation is a formal method for static program analysis which supports formal soundness proofs (it can be proven that no error is missed) and which scales. This article gives an overview of abstract interpretation and its application to compute safe worst-case execution time and stack bounds, and to find all potential run-time errors, and data races. We discuss the tool qualification of abstract interpretation-based static analyzers and describe their contribution with respect to EN-50128 compliant verification processes. We also illustrate their integration in the development process and report on practical experience."
SPRINGERLINK,Chapter,2016,Your Proof Fails? Testing Helps to Find the Reason,Guillaume PetiotNikolai KosmatovBernard BotellaAlain GiorgettiJacques Julliand,"Deductive Veriﬁcation, Failed Proof, PathCrawler, Veriﬁcation Engine, Weak Contraction",10,"Applying deductive verification to formally prove that a program respects its formal specification is a very complex and time-consuming task due in particular to the lack of feedback in case of proof failures. Along with a non-compliance between the code and its specification (due to an error in at least one of them), possible reasons of a proof failure include a missing or too weak specification for a called function or a loop, and lack of time or simply incapacity of the prover to finish a particular proof. This work proposes a complete methodology where test generation helps to identify the reason of a proof failure and to exhibit a counterexample clearly illustrating the issue. We define the categories of proof failures, introduce two subcategories of contract weaknesses (single and global ones), and examine their properties. We describe how to transform a formally specified C program into C code suitable for testing, and illustrate the benefits of the method on comprehensive examples. The method has been implemented in StaDy , a plugin of the software analysis platform Frama-C . Initial experiments show that detecting non-compliances and contract weaknesses allows to precisely diagnose most proof failures."
SPRINGERLINK,Chapter,2016,Privacy-Preserving Targeted Mobile Advertising: Formal Models and Analysis,Yang LiuAndrew Simpson,"Internet Economy, Mobile Advertising, Personal Information, Prototype Solution, Tschantz",10,"Targeted Mobile Advertising (TMA) has emerged as a significant driver of the Internet economy. TMA gives rise to interesting challenges: there is a need to balance privacy and utility; there is a need to guarantee that applications’ access to resources is appropriate; and there is a need to ensure that the targeting of ads is effective. As many authors have argued, formal models are ideal vehicles for reasoning about privacy, as well as for reasoning about the relationship between privacy and utility. To this end, we describe how the formal notation Z has been used to develop formal models to underpin a prototype privacy-preserving TMA system. We give consideration to how formal models can help in underpinning the prototype system, in analysing privacy in the context of targeted mobile advertising, and in allowing users to specify control of their personal information."
SPRINGERLINK,Chapter,2016,The Kind 2 Model Checker,Adrien ChampionAlain MebsoutChristoph StickselCesare Tinelli,"Compositional Reasoning, Contract Reﬁnement, Initial State Predicate, Invariant Generation Techniques, Synchronous Reactive Systems",10,"Kind  2 is an open-source, multi-engine, SMT-based model checker for safety properties of finite- and infinite-state synchronous reactive systems. It takes as input models written in an extension of the Lustre language that allows the specification of assume-guarantee-style contracts for system components. Kind  2 was implemented from scratch based on techniques used by its predecessor, the PKind model checker. This paper discusses a number of improvements over PKind in terms of invariant generation. It also introduces two main features: contract-based compositional reasoning and certificate generation."
SPRINGERLINK,Chapter,2016,Transforming CPN Models into Code for TinyOS: A Case Study of the RPL Protocol,Lars Michael KristensenVegard Veiset,"Coloured Petri Nets (CPN), Destination-oriented Directed Acyclic Graph (DODAG), Substitution Transition, TinyOS Components, TinyOS Platform",10,"TinyOS is a widely used platform for the development of networked embedded systems offering a programming model targeting resource constrained devices. We present a semi-automatic software engineering approach where Coloured Petri Net (CPNs) models are used as a starting point for developing protocol software for the TinyOS platform. The approach consists of five refinement steps that allow a developer to gradually transform a platform-independent CPN model into a platform-specific model that enables automatic code generation. To evaluate our approach, we use it to obtain an implementation of the IETF RPL routing protocol for sensor networks."
SPRINGERLINK,Chapter,2015,Model-Based Testing for Composite Web Services in Cloud Brokerage Scenarios,Mariam KiranAnthony J. H. Simons,"Cloud Service, Component Service, Composite Service, Service Composition, Test Suite",10,"Cloud brokerage is an enabling technology allowing various services to be merged together for providing optimum quality of service for the end-users. Within this collection of composed services, testing is a challenging task which brokers have to take on to ensure quality of service. Most Software-as-a-Service (SaaS) testing has focused on high-level test generation from the functional specification of individual services, with little research into how to achieve sufficient test coverage of composite services. This paper explores the use of model-based testing to achieve testing of composite services, when two individual web services are tested and combined. Two example web services – a login service and a simple shopping service – are combined to give a more realistic shopping cart service. This paper focuses on the test coverage required for testing the component services individually and their composition. The paper highlights the problems of service composition testing, requiring a reworking of the combined specification and regeneration of the tests, rather than a simple composition of the test suites; and concludes by arguing that more work needs to be done in this area."
SPRINGERLINK,Chapter,2015,Model-Based Testing from Input Output Symbolic Transition Systems Enriched by Program Calls and Contracts,Imen BoudhibaChristophe GastonPascale Le GallVirgile Prevosto,"Feasibility, Input output symbolic transition systems, Model-based testing, Program contracts, Symbolic execution",10,"An Input Output Symbolic Transition System (IOSTS) specifies all expected sequences of input and output messages of a reactive system. Symbolic execution over this IOSTS then allows to generate a set of test cases that can exercise the various possible behaviors of the system it represents. In this paper, we extend the IOSTS framework with explicit program calls, possibly equipped with contracts specifying what the program is supposed to do. This approach bridges the gap between a model-based approach in which user-defined programs are abstracted away and a code-based approach in which small pieces of code are separately considered regardless of the way they are combined. First, we extend symbolic execution techniques for IOSTS with programs, in order to re-use classical test case generation algorithms. Second, we explore how constraints coming from IOSTS symbolic execution can be used to infer contracts for programs used in the IOSTS."
SPRINGERLINK,Chapter,2015,Model-Based Robustness Testing in Event-B Using Mutation,Aymerick SavaryMarc FrappierMichael LeuschelJean-Louis Lanet,"
                  Event-B
                , 
                  ProB
                , Intrusion testing, Model-based testing, Robustness testing, Specification mutation, Vulnerability analysis",10,"Robustness testing aims at finding errors in a system under invalid conditions, such as unexpected inputs. We propose a robustness testing approach for Event-B based on specification mutation and model-based testing. We assume that a specification describes the valid inputs of a system. By applying negation rules, we mutate the precondition of events to explore invalid behaviour. Tests are generated from the mutated specification using ProB . ProB has been adapted to efficiently process mutated events. Mutated events are statically checked for satisfiability and enability using constraint satisfaction, to prune the transition search space. This has dramatically improve the performance of test generation. The approach is applied to the Java Card bytecode verifier. Large mutated specifications (containing 921 mutated events) can be easily tackled to ensure a good coverage of the robustness test space."
SPRINGERLINK,Chapter,2015,Risk-Driven Vulnerability Testing: Results from eHealth Experiments Using Patterns and Model-Based Approach,Alexandre VernotteCornel BoteaBruno LegeardArthur MolnarFabien Peureux,"eHealth web application, Empirical evaluation, Risk-driven testing, Security test pattern, Vulnerability testing",10,"This paper introduces and reports on an original tooled risk-driven security testing process called Pattern-driven and Model-based Vulnerability Testing. This fully automated testing process, drawing on risk-driven strategies and Model-Based Testing (MBT) techniques, aims to improve the capability of detection of various Web application vulnerabilities, in particular SQL injections, Cross-Site Scripting, and Cross-Site Request Forgery. It is based on a mixed modeling of the system under test: an MBT model captures the behavioral aspects of the Web application, while formalized vulnerability test patterns, selected from risk assessment results, drive the overall test generation process. An empirical evaluation, conducted on a complex and freely-accessible eHealth system developed by Info World, shows that this novel process is appropriate for automatically generating and executing risk-driven vulnerability test cases and is promising to be deployed for large-scale Web applications."
SPRINGERLINK,Chapter,2015,Model-Based Analysis for Safety Critical Software,Stefan GulanJens HarnischSven JohrRoberto KretschmerStefan RiegerRafael Zalman,"AUTOSAR, Formal methods, Functional safety, ISO 26262, Model checking, Model-based testing, Safety analysis",10,"Safety-relevant software developed within the automotive domain is subject to the safety standard ISO 26262. In particular, a supplier must show that implemented safety mechanisms sufficiently address relevant failure modes. This involves complex and costly testing procedures. We introduce an early analysis approach for safety mechanisms implemented in safety-relevant software by combining model checking and model-based testing. Model checking is applied to verify the correctness of an abstract amodel of the system under test. The verified model is then used to automatically generate tests for the verification of the implemented Safety Elements. The approach has been evaluated in an industrial case study, addressing Analogue Digital Converters as part of the motor control within a hybrid electric vehicle. The results suggest that our approach allows to create high quality test suites. In addition, the test model helps to reduce misunderstandings due to imprecise specification of safety mechanisms."
SPRINGERLINK,Chapter,2015,"Require, Test and Trace IT",Bernhard K. AichernigKlaus HörmaierFlorian LorberDejan NičkovićStefan Tiran,"Consistency checking, Formal specification, Incremental test-case generation, Model-based testing, Requirement interfaces, Requirements engineering, Synchronous systems, Test-case generation, Traceability",10,"We propose a framework for requirement-driven test generation that combines contract-based interface theories with model-based testing. We design a specification language, requirement interfaces , for formalizing different views (aspects) of synchronous data-flow systems from informal requirements. Multiple views of a system, modeled as requirement interfaces, are naturally combined by conjunction. We develop an incremental test generation procedure with several advantages. The test generation is driven by a single requirement interface at a time. It follows that each test assesses a specific aspect or feature of the system, specified by its associated requirement interface. Since we do not explicitly compute the conjunction of all requirement interfaces of the system, we avoid state space explosion while generating tests. However, we incrementally complete a test for a specific feature with the constraints defined by other requirement interfaces. This allows catching violations of any other requirement during test execution, and not only of the one used to generate the test. Finally, this framework defines a natural association between informal requirements, their formal specifications and the generated tests, thus facilitating traceability. We implemented a prototype test generation tool and we demonstrate its applicability on an industrial use case."
SPRINGERLINK,Chapter,2015,Bounded Determinization of Timed Automata with Silent Transitions,Florian LorberAmnon RosenmannDejan NičkovićBernhard K. Aichernig,"Bound Model Check, Bypass Transition, Observable Transition, Time Automaton, Unary Constraint",10,"Deterministic timed automata are strictly less expressive than their non-deterministic counterparts, which are again less expressive than those with silent transitions. As a consequence, timed automata are in general non-determinizable. This is unfortunate since deterministic automata play a major role in model-based testing, observability and implementability. However, by bounding the length of the traces in the automaton, effective determinization becomes possible. We propose a novel procedure for bounded determinization of timed automata. The procedure unfolds the automata to bounded trees, removes all silent transitions and determinizes via disjunction of guards. The proposed algorithms are optimized to the bounded setting and thus are more efficient and can handle a larger class of timed automata than the general algorithms. The approach is implemented in a prototype tool and evaluated on several examples. To our best knowledge, this is the first implementation of this type of procedure for timed automata."
SPRINGERLINK,Chapter,2015,A SysML Formal Framework to Combine Discrete and Continuous Simulation for Testing,Jean-Marie GauthierFabrice BouquetAhmed HammadFabien Peureux,"Constraint solving, Discrete & continuous simulation, Model-based testing, Model-driven engineering, Modelica, Real-time system, SysML",10,"The increasing interactions between huge amount of software and hardware subsystem (hydraulics, mechanics, electronics, etc.) lead to a new kind of complexity that is difficult to manage during the validation of safety-critical and complex embedded systems. This paper introduces a formal SysML-based framework to combine both discrete and continuous simulation to validate physical systems at the early stage of development. This original modelling framework takes as input a SysML model annotated with Modelica code and OCL constraints. Such a model provides a precise and unambiguous description of the designed system and its environment, involving both discrete and continuous features. This formal framework enables to automatically generate Modelica code to perform real-time simulation. On the basis of a constraint system derived from the discrete SysML/OCL modelling artefacts, it also makes it possible to automatically generate black-box test cases that can be used to validate the simulated system as well as the corresponding physical device. This framework has been validated by conclusive experiments conducted to prototype a new energy manager system for aeronautics."
SPRINGERLINK,Chapter,2015,Case Study: Automatic Test Case Generation for a Secure Cache Implementation,Roderick BloemDaniel HeinFranz RöckRichard Schumi,"Automatic test case generation, Model checking, Model-based testing, Trap properties",10,"While many approaches for automatic test case generation have been proposed over the years, it is often difficult to predict which of them may work well on concrete problems. In this paper, we therefore present a case study in automatic, model-based test case generation: We implemented several graph-based methods that compute test cases with a model checker using trap properties, and evaluate these methods on a Secure Block Device implementation. We compare the number of generated test cases, the required generation time and the achieved code coverage. Our conclusions are twofold: First, automatic test case generation is feasible and beneficial for this case study, and even found a real bug in the implementation. Second, simple coverage methods on the model may already yield test suites of sufficient quality."
SPRINGERLINK,Chapter,2015,Mobile Application Verification: A Systematic Mapping Study,Mehmet SahinogluKoray InckiMehmet S. Aktas,"Literature review, Mobile application, Software testing, Systematic mapping, Verification",10,"The proliferation of mobile devices and applications has seen an unprecedented rise in recent years. Application domains of mobile systems range from personal assistants to point-of-care health informatics systems. Software development for such diverse application domains requires stringent and well-defined development process. Software testing is a type of verification that is required to achieve more reliable system. Even though, Software Engineering literature contains many research studies that address challenging issues in mobile application development, we could not have identified a comprehensive literature review study on this subject. In this paper, we present a systematic mapping of the Software Verification in the field of mobile applications. We provide definitive metrics and publications about mobile application testing, which we believe will allow fellow researchers to identify gaps and research opportunities in this field."
SPRINGERLINK,Chapter,2015,Selective Test Generation Approach for Testing Dynamic Behavioral Adaptations,Mariam LahamiMoez KrichenHajer BarhoumiMohamed Jmaiel,,10,"This paper presents a model-based black-box testing approach for dynamically adaptive systems. Behavioral models of such systems are formally specified using timed automata. With the aim of obtaining the new test suite and avoiding its regeneration in a cost effective manner, we propose a selective test generation approach. The latter comprises essentially three modules: (1) a model differencing module that detects similarities and differences between the initial and the evolved behavioral models, (2) an old test classification module that identifies reusable and retestable tests from the old test suite, and finally (3) a test generation module that generates new tests covering new behaviors and adapts old tests that failed during animation. To show its efficiency, the proposed technique is illustrated through the Toast application and compared to the classical Regenerate All and Retest All approaches."
SPRINGERLINK,Chapter,2015,Safety.Lab: Model-Based Domain Specific Tooling for Safety Argumentation,Daniel RatiuMarc ZellerLennart Killian,"Assurance cases, Model driven engineering, Safety-critical systems, Tooling",10,"Assurance cases capture the argumentation that a system is safe by putting together pieces of evidence at different levels of abstraction and of different nature. Managing the interdependencies between these artefacts lies at the heart of any safety argument. Keeping the assurance case complete and consistent with the system is a manual and very ressource consuming process. Current tools do not address these challenges in constructing and maintaining safety arguments. In this paper we present a tooling prototype called Safety.Lab which features rich and deeply integrated models to describe requirements, hazards list, fault trees and architecture. We show how Safety.Lab opens opportunities to automate completeness and consistency checks for safety argumentation."
SPRINGERLINK,Chapter,2015,Applying Automata Learning to Embedded Control Software,Wouter SmeenkJoshua MoermanFrits VaandragerDavid N. Jansen,,10,"Using an adaptation of state-of-the-art algorithms for black-box automata learning, as implemented in the LearnLib tool, we succeeded to learn a model of the Engine Status Manager (ESM), a software component that is used in printers and copiers of Océ. The main challenge that we encountered was that LearnLib, although effective in constructing hypothesis models, was unable to find counterexamples for some hypotheses. In fact, none of the existing FSM-based conformance testing methods that we tried worked for this case study. We therefore implemented an extension of the algorithm of Lee and Yannakakis for computing an adaptive distinguishing sequence. Even when an adaptive distinguishing sequence does not exist, Lee and Yannakakis’ algorithm produces an adaptive sequence that ‘almost’ identifies states. In combination with a standard algorithm for computing separating sequences for pairs of states, we managed to verify states with on average 3 test queries. Altogether, we needed around 60 million queries to learn a model of the ESM with 77 inputs and 3.410 states. We also constructed a model directly from the ESM software and established equivalence with the learned model. To the best of our knowledge, this is the first paper in which active automata learning has been applied to industrial control software."
SPRINGERLINK,Chapter,2015,BPEL Integration Testing,Seema JehanIngo PillFranz Wotawa,"Mutation Score, Satisfying Assignment, Symbolic Execution, Test Case Generation, Test Suite",10,"Service-oriented architectures, and evolvements such as clouds, provide a promising infrastructure for future computing. They encapsulate an IP core’s functionality for easy access via well-defined business and web interfaces, and in turn allow us to flexibly realize complex software drawing on available expertise. In this paper, we take a look at some challenges we have to face during the task of testing such systems for verification purposes. In particular, we delve into the task of test suite generation, and compare the performance of two corresponding algorithms. In addition, we report on experiments for a collection of BPEL processes taken from the literature, in order to identify performance trends with respect to fault coverage metrics. Our results suggest that a structural reasoning might outperform a completely random approach."
SPRINGERLINK,Chapter,2015,Towards the Generation of Tests in the Test Description Language from Use Case Map Models,Patrice BouletDaniel AmyotBernard Stepien,"Model-based testing, Test Description Language, Tool, Use Case Map",10,"The Test Description Language (TDL) is an emerging standard from the European Telecommunications Standards Institute (ETSI) that targets the abstract description of tests for communicating systems and other application domains. TDL is meant to be used as an intermediate format between requirements and executable test cases. This paper explores the automated generation of TDL test descriptions from requirements expressed as Use Case Map (UCM) models. One generation mechanism, which exploits UCM scenario definitions, is prototyped in the jUCMNav tool and illustrated through an example. This transformation enables the exploration of model-based testing where the use of TDL models simplifies the generation of tests in various languages (including the Testing and Test Control Notation – TTCN-3) from UCM requirements. Remaining challenges are also discussed in the paper."
SPRINGERLINK,Chapter,2015,Combining Time and Concurrency in Model-Based Statistical Testing of Embedded Real-Time Systems,Daniel HommJürgen EckertReinhard German,"Concurrency, System testing, Timed usage models",10,"Timed usage models (TUMs) represent a model-based statistical approach for system testing of real-time embedded systems. They enable an automatic test case generation and the calculation of parameters that aid the test process. However, a classical TUM only supports sequential uses of the system under test (SUT). It is not capable of dealing with concurrency, which is required for state of the art real-time embedded systems. Therefore, we introduce TUMs with parallel regions. They also allow automatic test case generation, which is carried out similarly to classical TUMs. But, the semi-Markov process (SMP) that is usually used for analysis is not suitable here. We apply Markov renewal theory and define an SMP with parallel regions, which is used to calculate parameters. We validated our analytical approach by simulations."
SPRINGERLINK,Chapter,2015,Efficient Guiding Strategies for Testing of Temporal Properties of Hybrid Systems,Tommaso DreossiThao DangAlexandre DonzéJames KapinskiXiaoqing JinJyotirmoy V. Deshmukh,"Goal Cell, Guide Strategy, Simulation Trace, Star Discrepancy, Temporal Logic",10,"Techniques for testing cyberphysical systems (CPS) currently use a combination of automatic directed test generation and random testing to find undesirable behaviors. Existing techniques can fail to efficiently identify bugs because they do not adequately explore the space of system behaviors. In this paper, we present an approach that uses the rapidly exploring random trees (RRT) technique to explore the state-space of a CPS. Given a Signal Temporal Logic (STL) requirement, the RRT algorithm uses two quantities to guide the search: The first is a robustness metric that quantifies the degree of satisfaction of the STL requirement by simulation traces. The second is a metric for measuring coverage for a dense state-space, known as the star discrepancy measure. We show that our approach scales to industrial-scale CPSs by demonstrating its efficacy on an automotive powertrain control system."
SPRINGERLINK,Chapter,2015,Scenario-Based Design and Validation of REST Web Service Compositions,Irum RaufFaezeh SiavashiDragos TruscanIvan Porres,"Model-based testing, REST, TRON, UPPAAL, Web service composition",10,"We present an approach to design and validate RESTful composite web services based on user scenarios. We use the Unified Modeling Language (UML) to specify the requirements, behavior and published resources of each web service. In our approach, a service can invoke other services and exhibit complex and timed behavior while still complying with the REST architectural style. We specify user scenarios via UML Sequence Diagrams. The service specifications are transformed into UPPAAL timed automata for verification and test generation. The service requirements are propagated to the UPPAAL timed automata during the transformation. Their reachability is verified in UPPAAL and they are used for computing coverage level during test generation. We validate our approach with a case study of a holiday booking web service."
SPRINGERLINK,Chapter,2015,Runtime Verification of Expected Energy Consumption in Smartphones,Ana Rosario EspadaMaría del Mar GallardoAlberto SalmerónPedro Merino,"Analysis of traces, Energy consumption, Interval logic, Runtime verification",10,"Smartphones connected to Internet should work properly for days without a reset. One of the most critical non-functional properties to ensure the correct behavior is energy consumption. However, currently there is a lack of automated techniques to check whether the actual mobile consume is within the expected limits. To apply runtime verification techniques in this context, we need (a) detailed profiles of consumptions for specific actions in apps of interest (such as activate GPS, send a data packet to the network, etc.); (b) a method to automatically generate sufficiently representative use cases of the mobile behavior; (c) a language to describe the expected behavior in terms of energy consumption (energy properties); and (d) a method to monitor the mobile execution traces and analyze them against the energy properties. We aim to construct a tool chain addressing all these steps. We have already designed and implemented a model-based approach to automatically generate execution traces in mobile devices using Spin . This paper focuses on the formalization and analysis of energy properties with a specification language inspired by the interval logic. The paper presents this logic, the implementation of runtime verification using Büchi automata, and the practical use of the whole tool chain for model-based runtime verification of energy-related properties. Spin is a main ingredient for generating the test cases and checking the properties."
SPRINGERLINK,Chapter,2015,Empirical Evaluation of UML Modeling Tools–A Controlled Experiment,Safdar Aqeel SafdarMuhammad Zohaib IqbalMuhammad Uzair Khan,"Controlled experiment, Empirical software engineering, Model driven software engineering, Modeling tools, UML",10,"Model driven software engineering (MDSE) has shown to provide mark improvement in productivity and quality of software products. UML is a standard modeling language that is widely used in the industry to support MDSE. To provide tool support for MDSE, a large number of UML modeling tools are available, ranging from open-source tools to commercial tools with high price tag. A common decision faced while applying UML in practice is the selection of an appropriate tool for modeling. In this paper we conduct a study to compare three of the well-known modeling tools: IBM Rational Software Architect (RSA), MagicDraw, and Papyrus. In this study we conducted an experiment with undergraduate and graduate students. The goal is to compare the productivity of the software engineers while modeling with the tools. We measure the productivity in terms of modeling effort required to correctly complete a task, learnability, time and number of clicks required, and memory load required for the software engineer to complete a task. Our results show that MagicDraw performed significantly better in terms of learnability, memory load, and completeness of tasks. In terms of time and number of clicks, IBM RSA was significantly better while modeling class diagrams and state machines when compared to Papyrus. However no single tool outperformed others in all the modeling tasks with respect to time and number of clicks."
SPRINGERLINK,Chapter,2015,Advanced Test Modelling and Execution Based on the International Standardized Techniques TTCN-3 and UTP,Axel RennochMarc-Florian WendlandAndreas HoffmannMartin Schneider,"Model-based test design, Test automation, TTCN-3, UML, UTP",10,"In systems and service engineering testing is an important part to get confidence in quality and trust in security issues. Standardized testing techniques support the unique definition of abstract test models, configurations and behavior scenarios that can be executed automatically. This contribution presents the state of the art and future directions of two international standards for testing: the Testing and Test Control Notation (TTCN-3) from the European Telecommunication Standardization Institute (ETSI), and the UML testing profile (UTP) from the Open Management Group (OMG). Special emphasize is given to the translation from UTP to TTCN-3 test models, automated test execution using standard-compliant tool support and related examples from European projects."
SPRINGERLINK,Chapter,2015,A Top-Down Design Approach for an Automated Testing Framework,Abel Méndez-PorrasMario Nieto HidalgoJuan Manuel García-ChamizoMarcelo JenkinsAlexandra Martínez Porras,"Automated testing, Historical bug information, Interest points, Mobile applications, Top-down design, User-interaction features",10,"Mobile applications have become popular work tools. Portability and ease of Internet connectivity are characteristics that favor this adoption. However, mobile applications sometimes incorrectly process events associated with the user-interaction features. These features include content presentation or navigation. Rotating the devices, and gestures such as scroll or zoom into screens are some examples. There is a need to assess the quality with which mobile applications are processing these user-interaction features in order to improve their performance. In this paper, we present a top-down design approach for an automated testing framework for mobile applications. Our framework integrates digital image processing, GUI information, and historical bug information to identify new bugs based on user-interaction features. Our framework captures images before and after applying the user-interaction features and uses the SURF algorithm to identify interest points in each image. We compared interest points to note differences on the screens before and after applying the user-interaction features. This differences helps to find bugs in mobile applications. The first results show that it is feasible to identify bugs with user-interaction features using the proposed technique."
SPRINGERLINK,Chapter,2015,LearnLib Tutorial,Malte IsbernerBernhard SteffenFalk Howar,"Automaton Learning, Lower Common Ancestor, Membership Query, Observation Table, Regular Language",10,"Active automata learning is a promising technique to generate formal behavioral models of systems by experimentation. The practical applicability of active learning, however, is often hampered by the impossibility of realizing so-called equivalence queries , which are vital for ensuring progress during learning and finally resulting in correct models. This paper discusses the proposed approach of using monitoring as a means of generating counterexamples, explains in detail why virtually all existing learning algorithms are not suited for this approach, and gives an intuitive account of TTT, an algorithm designed to cope with counterexamples of extreme length. The essential steps and the impact of TTT are illustrated via experimentation with LearnLib , a free, open source Java library for active automata learning."
SPRINGERLINK,Chapter,2015,Stream X-Machines for Agent Simulation Test Case Generation,Ilias SakellariouDimitris DranidisMarina NtikaPetros Kefalas,"Agent based simulation, Formal methods, NetLogo, Test case generation",10,"Applying the Stream X-Machine formal method in the development of multi-agent simulations has a number of significant advantages, since it combines the power of executable specifications and test case generation. The present work supports this argument by reporting on the combined use of two tools that involve Stream X-Machines (SXM): the first is a domain specific language for effortlessly encoding agent behaviour using SXMs in a well known agent simulation platform. The second tool, supports among other things, automated test case generation using SXMs. The main benefits of using the specific formal approach in such a practical setting is that it offers a clear intuitive way of specifying agent behaviour and the automated generation of “agent simulation test scenarios” that can be used for validation."
SPRINGERLINK,Chapter,2015,An Industrial Case Study on Test Cases as Requirements,Elizabeth BjarnasonMichael UnterkalmsteinerEmelie EngströmMarkus Borg,"Acceptance test, Agile development, Behaviour-driven development, Case study, Requirements and test alignment",10,"It is a conundrum that agile projects can succeed ‘without requirements’ when weak requirements engineering is a known cause for project failures. While Agile development projects often manage well without extensive requirements documentation, test cases are commonly used as requirements. We have investigated this agile practice at three companies in order to understand how test cases can fill the role of requirements. We performed a case study based on twelve interviews performed in a previous study. The findings include a range of benefits and challenges in using test cases for eliciting, validating, verifying, tracing and managing requirements. In addition, we identified three scenarios for applying the practice, namely as a mature practice, as a de facto practice and as part of an agile transition. The findings provide insights into how the role of requirements may be met in agile development including challenges to consider."
SPRINGERLINK,Chapter,2015,Insertion Modeling and Symbolic Verification of Large Systems,Alexander LetichevskyOleksandr LetychevskyiVolodymyr PeschanenkoThomas Weigert,"Large system development, Symbolic techniques, Verification",10,"Insertion modeling has been developed over the last decade as an approach to a general theory of interaction between agents and an environment in complex distributed multiagent systems. The original work in this direction proposed a model of interaction between agents and environments based on an insertion function and the algebra of behaviors (similar to process algebra). Over the recent years, insertion modeling has been applied to the verification of requirement specifications of distributed interacting systems and to the generation of tests from such requirements. Our system, VRS (Verification of Requirements Specifications), has successfully verified specifications in the field of telecommunication systems, embedded systems, and real-time systems. Formal requirements in VRS are presented by means of local descriptions with a succession relation. Formalized requirements are represented in a formalism that combines logical specifications with control descriptions provided by the graphical syntax of UCM (Use Case Map) diagrams. This paper overviews the main concepts of insertion modeling, presents new algorithms developed for symbolic verification, especially a new predicate transformer for local descriptions, and provides a formal description of the method of generating traces from such specifications (which is the key technology used to verify requirements and derive test suites)."
SPRINGERLINK,Chapter,2015,Evaluation of Autonomous Approaches Using Virtual Environments,Katharina StahlJörg StöckleinSijia Li,"Anomaly Detection, Evaluation Environment, Mechatronic System, Virtual Environment, Virtual Prototype",10,"In this paper, we address the challenging problem of evaluating autonomous research approaches by the example of an online anomaly detection framework for dynamical real-time systems. We propose to use a virtual test environment that was conceptualized based on the specific evaluation requirements. The architecture is composed of all system parts required for evaluation: the operating system implementing the anomaly detection framework, reconfigurable autonomous applications, an execution platform device for the operating system and its applications, and the device’s environment. We demonstrate our concepts by the example of our miniature robot BeBot that acts as our virtual prototype (VP) to execute autonomous applications. With an interactive module, the virtual environment (VE) offers full control over the environment and the VP so that using different levels of hardware implementation for evaluation, but also failure injection at runtime becomes possible. Our architecture allows to determine clear system boundaries of the particular parts composed of perception function, decision making function and execution function which is essential for evaluating autonomous approaches. We define evaluation scenarios to show the effectiveness of each part of our approach and illustrate the powerfulness of applying virtual test environments to evaluate such approaches as the here referred one."
SPRINGERLINK,Chapter,2015,Maareech: Usability Testing Tool for Voice Response System Using XML Based User Models,Siddhartha AsthanaPushpendra Singh,"Usability testing, User-models",10,"Interactive Voice Response Systems (IVRS) are popular voice-based systems to access information over the telephone. In developing regions, HCI researchers have shown keen interest in IVRS due to high affordability and reach among rural, poor, and illiterate users. However, IVRS are also notorious for their usability issues. This makes researchers thrive for more usable IVRS. The lack of automated usability testing tools for voice-based systems makes researchers depend on human subjects for testing their proposed IVR systems that are both costly and time-consuming. To address this research gap, we present Maareech, a usability testing tool for voice response systems using XML-based user models. Maareech has a flexible architecture to accommodate different user models that can be used to perform usability tests. In this paper, we discuss Maareech’s architecture and its ability to mimic IVR user behavior based on different user models."
SPRINGERLINK,Chapter,2015,Stochastic Local Search for Falsification of Hybrid Systems,Jyotirmoy DeshmukhXiaoqing JinJames KapinskiOded Maler,"Input Sequence, Input Space, Local Search, Tabu Search, Temporal Logic",10,"Falsification techniques for models of embedded control systems automate the process of testing models to find bugs by searching for model-inputs that violate behavioral specifications given by logical and quantitative correctness requirements. A recent advance in falsification is to encode property satisfaction as a cost function based on a finite parameterization of the (bounded-time) input signal, which allows formulating bug-finding as an optimization problem. In this paper, we present a falsification technique that uses a local search technique called Tabu search to search for optimal inputs. The key idea is to discretize the space of input signals and use the Tabu list to avoid revisiting previously encountered input signals. As local search techniques may converge to local optima, we introduce stochastic aspects such as random restarts, sampling and probabilistically picking suboptimal inputs to guide the technique towards a global optimum. Picking the right parameterization of the input space is often challenging for designers, so we allow dynamic refinement of the input space as the search progresses. We implement the technique in a tool called sitar , and show scalability of the technique by using it to falsify requirements on an early prototype of an industrial-sized automotive powertrain control design."
SPRINGERLINK,Chapter,2015,Model-in-the-Loop Testing of a Railway Interlocking System,Fabio ScippacercolaRoberto PietrantuonoStefano RussoAndrás Zentai,"Model-Driven Engineering, Model-Driven Testing, Safety-critical systems",10,"Model-driven techniques offer new solutions to support development and verification and validation (V&V) activities of software-intensive systems. As they can reduce costs, and ease the certification process as well, they are attractive also in safety-critical domains. We present an approach for Model-in-the-loop testing within an OMG-based model-driven process, aimed at supporting system V&V activities. The approach is based on the definition of a model of the system environment, named Computation Independent Test (CIT) model. The CIT enables various forms of system test, allowing early detection of design faults. We show the benefits of the approach with reference to a pilot project that is part of a railway interlocking system. The system, required to be CENELEC SIL-4 compliant, has been provided by the Hungarian company Prolan Co. in the context of an industrial-academic partnership."
SPRINGERLINK,Chapter,2015,NAT2TEST Tool: From Natural Language Requirements to Test Cases Based on CSP,Gustavo CarvalhoFlávia BarrosAna CarvalhoAna CavalcantiAlexandre MotaAugusto Sampaio,"Natural-language requirements, Test-case generation, Tool",10,"Formal models are increasingly being used as input for automated test-generation strategies. However, typically the requirements are captured as English text, and these formal models are not readily available. With this in mind, we have devised a strategy (NAT2TEST) to obtain formal models from natural language requirements automatically, particularly to generate sound test cases. Our strategy is extensible, since we consider an intermediate and hidden formal characterisation of the system behaviour from which other formal notations can be derived. Here, we present the NAT2TEST tool, which implements our strategy."
SPRINGERLINK,Chapter,2015,LTSmin: High-Performance Language-Independent Model Checking,Gijs KantAlfons LaarmanJeroen MeijerJaco van de PolStefan BlomTom van Dijk,"Language Module, Model Check, State Label, Transition Group, Winning Strategy",10,"In recent years, the LTSmin model checker has been extended with support for several new modelling languages, including probabilistic ( Mapa ) and timed systems ( Uppaal ). Also, connecting additional language front-ends or ad-hoc state-space generators to LTSmin was simplified using custom C-code. From symbolic and distributed reachability analysis and minimisation, LTSmin ’s functionality has developed into a model checker with multi-core algorithms for on-the-fly LTL checking with partial-order reduction, and multi-core symbolic checking for the modal μ calculus, based on the multi-core decision diagram package Sylvan . In LTSmin , the modelling languages and the model checking algorithms are connected through a Partitioned Next-State Interface ( Pins ), that allows to abstract away from language details in the implementation of the analysis algorithms and on-the-fly optimisations. In the current paper, we present an overview of the toolset and its recent changes, and we demonstrate its performance and versatility in two case studies."
SPRINGERLINK,Chapter,2015,Security and Privacy in Vehicular Communications with INTER-TRUST,Juan M. Marín PérezAntonio Moragón JuanJaime Arrazola PérezJavier Monge RabadánAntonio F. Skarmeta Gómez,"AOP, INTER-TRUST, ITS, Policy-based, Privacy, Security",10,"Security systems in Intelligent Transport Systems (ITS) are woefully underprepared for the security threats in the modern landscape. However, the real potential for loss of life in the event of a successful attack makes these systems the more important to protect against such intrusions. In this paper, a new security framework that is the result of the INTER-TRUST European project will be presented and proposed as a solution that could solve most of ITS’s current security problems. The solution provides dynamic and adaptable security with a set of monitoring tools that also enable the adaptation of security to different contexts or situations that makes away with the need to recode the original applications. An overview on ITS security and how specific security features can be provided to ITS applications by deploying the INTER-TRUST framework is analyzed. A proof of concept implementation has been also developed during this research with some experimental results."
SPRINGERLINK,Chapter,2015,Revealing Differences in Anatomical Remodelling of the Systemic Right Ventricle,Ernesto ZacurJames WongReza RazaviTal GevaGerald GreilPablo Lamata,"Computational anatomy, Discriminative analysis, Statistical shape analysis, Systemic right ventricle",10,"Cardiac remodelling, which refers to the change of the shape and size of the myocardium, is an adaptive response to developmental, disease and surgical processes. Traditional metrics of length, volume, aspect ratio or wall thickness are used in the clinic and in medical research, but have limited capabilities to describe complex structures such as the shape of cardiac ventricles. In this work we present an example of how computational analysis of cardiac anatomy can reveal more detailed description of developmental and remodelling patterns. The clinical problem is the analysis of the impact of two different surgical palliation techniques for hypoplastic left heart syndrome. Construction of a computational atlas and the statistical description of its variability are performed from the short axis stack of 128 subjects. Results unveil, for the first time in the literature, the differences in remodelling of the systemic right ventricle depending on the surgical palliation technique."
SPRINGERLINK,Chapter,2015,TDQMed: Managing Collections of Complex Test Data,Johannes HeldRichard Lenz,"Information extraction and integration, Knowledge discovery, Test-data quality",10,"Medical devices like Medical Linear Accelerators (LINAC) are extensively tested before they are used in routine practice. Such systems typically interact with multiple other systems that produce complex input data, like medical images annotated with extensive metadata. Before such a system is actually used in a hospital with real patients it has to be tested with test data as realistic as possible. Suitable test data, however, cannot be easily generated. For this reason vendors typically accumulate large collections of patient files over the years to have them available for various test scenarios. In the TDQMed project we have developed methods and tools that enable a tester to estimate both the quality of a test data collection and its applicability for a particular test goal. A prototype system has been implemented to demonstrate the feasibility of measuring specific test data related quality criteria like coverage of test space and closeness to reality. An evaluation with professional testers indicates that the overall approach is promising."
SPRINGERLINK,Chapter,2015,Rigorous Examination of Reactive Systems:,Maren GeskeMalte IsbernerBernhard Steffen,"Automaton Learning, Internal Logic, Model Check, Symbolic Execution, Verification Task",10,"In this paper we present the RERS challenge 2015, a free-style program analysis challenge on reactive systems to evaluate the effectiveness of different validation and verification techniques. It brings together researchers from different areas including static analysis, model checking, theorem proving, symbolic execution, and testing. The challenge characteristics and set-up are discussed, while special attention is given to the Runtime Verification track that was newly introduced."
SPRINGERLINK,Chapter,2015,Learning Register Automata with Fresh Value Generation,Fides AartsPaul Fiterau-BrosteanHarco KuppensFrits Vaandrager,Expense,10,"We present a new algorithm for active learning of register automata. Our algorithm uses counterexample-guided abstraction refinement to automatically construct a component which maps (in a history dependent manner) the large set of actions of an implementation into a small set of actions that can be handled by a Mealy machine learner. The class of register automata that is handled by our algorithm extends previous definitions since it allows for the generation of fresh output values. This feature is crucial in many real-world systems (e.g. servers that generate identifiers, passwords or sequence numbers). We have implemented our new algorithm in a tool called Tomte."
SPRINGERLINK,Chapter,2015,Testing Business Processes Using TTCN-3,Bernard StepienKavya MallurLiam Peyton,"Business processes, SOA, Testing, TTCN-3",10,Business Process Management (BPM) applications in the medical domain pose challenging testing problems that result from parallel execution of test behaviors performed by different actors. Hospitals nowadays function with the principle of pools of personnel. Each pool addresses a specific functionality and each member of the pool can pick any task that is proposed to the pool. The challenge for BPM testing is in the existence of dependencies between actors and the corresponding test description where the stimuli sent to the BPM that is the system under test (SUT) by one actor produces responses that affect a selected number of other actors belonging to a pool. Unit testing of such systems has proven to be of limited efficiency in detecting faults that can be detected only during parallel execution of test components representing actors. We propose an architecture based on the TTCN-3 model of separation of concern and its intensive parallel test component (PTC) concept which provides solutions that are beyond traditional telecommunication systems testing and which have revealed opportunities for improving TTCN-3.
SPRINGERLINK,Chapter,2015,A Genetic Algorithm for Automatic Business Process Test Case Selection,Kristof BöhmerStefanie Rinderle-Ma,"Genetic algorithm, Process modeling and design, Process testing, Test case selection",10,"Process models tend to become more and more complex and, therefore, also more and more test cases are required to assure their correctness and stability during design and maintenance. However, executing hundreds or even thousands of process model test cases leads to excessive test suite execution times and, therefore, high costs. Hence, this paper presents a novel approach for process model test case selection which is able to address flexible user-driven test case selection requirements and which can integrate a diverse set of knowledge sources to select an appropriate minimal set of test cases which can be executed in minimal time. Additionally, techniques are proposed which enable the representation of unique coverage requirements and effects for each process node and process test case in a comprehensive way. For test case selection, a genetic algorithm is proposed. Its effectiveness is shown in comparison with other test case selection approaches."
SPRINGERLINK,Chapter,2015,Domain-Specific Languages with Scala,Cyrille ArthoKlaus HavelundRahul KumarYoriyuki Yamagata,"DSL, Evaluation, External and internal domain-specific language, Language design, Modeling, Programming, Scala",10,"Domain-Specific Languages (DSLs) are often classified into external and internal DSLs. An external DSL is a stand-alone language with its own parser. An internal DSL is an extension of an existing programming language, the host language, offering the user of the DSL domain-specific constructs as well as the constructs of the host language, thus providing a richer language than the DSL itself. In this paper we report on experiences implementing external as well as internal formal modeling DSLs with the Scala programming language, known in particular for its support for defining DSLs. The modeling languages include monitoring logics, a testing language, and a general purpose SysML inspired modeling language. We present a systematic overview of advantages and disadvantages of each option."
SPRINGERLINK,Chapter,2015,Helping the Tester Get It Right: Towards Supporting Agile Combinatorial Test Design,Anna ZamanskyEitan Farchi,,10,"Combinatorial test design (CTD) is an effective test planning technique that reveals faulty feature interaction in a given system. CTD takes a systematic approach to formally model the system to be tested, and propose test cases ensuring coverage of given conditions or interactions between parameters. In this position paper we propose a framework for supporting agile CTD, a human-centered methodology, which takes into account the human tester’s possible mistakes and supports revision and refinement. In this approach a combinatorial model of the system and test plans are constructed in an incremental and iterative way, providing the tester with the ability to refine and validate the constructions. We propose a formal framework which can be used as a theoretical foundation for the development of agile CTD support tools, and describe a use case of an envisioned tool."
SPRINGERLINK,Chapter,2015,Generating Performance Test Model from Conformance Test Logs,Gusztáv AdamisGábor KovácsGyörgy Réthy,"FSM Learning, Sequential pattern mining, Test model",10,"In this paper, we present a method that learns a deterministic finite state machine from the conformance test logs of a telecommunication protocol; then that machine is used as test model for performance testing. The learning process is in contrast to most theoretical methods automatic; it applies a sequential pattern mining algorithm on the test logs, and uses a recently proposed metric for finding frequent and significant transition sequences. The method aims to help and speed up test model design, and at the same time it may not provide an exact solution, the equivalence of some states may not be proven. In the paper, we show the results of experiments on random machines, and issues and considerations that arise when the method was applied to 3GGP Telephony Application Server test logs."
SPRINGERLINK,Chapter,2014,An Approach to Derive Usage Models Variants for Model-Based Testing,Hamza SamihHélène Le GuenRalf BoguschMathieu AcherBenoit Baudry,"Model-based Testing, Orthogonal Variability Model, Product Line, Requirements, Usage Model, Usage Model Variant",10,"Testing techniques in industry are not yet adapted for product line engineering (PLE). In particular, Model-based Testing (MBT), a technique that allows to automatically generate test cases from requirements, lacks support for managing variability (differences) among a set of related product. In this paper, we present an approach to equip usage models, a widely used formalism in MBT, with variability capabilities. Formal correspondences are established between a variability model, a set of functional requirements, and a usage model. An algorithm then exploits the traceability links to automatically derive a usage model variant from a desired set of selected features. The approach is integrated into the professional MBT tool MaTeLo and is currently used in industry."
SPRINGERLINK,Chapter,2014,Model-Based Testing from Controlled Natural Language Requirements,Gustavo CarvalhoFlávia BarrosFlorian LapschiesUwe SchulzeJan Peleska,"Case grammar, Natural language, Solver, Test case",10,"Model-Based Testing (MBT) techniques usually take as input models that are not available in the very beginning of a development. Therefore, its use is postponed. In this work we present an approach to MBT that takes as input requirements described in a Controlled Natural Language. Initially, the requirements are syntactically analyzed according to a domain specific language for describing system requirements, and their informal semantics is depicted based on the Case Grammar theory. Then, the requirements semantics is automatically represented as a Transition Relation, which provides formal basis for MBT, and test cases are generated with the support of a solver. Our approach was evaluated considering four examples from different domains. Within seconds, our approach generated 94 % of the test vectors manually written by specialists. Moreover, considering a mutant-based strength analysis, our approach yielded a mutation score between 54 % and 98 %."
SPRINGERLINK,Chapter,2014,Model-Based Testing in Cloud Brokerage Scenarios,Mariam KiranAndreas FriesenAnthony J. H. SimonsWolfgang K. R. Schwach,"Cloud Broker, Cloud Service Brokerage, Lifecycle Governance, Model-based Testing, Web Service Testing",10,"In future Cloud ecosystems, brokers will mediate between service providers and consumers, playing an increased role in quality assurance, checking services for functional compliance to agreed standards, among other aspects. To date, most Software-as-a-Service (SaaS) testing has been performed manually, requiring duplicated effort at the development, certification and deployment stages of the service lifecycle. This paper presents a strategy for achieving automated testing for certification and re-certification of SaaS applications, based on the adoption of simple state-based and functional specifications. High-level test suites are generated from specifications, by algorithms that provide the necessary and sufficient coverage. The high-level tests must be grounded for each implementation technology, whether SOAP, REST or rich-client. Two examples of grounding are presented, one into SOAP for a traditional web service and the other into Selenium for a SAP HANA rich-client application. The results demonstrate good test coverage. Further work is required to fully automate the grounding."
SPRINGERLINK,Chapter,2014,Model-Based Testing: An Approach with SDL/RTDS and DIVERSITY,Julien DeltourAlain FaivreEmmanuel GaudinArnault Lapitre,"Model-based testing, SDL, Test generation, TTCN-3",10,"The objective of the PragmaList Lab, a joint laboratory between PragmaDev and CEA LIST, is to integrate the test generation tool DIVERSITY in the SDL modeling environment Real Time Developer Studio (RTDS). The resulting environment aims to extend RTDS with a Model-Based Testing approach. After briefly describing the characteristics of RTDS and DIVERSITY, this paper presents the work done to integrate these two environments. Then, it highlights the main principles of DIVERSITY based on symbolic execution, which enables the generation of test cases in TTCN-3 format. The paper then presents the existing coverage criteria in the integrated generation of test cases. It concludes with the open strategy of the PragmaList approach to work together with industrial actors based on the definition and integration of new specific coverage criteria consistent with their validation constraints."
SPRINGERLINK,Chapter,2014,Environment-Model Based Testing of Control Systems: Case Studies,Erwan JahierSimplice Djoko-DjokoChaouki MaizaEric Lafont,"Black-box testing, Control-command, Dynamic systems, Reactive systems, Requirements engineering, SCADA, Synchronous Languages, Test Booklets",10,"A reactive system reacts to an environment it tries to control. Lurette is a black-box testing tool for such closed-loop systems. It focuses on environment modeling using Lutin, a language designed to perform guided random exploration of the System Under Test (SUT) environment, taking into account the feedback. The test decision is automated using Lustre oracles resulting from the formalisation of functional requirements. In this article, we report on experimentations conducted with Lurette on two industrial case studies. One deals with a dynamic system which simulates the behavior of the temperature and the pressure of a fluid in a pipe. The other one reports on how Lurette can be used to automate the processing of an existing test booklet of a Supervisory Control and Data Acquisition (SCADA) library module."
SPRINGERLINK,Chapter,2014,True Error or False Alarm? Refining Astrée’s Abstract Interpretation Results by Embedded Tester’s Automatic Model-Based Testing,Sayali SalviDaniel KästnerTom BienmüllerChristian Ferdinand,"Abstract Interpretation, Code Fragment, False Alarm, Test Vector, True Error",10,"A failure of safety-critical software may cause high costs or even endanger human beings. Contemporary safety standards require to identify potential functional and non-functional hazards and to demonstrate that the software does not violate the relevant safety goals. Typically for ensuring functional program properties model-based testing is used while non-functional properties like occurrence of runtime errors are addressed by abstract interpretation-based static analysis. Hence the verification process is split into two distinct parts – currently without any synergy between them being exploited. In this article we present an approach to couple model-based testing with static analysis based on a tool coupling between Astrée and BTC Embedded Tester ® . Astrée reports all potential runtime errors in C programs. This makes it possible to prove the absence of runtime errors, but typically users have to deal with false alarms, i.e. spurious notifications about potential runtime errors. Investigating alarms to find out whether they are true errors which have to be fixed, or whether they are false alarms can cause significant effort. The key idea of this work is to apply model-based testing to automatically find test cases for alarms reported by the static analyzer. When a test case reproducing the error has been found, it has been proven that it is a true error; when no error has been found with full test coverage, it has been proven to be a false alarm. This can significantly reduce the alarm analysis effort and reduces the level of expertise needed to perform the code-level software verification. We describe the underlying concept and report on experimental results and future work."
SPRINGERLINK,Chapter,2014,Model-Based Shrinking for State-Based Testing,Pieter KoopmanPeter AchtenRinus Plasmeijer,,10,Issues found in model-based testing of state-based systems are traces produced by the system under test that are not allowed by the model used as specification. It is usually easier to determine the error behind the reported issue when there is a short trace revealing the issue. Our model-based test system treats the system under test as a black box. Hence the test system cannot use internal information from the system under test to find short traces. This paper shows how the model can be used to systematically search for shorter traces producing an issue based on some trace revealing an issue.
SPRINGERLINK,Chapter,2014,Risk-Based Vulnerability Testing Using Security Test Patterns,Julien BotellaBruno LegeardFabien PeureuxAlexandre Vernotte,"CORAS, Model-Based Testing, Risk-Based Testing, Security test pattern, SQL Injection, Web application vulnerability",10,"This paper introduces an original security testing approach guided by risk assessment, by means of risk coverage, to perform and automate vulnerability testing for Web applications. This approach, called Risk-Based Vulnerability Testing, adapts Model-Based Testing techniques, which are mostly used currently to address functional features. It also extends Model-Based Vulnerability Testing techniques by driving the testing process using security test patterns selected from risk assessment results. The adaptation of such techniques for Risk-Based Vulnerability Testing defines novel features in this research domain. In this paper, we describe the principles of our approach, which is based on a mixed modeling of the System Under Test: the model used for automated test generation captures some behavioral aspects of the Web applications, but also includes vulnerability test purposes to drive the test generation process."
SPRINGERLINK,Chapter,2014,Complete Model-Based Equivalence Class Testing for the ETCS Ceiling Speed Monitor,Cécile BraunsteinAnne E. HaxthausenWen-ling HuangFelix HübnerJan PeleskaUwe SchulzeLinh Vu Hong,"Ceiling Speed Monitoring, Equivalence class partition testing, European Train Control System ETCS, Model-based testing, SysML",10,"In this paper we present a new test model written in SysML and an associated blackbox test suite for the Ceiling Speed Monitor (CSM) of the European Train Control System (ETCS). The model is publicly available and intended to serve as a novel benchmark for investigating new testing theories and comparing the capabilities of model-based test automation tools. The CSM application inputs velocity values from a domain which could not be completely enumerated for test purposes with reasonable effort. We therefore apply a novel method for equivalence class testing that – despite the conceptually infinite cardinality of the input domains – is capable to produce finite test suites that are complete (i.e. sound and exhaustive) for a given fault model. In this paper, an overview of the model and the equivalence class testing strategy is given, and tool-based evaluation results are presented. For the technical details we refer to the published model and a technical report that is also available on the same website."
SPRINGERLINK,Chapter,2014,A Model-Based Certification Framework for the EnergyBus Standard,Alexander Graf-BrillHolger HermannsHubert Garavel,"Battery Pack, Energy Management System, Model Check, Test Execution, Test Graph",10,"The EnergyBus is an upcoming industrial standard for electric power transmission and management, based on the CANopen field bus. This paper reviews the particularities of the EnergyBus architecture and reports on the application of formal methods and protocol engineering tools to build a model-based conformance testing framework that is considered to become part of the certification process for EnergyBus-compliant products."
SPRINGERLINK,Chapter,2014,Evaluating Normalization Functions with Search Algorithms for Solving OCL Constraints,Shaukat AliTao Yue,"Empirical evaluation, Model-Based Testing, OCL, Search Algorithm, Test data",10,"The use of search algorithms requires the definition of a fitness function that guides the algorithms to find an optimal solution. The definition of a fitness function may require the use of a normalization function for various purposes such as assigning equal importance to various factors constituting a fitness function and normalizing only one factor of a fitness function to give it less/more importance than the others. In our previous work, we defined various branch distance functions (a commonly used heuristic in the literature at the code-level) corresponding to the constructs defined in the Object Constraint Language (OCL) to solve OCL constraints to generate test data for supporting automated Model-Based Testing (MBT). The definition of several of these distance functions required the use of a normalization function. In this paper, we extend the empirical evaluation reported in one of the works in the literature that compares the impact of using various normalization functions for calculating branch distances at the code-level on the performance of search algorithms. The empirical evaluation reported in this paper assesses the impact of the commonly used normalization functions for the branch distance calculation of OCL constraints at the model-level. Results show that for one of the newly studied algorithms Harmony Search (HS) and Random Search (RS), the use of the normalization functions has no impact on the performance of the search. However, HS achieved 100% success rates for all the problems, where RS obtained very poor success rates (less than 38%). Based on the results, we conclude that the randomness in creating a solution in search algorithms may mask the impact of using a normalization function."
SPRINGERLINK,Chapter,2014,Insights on the Use of OCL in Diverse Industrial Applications,Shaukat AliTao YueMuhammad Zohaib IqbalRajwinder Kaur Panesar-Walawege,"Constraint Parsing, Constraint Solving, Industrial Applications, Object Constraint Language",10,"The Object Constraint Language (OCL) is a widely accepted language, standardized by OMG, for specifying constraints at various meta levels (e.g., meta-models and models). Despite its wide acceptance, there is a lack of understanding about terminology and purposes for which OCL can be used. In this paper, we aim to reduce this gap and provide guidance for applying OCL in practical contexts and we report our experience of applying OCL for different industrial projects in diverse domains: Communications and Control, Oil and Gas production, Energy Equipment and Services, and Recycling. Based on our experience, first, we unify the commonly used terminology in the literature for applying OCL in different ways for addressing diverse industrial problems. Second, we report the key results of the industrial application of OCL. Finally, we provide guidance to researchers and practitioners for choosing an appropriate meta level and purpose for their specific industrial problem at hand."
SPRINGERLINK,Chapter,2014,A Functional Verification of a Web Voting System,Maximiliano CristiáClaudia Frydman,"Generate Test Case, Proof Obligation, Proof Script, Requirement Document, Vote System",10,"The Consejo Nacional de Investigaciones Científicas y Técni-cas (CONICET) is the most important research institution in Argentina. Its internal authorities are elected by around 8,000 researches across the country. During 2011 the CONICET developed a web voting system to replace the traditional mail-based system. In this paper we present the verification process conducted to assess the functional correctness of the voting system. This process is the result of integrating automatic and semi-automatic verification activities from formal proof to code inspection and model-based testing."
SPRINGERLINK,Chapter,2014,Back-To-Back Testing of Model-Based Code Generators,Sven JörgesBernhard Steffen,"Code Generator, Source Language, System Under Test, Test Vector, Testing Approach",10,"In this paper, we present the testing approach of the Genesys code generator framework. The employed approach is based on back-to-back-testing, which tests the translation performed by a code generator from a semantic perspective rather than just checking for syntactic correctness of the generation result. We describe the basic testing framework and show that it scales in three dimensions: parameterized tests, testing across multiple target platforms and testing on multiple meta-levels. In particular, the latter is only possible due to the fact that Genesys code generators are constructed as models. Furthermore, in order to facilitate simplicity, Genesys consistently employs one single notation for all artifacts involved in this testing approach: Test data, test cases, the code generators under test, and even the testing framework itself are all modeled using the same graphical modeling language."
SPRINGERLINK,Chapter,2014,A Systematic Approach to Requirements Driven Test Generation for Safety Critical Systems,Toby WilkinsonMichael ButlerJohn Colley,"Event-B, Safety Critical Systems, STPA, Test Generation",10,"We describe ongoing work into the generation of test cases for safety critical systems using Event-B and the Rodin toolset. Verification of software to DO-178C is a two stage process. First a suite of test cases must be validated against the system requirements (requirements coverage), and then the software implementation is verified using the validated test suite. During verification of the implementation structural coverage is also measured. Our work focuses on the first step, the generation of test cases and their validation against the requirements. We construct closed-system models incorporating both the system to be tested and its environment. These models capture the system requirements, and describe the interactions between the system and its environment. In particular, safety constraints can be represented by invariants, and their preservation ensured through event guards. From these models test cases can be generated, and requirements coverage can be measured from model coverage."
SPRINGERLINK,Chapter,2014,Active Learning of Nondeterministic Systems from an ioco Perspective,Michele VolpatoJan Tretmans,,10,"Model-based testing allows the creation of test cases from a model of the system under test. Often, such models are difficult to obtain, or even not available. Automata learning helps in inferring the model of a system by observing its behaviour. The model can be employed for many purposes, such as testing other implementations, regression testing, or model checking. We present an algorithm for active learning of nondeterministic, input-enabled, labelled transition systems, based on the well known Angluin’s L  ⋆  algorithm. Under some assumptions, for dealing with nondeterminism, input-enabledness and equivalence checking, we prove that the algorithm produces a model whose behaviour is equivalent to the one under learning. We define new properties for the structure used in the algorithm, derived from the semantics of labelled transition systems. Such properties help the learning, by avoiding to query the system under learning when it is not necessary."
SPRINGERLINK,Chapter,2014,Generating Test Data from a UML Activity Using the AMPL Interface for Constraint Solvers,Felix KurthSibylle SchuppStephan Weißleder,"Activity Diagram, AMPL, Boundary Value Analysis, Constraint Solving, Infeasible Path Elimination, Mixed Integer Non–Linear Programming, Model–Based Testing",10,"Testing is one of the most wide-spread means for quality assurance. Modelling and automated test design are two means to improve effectivity and efficiency of testing. In this paper, we present a method to generate test data from UML activity diagrams and OCL constraints by combining symbolic execution and state–of–the–art constraint solvers. Our corresponding prototype implementation is integrated in the existing test generator ParTeG and generates C++ unit tests. Our key improvement is the transparent use of multiple industry strength solvers through a common interface; this allows the user to choose between an expressive constraint language or highly optimised test data generation. We use infeasible path elimination to improve the performance of test generation and boundary value analysis to improve the quality of the generated test data. We provide an industrial case study and measure the performance of our tool using different solvers in several scenarios."
SPRINGERLINK,Chapter,2014,The Relevance of Model-Driven Engineering Thirty Years from Now,Gunter MussbacherDaniel AmyotRuth BreuJean-Michel BruelBetty H. C. ChengPhilippe ColletBenoit CombemaleRobert B. FranceRogardt HeldalJames HillJörg KienzleMatthias SchöttleFriedrich SteimannDave StikkolorumJon Whittle,"challenges, Model-driven engineering, research opportunities",10,"Although model-driven engineering (MDE) is now an established approach for developing complex software systems, it has not been universally adopted by the software industry. In order to better understand the reasons for this, as well as to identify future opportunities for MDE, we carried out a week-long design thinking experiment with 15 MDE experts. Participants were facilitated to identify the biggest problems with current MDE technologies, to identify grand challenges for society in the near future, and to identify ways that MDE could help to address these challenges. The outcome is a reflection of the current strengths of MDE, an outlook of the most pressing challenges for society at large over the next three decades, and an analysis of key future MDE research opportunities."
SPRINGERLINK,Chapter,2014,Pragmatic Approach to Test Case Reuse - A Case Study in Android OS BiDiTests Library,Suriya Priya R. AsaithambiStan Jarzabek,"Android Platform Test Libraries, Mobile Platform, Reusability, Software Testing, Test Clones, Test Construction Approach, Test Libraries",10,"Test libraries explode in size, but both practitioners and researchers report much redundancy among test cases. Similar functions require similar test cases. Redundancy may be particularly overwhelming in test libraries for mobile computing, where we need to test the same functionality implemented on various models/brands of mobile phones. Redundancies create reuse opportunities. We propose a generic adaptive test template (GATT) approach to contain explosion of test libraries by reusing common recurring test patterns instead of enumerating the same test case in many variant forms. The objective is to ease the test development and maintenance effort. The process starts with automated detection of test clones. We represent a group of similar test cases by a test template along with specifications for automated generation of test cases in a group. We illustrate GATT with examples from Android OS test libraries, and evaluate its benefits and trade-offs. The approach scales to large test libraries and is oblivious to application domains or programming languages. GATT is practical as it focuses on managing test libraries without affecting the follow up test execution. Therefore, it smoothly blends with any other existing techniques and tools used for testing."
SPRINGERLINK,Chapter,2014,"Security Testing Approaches – For Research, Industry and Standardization",Axel RennochIna SchieferdeckerJürgen Großmann,"Fuzzing, Model-based security testing, Risk analysis, Test automation",10,"Recently, in the Security testing domain a lot of knowledge has been collected from a significant amount of research. The contribution provides an introduction to advanced security testing methods and techniques in the context of European research and standardization projects. This includes numerous guidelines and best practices that have been identified and are applied in the context of industrial case studies. In particular it addresses risk modeling, security test pattern, functional security tests as well as fuzz testing, as important contributions to systematic, automatized test approaches in research, industry and standardization."
SPRINGERLINK,Chapter,2014,A Trace Management Platform for Risk-Based Security Testing,Jürgen GroßmannMichael BergerJohannes Viehmann,"Query Interpreter, Security Testing, Test Pattern, Trace Link, Trace Management",10,"The goal of risk-based security testing is to improve the security testing process in order to cover especially risky areas of the application under test and at the same time minimize the time to market and to improve the use of resources by focusing testing work on areas with the highest risks. In RBST risk factors are identified and risk-based security test cases are created and prioritized according to an applicable selection strategy. One of the challenges in RBST is to keep track of the different artifacts that are often managed by different tools. Traceability is the key to manage complex systems in development and testing. This paper introduces RISKTest , a trace management platform on the basis of Eclipse that supports the creation and documentation of cross-tool relations during test development and test execution. RISKTest is dedicated to risk-based security testing. Thus, we concentrate on the management of traces between the artifacts from risk assessment and testing and the definitions of services that automatically analyze the related artifacts for security and testing related aspects. RISKTest has been developed in the DIAMONDS and RASEN projects and evaluated within the project’s case studies."
SPRINGERLINK,Chapter,2014,The FITTEST Tool Suite for Testing Future Internet Applications,Tanja E. J. VosPaolo TonellaI. S. Wishnu B. PrasetyaPeter M. KruseOnn ShehoryAlessandra BagnatoMark Harman,"Audit Testing, Service Composition, System Under Test, Test Case Generation, Test Case Prioritization",10,"Future Internet applications are expected to be much more complex and powerful, by exploiting various dynamic capabilities For testing, this is very challenging, as it means that the range of possible behavior to test is much larger, and moreover it may at the run time change quite frequently and significantly with respect to the assumed behavior tested prior to the release of such an application. The traditional way of testing will not be able to keep up with such dynamics. The Future Internet Testing (FITTEST) project ( http://crest.cs.ucl.ac.uk/fittest/ ), a research project funded by the European Commission (grant agreement n. 257574) from 2010 till 2013, was set to explore new testing techniques that will improve our capacity to deal with the challenges of testing Future Internet applications. Such techniques should not be seen as replacement of the traditional testing, but rather as a way to complement it. This paper gives an overview of the set of tools produced by the FITTEST project, implementing those techniques."
SPRINGERLINK,Chapter,2014,Acceptance Test Optimization,Mohamed MussaFerhat Khendek,"Acceptance testing, Integration testing, Model Based Testing, Sequence diagrams, Test optimization",10,"Test case generation and execution may be time and effort consuming. At a given testing phase, test case execution can be optimized by avoiding the consideration of test cases that have already been exercised in a previous phase. For instance, one can avoid test case redundancy between integration testing and acceptance testing. Characterizing this redundancy is not straightforward since some integration test cases are applied on an incomplete system with test stubs emulating system components and therefore cannot be substituted to acceptance test cases. In this paper, we propose an approach that maps acceptance test cases to integration test cases and eliminates test cases that have already been exercised on the system during the integration testing phase."
SPRINGERLINK,Chapter,2014,Distinguishing Sequences for Partially Specified FSMs,Robert M. HieronsUraz Cengiz Türker,"Conformance Testing, Distinguishing Sequence, Finite State Machine, Input Sequence, Polynomial Space",10,"Distinguishing Sequences (DSs) are used inmany Finite State Machine (FSM) based test techniques. Although Partially Specified FSMs (PSFSMs) generalise FSMs, the computational complexity of constructing Adaptive and Preset DSs (ADSs/PDSs) for PSFSMs has not been addressed. This paper shows that it is possible to check the existence of an ADS in polynomial time but the corresponding problem for PDSs is PSPACE-complete . We also report on the results of experiments with benchmarks and over 8 ∗ 10 6 PSFSMs."
SPRINGERLINK,Chapter,2014,A Systematic Approach to Automatically Derive Test Cases from Use Cases Specified in Restricted Natural Languages,Man ZhangTao YueShaukat AliHuihui ZhangJi Wu,"Natural Language, Restricted Test Case Specification, Restricted Use Case Modeling, Test Case Specification, Test Cases, Test Generation, Transformation and Automation, Use Cases",10,"In many domains, such as avionics, oil and gas, and maritime, a common practice is to derive and execute test cases manually from requirements, where both requirements and test cases are specified in natural language (NL) by domain experts. The manual execution of test cases is largely dependent on the domain experts who wrote the test cases. The process of manual writing of requirements and test cases introduces ambiguity in their description and, in addition, test cases may not be effective since they may not be derived by systematically applying coverage criteria. In this paper, we report on a systematic approach to support automatic derivation of manually executable test cases from use cases. Both use cases and test cases are specified in restricted NLs along with carefully-defined templates implemented in a tool. We evaluate our approach with four case studies (in total having 30 use cases and 579 steps from flows of events), two of which are industrial case studies from the oil/gas and avionics domains. Results show that our tool was able to correctly process all the case studies and systematically (by following carefully-defined structure coverage criteria) generate 30 TCSs and 389 test cases. Moreover, our approach allows defining different test coverage criteria on requirements other than the one already implemented in our tool."
SPRINGERLINK,Chapter,2014,On the Usage of TGGs for Automated Model Transformation Testing,Martin WieberAnthony AnjorinAndy Schürr,"Eclipse Modelling Framework, Graph Grammar, Model Transformation, System Under Test, Test Suite",10,"As model transformations are fundamental to model-driven engineering, assuring their quality is a central task which can be achieved by testing with sufficiently adequate and large test suites. As the latter requirement can render manual testing prohibitively costly in practice, a high level of automation is advisable. Triple Graph Grammars (TGGs) have been shown to provide a promising solution to this challenge as not only test case generators , but also generic test oracles can be derived from them. It is, however, unclear if such generated test suites are indeed adequate and, as different strategies can be used to steer the test generation process, a systematic means of comparing and evaluating such test suites and strategies is required. In this paper, we extend existing work on TGG-based testing by(i) presenting a generic framework for TGG-based testing, (ii) describing a concrete instantiation of this framework with our TGG tool eMoflon, and (iii) exploring how the well-known technique of mutation analysis can be used to evaluate a set of test generation strategies by analyzing the generated test suites."
SPRINGERLINK,Chapter,2014,Distributed Testing of Concurrent Systems: Vector Clocks to the Rescue,Hernán Ponce-de-LeónStefan HaarDelphine Longuet,"Concurrent System, Conformance Testing, Local Clock, System Under Test, Time Stamp",10,"The ioco relation has become a standard in model-based conformance testing. The co-ioco conformance relation is an extension of this relation to concurrent systems specified with true-concurrency models. This relation assumes a global control and observation of the system under test, which is not usually realistic in the case of physically distributed systems. Such systems can be partially observed at each of their points of control and observation by the sequences of inputs and outputs exchanged with their environment. Unfortunately, in general, global observation cannot be reconstructed from local ones, so global conformance cannot be decided with local tests. We propose to append time stamps to the observable actions of the system under test in order to regain global conformance from local testing."
SPRINGERLINK,Chapter,2014,An Abstraction Technique for Testing Decomposable Systems by Model Checking,Paolo ArcainiAngelo GargantiniElvinia Riccobene,"Computation Tree Logic, Kripke Structure, Linear Temporal Logic, Model Check, Test Generation",10,"Test generation by model checking exploits the capability of model checkers to return counterexamples upon property violations. The approach suffers from the state explosion problem of model checking. For property verification, different abstraction techniques have been proposed to tackle this problem. However, such techniques are not always suitable for test generation. In this paper we focus on Decomposable by Dependency Asynchronous Parallel (DDAP) systems, composed by several subsystems running in parallel and connected together in a way that the inputs of one subsystem are provided by another subsystem. We propose a test generation approach for DDAP systems based on a decompositional abstraction that considers one subsystem at a time. It builds tests for the single subsystems and combines them later in order to obtain a global system test. Such approach avoids the exponential increase of the test generation time and memory consumption. The approach is proved to be sound, but not complete."
SPRINGERLINK,Chapter,2014,An Evaluation of the Effectiveness of the Atomic Section Model,Sunitha ThummalaJeff Offutt,"Atomic section modeling, Model based testing, Test criteria, Web applications",10,"Society increasingly depends on web applications for business and pleasure. As the use of web applications continues to increase, the number of failures, some minor and some major, continues to grow. A significant problem is that we still have relatively weak abilities to test web applications. Traditional testing techniques do not adequately model or test these novel technologies. The atomic section model (ASM), models web applications to support design, analysis, and testing. This paper presents an empirical study to evaluate the effectiveness of the ASM. The model was implemented into a tool, WASP, which extracts the ASM from the implementation and supports various test criteria. We studied ten web applications, totaling 156 components and 11,829 lines of code. Using WASP, we generated 207 tests, which revealed 31 faults.Seventeen of those faults exposed internal information about the application and server."
SPRINGERLINK,Chapter,2014,Formalizing DSL Semantics for Reasoning and Conformance Testing,Sarmen KeshishzadehArjan J. Mooij,"Code Generation, Conformance Testing, Domain Specific Language (DSL), Model-based Testing, Semantics",10,"A Domain Specific Language (DSL) focuses on the essential concepts in a certain problem domain, thus abstracting from low-level implementation details. In combination with code generators, DSLs bring software development closer to domain requirements. The development of DSLs usually centers around the grammar and a code generator; there is little attention for the semantics of the DSL. However, a formal semantics is essential for reasoning about specifications in terms of the DSL (i.e., DSL instances). We argue that the semantics should be expressed independent of a code generator. Thus semantic issues can be revealed that could otherwise remain undetected. We also use the semantics to define the conformance of an implementation to a DSL instance, and to automatically test conformance of the (generated) implementation code to a DSL instance. We illustrate our approach using an industrial prototype DSL for collision prevention."
SPRINGERLINK,Chapter,2014,On the Complexity of Input Output Conformance Testing,Neda NorooziMohammad Reza MousaviTim A. C. Willemse,"Input Output Transition Systems, Interface Automata, Ioco Testing Theory, Model-based Testing, Suspension Traces",10,"Input-output conformance (ioco) testing is a well-known approach to model-based testing. In this paper, we study the complexity of checking ioco. We show that the problem of checking ioco is PSPACE-complete. To provide a more efficient algorithm, we propose a more restricted setting for checking ioco, namely with deterministic models and show that in this restricted setting ioco checking can be performed in polynomial time."
SPRINGERLINK,Chapter,2014,Twenty-Five Years of Formal Methods and Railways: What Next?,Alessandro Fantechi,"Automatic Code Generation, Formal Method, Formal Verification, Model Check, Software Model Check",10,"Since more than 25 years, railway signalling is the subject of successful industrial application of formal methods in the development and verification of its computerized equipment. However the evolution of the technology of railways signalling systems in this long term has had a strong influence on the way formal methods can be applied in their design and implementation. At the same time important advances had been also achieved in the formal methods area. The scope of the formal methods discipline has enlarged from the methodological provably correct software construction of the beginnings to the analysis and modelling of increasingly complex systems, always on the edge of the ever improving capacity of the analysis tools, thanks to the technological advances in formal verification of both qualitative and quantitative properties of such complex systems. The thesis we will put forward in this paper is that the complexity of future railway systems of systems can be addressed with advantage only by a higher degree of distribution of functions on local interoperable computers - communicating by means of standard protocols - and by adopting a multi-level formal modelling suitable to support the verification at different abstraction levels, and at different life-cycle times, of the safe interaction among the distributed functions."
SPRINGERLINK,Chapter,2014,Minimum Number of Test Paths for Prime Path and Other Structural Coverage Criteria,Anurag DwarakanathAruna Jankiti,"Minimum Flow, Minimum Number of Test Paths, Model Based Testing, Prime Path Coverage",10,"The software system under test can be modeled as a graph comprising of a set of vertices, V and a set of edges, E . Test Cases are Test Paths over the graph meeting a particular test criterion. In this paper, we present a method to achieve the minimum number of Test Paths needed to cover different structural coverage criteria. Our method can accommodate Prime Path, Edge-Pair, Simple & Complete Round Trip, Edge and Node coverage criteria. Our method obtains the optimal solution by transforming the graph into a flow graph and solving the minimum flow problem. We present an algorithm for the minimum flow problem that matches the best known solution complexity of $ O\left(\left\vert{V}\right\vert\left\vert{E}\right\vert\right)$ . Our method is evaluated through two sets of tests. In the first, we test against graphs representing actual software. In the second test, we create random graphs of varying complexity. In each test we measure the number of Test Paths, the length of Test Paths, the lower bound on minimum number of Test Paths and the execution time."
SPRINGERLINK,Chapter,2014,Modeling and Analyzing Using ASMs: The Landing Gear System Case Study,Paolo ArcainiAngelo GargantiniElvinia Riccobene,"Abstract State Machine, Computation Tree Logic, Ground Model, Monitor Function, Transition Rule",10,"The paper presents an Abstract State Machine (ASM) specification of the Landing Gear System case study, and shows how the ASMETA framework can be used to support the modeling and analysis (validation and verification) activities for developing a rigorous and correct model in terms of ASMs. We exploit the two fundamental concepts of the ASM method, i.e., the notion of ground model and the refinement principle, and we achieve model development and model analysis by the combined use of formal methods for specification and for verification."
SPRINGERLINK,Chapter,2014,Using CP in Automatic Test Generation for ABB Robotics’ Paint Control System,Morten MossigeArnaud GotliebHein Meling,"Constraint Programming, Global Constraint, Process Control System, Test Execution, Test Scenario",10,"Designing industrial robot systems for welding, painting, and assembly, is challenging because they are required to perform with high precision, speed, and endurance. ABB Robotics has specialized in building highly reliable and safe robotized paint systems based on an integrated process control system . However, current validation practices are primarily limited to manually designed test scenarios. A tricky part of this validation concerns testing the timing aspects of the control system, which is particularly challenging for paint robots that need to coordinate paint activation with the robot motion control. To overcome these challenges, we have developed and deployed a costeffective, automated test generation technique based on Constraint Programming, aimed at validating the timing behavior of the process control system. We designed a constraint optimization model in SICStus Prolog, using arithmetic and logic constraints including use of global constraints. This model has been integrated into a fully automated continuous integration environment, allowing the model to be solved on demand prior to test execution, which allows us to obtain the most optimal and diverse set of test scenarios for the present system configuration. After three months of daily operational use of the constraint model in our testing process, we have collected data on its performance and bug finding capabilities. We report on these aspects, along with our experiences and the improvements gained by the new testing process."
SPRINGERLINK,Chapter,2014,The TTT Algorithm: A Redundancy-Free Approach to Active Automata Learning,Malte IsbernerFalk HowarBernhard Steffen,"Finite Automaton, Membership Query, Model Check, Observation Table, Symbol Execution",10,"In this paper we present TTT, a novel active automata learning algorithm formulated in the Minimally Adequate Teacher (MAT) framework. The distinguishing characteristic of TTT is its redundancy-free organization of observations, which can be exploited to achieve optimal (linear) space complexity. This is thanks to a thorough analysis of counterexamples, extracting and storing only the essential refining information. TTT is therefore particularly well-suited for application in a runtime verification context, where counterexamples (obtained, e.g., via monitoring) may be excessively long: as the execution time of a test sequence typically grows with its length, this would otherwise cause severe performance degradation. We illustrate the impact of TTT’s consequent redundancy-free approach along a number of examples."
SPRINGERLINK,Chapter,2014,Software Quality Testing Model for Mobile Application,Zhenyu LiuYun HuLizhi Cai,,10,"With the rapid development of the network technology, intelligent device and mobile applications has been the developed fastly. The mobile device will increasingly widely used even replace the traditional computer, the application test for mobile Internet was put on the agenda. From this paper, the characteristics of mobile applications are analyzed. The paper proposed quality model and quality attributes corresponding to testing requirements for mobile applications under mobile Internet. Also relevant properties testing techniques and methods is given to pay attention during the test from different test view, which indicating that the quality of the final model could be effective for mobile applications."
SPRINGERLINK,Chapter,2014,Fomal Methods and Analyses in Software Product Line Engineering,Ina SchaeferMaurice H. ter Beek,"Coverage Criterion, Delta Module, Formal Method, Label Transition System, Software Product Line",10,"Software product line engineering (SPLE) [5,11] aims to develop a family of software-intensive systems via systematic, large-scale reuse in order to reduce time-to-market and costs and to increase the quality of individual products. In order to achieve these goals, formal methods offer promising analysis techniques, which are best applied throughout the product-line lifecycle so as to maximize their overall efficiency and effectiveness."
SPRINGERLINK,Chapter,2014,Learning Extended Finite State Machines,Sofia CasselFalk HowarBengt JonssonBernhard Steffen,"Data Language, Data Word, Priority Queue, Root Location, Symbolic Execution",10,"We present an active learning algorithm for inferring extended finite state machines (EFSM)s, combining data flow and control behavior. Key to our learning technique is a novel learning model based on so-called tree queries . The learning algorithm uses the tree queries to infer symbolic data constraints on parameters, e.g., sequence numbers, time stamps, identifiers, or even simple arithmetic. We describe sufficient conditions for the properties that the symbolic constraints provided by a tree query in general must have to be usable in our learning model. We have evaluated our algorithm in a black-box scenario, where tree queries are realized through (black-box) testing. Our case studies include connection establishment in TCP and a priority queue from the Java Class Library."
SPRINGERLINK,Chapter,2014,Test Coverage Estimation Using Threshold Accepting,Thao DangNoa Shalev,,10,"This paper is concerned with model-based testing of hybrid systems. In our previous work [6], we proposed a test generation algorithm, called gRRT, guided by a coverage measure defined using the star discrepancy notion. An important ingredient in this algorithm is a procedure for dynamically estimating the coverage, which is done based on a box partition of the continuous state space. The goal of this estimation is to identify the areas in the state space which have not been sufficiently visited. A drawback of this guiding method is that its complexity depends on the number of the boxes in the partition, which needs to be fine enough to guarantee a good coverage estimate. Thus in high dimensions the method can become very costly. To enhance the scalability of the algorithm gRRT we propose in this paper a new guiding method, motivated by the observation that trying to optimize the coverage in each exploration step is, on one hand, computationally costly, and on the other hand, not always a good choice since this may make the system try to expand in the directions which are not reachable (due to the controllability of the system). Instead of considering all the boxes in the partition, we propose to use a randomized search to quickly find a region that yields a high local discrepancy value. This randomized search is based on threshold accepting, a well-known integer optimization heuristic. We also present some experimental results obtained on a challenging circuit benchmark and a number of randomly generated examples, which shows that the new guiding method allows achieving better time and coverage efficiency."
SPRINGERLINK,Chapter,2014,An Expressive Semantics of Mocking,Josef SvenningssonHans SvenssonNicholas SmallboneThomas ArtsUlf NorellJohn Hughes,,10,"We present a semantics of mocking, based on a process calculus-like formalism, and an associated mocking framework. We can build expressive mocking specifications from a small, orthogonal set of operators. Our framework detects and rejects ambiguous specifications as a validation measure. We report our experience testing software components for the car industry, which needed the full power of our framework."
SPRINGERLINK,Chapter,2014,A TASM-Based Requirements Validation Approach for Safety-Critical Embedded Systems,Jiale ZhouYue LuKristina Lundqvist,"Brake Force, Brake Pedal, Execution Semantic, Model Check, Requirement Validation",10,"Requirements validation is an essential activity to carry out in the system development life cycle, and it confirms the completeness and consistency of requirements through various levels. Model-based formal methods can provide a cost-effective solution to requirements validation in a wide range of domains such as safety-critical applications. In this paper, we extend a formal language Timed Abstract State Machine (TASM) with two newly defined constructs Event and Observer , and propose a novel requirements validation approach based on the extended TASM. Specifically, our approach can: 1) model both functional and non-functional (e.g. timing and resource consumption) requirements of the system at different levels and, 2) perform requirements validation by utilizing our developed toolset and a model checker. Finally, we demonstrate the applicability of our approach in real world usage through an industrial case study of a Brake-by-Wire system."
SPRINGERLINK,Chapter,2014,Domain-Specific Code Generator Modeling: A Case Study for Multi-faceted Concurrent Systems,Stefan NaujokatLouis-Marie TraonouezMalte IsbernerBernhard SteffenAxel Legay,"Code Generator, Eclipse Modeling Framework, Graphical Editor, Label Transition System, Markov Decision Process",10,"In this paper we discuss an elaborate case study utilizing the domain-specific development of code generators within the Cinco meta tooling suite. Cinco is a framework that allows for the automatic generation of a wide range of graphical modeling tools from an abstract high-level specification. The presented case study makes use of Cinco to rapidly construct custom graphical interfaces for multi-faceted, concurrent systems, comprising non-functional properties like time, probability, data, and costs. The point of this approach is to provide user communities and their favorite tools with graphical interfaces tailored to their specific needs. This will be illustrated by generating graphical interfaces for timed automata (TA), probabilistic timed automata (PTA), Markov decision processes (MDP) and simple labeled transition systems (LTS). The main contribution of the presented work, however, is the metamodel-based domain-specific construction of the corresponding code generators for the verification tools Uppaal , Spin , Plasma-lab , and Prism ."
SPRINGERLINK,Chapter,2014,IncQuery-D: A Distributed Incremental Model Query Framework in the Cloud,Gábor SzárnyasBenedek IzsóIstván RáthDénes HarmathGábor BergmannDániel Varró,"Graph Database, Model Query, Query Evaluation, Resource Description Framework, SPARQL Query",10,"Queries are the foundations of data intensive applications. In model-driven software engineering (MDE), model queries are core technologies of tools and transformations. As software models are rapidly increasing in size and complexity, traditional tools exhibit scalability issues that decrease productivity and increase costs [17]. While scalability is a hot topic in the database community and recent NoSQL efforts have partially addressed many shortcomings, this happened at the cost of sacrificing the ad-hoc query capabilities of SQL. Unfortunately, this is a critical problem for MDE applications due to their inherent workload complexity. In this paper, we aim to address both the scalability and ad-hoc querying challenges by adapting incremental graph search techniques – known from the EMF-IncQuery framework – to a distributed cloud infrastructure. We propose a novel architecture for distributed and incremental queries, and conduct experiments to demonstrate that IncQuery-D , our prototype system, can scale up from a single workstation to a cluster that can handle very large models and complex incremental queries efficiently."
SPRINGERLINK,Chapter,2014,Tutorial: Automata Learning in Practice,Falk HowarMalte IsbernerBernhard Steffen,"Automaton Learning, Lower Common Ancestor, Membership Query, Regular Language, Span Tree",10,"The paper reviews active automata learning with a particular focus on sources of redundancy. In particular, it gives an intuitive account of TTT, an algorithm based on three tree structures which concisely capture all the required information. This guarantees minimal memory consumption and it drastically reduces the length of membership queries, in particular in application scenarios like monitoring-based learning, where long counter examples arise. The essential steps and the impact of TTT are illustrated via experimentation with LearnLib , a free, open source Java library for active automata learning."
SPRINGERLINK,Chapter,2014,Integrity Assurance for Outsourced Databases without DBMS Modification,Wei WeiTing Yu,"Data Integrity, Database Outsourcing, Radix-Path Identifier",10,"Database outsourcing has become increasingly popular as a cost-effective solution to provide database services to clients. Previous work proposed different approaches to ensuring data integrity, one of the most important security concerns in database outsourcing. However, to the best of our knowledge, existing approaches require modification of DBMSs to facilitate data authentication, which greatly hampers their adoption in practice. In this paper, we present the design and implementation of an efficient and practical integrity assurance scheme without requiring any modification to the DBMS at the server side . We develop novel schemes to serialize Merkle B-tree based authentication structures into a relational database that allows efficient data retrieval for integrity verification. We design efficient algorithms to accelerate query processing with integrity protection. We further build a proof-of-concept prototype and conduct extensive experiments to evaluate the performance overhead of the proposed schemes. The experimental results show that our scheme imposes a low overhead for queries and a reasonable overhead for updates while ensuring integrity of an outsourced database without special support from server-side DBMSs."
SPRINGERLINK,Chapter,2014,Using Model Driven Security Approaches in Web Application Development,Christoph HochreinerZhendong MaPeter KiesebergSebastian SchrittwieserEdgar Weippl,"Case Diagram, Goal Model, Input Validation, Misuse Case, Model Drive Engineer",10,"With the rise of Model Driven Engineering (MDE) as a software development methodology, which increases productivity and, supported by powerful code generation tools, allows a less error-prone implementation process, the idea of modeling security aspects during the design phase of the software development process was first suggested by the research community almost a decade ago. While various approaches for Model Driven Security (MDS) have been proposed during the years, it is still unclear, how these concepts compare to each other and whether they can improve the security of software projects. In this paper, we provide an evaluation of current MDS approaches based on a simple web application scenario and discuss the strengths and limitations of the various techniques, as well as the practicability of MDS for web application security in general."
SPRINGERLINK,Chapter,2014,Learning Fragments of the TCP Network Protocol,Paul Fiterău-BroşteanRamon JanssenFrits Vaandrager,"Mapper Component, Sequence Number, Session Initiation Protocol, System Under Test, Transmission Control Protocol",10,"We apply automata learning techniques to learn fragments of the TCP network protocol by observing its external behaviour. We show that different implementations of TCP in Windows 8 and Ubuntu induce different automata models, thus allowing for fingerprinting of these implementations. In order to infer our models we use the notion of a mapper component introduced by Aarts, Jonsson and Uijen, which abstracts the large number of possible TCP packets into a limited number of abstract actions that can be handled by the regular inference tool LearnLib. Inspection of the learned models reveals that both Windows 8 and Ubuntu 13.10 violate RFC 793."
SPRINGERLINK,Chapter,2014,A Framework for Business Rules,Naveen PrakashDeepak Kumar SharmaDeepika PrakashDheerendra Singh,"BRG Manifesto, Business Motivation Model, business rule management, Business rules, Semantics of Business Vocabulary and business Rules",10,"The subject of business rules is complex. We propose a 4-dimensional framework to better understand, communicate, and realize such rules in organizations and application systems. Our 4-dimensions are domain , that considers the role of business rules in business; system for properties of business rule management systems; application platform to understand support for business rules applications; and representation for expressing business rules. We derive these from work of the Business Rules Group, namely, the Business Rules Manifesto, Business Motivation Model, and Semantics of Business Vocabulary and business Rules, SBVR. We characterize our research position in terms of this framework."
SPRINGERLINK,Chapter,2014,Learning Regular Languages over Large Alphabets,Oded MalerIrini-Eleftheria Mens,"Automaton Learning, Evidence Function, Membership Query, Regular Language, Target Language",10,"This work is concerned with regular languages defined over large alphabets, either infinite or just too large to be expressed enumeratively. We define a generic model where transitions are labeled by elements of a finite partition of the alphabet. We then extend Angluin’s L * algorithm for learning regular languages from examples for such automata. We have implemented this algorithm and we demonstrate its behavior where the alphabet is the set of natural numbers."
SPRINGERLINK,Chapter,2014,Mining State-Based Models from Proof Corpora,Thomas GransdenNeil WalkinshawRajeev Raman,"Extended State Machines, Interactive Theorem Proving, Model Inference",10,Interactive theorem provers have been used extensively to reason about various software/hardware systems and mathematical theorems. The key challenge when using an interactive prover is finding a suitable sequence of proof steps that will lead to a successful proof requires a significant amount of human intervention. This paper presents an automated technique that takes as input examples of successful proofs and infers an Extended Finite State Machine as output. This can in turn be used to generate proofs of new conjectures. Our preliminary experiments show that the inferred models are generally accurate (contain few false-positive sequences) and that representing existing proofs in such a way can be very useful when guiding new ones.
SPRINGERLINK,Chapter,2014,The Design and Implementation of the Random HTML Tags and Attributes-Based XSS Defence System,Heng LinYiwen YanHongfei CaiWei Zhang,"cross-site scripting, defence system, random, tag prefix",10,"At present, cross site scripting (XSS) is still one of the biggest threat for Internet security. But the defensive approach is still feature matching mostly; that is, to check for a matching and filter in all information submitted. However, filtering technology has many disadvantages as heavy-workload, complex-operation, high-risk and so on. For this reason, our system use the randomization techniques of HTML tags and attributes innovatively, based on the prefix of HTML tags and attributes, to determine the tags and attributes are Web designers expect to generate or other users insert in, and then we follow the results to carry out different policies, only tags and attributes that Web designers expected to generate can be rendered and implemented. By this way, we can defend against XSS attacks completely. The test results show that the system is able to solve a variety of problems in filtering technology. It uses simple and convenient operation and safe and secure effect to free developers from heavy filtering work. System has a good compatibility and portability across platforms, it also can connect with all web-based applications seamlessly. In all, system defend against XSS better and meet the need of today’s XSS attacks defence."
SPRINGERLINK,Chapter,2014,Web Application Relations Mapping,Radek MaříkZdeněk KoubaMichal Pantůček,"association mining, data flow, GUI events, reverse engineering, software comprehension, SQL statements",10,"Web applications are developed and modified often so fast that architects, developers, and managers lose their control over quality of such software products. Reverse engineering techniques focused on different aspects of software implementation might help in keeping comprehension to implementation of web applications at appropriate level required for fulfilling change requests. We focus our effort on a reconstruction of implicit associations among GUI data items and back-end database entities. Our approach is based on an association analysis and mining using a synchronized log of GUI events and related counterparts of SQL statements. Recovered dependencies between GUI and back-end databases can be utilized advantageously in an automated design of web application data flow testing."
SPRINGERLINK,Chapter,2014,Wind Turbine System: An Industrial Case Study in Formal Modeling and Verification,Jagadish SuryadevaraGaetana SapienzaCristina SeceleanuTiberiu SeceleanuStein-Erik EllevsethPaul Pettersson,"EAST-ADL, Industrial case-study, MARTE/CCSL, Model checking, UPPAAL, Verification, Wind turbine system",10,"In the development of embedded systems, the formal analysis of system artifacts, such as structural and behavioral models, helps the system engineers to understand the overall functional and timing behavior of the system. In this case study paper, we present our experience in applying formal verification and validation (V&V) techniques, we had earlier proposed, for an industrial wind turbine system (WTS). We demonstrate the complementary benefits of formal verification in the context of existing V&V practices largely based on simulation and testing . We also discuss some modeling trade-offs and challenges we have identified with the case-study, which are worth being emphasized. One issue is related, for instance, to the expressiveness of the system artifacts, in view of the known limitations of rigorous verification, e.g. model-checking , of industrial systems."
SPRINGERLINK,Chapter,2014,Formal System Modelling Using Abstract Data Types in Event-B,Andreas FürstThai Son HoangDavid BasinNaoto SatoKunihiko Miyazaki,"abstract data types, Event-B, refinement",10,"We present a formal modelling approach using Abstract Data Types (ADTs) for developing large-scale systems in Event-B. The novelty of our approach is the combination of refinement and instantiation techniques to manage the complexity of systems under development. With ADTs, we model system components on an abstract level, specifying only the necessary properties of the components. At the same time, we postpone the introduction of their concrete definitions to later development steps. We evaluate our approach using a largescale case study in train control systems. The results show that our approach helps reduce system details during early development stages and leads to simpler and more automated proofs."
SPRINGERLINK,Chapter,2014,Developing Corpus-Based Translation Methods between Informal and Formal Mathematics: Project Description,Cezary KaliszykJosef UrbanJiří VyskočilHerman Geuvers,,10,"The goal of this project is to (i) accumulate annotated informal/formal mathematical corpora suitable for training semi-automated translation between informal and formal mathematics by statistical machine-translation methods, (ii) to develop such methods oriented at the formalization task, and in particular (iii) to combine such methods with learning-assisted automated reasoning that will serve as a strong semantic component. We describe these ideas, the initial set of corpora, and some initial experiments done over them."
SPRINGERLINK,Chapter,2014,Issues in Applying Model Based Process Improvement in the Cloud Computing Domain,Jeremy CadeLian WenTerry Rout,"Behavior Engineering, Cloud Computing, Process Model, Software Process",10,"Cloud Computing offers organisations a range of benefits, both economic and technological. However the decision to deploy an application or service to the cloud is a not a trivial one. Organisations need to be fully aware of not only the business requirements for a given application or service, but also the technological requirements and or constraints of the cloud. Model-based process assessment and improvement has been shown to support organisational change in different domains of application, but there are few reports of application in cloud computing. As a first step in defining suitable models to support process management, the impact of working with cloud resources on existing standard processes has been examined using the techniques of behavior engineering. A path for future work is proposed."
SPRINGERLINK,Chapter,2014,In-Place Natural and Effortless Navigation for Large Industrial Scenarios,Lucas S. FigueiredoMariana PinheiroEdvar Vilar NetoThiago MenezesJoão Marcelo TeixeiraVeronica TeichriebPedro AlessioDaniel Freitas,"body gestures, in-place navigation, natural interaction",10,"Here we address the problem of navigating in virtual environments with fixed display visualizations (e.g. projections and tvs) by using natural gestures. Gesture metaphors have proven to be a powerful tool for human computer interaction. Examples arise from smartphones to state of the art projects like the Holodesk (from Microsoft Research). However, regarding the use of gestures for navigation in virtual environments, a specific limitation arises in respect to the user movimentation in the real space. The gestures should provide the user a way of turning the virtual camera direction without losing the view of the screen. Moreover, the user must be able to move long distances in the virtual environment without trespassing real world boundaries and without becoming fatigued."
SPRINGERLINK,Chapter,2014,Randomised Testing of a Microprocessor Model Using SMT-Solver State Generation,Brian CampbellIan Stark,"HOL, microprocessor models, Randomised testing, SMT",10,"We validate a HOL4 model of the ARM Cortex-M0 microcontroller core by testing the model’s behaviour on randomly chosen instructions against a real chip. The model and our intended application involve precise timing information about instruction execution, but the implementations are pipelined, so checking the behaviour of single instructions would not give us sufficient confidence in the model. Thus we test the model using sequences of randomly chosen instructions. The main challenge is to meet the constraints on the initial and intermediate execution states: we must ensure that memory accesses are in range and that we respect restrictions on the instructions. By careful transformation of these constraints an off-the-shelf SMT solver can be used to find suitable states for executing test sequences."
SPRINGERLINK,Chapter,2014,3D Rectangulations and Geometric Matrix Multiplication,Peter FloderusJesper JanssonChristos LevcopoulosAndrzej LingasDzmitry Sledneu,"Geometric decompositions, Matrix multiplication, Minimum number rectangulation, Polyhedron, Time complexity",10,"The problem of partitioning an input rectilinear polyhedron $$P$$ into a minimum number of 3D rectangles is known to be NP-hard. We first develop a $$4$$ -approximation algorithm for the special case in which $$P$$ is a 3D histogram. It runs in $$O(m \log m)$$ time, where $$m$$ is the number of corners in $$P$$ . We then apply it to compute the arithmetic matrix product of two $$n \times n$$ matrices $$A$$ and $$B$$ with nonnegative integer entries, yielding a method for computing $$A \times B$$ in $$\tilde{O}(n^2+ \min \{ r_Ar_B, n\min \{r_A,\ r_B\}\})$$ time, where $$\tilde{O}$$ suppresses polylogarithmic (in $$n$$ ) factors and where $$r_A$$ and $$r_B$$ denote the minimum number of 3D rectangles into which the 3D histograms induced by $$A$$ and $$B$$ can be partitioned, respectively."
SPRINGERLINK,Chapter,2013,Model-Based Testing for Verification Back-Ends,Cyrille ArthoArmin BiereMartina Seidl,"Application Programming Interface, Conjunctive Normal Form, Propositional Formula, Software Product Line, System Under Test",10,"Many verification tools used in practice rely on sophisticated SAT and SMT solvers. These reasoning engines are assumed and expected to be correct, but, in general, too complex to be fully verified. Therefore, effective testing techniques have to be employed. In this paper, we show how to employ model-based testing (MBT) to test sequences of application programming interface (API) calls and different system configurations. We applied this approach to our SAT solver Lingeling and compared it to existing testing approaches, revealing the effectiveness of MBT for the development of reliable SAT solvers."
SPRINGERLINK,Chapter,2013,Case Studies in Learning-Based Testing,Lei FengSimon LundmarkKarl MeinkeFei NiuMuddassar A. SindhuPeter Y. H. Wong,"Kripke Structure, Model Check, Requirement Modeling, Slip Rate, System Under Test",10,"We present case studies which show how the paradigm of learning-based testing (LBT) can be successfully applied to black-box requirements testing of industrial reactive systems. For this, we apply a new testing tool LBTest, which combines algorithms for incremental black-box learning of Kripke structures with model checking technology. We show how test requirements can be modeled in propositional linear temporal logic extended by finite data types. We then provide benchmark performance results for LBTest applied to three industrial case studies."
SPRINGERLINK,Chapter,2013,Modbat: A Model-Based API Tester for Event-Driven Systems,Cyrille Valentin ArthoArmin BiereMasami HagiyaEric PlatonMartina SeidlYoshinori TanabeMitsuharu Yamamoto,"model-based testing, Software testing, test case derivation",10,"Model-based testing derives test executions from an abstract model that describes the system behavior. However, existing approaches are not tailored to event-driven or input/output-driven systems. In particular, there is a need to support non-blocking I/O operations, or operations throwing exceptions when communication is disrupted. Our new tool “Modbat” is specialized for testing systems where these issues are common. Modbat uses extended finite-state machines to model system behavior. Unlike most existing tools, Modbat offers a domain-specific language that supports state machines and exceptions as first-class constructs. Our model notation also handles non-determinism in the system under test, and supports alternative continuations of test cases depending on the outcome of non-deterministic operations. These features allow us to model a number of interesting libraries succinctly. Our experiments show the flexibility of Modbat and how language support for model features benefits their correct use."
SPRINGERLINK,Chapter,2013,Experience with Industrial Adoption of Business Process Models for User Acceptance Testing,Deepali KholkarPooja YelureHarshit TiwariAjay DeshpandeAditya Shetye,"Business Analyst, Business Process Model, Business Process Modeling Notation, Business Rule, Unify Modeling Language",10,"Model based testing or the generation of tests from machine readable models has been widely deployed in industry for testing embedded systems and devices. Attempts are being made to extend its use to business systems. However, in spite of its potential for process improvement, its large-scale adoption for testing business systems is not yet seen, mainly due to little data being available on such use. This paper presents the findings from industrial deployment of a business process model based testing approach for User Acceptance Testing of large banking and insurance systems. The approach met with easier acceptance from the user community due to use of business process models and has proved to scale to very large models. It resulted in an overall productivity benefit of 20-30% in test design and planning, in addition to digitization of domain and process knowledge and has been successfully adopted organization-wide. Benefits as well as issues faced in large-scale adoption are discussed along with solutions found and open problems."
SPRINGERLINK,Chapter,2013,Unfolding-Based Test Selection for Concurrent Conformance,Hernán Ponce de LeónStefan HaarDelphine Longuet,"Coverage Criterion, Label Transition System, Partial Order, System Under Test, Test Suite",10,"Model-based testing has mainly focused on models where currency is interpreted as interleaving (like the ioco theory for labeled transition systems), which may be too coarse when one wants concurrency to be preserved in the implementation. In order to test such concurrent systems, we choose to use Petri nets as specifications and define a concurrent conformance relation named co-ioco . We propose a test generation algorithm based on Petri net unfolding able to build a complete test suite w.r.t our co-ioco conformance relation. In addition we propose a coverage criterion based on a dedicated notion of complete prefixes that selects a manageable test suite."
SPRINGERLINK,Chapter,2013,Identification and Selection of Interaction Test Scenarios for Integration Testing,Mohamed MussaFerhat Khendek,"Components, Integration, Interactions, Model Based Testing, Testing",10,"Integration testing checks for compatibility and interoperability between the components in the system. Integration test models are, typically, generated independently from the other testing level models. In our research, we aim at a model-based framework across unit, integration, and acceptance level testing. This paper contributes to this framework and for the generation of integration test models from unit test models. More precisely, we focus on component interaction test scenarios identification and selection. Following our approach, at each integration step, unit test cases with interaction scenarios involving the component and the context are identified, selected and merged to build the integration test model for the next step. Unit test stubs and drivers are reused in the integration test model. Redundant test cases are eliminated from the generated test models."
SPRINGERLINK,Chapter,2013,Model-Driven Test Code Generation,Beatriz Pérez LamanchaPedro RealesMacario PoloDanilo Caivano,"Model Transformation, Object Management Group, Sequence Diagram, Software Product Line, System Under Test",10,"Model-driven Testing (MDT) refers a model-based testing that follows Model Driven Engineering paradigm, i.e., the test cases are automated generated using models extracted from software artifacts through model transformations. In previous work, we developed a model to model transformation that takes as input UML 2.0 sequence diagrams, and automatically derive test cases scenarios that conforms the UML Testing Profile. In this work, these test case scenarios are automatically transformed using model to text transformation. This transformation, which can be applied to obtain test cases in a variety of programming languages, is implemented with MOFScript, which is also an OMG standard."
SPRINGERLINK,Chapter,2013,Towards a GUI Test Model Using State Charts and Programming Code,Daniel MauserAlexander KlausKonstantin Holl,"automotive, human machine interface, model based testing",10,"Modern human machine interfaces provide a sophisticated structure and logic to ease their use. As they are the only mean to control the system behind, extensive testing and highest quality is required in the automotive domain. A common testing approach in literature is to derive the necessary test cases from a formal model. However, redundancy and data dependency still hinder manual modeling in the industrial context. In this paper, we present preliminary work to address these obstacles. As a first step, we combined depictive state charts with reusable programming code. We modeled parts of the graphical user interface of a state-of-the-art infotainment system and successfully generated a test suite that covers our testing goal to reach each button at least once."
SPRINGERLINK,Chapter,2013,Automatic Grammar-Based Test Generation,Hai-Feng GuoZongyan Qiu,"Coverage Tree, Generate Test Case, Production Rule, Software Product Line, Test Generation",10,"In this paper, we present an automatic grammar-based test generation approach which takes a symbolic grammar as input, requires zero control input from users, and produces well-distributed test cases. Our approach utilizes a novel dynamic stochastic model where each variable is associated with a tuple of probability distributions, which are dynamically adjusted along the derivation. The adjustment is based on a tabling strategy to keep track of the recursion of each grammar variable. We further present a test generation coverage tree illustrating the distribution of generated test cases and their detailed derivations, more importantly, it provides various implicit balance control mechanisms. We implemented this approach in a Java-based system, named Gena . Experimental results demonstrate the effectiveness of our test generation approach and show the balanced distribution of generated test cases over grammatical structures."
SPRINGERLINK,Chapter,2013,Systematic Review on Software Product Line Testing,Beatriz Pérez LamanchaMacario PoloMario Piattini,"Software product lines, Software testing, Survey, Systematic review, Test",10,"This article presents a systematic review of the literature about Testing in Software Product Lines. The objective is to analyze the existing approaches to testing in software product lines, discussing the significant issues related to this area of knowledge and providing an up-to-date state of the art, which can serve as a basis for innovative research activities. The paper includes an analysis on how SPL research can contribute to dynamize the research in software testing."
SPRINGERLINK,Chapter,2013,Behavioral Fuzzing Operators for UML Sequence Diagrams,Martin SchneiderJürgen GroßmannNikolay TcholtchevIna SchieferdeckerAndrej Pietschker,"Fuzzing, Model-based Testing, Security Testing, UML",10,"Model-based testing is a recognized method for testing the functionality of a system under test. However, it is not only the functionality of a system that has to be assessed. Also the security aspect has to be tested, especially for systems that provide interfaces to the Internet. In order to find vulnerabilities that could be exploited to break into or to crash a system, fuzzing is an established technique in industry. Model-based fuzzing complements model-based testing of functionality in order to find vulnerabilities by injecting invalid input data into the system. While it focuses on invalid input data, we present a complementary approach called behavioral fuzzing. Behavioral fuzzing does not inject invalid input data but sends an invalid sequence of messages to the system under test. We start with existing UML sequence diagrams – e.g. functional test cases – and modify them by applying fuzzing operators in order to generate invalid sequences of messages. We present the identified fuzzing operators and propose a classification for them. A description of a case study from the ITEA-2 research project DIAMONDS as well as preliminary results are presented."
SPRINGERLINK,Chapter,2013,Incremental Refinement Checking for Test Case Generation,Bernhard K. AichernigElisabeth JöbstlMatthias Kegele,"action systems, conformance, constraint solving, model-based testing, mutation testing, refinement, SMT solving",10,"We combine model-based testing and mutation testing to automatically generate a test suite that achieves a high mutation adequacy score. The original model representing the system under test is mutated. To generate test cases that detect whether a modelled fault has been implemented, we perform a refinement check between the original and the mutated models. Action systems serve as formal models. They are well-suited to model reactive systems and allow non-determinism. We extend our previous work by two techniques to improve efficiency: (1) a strategy to efficiently handle a large number of mutants and (2) incremental solving. A case study illustrates the potential of our improvements. The runtime for checking appr. 200 mutants could be reduced from 20s to 3s. We implemented our algorithms in two versions: one uses a constraint solver, the other one an SMT solver. Both show similar performance."
SPRINGERLINK,Chapter,2013,A Generic Fault Model for Quality Assurance,Alexander PretschnerDominik HollingRobert EschbachMatthias Gemmar,,10,"Because they are comparatively easy to implement, structural coverage criteria are commonly used for test derivation in model- and code-based testing. However, there is a lack of compelling evidence that they are useful for finding faults, specifically so when compared to random testing. This paper challenges the idea of using coverage criteria for test selection and instead proposes an approach based on fault models. We define a general fault model as a transformation from correct to incorrect programs and/or a partition of the input data space. Thereby, we leverage the idea of fault injection for test assessment to test derivation. We instantiate the developed general fault model to describe existing fault models. We also show by example how to derive test cases."
SPRINGERLINK,Chapter,2013,A Grey-Box Approach for Automated GUI-Model Generation of Mobile Applications,Wei YangMukul R. PrasadTao Xie,"Android Application, Call Graph, Graphical User Interface, Mobile Platform, Symbolic Execution",10,"As the mobile platform continues to pervade all aspects of human activity, and mobile applications, or mobile apps for short, on this platform tend to be faulty just like other types of software, there is a growing need for automated testing techniques for mobile apps. Modelbased testing is a popular and important testing approach that operates on a model of an app’s behavior. However, such a model is often not available or of insufficient quality. To address this issue, we present a novel grey-box approach for automatically extracting a model of a given mobile app. In our approach, static analysis extracts the set of events supported by the Graphical User Interface (GUI) of the app. Then dynamic crawling reverse-engineers a model of the app, by systematically exercising these events on the running app. We also present a tool implementing this approach for the Android platform. Our empirical evaluation of this tool on several Android apps demonstrates that it can efficiently extract compact yet reasonably comprehensive models of high quality for such apps."
SPRINGERLINK,Chapter,2013,State-Driven Testing of Distributed Systems,Domenico CotroneoRoberto NatellaStefano RussoFabio Scippacercola,"Experimental Dependability Assessment, Fault Injection, Fault Tolerance, Genetic Algorithms, State-based Testing, Workload",10,"In distributed systems, failures are often caused by software faults that manifest themselves only when the system enters a particular, rarely occurring system state. It thus becomes important to identify these failure-prone states during testing. We propose a state-driven testing approach for distributed systems, able to execute tests in hard-to-reach states in a repeatable and accurate way. Moreover, we present the implementation and experimental evaluation of the approach in the context of a fault-tolerant flight data processing system. Experimental results confirm the feasibility of the approach, and the accuracy and reproducibility of tests."
SPRINGERLINK,Chapter,2013,Testing Idempotence for Infrastructure as Code,Waldemar HummerFlorian RosenbergFábio OliveiraTamar Eilam,"Convergence, Idempotence, Infrastructure as Code, Middleware Deployment, Software Automation, Software Testing",10,"Due to the competitiveness of the computing industry, software developers are pressured to quickly deliver new code releases. At the same time, operators are expected to update and keep production systems stable at all times. To overcome the development–operations barrier, organizations have started to adopt Infrastructure as Code (IaC) tools to efficiently deploy middleware and applications using automation scripts. These automations comprise a series of steps that should be idempotent to guarantee repeatability and convergence. Rigorous testing is required to ensure that the system idempotently converges to a desired state, starting from arbitrary states. We propose and evaluate a model-based testing framework for IaC. An abstracted system model is utilized to derive state transition graphs, based on which we systematically generate test cases for the automation. The test cases are executed in light-weight virtual machine environments. Our prototype targets one popular IaC tool (Chef), but the approach is general. We apply our framework to a large base of public IaC scripts written by operators, showing that it correctly detects non-idempotent automations."
SPRINGERLINK,Chapter,2013,An Implementation Relation and Test Framework for Timed Distributed Systems,Christophe GastonRobert M. HieronsPascale Le Gall,"distributed systems, model based testing, symbolic input output transition systems, timed systems",10,"Many systems interact with their environment at physically distributed interfaces and the distributed nature of any observations made is known to complicate testing. This paper concerns distributed testing, where a separate tester is placed at each localised interface and may only observe what happens at this interface. Most previous work on distributed model based testing has used models that are either finite state machines or input output transition systems. In this paper we define a framework for distributed testing from timed input output transition systems along with corresponding test hypotheses and a distributed conformance relation."
SPRINGERLINK,Chapter,2013,Automated Test Case Selection Using Feature Model: An Industrial Case Study,Shuai WangArnaud GotliebShaukat AliMarius Liaaen,"Component Family Model, Feature Model, Product Line, Test Case Selection",10,"Automated test case selection for a new product in a product line is challenging due to several reasons. First, the variability within the product line needs to be captured in a systematic way; second, the reusable test cases from the repository are required to be identified for testing a new product. The objective of such automated process is to reduce the overall effort for selection (e.g., selection time), while achieving an acceptable level of the coverage of testing functionalities. In this paper, we propose a systematic and automated methodology using a Feature Model for Testing (FM_T) to capture commonalities and variabilities of a product line and a Component Family Model for Testing (CFM_T) to capture the overall structure of test cases in the repository. With our methodology, a test engineer does not need to manually go through the repository to select a relevant set of test cases for a new product. Instead, a test engineer only needs to select a set of relevant features using FM_T at a higher level of abstraction for a product and a set of relevant test cases will be selected automatically. We applied our methodology to a product line of video conferencing systems called Saturn developed by Cisco and the results show that our methodology can reduce the selection effort significantly. Moreover, we conducted a questionnaire-based study to solicit the views of test engineers who were involved in developing FM_T and CFM_T. The results show that test engineers are positive about adapting our methodology and models (FM_T and CFM_T) in their current practice."
SPRINGERLINK,Chapter,2013,Using Logic Coverage to Improve Testing Function Block Diagrams,Eduard Paul EnoiuDaniel SundmarkPaul Pettersson,"function block diagram, logic coverage, model-driven engineering, structural testing, timed automata",10,"In model-driven development, testers are often focusing on functional model-level testing, enabling verification of design models against their specifications. In addition, in safety-critical software development, testers are required to show that tests cover the structure of the implementation. Testing cost and time savings could be achieved if the process of deriving test cases for logic coverage is automated and provided test cases are ready to be executed. The logic coverage artifacts, i.e., predicates and clauses, are required for different logic coverage, e.g., MC/DC. One way of dealing with test case generation for ensuring logic coverage is to approach it as a model-checking problem, such that model-checking tools automatically create test cases. We show how logic coverage criteria can be formalized and used by a model-checker to provide test cases for ensuring coverage on safety-critical software described in the Function Block Diagram programming language. Based on our experiments, this approach, supported by a tool chain, is an applicable and useful way of generating test cases for covering Function Block Diagrams."
SPRINGERLINK,Chapter,2013,Constraints: The Core of Supporting Automated Product Configuration of Cyber-Physical Systems,Kunming NieTao YueShaukat AliLi ZhangZhiqiang Fan,"Classification, Configuration, Constraints, Cyber-Physical Systems, Industrial Case Studies, Product Line Engineering",10,"In the context of product line engineering of cyber-physical systems, there exists a large number of constraints to support, for example, consistency checking of design decisions made in hardware and software components during configuration. Manual configuration is not feasible in this context considering that managing and manipulating all these constraints in a real industrial context is very complicated and thus warrants an automated solution. Typical automation activities in this context include automated configuration value inference, optimizing configuration steps and consistency checking. However, to this end, relevant constraints have to be well-specified and characterized in the way such that automated configuration can be enabled. In this paper, we classify and characterize constraints that are required to be specified to support most of the key functionalities of any automated product configuration solution, based on our experience of studying three industrial product lines."
SPRINGERLINK,Chapter,2013,Machine-Readable Privacy Certificates for Services,Marco AnisettiClaudio A. ArdagnaMichele BezziErnesto DamianiAntonino Sabetta,"certification, privacy, testing",10,"Privacy-aware processing of personal data on the web of services requires managing a number of issues arising both from the technical and the legal domain. Several approaches have been proposed to matching privacy requirements (on the clients side) and privacy guarantees (on the service provider side). Still, the assurance of effective data protection (when possible) relies on substantial human effort and exposes organizations to significant (non-)compliance risks. In this paper we put forward the idea that a privacy certification scheme producing and managing machine-readable artifacts in the form of privacy certificates can play an important role towards the solution of this problem. Digital privacy certificates represent the reasons why a privacy property holds for a service and describe the privacy measures supporting it. Also, privacy certificates can be used to automatically select services whose certificates match the client policies (privacy requirements). Our proposal relies on an evolution of the conceptual model developed in the Assert4Soa project and on a certificate format specifically tailored to represent privacy properties. To validate our approach, we present a worked-out instance showing how privacy property Retention-based unlinkability can be certified for a banking financial service."
SPRINGERLINK,Chapter,2013,Automated Model-in-the-Loop Testing of Continuous Controllers Using Search,Reza MatinnejadShiva NejatiLionel BriandThomas BruckmannClaude Poull,"Controller Property, Exploration Algorithm, Hybrid Automaton, Industry Partner, Random Search",10,"The number and the complexity of software components embedded in today’s vehicles is rapidly increasing. A large group of these components monitor and control the operating conditions of physical devices (e.g., components controlling engines, brakes, and airbags). These controllers are known as continuous controllers . In this paper, we study testing of continuous controllers at the Model-in-Loop (MiL) level where both the controller and the environment are represented by models and connected in a closed feedback loop system. We identify a set of common requirements characterizing the desired behavior of continuous controllers, and develop a search-based technique to automatically generate test cases for these requirements. We evaluated our approach by applying it to a real automotive air compressor module. Our experience shows that our approach automatically generates several test cases for which the MiL level simulations indicate potential violations of the system requirements. Further, not only do our approach generates better test cases faster than random test case generation, but we also achieve better results than test scenarios devised by domain experts."
SPRINGERLINK,Chapter,2013,Big Metamodels Are Evil,Frédéric FondementPierre-Alain MullerLaurent ThiryBrice WittmannGermain Forestier,"Model Drive Engineering, Model Transformation, Object Management Group, Unify Modeling Language, Unify Modeling Language Model",10,"While reuse is typically considered a good practice, it may also lead to keeping irrelevant concerns in derived elements. For instance, new metamodels are usually built upon existing metamodels using additive techniques such as profiling and package merge. With such additive techniques, new metamodels tend to become bigger and bigger, which leads to harmful overheads of complexity for both tool builders and users. In this paper, we introduce ≪ package unmerge≫ - a proposal for a subtractive relation between packages - which complements existing metamodel-extension techniques."
SPRINGERLINK,Chapter,2013,Adaptive Homing and Distinguishing Experiments for Nondeterministic Finite State Machines,Natalia KushikKhaled El-FakihNina Yevtushenko,"adaptive homing and distinguishing experiments, conformance testing, Nondeterministic finite state machine",10,"Adaptive experiments are well defined in the context of finite state machine (FSM) based analysis, in particular, in FSM based testing where homing and distinguishing experiments with FSMs are used in test derivation. In this paper, we define and propose algorithms for deriving adaptive homing and distinguishing experiments for non-initialized nondeterministic finite state machines (NFSM). For NFSMs, the construction of adaptive experiments is rather complex as the partition over produced outputs does not define a partition over the set of states but rather a collection of intersecting subsets, and thus, the refinement of such subsets is more difficult than the refinement of a partition. Given a complete non-initialized observable NFSM, we establish necessary and sufficient conditions for having adaptive homing and distinguishing experiments and evaluate the upper bound on the height of these experiments. Simple application examples demonstrating a proposed approach are provided."
SPRINGERLINK,Chapter,2013,A CSP Timed Input-Output Relation and a Strategy for Mechanised Conformance Verification,Gustavo CarvalhoAugusto SampaioAlexandre Mota,"Conformance Relation, Constraint Solver, CSP, Data, Time",10,"Here we propose a timed input-output conformance relation (named CSPTIO) based on the process algebra CSP. In contrast to other relations, CSPTIO analyses data-flow reactive systems and conformance verification is mechanised in terms of a high-level strategy by reusing successful techniques and tools: refinement checking (particularly, using the FDR tool) and SMT solving (using Z3). Therefore, conformance verification does not require the implementation of specific algorithms or the manipulation of complex data structures. Furthermore, the mechanisation is proved sound. To analyse the usefulness of CSPTIO, we first consider a toy example. Then we analyse critical systems from two different domains: aeronautics and automotive. CSPTIO detected all undesired behaviours in the analysed implementation models."
SPRINGERLINK,Chapter,2013,Building Rich Internet Applications Models: Example of a Better Strategy,Suryakant ChoudharyMustafa Emre DincturkSeyed M. MirtaheriGuy-Vincent JourdanGregor v. BochmannIosif Viorel Onut,"AJAX, Crawling, Modeling, RIAs",10,"Crawling “classical” web applications is a problem that has been addressed more than a decode ago. Efficient crawling of web applications that use advanced technologies such as AJAX (called Rich Internet Applications, RIAs) is still an open problem. Crawling is important not only for indexing content, but also for building models of the applications, which is necessary for automated testing, automated security and accessibility assessments and in general for using software engineering tools. This paper presents a new strategy to crawl RIAs. It uses the concept of Model-Based Crawling (MBC) first introduced in [1], and introduces a new model, the “menu model”, which we show to be much simpler than previous models for MBC and more effective at building models than previously published methods. This method and others are compared against a set of experimental and real RIAs."
SPRINGERLINK,Chapter,2013,Issues and Ongoing Work on State-Driven Workload Generation for Distributed Systems,Roberto NatellaFabio Scippacercola,"Distributed Systems, Fault Injection, Fault Tolerance, Genetic Algorithms, Off-line synchronization, State-based Testing, Workload",10,"The dependability of a complex distributed system needs to be assured against the several conditions, namely states , in which it can operate. Generating a workload able to cover a desired target state of a distributed system is still a difficult task, since the relationship between the workload and states is nontrivial due to system complexity and non-deterministic factors. This work discusses our ongoing work on a state-driven workload generation approach for distributed systems, based on an evolutionary algorithm, and its preliminary implementation for testing a fault-tolerant distributed system for flight data processing."
SPRINGERLINK,Chapter,2013,Combining Testing and Runtime Verification Techniques,Kevin FalzonGordon J. Pace,"Outgoing Transition, Runtime Monitoring, Runtime Verification, Test Case Generation, Testing Oracle",10,"Testing is an established and integral part of the system design and development process, but incomplete coverage still leaves room for potential undiscovered bugs. Runtime verification addresses this issue by integrating verification oracles into the code, allowing for reparatory action to be taken in case of system failure after deployment. Despite the complementarity of the two approaches, the application of the two approaches at different stages in the development and deployment process results in much duplication of effort. In this paper we investigate the combination of the two approaches, by showing how one can use testing oracles to derive correct runtime verification monitors. We show how this can be achieved using QuickCheck and Larva , and apply the resulting framework to Riak, a fault-tolerant distributed database written in Erlang."
SPRINGERLINK,Chapter,2013,WebMate: Generating Test Cases for Web 2.0,Valentin DallmeierMartin BurgerTobias OrthAndreas Zeller,"automate testing, test case generation, Web 2.0, web applications",10,"Web applications are everywhere—well tested web applications however are in short supply. The mixture of JavaScript, HTML and CSS in a variety of different browsers makes it virtually impossible to apply static analysis techniques. In this setting, systematic testing becomes a real challenge. We present a technique to automatically generate tests for Web 2.0 applications. Our approach systematically explores and tests all distinct functions of a web application. Our prototype implementation WEBMATE handles interfaces as complex as Facebook and is able to cover up to 7 times as much code as existing tools. The only requirements to use WEBMATE are the address of the application and, if necessary, user name and password."
SPRINGERLINK,Chapter,2013,System Level Formal Verification via Model Checking Driven Simulation,Toni ManciniFederico MariAnnalisa MassiniIgor MelattiFabio MerliEnrico Tronci,"Discrete Event System, Event List, Model Check, Simulation Campaign, Simulation Scenario",10,"We show how by combining Explicit Model Checking techniques and simulation it is possible to effectively carry out (bounded) System Level Formal Verification of large Hybrid Systems such as those defined using model-based tools like Simulink . We use an explicit model checker (namely, CMurphi ) to generate all possible ( finite horizon ) simulation scenarios and then optimise the simulation of such scenarios by exploiting the ability of simulators to save and restore visited states. We show feasibility of our approach by presenting experimental results on the verification of the fuel control system example in the Simulink distribution. To the best of our knowledge this is the first time that (exhaustive) verification has been carried out for hybrid systems of such a size."
SPRINGERLINK,Chapter,2013,Log File Analysis with Context-Free Grammars,Gregory BosmanStefan Gruner,"context-free grammars, Intrusion detection, log file analysis",10,"Classical intrusion analysis of network log files uses statistical machine learning or regular expressions. Where statistically machine learning methods are not analytically exact, methods based on regular expressions do not reach up very far in Chomsky’s hierarchy of languages. This paper focuses on parsing traces of network traffic using context-free grammars. “Green grammars” are used to describe acceptable log files while “red grammars” are used to represent known intrusion patterns. This technique can complement or augment existing approaches by providing additional precision. Analytically, the technique is also more powerful than existing techniques that use regular expressions."
SPRINGERLINK,Chapter,2013,An Approach to Testing Java Implementation against Its UML Class Model,Hector M. ChavezWuwei ShenRobert B. FranceBenjamin A. Mechling,"Class diagram, Java, Model checking, UML",10,"Model Driven Engineering (MDE) aims to expedite the software development process by providing support for transforming models to running systems. Many modeling tools provide forward engineering features that automatically translate a model into a skeletal program that developers must complete. Inconsistencies between a design model and its implementation can result as a consequence of manually-added code. Manually checking that an implementation conforms to the model is a daunting task. Thus, there is a need for MDE tools that developers can use to check whether an implementation conforms to a model, especially when generated code is manually modified. This paper presents an approach for testing that an implementation satisfies the constraints specified in its design model. We also describe a prototypical tool that supports the approach, and we describe how its application to two Eclipse UML2 projects uncovered errors."
SPRINGERLINK,Chapter,2013,Data-Flow Based Model Analysis and Its Applications,Christian SaadBernhard Bauer,"Abstract Syntax, Dependency Graph, Meta Model, Object Constraint Language, Reference Node",10,"In this paper we present a data-flow based approach to static model analysis to address the problem of current methods being either limited in their expressiveness or employing formalisms which complicate seamless integration with standards and tools in the modeling domain. By applying data-flow analysis - a technique widely used for static program analysis - to models, we realize what can be considered a generic “programming language” for context-sensitive model analysis through declarative specifications. This is achieved by enriching meta models with data-flow attributes which are afterward instantiated for models. The resulting equation system is subjected to a fixed-point computation that yields a static approximation of the model’s dynamic behavior as specified by the analysis. The applicability of the approach is evaluated in the context of a running example, the examination of viable application domains and a statistical review of the algorithm’s performance."
SPRINGERLINK,Chapter,2013,Remote Testing of Timed Specifications,Alexandre DavidKim G. LarsenMarius MikučionisOmer L. Nguena TimoAntoine Rollet,"Causal Order, Communication Latency, Label Transition System, System Under Test, Test Purpose",10,We present a study and a testing framework on black box remote testing of real-time systems using Uppaal-TIGA. One of the essential challenges of remote testing is the communication latency between the tester and the system under test (SUT) that may lead to interleaving of inputs and outputs. This affects the generation of inputs for the SUT and the observation of outputs that may trigger a wrong test verdict. We model the overall test setup using Timed Input-Output Automata (TIOA) and present an adapted asynchronous semantics with explicit communication delays. We propose the $\varDelta$ -testability criterion for the requirement model where $\varDelta$ describes the communication latency. The test case generation problem is then reduced into a controller synthesis problem. We use Uppaal-TIGA for this purpose to solve a timed game with partial observability between the tester and the communication media together with the SUT. The objective of the game corresponds to a test purpose.
SPRINGERLINK,Chapter,2013,Validating Code-Level Behavior of Dynamic Adaptive Systems in the Face of Uncertainty,Erik M. FredericksAndres J. RamirezBetty H. C. Cheng,"genetic algorithm, novelty search, search-based software engineering, software assurance",10,"A dynamically adaptive system (DAS) self-reconfigures at run time in order to handle adverse combinations of system and environmental conditions. Techniques are needed to make DASs more resilient to system and environmental uncertainty. Furthermore, automated support to validate that a DAS provides acceptable behavior even through reconfigurations are essential to address assurance concerns. This paper introduces F enrir , an evolutionary computation-based approach to address these challenges. By explicitly searching for diverse and interesting operational contexts and examining the resulting execution traces generated by a DAS as it reconfigures in response to adverse conditions, F enrir can discover undesirable behaviors triggered by unexpected environmental conditions at design time, which can be used to revise the system appropriately. We illustrate F enrir by applying it to a dynamically adaptive remote data mirroring network that must efficiently diffuse data even in the face of adverse network conditions."
SPRINGERLINK,Chapter,2013,Augmenting Sequence Enumeration with String-Rewriting for Requirements Analysis and Behavioral Specification,Lan LinJesse H. PooreRobert EschbachRobert M. HieronsChristopher Robinson-Mallett,"requirements engineering, sequence enumeration, sequence-based specification, software specification, string-rewriting",10,"Sequence enumeration is a method for deriving a system model based on informal requirements. Under sequence enumeration, stimulus (input) sequences are considered in a breadth-first manner, with the expected system response to each sequence given. Not all sequences of stimuli are considered since a sequence need not be extended if either it is illegal (it cannot be applied in practice) or it can be reduced to another sequence previously considered (the sequences take the system to the same state). Sequence enumeration is mostly a manual process, which leads to a model that can be used as the basis for automation. This paper describes a method, based on string-rewriting, that automates parts of sequence enumeration. This automation has the potential to reduce both the cost and time involved in sequence enumeration but also to reduce the scope for human error. In addition to outlining this method, we discuss our experiences in applying it to four case studies."
SPRINGERLINK,Chapter,2013,Inferring Automata with State-Local Alphabet Abstractions,Malte IsbernerFalk HowarBernhard Steffen,"Automaton Learning, Input Alphabet, Input Symbol, Membership Query, Observation Table",10,"A major hurdle for the application of automata learning to realistic systems is the identification of an adequate alphabet: it must be small enough, in particular finite, for the learning procedure to converge in reasonable time, and it must be expressive enough to describe the system at a level where its behavior is deterministic. In this paper, we combine our automated alphabet abstraction approach, which refines the global alphabet of the system to be learned on the fly during the learning process, with the principle of state-local alphabets: rather than determining a single global alphabet, we infer the optimal alphabet abstraction individually for each state. Our experimental results show that this does not only lead to an increased comprehensibility of the learned models, but also to a better performance of the learning process: indeed, besides the drastic – yet foreseeable – reduction in terms of membership queries, we also observed interesting cases where the number of equivalence queries was reduced."
SPRINGERLINK,Chapter,2013,POGen: A Test Code Generator Based on Template Variable Coverage in Gray-Box Integration Testing for Web Applications,Kazunori SakamotoKaizu TomohiroDaigo HamuraHironori WashizakiYoshiaki Fukazawa,"software testing, template engine, test code generation, test coverage, web application",10,"Web applications are complex; they consist of many subsystems and run on various browsers and platforms. This makes it difficult to conduct adequate integration testing to detect faults in the connections between subsystems or in the specific environments. Therefore, establishing an efficient integration testing method with the proper test adequacy criteria and tools is an important issue. In this paper, we propose a new test coverage called template variable coverage. We also propose a novel technique for generating skeleton test code that includes accessor methods and improves the template variable coverage criterion, using a tool that we developed called POGen. Our experiments show that template variable coverage correlates highly with the capability to detect faults, and that POGen can reduce testing costs."
SPRINGERLINK,Chapter,2013,Testing with Inputs and Outputs in CSP,Ana CavalcantiRobert M. Hierons,"Conformance Relation, Exhaustive Test, Output Event, System Under Test, Test Execution",10,"This paper addresses refinement and testing based on CSP models, when we distinguish input and output events. From a testing perspective, there is an asymmetry: the tester (or the environment) controls the inputs, and the system under test controls the outputs. The standard models and refinement relations of CSP are, therefore, not entirely suitable for testing. Here, we adapt the CSP stable-failures model, resulting in the notion of input-output failures refinement. We compare that with the ioco relation often used in testing.Finally, we adapt the CSP testing theory, and show that some tests become unnecessary."
SPRINGERLINK,Chapter,2013,Machine Learning for Emergent Middleware,Amel BennaceurValérie IssarnyDaniel SykesFalk HowarMalte IsbernerBernhard SteffenRichard JohanssonAlessandro Moschitti,"Automata learning, Automated Mediation, Interoperability, Machine learning, Natural language processing",10,"Highly dynamic and heterogeneous distributed systems are challenging today’s middleware technologies. Existing middleware paradigms are unable to deliver on their most central promise, which is offering interoperability. In this paper, we argue for the need to dynamically synthesise distributed system infrastructures according to the current operating environment, thereby generating “Emergent Middleware” to mediate interactions among heterogeneous networked systems that interact in an ad hoc way. The paper outlines the overall architecture of Enablers underlying Emergent Middleware, and in particular focuses on the key role of learning in supporting such a process, spanning statistical learning to infer the semantics of networked system functions and automata learning to extract the related behaviours of networked systems."
SPRINGERLINK,Chapter,2013,A New Test-Generation Methodology for System-Level Verification of Production Processes,Allon AdirAlex GoryachevLev GreenbergTamer SalmanGil Shurek,"Production processes / Manufacturing processes, Test generation, Transaction-based modeling, UML/SysML",10,"The continuing growth in the complexity of production processes is driven mainly by the integration of smart and cheap devices, such as sensors and custom hardware or software components. This naturally leads to higher complexity in fault detection and management, and, therefore to a higher demand for sophisticated quality control tools. A production process is commonly modeled prior to its physical construction to enable early testing. Many simulation platforms were developed to assess the widely varying aspects of the production process, including physical behavior, hardware-software functionality, and performance. However, the efficacy of simulation for the verification of modeled processes is still largely limited by manual operation and observation. We propose a massive random-biased, ontology-based, test-generation methodology for system-level verification of production processes. The methodology has been successfully applied for simulation-based processor hardware verification and proved to be a cost-effective solution. We show that it can be similarly beneficial in the verification of production processes and control."
SPRINGERLINK,Chapter,2013,Regression Testing for Model Transformations: A Multi-objective Approach,Jeffery ShelburgMarouane KessentiniDaniel R. Tauritz,"model transformation, multi-objective optimization, search-based software engineering, testing",10,"In current model-driven engineering practices, metamodels are modified followed by an update of transformation rules. Next, the updated transformation mechanism should be validated to ensure quality and robustness. Model transformation testing is a recently proposed effective technique used to validate transformation mechanisms. In this paper, a more efficient approach to model transformation testing is proposed by refactoring the existing test case models, employed to test previous metamodel and transformation mechanism versions, to cover new changes. To this end, a multi-objective optimization algorithm is employed to generate test case models that maximizes the coverage of the new metamodel while minimizing the number of test case model refactorings as well as test case model elements that have become invalid due to the new changes. Validation results on a widely used transformation mechanism confirm the effectiveness of our approach."
SPRINGERLINK,Chapter,2013,Path-Aware Time-Triggered Runtime Verification,Samaneh NavabpourBorzoo BonakdarpourSebastian Fischmeister,,10,"A time-triggered monitor runs in parallel with the program under inspection and periodically samples the program state to evaluate a set of properties. However, a time-triggered monitor working with a fixed sampling frequency often suffers from redundant sampling, which results in excessive overhead. In this paper, we propose an effective approach to reduce redundant sampling. Our approach calculates the sampling frequency with respect to the program behavior at run time. We further advance this approach to dynamically adjust the sampling frequency at run time by predicting the program behavior using symbolic execution. Experiments show that our approach reduces the sampling frequency, runtime overhead, and the number of redundant samples by up to 3.5 times, 69%, and 86%, respectively."
SPRINGERLINK,Chapter,2013,State Coverage: An Empirical Analysis Based on a User Study,Dries VanoverbergheEmma EyckmansFrank Piessens,"state coverage, test adequacy metric, user study",10,"State coverage is a relatively new metric to evaluate the quality of test suites. While most existing test adequacy criteria measure the degree of exploration of the code under test, state coverage estimates the strength of the assertions in the test suite. Initial experiments have shown that there is a correlation between state coverage and mutation adequacy, and that expert users can discover new faults by modifying the test suite to increase state coverage. Since the faults injected by mutation testing are relatively simple, it is not clear whether these experiment are valid in a broader setting. Furthermore, these results may not be reproducible by average users, since they usually lack full understanding of the internals of the tool. This paper presents a user-based experiment to evaluate whether the state coverage of a test suite correlates with the number defects it discovers. While the results of the experiments fail to confirm this hypothesis, they do raises important questions. First, test suites with high state coverage should be good in finding logical software faults, but these faults occur less frequently than structural faults. Second, state coverage is not monotonic in the size of the test suite. Therefore, adding new test cases which check new properties and detect new faults can often reduce state coverage. Based on this, we suggest a number of improvements."
SPRINGERLINK,Chapter,2013,Systematic Testing of Graph Transformations: A Practical Approach Based on Graph Patterns,Martin WieberAndy Schürr,"Coverage, Programmed Graph Transformations, Testing",10,"Correctness is an essential property of model transformations. Although testing is a well-accepted method for assuring software quality in general, the properties of declarative transformation languages often prevent a direct application of testing strategies from imperative programming languages. A key challenge of transformation testing concerns limiting the testing effort by a good stop criterion . In this work, we tackle this issue for programmed graph transformations , and present a practical methodology to derive sufficient test suites based on a new coverage notion inspired by mutation analysis. We systematically generate requirement (graph) patterns from the transformation under test, applying different requirement construction strategies, and analyze the approach in terms of practicability, test suite quality and the ability to guide and support test case construction."
SPRINGERLINK,Chapter,2013,Challenges of Testing Periodic Messages in Avionics Systems Using TTCN-3,Bernard StepienLiam Peyton,"avionics, periodic messages, testing, TTCN-3",10,"The TTCN-3 language was conceived initially for testing telecommunications protocols that consist of sequences of discrete messages between communicating entities. TTCN-3 has a clear model of separation of concerns between an abstract layer, where test behavior is specified, and a concrete layer, where messages are encoded / decoded and sent and received to/from the system under test. This model, however, is cumbersome for testing protocols with periodic messages as used in avionics systems. This paper presents an innovative approach to addressing issues involving periodic messages in TTCN-3, based on our experiences working with avionics systems. Extensions to the TTCN-3 standard are proposed, based on our approach. We also demonstrate how the approach can be used for test system certification and requirements verification for avionics systems."
SPRINGERLINK,Chapter,2013,Testing Stochastic Systems Using MoVoS Tool: Case Studies,Kenza BouaroudjDjamel-Eddine SaidouniIlham Kitouni,"canonical tester, formal testing models, maximality semantics, refusals graphs",10,"MoVoS tool is an implementation of testing theory based on stochastic refusals graph. It allows the automatic extraction of test cases from specification of stochastic systems. Those systems are modeled by Maximality based Labeled Stochastic Transition System “MLSTS”. In This paper, we present the application of MoVoS tool on two cases studies to valid it. Those case studies permit us to illustrate the functionality of tool and to show that this tool can deal with large system."
SPRINGERLINK,Chapter,2013,Automatic Inference of Erlang Module Behaviour,Ramsay TaylorKirill BogdanovJohn Derrick,"Behaviour Inference, Callback Function, Initial Trace, Locker Module, Positive Trace",10,"Previous work has shown the benefits of using grammar inference techniques to infer models of software behaviour for systems whose specifications are not available. However, this inference has required considerable direction from an expert user who needs to have familiarity with the system’s operation, and must be actively involved in the inference process. This paper presents an approach that can be applied automatically to infer a model of the behaviour of Erlang modules with respect to their presented interface. It integrates the automated learning system StateChum with the automated refactoring tool Wrangler to allow both interface discovery and behaviour inference to proceed without human involvement."
SPRINGERLINK,Chapter,2013,A Fast Algorithm Finding the Shortest Reset Words,Andrzej KisielewiczJakub KowalskiMarek Szykuła,"Černý conjecture, Synchronizing automaton, synchronizing word",10,"In this paper we present a new fast algorithm for finding minimal reset words for finite synchronizing automata, which is a problem appearing in many practical applications. The problem is known to be computationally hard, so our algorithm is exponential in the worst case, but it is faster than the algorithms used so far and it performs well on average. The main idea is to use a bidirectional BFS and radix (Patricia) tries to store and compare subsets. Also a number of heuristics are applied. We give both theoretical and practical arguments showing that the effective branching factor is considerably reduced. As a practical test we perform an experimental study of the length of the shortest reset word for random automata with n  ≤ 300 states and 2 input letters. In particular, we obtain a new estimation of the expected length of the shortest reset word $\approx 2.5\sqrt{n-5}$ ."
SPRINGERLINK,Chapter,2013,Fast-Forward Runtime Monitoring — An Industrial Case Study,Christian ColomboGordon J. Pace,"Label Transition System, Monitor State, System Trace, Transition System, Translation Function",10,"Amongst the challenges of statefully monitoring large-scale industrial systems is the ability to efficiently advance the monitors to the current state of the system. This problem presents itself under various guises such as when a monitoring system is being deployed for the first time, when monitors are changed and redeployed, and when asynchronous monitors fall too much behind the system. We propose fast-forward monitoring — a means of reaching the monitoring state at a particular point in time in an efficient manner, without actually traversing all the transitions leading to that state, and which we applied to a financial transaction system with millions of transactions already affected. In this paper we discuss our experience and present a generic theory of monitor fast-forwarding instantiating it for efficient monitor deployment in real-life systems."
SPRINGERLINK,Chapter,2013,Reducing Monitoring Overhead by Integrating Event- and Time-Triggered Techniques,Chun Wah Wallace WuDeepak KumarBorzoo BonakdarpourSebastian Fischmeister,"Basic Block, Execution Path, Linear Temporal Logic, Monitoring Mode, Symbolic Execution",10,"Runtime verification is a formal technique used to check whether a program under inspection satisfies its specification by using a runtime monitor. Existing monitoring approaches use one of two ways for evaluating a set of logical properties: (1) event-triggered , where the program invokes the monitor when the state of the program changes, and (2) time-triggered , where the monitor periodically preempts the program and reads its state. Realizing the former is straightforward, but the runtime behaviour of event-triggered monitors are difficult to predict. Time-triggered monitoring (designed for real-time embedded systems), on the other hand, provides predictable monitoring behavior and overhead bounds at run time. Our previous work shows that time-triggered monitoring can potentially reduce the runtime overhead provided that the monitor samples the program state at a low frequency. In this paper, we propose a hybrid method that leverages the benefits of both event- and time-triggered methods to reduce the overall monitoring overhead. We formulate an optimization problem, whose solution is a set of instrumentation instructions that switches between event-triggered and time-triggered modes of monitoring at run time; the solution may indicate the use of exactly one mode or a combination of the two modes. We fully implemented this method to produce instrumentation schemes for C programs that run on an ARM Cortex-M3 processor, and experimental results validate the effectiveness of this approach."
SPRINGERLINK,Chapter,2013,A Metric for Testing Program Verification Systems,Bernhard BeckertThorsten BormerMarkus Wagner,"Code Coverage, Coverage Criterion, Java Modeling Language, Proof Search, Test Suite",10,"The correctness of program verification systems is of great importance, and it needs to be checked and demonstrated to users and certification agencies. One of the contributing factors to the correctness of the whole verification system is the correctness of the background axiomatization, respectively the correctness of calculus rules. In this paper, we examine how testing verification systems is able to provide evidence for the correctness of the rule base or the axiomatization. For this, we present a new coverage criterion called axiomatization coverage, which allows us to judge the quality of existing test suites for verification systems. We evaluate this coverage criterion at two verification tools using the test suites provided by each tool."
SPRINGERLINK,Chapter,2013,Constraint Specification and Test Generation for OSEK/VDX-Based Operating Systems,Yunja Choi,"Constraint Type, Model Check, Regular Language, Task Model, Test Sequence",10,"This work suggests a method for systematically constructing an environment model for automotive operating systems compliant with the OSEK/VDX international standard by introducing a constraint specification language, OSEK_CSL, and defining its underlying formal models. OSEK_CSL is designed for specifying constraints of OSEK/VDX using a pre-defined set of constraint types identified from the OSEK/VDX standard. Each constraint specified in OSEK_CSL is interpreted as a context-free language and is converted into push-down automata using NuSMV, which allows automated test sequence generation using LTL model checking. This approach supports selective applications of constraints and thus is able to control the “degree” of test sequences with respect to test purposes. An application of the suggested approach demonstrates its effectiveness in identifying safety problems."
SPRINGERLINK,Chapter,2013,A Fault Injection Based Approach to Assessment of Quality of Test Sets for BPEL Processes,Damian GrelaKrzysztof SapiechaJoanna Strug,"BPEL, Business Processes, Fault Injection, Mutation Testing, Orchestration, Test Sets Quality Assessment, Web-Services",10,"Mutation testing is an effective technique for assessing a quality of test sets for software systems, but it suffers from high computational costs of generating and executing a large number of mutants. In the domain of BPEL processes each mutant needs to be deployed before it can be executed, thus the cost of processing mutants increases further. In contrast to mutation testing, fault injection is able to inject faults directly into the original process what reduces the redeployment requirement. The paper presents an experiment of the application of software fault injection to assess quality of test sets for BPEL processes. Faults are introduced by a Software Fault Injector for BPEL Processes (SFIBP). SFIBP simulates effects of the faults by modifying invocations of web-services and their internal variables. The experiment proved high superiority of the application of the SFIBP over the mutation testing, especially in the case of time requirements."
IEEEXPLORE,Conference Paper,2019,Enhancing Acceptance Test-Driven Development with Model-Based Test Generation,R. Ramler; C. Klammer,acceptance testing;model based testing;BDD;GUI testing;end-to-end testing;test automation architecture,2,"Acceptance test-driven development is widely used in practice. However, writing and maintaining acceptance tests is a costly and time-consuming activity, in particular when a system is tested via the GUI. In model-based testing, the tests are automatically generated from a model of the system. In this paper, we report our experience from applying a combination of acceptance test-driven development and model-based testing in several real-world projects from industry. With the application of model-based testing, we increased test coverage and extend testing to usage scenarios not exercised by the existing acceptance tests. In the industry projects, MBT was used as an enhancement rather than a replacement for ATDD. By creating a layered test automation architecture, we were able to reuse the established automation for model-based testing and to apply both approaches simultaneously. This strategy also helped us to minimize the risks and to reduce the effort involved in introducing MBT in the projects."
IEEEXPLORE,Conference Paper,2015,"U-Test: Evolving, Modelling and Testing Realistic Uncertain Behaviours of Cyber-Physical Systems",S. Ali; T. Yue,,2,"Uncertainty is intrinsic in Cyber-Physical Systems (CPSs) due to novel interactions of embedded systems, networking equipment, cloud infrastructures and humans. Our daily life has been increasing dependent on CPS applications in safety/mission critical domains such as healthcare, aerospace, oil/gas and maritime. For example, the National Institute of Standards and Technology (NIST) reported that direct CPS applications account for more than $32.3 trillions and expect to grow $82 trillions by 2025 (about half of the world economy). Expecting enormous dependence of our lives on CPSs in the future, dealing with uncertainty at an acceptable cost is vital to avoid posing undue threats to its users and environment. To ensure correct delivery of their functions at an acceptable cost even in the presence of uncertainty, CPSs must be reliable, robust, efficient, safe, and secure. All these properties are facets of a more general property often known as dependability. Improving system dependability first and foremost relies on the ability to verify and validate CPSs in a cost-effective manner and one way of achieving this is via systematic and automated Model-Based Testing (MBT): automated derivation of test cases from a behavioral model of a system. MBT supports rigorous, systematic, and automated testing, which eventually reduces the number of faults in the delivered systems and thus improves their quality. The goal of the U-Test project (a recently funded project under the EU Horizon2020 program (http://ec.europa.eu/programmes/horizon2020/) is to improve the dependability of CPSs, via cost-effective, model-based and search-based testing of CPSs under unknown risky uncertainty. Unknown uncertainty is the state of a CPS that can only be determined at the runtime as opposed to known uncertainty that is known at the design time and outcome from risky uncertainty is undesirable. To achieve our goal, we will advance the current state-of-art of testing CPSs by developing a novel solution based on sound theoretical foundation for uncertainty testing in the following steps: 1) Developing a light-weight modelling solution with rich formalism to support minimal modelling of known uncertainty with risk information; 2) Intelligently evolving known uncertainty models towards realistic and risky unknown uncertainty models (evolved models) using search algorithms (e.g., genetic algorithms mimicking natural selection); and 3) Automatically generating test cases from the evolved models to test a CPS under unknown uncertainty to ensure that the CPS continues to operate properly and possibly at a reduced quality of operation, rather than failing completely."
IEEEXPLORE,Conference Paper,2019,Exploiting MDE for Platform-Independent Testing of Service Orchestrations,L. Leal; L. Montecchi; A. Ceccarelli; E. Martins,model-driven engineering;model-based testing;SOA;orchestration,4,"Service Oriented Architecture (SOA) is a common design pattern that allows building applications composed of several services. It promotes features as interoperability, scalability, and software reuse. Services composing a SOA system may evolve and change during runtime, often outside the control of the owner of the application, which makes the verification and validation processes complex. Among all the automated techniques to validate the behavior of an SOA application, is Model-Based Testing (MBT). MBT requires an accurate model of the application in order to generate suitable test cases. However, the intrinsic of a SOA application sets significant challenges to MBT effectiveness. In this paper we discuss the challenges in the testing of SOA applications, and we propose the use of Model-Driven Engineering (MDE) to improve the flexibility of testing tools. Finally, we outline our plan for realizing MDE-driven MBT within an existing online testing framework."
IEEEXPLORE,Conference Paper,2020,Lightweight MBT Testing for National e-Health Portal in Norway,D. Gafurov; M. S. Grovan; A. E. Hurum,Model based testing;GDPR testing;Helsenorge,5,"We present lightweight model-based testing (MBT) of privacy and authorization concepts of national portal for electronic health services in Norway (which has over a million of visits per month). We have developed test models for creating and updating privacy levels and authorization categories using finite state machine. Our models emphasize not only positive but also negative behavioral aspects of the system. Using edge and edge-pair coverage as an acceptance criteria we identify and systematically derive abstract tests (high level user scenario) from models. Abstract tests are further refined and transformed into concrete tests with detailed steps and data. Although derivation of abstract tests and their transformation into concrete ones are manual, execution of concrete tests and generation of test report are automated. In total, we extracted 85 abstract test cases which resulted in 80 concrete test cases with over 550 iterations. Automated execution of all tests takes about 1 hour, while manual execution of one takes about 5 minutes (over 40 times speedup). MBT contributed to shift the focus of our intellectual work effort into model design rather than test case design, thus making derivation of test scenarios systematic and straight forward. In addition, applying MBT augmented and extended our traditional quality assurance techniques by facilitating better comprehension of new privacy and authorization concepts. Graphical models served as a useful aid in learning these concepts for newcomers."
IEEEXPLORE,Conference Paper,2014,Supporting the Combined Selection of Model-Based Testing Techniques,A. C. Dias-Neto; G. H. Travassos,Software testing;model-based testing;software technology selection;recommendation system;experimental software engineering,17,"The technical literature on model-based testing (MBT) offers us several techniques with different characteristics and goals. Contemporary software projects usually need to make use of different software testing techniques. However, a lack of empirical information regarding their scalability and effectiveness is observed. It makes their application difficult in real projects, increasing the technical difficulties to combine two or more MBT techniques for the same software project. In addition, current software testing selection approaches offer limited support for the combined selection of techniques. Therefore, this paper describes the conception and evaluation of an approach aimed at supporting the combined selection of MBT techniques for software projects. It consists of an evidence-based body of knowledge with 219 MBT techniques and their corresponding characteristics and a selection process that provides indicators on the level of adequacy (impact indicator) amongst MBT techniques and software projects characteristics. Results from the data analysis indicate it contributes to improve the effectiveness and efficiency of the selection process when compared to another selection approach available in the technical literature. Aiming at facilitating its use, a computerized infrastructure, evaluated into an industrial context and evolved to implement all the facilities needed to support such selection approach, is presented."
IEEEXPLORE,Conference Paper,2022,A Model-Based Testing System for Safety of Railway Interlocking,H. Su; M. Chai; H. Liu; J. Chai; C. Yue,,6,"Testing is an important safety assurance technique for railway interlocking systems. Model-based testing (MBT) allows for designing and maintaining tests with high-level models and generating test suites from these models automatically. Although MBT has the potential to improve testing efficiency and quality, it is not clear whether this technique is applicable for testing complex variant-rich interlocking software. In this paper, we report our experience in introducing MBT in inter-locking testing. We develop feature models of the interlocking route control process to improve the reusability of the models. The experimental results show that our approach is able to improve the quality and efficiency of real-world interlocking acceptance testing."
IEEEXPLORE,Conference Paper,2013,"Test Generation for RTES from SysML Models: Context, Motivations and Research Proposal",J. -M. Gauthier,Model-Based Testing;Real-time systems;SysML,2,"This paper presents the context, motivations and perspectives of my PhD research about model-based testing for real-time and embedded systems using SysML. This work is based on an existing model-based approach which has been proposed during the VETESS project. This approach aims to generate tests for embedded systems. In this paper, we identify areas of improvement, which permit us to evolve the initial approach by taking into account real-time aspects. This will contribute to an automated Model-Based Testing tool-chain for real-time and embedded systems."
IEEEXPLORE,Conference Paper,2023,From BDD Scenarios to Test Case Generation,T. Zameni; P. van Den Bos; J. Tretmans; J. Foederer; A. Rensink,Behavior-Driven Development;Model-Based testing;Compositional testing,9,"Model-based testing (MBT) offers the possibility of automatic generation and execution of tests. However, it is not yet widely used in industry due to the difficulty in creating and maintaining models. On the other hand, Behavior Driven Development (BDD) is becoming more popular in the agile development process to achieve a common understanding of the system under development among stakeholders and to automate testing. However, BDD scenarios are written in human language and are usually not precise enough. Moreover, tests extracted from BDD scenarios are too short and incomplete; they only cover a very small part of the system. Our goal is to combine these two approaches to benefit from the usability of BDD and the test automation capabilities of MBT. In this paper, we first define a formal model of scenarios that we call BDD Transition Systems, second, we create more complete tests by composing scenarios (model composition), and finally, we generate and execute tests automatically. We demonstrate the applicability of this approach in a real-world example: an industrial printer."
IEEEXPLORE,Conference Paper,2016,D-MBTDD: An Approach for Reusing Test Artefacts in Evolving System,T. H. Ussami; E. Martins; L. Montecchi,Model-Based Test Driven Development;Evolving System;Agile Development;Incremental Tests;Test Reuse;Model-Based Regression Tests,8,"Agile software development methodologies use an iterative and incremental development in order to handle evolving systems. Consolidated techniques in the field of testing have been applied to these techniques with the main purpose of aiding in the test creation stage. An example is Model-Based Test Driven Development (MBTDD) which joins the concepts of Model-Based Testing (MBT) and Test Driven Development (TDD). However, when iterative and incremental processes are used, problems appear as the consequence of the evolution of the system, such as: how to reuse the test artefacts, and how to select the relevant tests for implementing the new version of the system. In this context, this work proposes a process called D-MBTDD in which the agile development of a system is guided by model-based tests, focusing on helping with the reuse of test artefacts and on the process of identifying tests relevant to development. The information about the modifications between two versions of the test model are used in this approach, which was compared to the Regenerate-All approach, which regenerates test cases along the iterations and does not reuse any of them."
IEEEXPLORE,Conference Paper,2018,A Model-Based Test Case Management Approach for Integrated Sets of Domain-Specific Models,R. Pröll; B. Bauer,Model-Based Testing;Test Case Management;Test Selection;Test Prioritization;Test Suite Reduction;Test Model Scoping,10,"Due to rapid improvements in the area of embedded processing hardware, the complexity of developed systems constantly increases. In order to ensure a high quality level of such systems, related quality assurance concepts have to evolve. The introduction of Model-Based Testing (MBT) approaches has shown promising results by automating and abstracting multiple activities of the software testing life cycle. Nevertheless, there is a strong need for approaches supporting scoped test models, i.e. subsets of test cases, reflecting specific test purposes driven by risk-oriented development strategies. Therefore, we developed an integrated and model-based approach supporting test case management, which incorporates the beneficial aspects of abstract development methodologies with predominant research for test case management in non-model-based scenarios. Based on a new model artifact, the integration model, tasks like cross-domain information mapping and the integration of domain-specific KPIs derived by analyses favor the subsequently applied constraint-based mechanism for test case management. Further, a prototypical implementation of these concepts within the Architecture And Analysis Framework (A3F) is elaborated and further evaluated based on representative application scenarios. A comparative view on related work leads to a conclusive statement regarding our future work."
IEEEXPLORE,Conference Paper,2022,"Impact of Software Quality on ""GA-FC"" Software Testing Technique",S. Hooda; V. Lamba; S. Kaur; V. K. Sharma; R. Kumar; V. Sood,Software Quality;Software Testing;Software Quality Model;Quality Metric,6,"Testing of Software quality is an important and crucial task which must be performed on every software product to meet the customer’s expectation and to deliver a quality software. Model based testing reduces the reoccurring cost and time for test suites maintained in long term. Recently a ""GA-FC"" software testing approach based on model based testing has formulated for aspect-oriented software system which reduces the size of the test suites and testing time. Performance analysis of ""GA-FC"" demonstrates its efficiency in terms of maximum coverage of aspects and minimization of the size of the test suite. This paper discusses the impact of software quality on ""GA-FC"" technique on medium size application of aspect-oriented software system."
IEEEXPLORE,Conference Paper,2018,Managing aircraft by trajectory: Literature review and lessons learned,K. Leiden; A. Fernandes; S. Atkins,,16,"In order to realize the full potential of the Next Generation Air Transportation System (NextGen), improved management along planned trajectories between air navigation service providers (ANSPs) and system users (e.g., pilots and airline dispatchers) is needed. Automation improvements and increased data communications between aircraft and ground automation would make the concept of Management by Trajectory (MBT) possible. Key components of the MBT concept include: The ability for air traffic controllers and managers to quickly generate, evaluate and implement changes to an aircraft's trajectory; Imposing constraints on flight operator-preferred trajectories only to the extent necessary to maintain safe and efficient traffic flows; A method for the exchange of trajectory information between ground automation systems and the aircraft that allows for trajectory synchronization and trajectory negotiation. MBT addresses shortfalls that remain in the Trajectory Based Operations (TBO) solution set, despite years of research into various aspects of transitioning from the current airspace environment to TBO. This paper provides findings and insights from a literature survey of TBO-related concepts and technologies. These insights can be applied to improve the feasibility and ultimate adoption of MBT."
IEEEXPLORE,Conference Paper,2015,Model-based integration testing of ROS packages: A mobile robot case study,J. Ernits; E. Halling; G. Kanter; J. Vain,,7,"We apply model-based testing - a black box testing technology - to improve the state of the art of integration testing of navigation and localisation software for mobile robots built in ROS. Online model-based testing involves building executable models of the requirements and executing them in parallel with the implementation under test (IUT). In the current paper we present an automated approach to generating a model from the topological map that specifies where the robot can move to. In addition, we show how to specify scenarios of interest and how to add human models to the simulated environment according to a specified scenario. We measure the quality of the tests by code coverage, and empirically show that it is possible to achieve increased test coverage by specifying simple scenarios on the automatically generated model of the topological map. The scenarios augmented by adding humans to specified rooms at specified stages of the scenario simulate the changes in the environment caused by humans. Since we test navigation at coordinate and topological level, we report on finding problems related to the topological map."
IEEEXPLORE,Conference Paper,2016,Model-Based Continuous Verification,L. Fan; S. Chen; L. Xu; Z. Yang; H. Zhu,consistency checking;model-based testing;linear temporal logic;model checking,8,"Model-based engineering has emerged as a key set of technologies to engineer software systems. While system source code is expected to match with the designed model, legacy systems and workarounds during deployment would undoubtedly change the source code, making the actual running implementation mismatch with its model. Such mismatch poses a challenge of maintaining the conformance between the model and the corresponding implementation. Prior techniques, such as model checking and model-based testing, simply assumed the sole correctness of the model or the implementation, which is naive since they both could contain correct information (e.g. representing either the software requirements or the actual running environment).In this paper, we aim to address this problem through model-based continuous verification (ConV), an iterative verification process that links the traditional model checking phase with the software testing phase to a feedback loop, ensuring the conformance between the system model and its implementation. It allows to execute the abstract test cases over the implementation through a semi-automatic binding mechanism to guide the update of the code, and augments system properties from the actually running system to guide the update of the model through model checking. Based on these techniques, we implemented Eunomia, a conformance verification system, to support the continuous verification process. Experiments show that Eunomia can effectively detect and locate inconsistencies both in the model and the source code."
IEEEXPLORE,Conference Paper,2020,Model-Based Testing of Read Only Graph Queries,L. Lambers; S. Schneider; M. Weisgut,Automatic testing;Logic testing;Software testing;NoSQL databases,11,"Modern software applications often interface with graph-structured data managed by graph databases queried with specific graph query languages. Writing, understanding, and maintaining graph queries can be difficult and error-prone. Important decisions taken by the software application are in many cases based on the outcome of these graph queries. If test design does not account for the complexity incorporated in these queries, considerable parts of the business logic of such applications will not be tested appropriately.We aim at tackling the challenge of developing dedicated testing techniques for graph queries. In particular, we present a first model-based testing approach for read only queries supporting automated test creation, execution, and evaluation. We model queries using a well-established graph logic, being expressively equivalent to first-order logic on graphs. We develop a first coverage criterion requiring the presence of a test case returning an empty query result as well as the presence of a test case returning a non-empty result. We present the architecture of our model-based testing approach, which is supported by a first implementation. We illustrate our approach with complex read only graph queries from an industrial benchmark case study."
IEEEXPLORE,Conference Paper,2014,A Heuristic-Based Approach to Refactor Crosscutting Behaviors in UML State Machines,M. U. Khan; M. Z. Iqbal; S. Ali,Model Refactoring;UML State machine;Aspect-Oriented Modeling;Heuristics,4,"UML state machines are commonly used to model the state-based behavior of communication and control systems to support various activities such as test cases and code generation. Standard UML state machines are well suited to model functional behavior, however extra-functional behavior such as robustness and security can also be directly modeled on them, but this often results in cluttered models since extra-functional behaviors are often crosscutting. Such modeling crosscutting behavior directly on UML state machines is a common practice. Aspect-Oriented Modeling (AOM) allows systematically modeling of crosscutting behavior and has shown to provide a scalable solution in the recent years. However, due to lack of familiarity of AOM in both academic and industry, extra-functional behavior is often modeled directly on UML state machines and as a result those UML state machines are difficult to read and maintain. To improve the readability of already developed UML state machines and ease maintenance, we propose a set of heuristics, derived from two industrial cases studies, implemented in a tool to automatically identify commonly observed crosscutting behaviors in UML state machines and refactor them as Aspect State Machines. Such refactoring makes the state machines easier to maintain and comprehend. We present the results of applying our proposed heuristics to the existing UML state machines of two industrial case studies developed for model-based testing."
IEEEXPLORE,Conference Paper,2019,Extending MUD Profiles Through an Automated IoT Security Testing Methodology,S. N. Matheu; J. L. Hernández-Ramos; S. Pérez; A. F. Skarmeta,Internet of Things;security testing;MUD;EDHOC,20,"Defining the intended behaviour of IoT devices is considered as a key aspect to detect and mitigate potential security attacks. In this direction, the Manufacturer Usage Description (MUD) has been recently standardised to reduce the attack surface of a certain device through the definition of access control policies. However, the semantic model is only intended to provide network level restrictions for the communication of such device. In order to increase the expressiveness of this approach, we propose the use of an automated IoT security testing methodology, so that testing results are used to generate augmented MUD profiles, in which additional security aspects are considered. For the enforcement of these profiles, we propose the use of different access control technologies addressing application layer security concerns. Furthermore, the methodology is based on the use of Model-Based Testing (MBT) techniques to automate the generation, design and implementation of security tests. Then, we describe the application of the resulting approach to the Elliptic Curve Diffie-Hellman over COSE (EDHOC) protocol, which represents a standardisation effort to build a lightweight authenticated key exchange protocol for IoT constrained scenarios."
IEEEXPLORE,Conference Paper,2013,XSS pattern for attack modeling in testing,J. Bozic; F. Wotawa,Attack pattern model;cross-site scripting;model-based testing;security testing,4,"Security issues of web applications are still a current topic of interest especially when considering the consequences of unintended behaviour. Such services might handle sensitive data about several thousands or millions of users. Hence, exploiting services or other undesired effects that cause harm on users has to be avoided. Therefore, for software developers of such applications one of the major tasks in providing security is to embed testing methodologies into the software development cycle, thus minimizing the subsequent damage resulting in debugging and time intensive upgrading. Model-based testing evolved as one of the methodologies which offer several theoretical and practical approaches in testing the system under test (SUT) that combine several input generation strategies like mutation testing, using of concrete and symbolic execution etc. by putting the emphasis on specification of the model of an application. In this work we propose an approach that makes use of an attack pattern model in form of a UML state machine for test case generation and execution. The paper also discusses the current implementation of our attack pattern testing tool using a XSS attack pattern and demonstrates the execution in a case study."
IEEEXPLORE,Conference Paper,2014,Test Process Improvement with Documentation Driven Integration Testing,F. Häser; M. Felderer; R. Breu,Model-Based Integration Testing;Test Process Improvement;Regression Testing,6,"Improving the maturity of the test process in an organization, especially but not limited to integration testing, involves obstacles and risks, such as the additional work overhead of the new process. In addition, integration testing descriptions are often too technical not addressing the language needs of the domain. In research cooperations with companies from the insurance and banking domain it turned out that test descriptions and reports are one of the most useful testing artifacts, while doing adhoc testing. This paper presents a bottom up testing approach, which first helps the integration tester in producing a semi-formal test description and report, up to be an enabler for automatic model-based testing in the very end. The presented approach is based on a textual domain specific language that is able to evolve over time. This is done by analyzing the test descriptions and reports automatically with machine learning techniques as well as manually by integration testers. Often recurring test steps or used components are integrated into the test language, making it specially tailored for a specific organization. For each test step implementations can be attached, preparing it for the next iteration. In this paper the methodology and architecture of our integration testing approach are presented together with the underlying language concepts."
IEEEXPLORE,Conference Paper,2015,Test Script Generation Based on Design Documents for Web Application Testing,H. Tanno; X. Zhang,model based testing;test script generation;test case derivation;design document,2,"Testing is critical for software quality assurance, but as most of this work is done manually, it is an area ripe for cost reductions. One good approach to cost reduction is to produce test scripts, the inputs of the test execution tool, and to execute tests automatically. However, when applying this approach, making and maintaining the test scripts are costly tasks. To solve this problem, we propose an approach to automatically generate test scripts from design documents, which are artifacts of the design process, using model-based testing. We confirm effectiveness of our approach by comparing it to an existing approach."
IEEEXPLORE,Conference Paper,2023,Comparative study on model based test of automotive automatic control system,Z. Gao,EUC;Maximum coverage;CANoe;GraphWalker Tools,5,"In today’s automotive industry, due to the increasingly complex nature of ECUs, there is a great need to create a model that can be tested early to maintain functional functioning. However, there are not many solutions that teach us how to organize and run these tests for maximum coverage. This article evaluates prototype CANoe+, which maximizes the coverage of test cases generated using the CANoe and GraphWalker tools from the perspective of software developers and software testers. CANoe+ was significantly more effective than CANOE alone when the Mann-Whitney Wilcoxon statistical test was used in the experiment. Such experimental results add to the existing evidence and demonstrate the irreplaceable advantages of using model-based testing techniques such as C.."
IEEEXPLORE,Conference Paper,2016,Dependability Verification of Nanosatellite Embedded Software Supported by a Reusable Test System,C. A. P. L. Conceicao; F. Mattiello-Francisco; C. L. G. Batista,dependability;CubeSat;interoperability;verification;failure,7,"The use of CubeSats has increased tremendously over the 15 years since the standard creation because the low cost and reduced project development cycle. However, one of the most concerns in reducing a project delivery time is the collateral effect in test process, resulting in failures in the mission operation. This paper proposes the combined use of the Model-Driven Engineering (MDE) and Model-Base Testing (MBT) approaches in the Validation and Verification (V&V) process of a nanosatellite mission, focusing on an evolved way to measure the dependability requirements of the interoperable on-board software. The proposal counts on a reusable Test System (TS) based on Arduinos that are integrated in the engineering model of the Cubesat architecture via I2C bus. From the behavioral models of both the on-board computer and the satellite payloads, source code can be generated in order to be embedded in the Arduinos, prototyping in the TS the expected behavior of the interactions between the specified subsystems. These models can also be useful to derive test suites following a MBT approach. Thus the TS can support the execution of different test cases at different stages of development of the software intensive subsystems. The proposed V&V process is discussed in the context of a particular nanosatellite named NanosatC-Br2 under development at INPE."
IEEEXPLORE,Conference Paper,2016,An Approach for Verification of a Satellite Simulator - An Evolving System,P. D. Barbosa Da Silva; A. M. Ambrosio; E. Villani; D. R. Azevedo,Satellite simulator;Test automation;Verification;Validation;Formal methods;Model checking;Model based-testing,7,"Satellite simulators are developed in the context of a space mission lifecycle to represent the real behavior of a satellite during operation and may be used for different purposes. To attend a particular purpose new functions are added or modified according to the mission phase needs, requiring models re-adaptation in a system evolving concept. The process of verification of satellite simulator software requires high-efficiency in accomplishing realistic functional and behavioral requirements. Based on the complex set of requirements the satellite behavior is represented in the simulator through software models specified by tables of cause-effect rules. Considering that the Satellite Simulator is an evolving systems and it needs to assure that the logic implemented in the simulator conforms to the requirements, the manual verification process becomes impracticable, therefore demanding a compatible verification approach. The approach suggested here unifies two techniques Conformance and Fault Inject (CoFI), constructed on Model-Based Testing and Model Checking added to a method so that it can translate the tables of cause-effect rules into finite state machines. This paper presents the verification approach illustrating it with the Data Collection Subsystem (DCS) model of the CBERS satellite simulator being developed at National Institute for Space Research (INPE)."
IEEEXPLORE,Conference Paper,2020,Model-based Knock Prediction and its Stochastic Feedforward Compensation,R. C. Li; G. G. Zhu,,6,"This article studies the correlation between incylinder mixture temperature at intake valve closing and the engine knock, along with cycle-to-cycle knock variability based on a knock predictive model developed earlier. Based on the correlated stochastic relationship, a feedforward knock limit control strategy is developed to reduce the knock cycle-to-cycle variability and maintain the knock mean-intensity within a desired up bound while keeping spark timing close to engine MBT (maximum brake torque) timing as close as possible. The proposed feedforward control strategy is evaluated based on the knock predictive model in terms of knock mean-intensity and standard deviation and demonstrated its capability of reducing the knock cycle-to-cycle variability under the knock intensity constraint."
IEEEXPLORE,Conference Paper,2018,Taking trajectory based operations to the next level: Management by trajectory,A. Fernandes; S. Atkins; K. Leiden; T. Bagnali; C. Kaler; M. Evans; A. Bell; T. Kilbourne; M. R. C. Jackson,,26,"· Assigned trajectory from flight's current state to its destination composed of: - Minimal set of trajectory constraints to achieve safety and efficiency goals - Trajectory description so the assigned trajectory is a complete trajectory when few trajectory constraints are required · All aircraft follow their assigned trajectories unless they negotiate a revised trajectory - All airspace users provide and maintain trajectory intent and aircraft capability info - Aircraft intent may contain details such as ETAs at waypoints that do not have time constraints in the assigned trajectory - Intent can change freely without negotiation, as long as it conforms to the assigned trajectory - Together, the assigned trajectory and aircraft intent enable accurate prediction of the 4DT that the aircraft will fly · NAS Constraint Service gathers and publishes information about all known NAS constraints - Assigned trajectory references NAS constraints driving the trajectory constraints · Facilitates identifying aircraft affected by changes to (or removal of) NAS constraints · Uncertainty and disruptions are handled by modifying the assigned trajectory as far in advance as possible - Allows changes to be negotiated and communicated as assigned trajectory amendments and not tactical control actions · MBT enables more accurate trajectory predictions, leading to: - Improved ATM performance and robustness to off-nominal conditions - Increased flexibility and operational efficiency."
IEEEXPLORE,Conference Paper,2013,Distributed Online Test Generation for Model-Based Testing,T. Kanstrén; T. Kekkonen,online test generation;optimization;algorithm;model-based testing;distributed testing,8,"In online model-based testing, test execution is interleaved with test generation. Test cases should be generated and executed with minimal delay, while still achieving targeted coverage criteria quickly. Extensive model analysis in such case is not possible as any delays in choosing the next step will immediately impact the response times of test execution. The algorithms thus need to be as fast as possible, where a limiting factor is the available computing power. Experts working on the test models used for the generation often need to be able to quickly edit the models, generate test cases, and use the feedback to further evolve the models. Reserving large-scale computing resources while editing the model is unnecessary, but performing the analysis on them for test generation can improve the execution response time significantly. In this paper, we present an approach and algorithm for distributing the online test generation analysis part concurrently over the network, while enabling the expert to work on the models and execute the test cases locally at the same time."
IEEEXPLORE,Conference Paper,2018,Uncovering Unknown System Behaviors in Uncertain Networks with Model and Search-Based Testing,R. Ji; Z. Li; S. Chen; M. Pan; T. Zhang; S. Ali; T. Yue; X. Li,uncertainty;Model-based Testing;Search-based Testing;Uncertain Networks,11,"Modern software systems rely on information networks for communication. Such information networks are inherently unpredictable and unreliable. Consequently, software systems behave in an unstipulated manner in uncertain network conditions. Discovering unknown behaviors of these software systems in uncertain network conditions is essential to ensure their correct behaviors. Such discovery requires the development of systematic and automated methods. We propose an online and iterative model-based testing approach to evolve test models with search algorithms. Our ultimate aim is to discover unknown expected behaviors that can only be observed in uncertain network conditions. Also, we have implemented an adaptive search-based test case generation strategy to generate test cases that are executed on the system under test. We evaluated our approach with an open source video conference application-Jitsi with three search algorithms in comparison with random search. Results show that our approach is efficient in discovering unknown system behaviors. In particular, (1+1) Evolutionary Algorithm outperformed the other algorithms."
SCIENCEDIRECT,Journal Article,2018,End-to-end Automatic Business Process Validation,"Paiva AC,Flores NH,Faria JP,Marques JM","Software Testing, Business Process Testing, End-to-end Process Testing, Model Based Testing",6,"Business Process Testing is the act of validating that end-to-end transactions through enterprise systems continue to work correctly as the underlying packaged applications evolve. End-to-end automatic business process validation can be a challenging task, but an important way to check that business rules continue to work properly and that problems are detected and corrected as soon as possible. This paper presents the design of a test automation platform, ETAP-Pro, to test end-to-end business processes that aims to overcome some challenges in validating business processes."
SCIENCEDIRECT,Journal Article,2018,Increasing test efficiency by risk-driven model-based testing,"Şahin Gebizli C,Kırkıcı A,Sözer H","Model-based testing, Model refinement, Statistical usage testing, Risk-based testing, Industrial case study, Software test automation",10,"We introduce an approach and a tool, RIMA, for adapting test models used for model-based testing to augment information regarding failure risk. We represent test models in the form of Markov chains. These models comprise a set of states and a set of state transitions that are annotated with probability values. These values steer the test case generation process, which aims at covering the most probable paths. RIMA refines these models in 3 steps. First, it updates transition probabilities based on a collected usage profile. Second, it updates the resulting models based on fault likelihood at each state, which is estimated based on static code analysis. Third, it performs updates based on error likelihood at each state, which is estimated with dynamic analysis. The approach is evaluated with two industrial case studies for testing digital TVs and smart phones. Results show that the approach increases test efficiency by revealing more faults in less testing time."
SCIENCEDIRECT,Journal Article,2018,SATE: Model-Based Testing with Design-to-Test and Plant Features,"Ma C,Jordan C,Provost J","discrete event system, programmable logic controller, conformance testing, validation",6,"In this paper we present SATE, a tool aiming at increasing test efficiency of model-based testing of DES using two approaches: design-to-test and plant features. First, the design-to-test approach automatically modifies the design while maintaining the original system behavior to overcome controllability, observability and SIC-testability issues. Secondly, testing with plant features reduces the number of test cases taking into account restrictions on the input space of programmable logic controllers caused by the plant that is to be controlled."
SCIENCEDIRECT,Journal Article,2022,A Systematic Literature Review on prioritizing software test cases using Markov chains,"Barbosa G,de Souza ÉF,dos Santos LB,da Silva M,Balera JM,Vijaykumar NL","Systematic Literature Review, Markov Chains, Test case prioritization",106902,"Context: Software Testing is a costly activity since the size of the test case set tends to increase as the construction of the software evolves. Test Case Prioritization (TCP) can reduce the effort and cost of software testing. TCP is an activity where a subset of the existing test cases is selected in order to maximize the possibility of finding defects. On the other hand, Markov Chains representing a reactive system, when solved, can present the occupation time of each of their states. The idea is to use such information and associate priority to those test cases that consist of states with the highest probabilities. Objective: The objective of this paper is to conduct a survey to identify and understand key initiatives for using Markov Chains in TCP. Aspects such as approaches, developed techniques, programming languages, analytical and simulation results, and validation tests are investigated. Methods: A Systematic Literature Review (SLR) was conducted considering studies published up to July 2021 from five different databases to answer the three research questions. Results: From SLR, we identified 480 studies addressing Markov Chains in TCP that have been reviewed in order to extract relevant information on a set of research questions. Conclusion: The final 12 studies analyzed use Markov Chains at some stage of test case prioritization in a distinct way, that is, we found that there is no strong relationship between any of the studies, not only on how the technique was used but also in the context of the application. Concerning the fields of application of this subject, 6 forms of approach were found: Controlled Markov Chain, Usage Model, Model-Based Test, Regression Test, Statistical Test, and Random Test. This demonstrates the versatility and robustness of the tool. A large part of the studies developed some prioritization tool, being its validation done in some cases analytically and in others numerically, such as: Measure of the software specification, Optimal Test Transition Probabilities, Adaptive Software Testing, Automatic Prioritization, Ant Colony Optimization, Model Driven approach, and Monte Carlo Random Testing."
SCIENCEDIRECT,Journal Article,2018,An investigation on utilization of biogas and syngas produced from biomass waste in premixed spark ignition engine,"Kan X,Zhou D,Yang W,Zhai X,Wang CH","Syngas, Biogas, SI engine, Experiment, KIVA-CHEMKIN, Blended fuel",13,"Syngas and biogas are two typical biofuels generated from biomass wastes through gasification and anaerobic digestion processes, which are considered to be the future fuels for IC engines. In this work, the utilization of biogas and syngas produced from horticultural waste in a premixed spark ignition engine was investigated. An experimentally validated KIVA4-based CFD simulation integrated with CHEMKIN was performed to evaluate engine performance fuelled by syngas and biogas under both single and blended-fuel modes. Effects of ignition timing, hydrogen content in syngas and methane content in biogas on both energetic and environmental performance have been studied. The indicated thermal efficiency (ITE) of syngas fueled engine at wide open throttle (WOT) condition under maximum brake torque (MBT) operation was found to be higher than that of biogas fueled engine, meanwhile, with much lower NOx emission. In addition, a comparison of the engine performance between the single and blended-fuel modes under different syngas mixing ratios was conducted in terms of ITE and NOX emission. The results suggest that the utilization of syngas and biogas under blended-fuel mode can not only maintain the MBT energetic performance under single-fuel mode, but also show its potential in reducing NOx emission and lessening the tendency of knock onset."
SCIENCEDIRECT,Journal Article,2016,Test automation of a measurement system using a domain-specific modelling language,"Kos T,Mernik M,Kosar T","Test automation, Domain-specific modelling languages, Usage experience",15,"The construction of domain-specific modelling languages (DSMLs) is only the first step within the needed toolchain. Models need to be maintained, modified or functional errors searched for. Therefore, tool support is vital for the DSML end-user’s efficiency. This paper presents SeTT, a simple but very useful tool for DSML end-users, a testing framework integrated within a DSML Sequencer. This Sequencer, part of the DEWESoft data acquisition system, supports the development of model-based tests using a high-level abstraction. The tests are used during the whole data acquisition process and able to test different systems’ parts. This paper shows how high-level specifications can be extended to describe a testing infrastructure for a specific DSML. In this manner, the Sequencer and SeTT were combined at the metamodel level. The contribution of the paper is to show that one can leverage on the DSML to build a testing framework with relatively little effort, by implementing assertions to it."
SCIENCEDIRECT,Journal Article,2014,"Experiences with formal engineering: Model-based specification, implementation and testing of a software bus at Neopost","Sijtema M,Belinfante A,Stoelinga MI,Marinelli L","Formal methods, Formal engineering, Model-based testing, IOCO, JTorX, mCRL2, LTSmin, CADP, , MCL, LPS,",22,"We report on the actual industrial use of formal methods during the development of a software bus. During an internship at Neopost Inc., of 14 weeks, we developed the server component of a software bus, called the XBus, using formal methods during the design, validation and testing phase: we modeled our design of the XBus in the process algebra mCRL2, validated the design using the mCRL2-simulator, and fully automatically tested our implementation with the model-based test tool JTorX. This resulted in a well-tested software bus with a maintainable architecture. Writing the model (mdev), simulating it, and testing the implementation with JTorX only took 17% of the total development time. Moreover, the errors found with model-based testing would have been hard to find with conventional test methods. Thus, we show that formal engineering can be feasible, beneficial and cost-effective. The findings above, reported earlier by us in (Sijtema et al., 2011) [1], were well-received, also in industrially oriented conferences (Ferreira and Romanenko, 2010) [2] and [3]. In this paper, we look back on the case study, and carefully analyze its merits and shortcomings. We reflect on (1) the added benefits of model checking, (2) model completeness and (3) the quality and performance of the test process. Thus, in a second phase, after the internship, we model checked the XBus protocol—this was not done in [1] since the Neopost business process required a working implementation after 14 weeks. We used the CADP tool evaluator4 to check the behavioral requirements obtained during the development. Model checking did not uncover errors in model mdev, but revealed that model mdev was neither complete nor optimized: in particular, requirements to the so-called bad weather behavior (exceptions, unexpected inputs, etc.) were missing. Therefore, we created several improved models, checked that we could validate them, and used them to analyze quality and performance of the test process. Model checking was expensive: it took us approx. 4 weeks in total, compared to 3 weeks for the entire model-based testing approach during the internship. In the second phase, we analyzed the quality and performance of the test process, where we looked at both code and model coverage. We found that high code coverage (almost 100%) is in most cases obtained within 1000 test steps and 2 minutes, which matches the fact that the faults in the XBus were discovered within a few minutes. Summarizing, we firmly believe that the formal engineering approach is cost-effective, and produces high quality software products. Model checking does yield significantly better models, but is also costly. Thus, system developers should trade off higher model quality against higher costs."
SCIENCEDIRECT,Journal Article,2021,Towards an automatic model-based Scrum Methodology,"Chantit S,Essebaa I","Model Driven Engineering, Model Driven Architecture, Model-Based Testing, Agile Methodologies, Scrum, V development Life Cycle",6,"Software systems evolve continuously and must be developed quickly to fit user requirements and new advances in technology. This has led the software engineering to propose several methods and approaches to overcome the development and maintenance of these software systems. In this regard, Agile Methodologies and Model-Driven Engineering (MDE) are two main approaches that have emerged in recent years and suggest a solution to some of the issues associated with Software systems developments. MDE focuses on software reuse through models and on generative approaches based on separation of concerns whereas Agile Methods promote the use of simpler models and best practices for programming to achieve quick feedback from clients within a development process. However, these two approaches have evolved separately and there are only a few works related to their combination. This paper presents a customized V development life cycle based on models which combines the two MDE variants: The MDA approach in the V left branch with the MBT approach to generate tests of the V right branch. In addition, we integrate this customized V life cycle in the agile Scrum methodology to facilitate the management of each Scrum sprint."
SCIENCEDIRECT,Journal Article,2021,An abstract framework for choreographic testing,"Coto A,Guanciale R,Tuosto E","Model-based testing, Choreography, Communicating finite state machines, Projection, Well-formedness",100712,We present a tool-supported approach for the model-driven testing of message-passing applications. Our approach envisages choreographies as a particularly suited model to derive tests in order to tame the problems of correctness of distributed applications.
SCIENCEDIRECT,Journal Article,2019,Hierarchical featured state machines,"Fragal VH,Simao A,Mousavi MR","Model validation, Software product line, Featured finite state machine, Hierarchical featured finite state machine",22,"Variants of the Finite State Machine (FSM) model have been extensively used to describe the behavior of reactive systems. In particular, several model-based testing techniques have been developed to support test case generation from FSMs and test case execution. Most of such techniques require several validation properties to hold for the underlying test models. Featured Finite State Machine (FFSM) is an extension of the FSM model proposed in our earlier publication that represents the abstract behavior of an entire Software Product Line (SPL). By validating an FFSM, we validate all valid products configurations of the SPL looking forward configurable test suites. However, modeling a large SPL using flat FFSMs may lead to a huge and hard-to-maintain specification. In this paper, we propose an extension of the FFSM model, named Hierarchical Featured State Machine (HFSM). Inspired by Statecharts and UML state machines, we introduce the HFSM model to improve model readability by grouping up FFSM conditional states and transitions into abstracted entities. Our ultimate goal is to use HFSMs as test models. To this end, we first define some syntactic and semantical validation criteria for HFSMs as prerequisites for using them as test models. Moreover, we implement an adapted graphical Eclipse-based editor from the Yakindu Project for modeling, derivation, and checking feature-oriented properties using Satisfiability Modulo Theory (SMT) solver tools. We investigate the applicability of our approach by applying it to an HFSM for a realistic case study (the Body Comfort System). The results indicate that HFSMs can be used to compactly represent and efficiently validate the behavior of parallel components in SPLs."
SCIENCEDIRECT,Journal Article,2017,Uncertainty-wise evolution of test ready models,"Zhang M,Ali S,Yue T,Norgre R","Uncertainty, Belief model, Belief test ready model, Model evolution, Model-based testing",20,"Context Cyber-Physical Systems (CPSs), when deployed for operation, are inherently prone to uncertainty. Considering their applications in critical domains (e.g., healthcare), it is important that such CPSs are tested sufficiently, with the explicit consideration of uncertainty. Model-based testing (MBT) involves creating test ready models capturing the expected behavior of a CPS and its operating environment. These test ready models are then used for generating executable test cases. It is, therefore, necessary to develop methods that can continuously evolve, based on real operational data collected during the operation of CPSs, test ready models and uncertainty captured in them, all together termed as Belief Test Ready Models (BMs) Objective Our objective is to propose a model evolution framework that can interactively improve the quality of BMs, based on operational data. Such BMs are developed by one or more test modelers (belief agents) with their assumptions about the expected behavior of a CPS, its expected physical environment, and potential future deployments. Thus, these models explicitly contain subjective uncertainty of the test modelers. Method We propose a framework (named as UncerTolve) for interactively evolving BMs (specified with extended UML notations) of CPSs with subjective uncertainty developed by test modelers. The key inputs of UncerTolve include initial BMs of CPSs with known subjective uncertainty and real data collected from the operation of CPSs. UncerTolve has three key features: 1) Validating the syntactic correctness and conformance of BMs against real operational data via model execution, 2) Evolving objective uncertainty measurements of BMs via model execution, and 3) Evolving state invariants (modeling test oracles) and guards of transitions (modeling constraints for test data generation) of BMs with a machine learning technique. Results As a proof-of-concept, we evaluated UncerTolve with one industrial CPS case study, i.e., GeoSports from the healthcare domain. Using UncerTolve, we managed to evolve 51% of belief elements, 18% of states, and 21% of transitions as compared to the initial BM developed in an industrial setting. Conclusion UncerTolve can successfully evolve model elements of the initial BM, in addition to objective uncertainty measurements using real operational data. The evolved model can be used to generate additional test cases covering evolved model elements and objective uncertainty. These additional test cases can be used to test the current and future deployments of a CPS to ensure that it will handle uncertainty gracefully during its operations."
SCIENCEDIRECT,Journal Article,2018,Model-Based Runtime Monitoring of Smart City Systems,"Incki K,Ari I","runtime monitoring, component-based iot, model-based testing, internet of things, complex-event processing, intelligent transportation, smart city",8,"The pace of proliferation for smart systems in city wide applications is unmatched. The introduction of Internet of Things (IoT), an enabler of smart city phenomenon, has incubated a productive environment for such innovations. Smart things equipped with IoT capabilities, allow for developing smart city applications at such large scale that each application can be represented as a system of systems (SoS). Nevertheless, the complexity of engineering such SoS has been a major challenge in developing and maintaining smart city applications. One of the engineering challenges that industry face today is the verification of a SoS smart city application at runtime. We introduce utilization of a model-based runtime monitoring approach for providing reliable service. We propose to use message sequence charts for representing a smart city application, later allow the practitioners to express expected behavior of an application in terms of complex-event processing patterns. We demonstrate the fidelity of our approach on a sample smart parking system. Our approach is one of its kind in enabling a non-intrusive monitoring of IoT behavior at runtime (online)."
SCIENCEDIRECT,Journal Article,2019,Retest test selection for product-line regression testing of variants and versions of variants,"Lity S,Nieke M,Thüm T,Schaefer I","Regression testing, Software evolution, Software product lines",18,"Testing is a crucial activity of product-line engineering. Due to shared commonality, testing each variant individually results in redundant testing processes. By adopting regression testing strategies, variants are tested incrementally by focusing on the variability between variants to reduce the overall testing effort. However, product lines evolve during their life-cycle to adapt, e.g., to changing requirements. Hence, quality assurance has also to be ensured after product-line evolution by efficiently testing respective versions of variants. In this paper, we propose retest test selection for product-line regression testing of variants and versions of variants. Based on delta-oriented test modeling, we capture the commonality and variability of an evolving product line by means of differences between variants and versions of variants. We exploit those differences to apply change impact analyses, where we reason about changed dependencies to be retested when stepping from a variant or a version of a variant to its subsequent one by selecting test cases for reexecution. We prototypically implemented our approach and evaluated its effectiveness and efficiency by means of two evolving product lines showing positive results."
SCIENCEDIRECT,Journal Article,2018,Effect of benzothiazole biocide on SRB-induced biocorrosion of hot-dip galvanized steel,"Eduok U,Faye O,Szpunar J","SRB-induced corrosion, Hot-dip galvanized steel, Surface pitting, 2-Mercaptobenzothiazole biocide, Biofilm",11,"In recent times, hot-dip galvanized steel (HDGS) products have been utilized in several engineering construction projects including architecture and structural fabrication due to their excellent durability and appearance. The galvanized Zn layer on steel is designed as a sacrificial anode against corrosion but it eventually fails due to biofouling and chloride-induced degradation. This work is designed to study the extent of damage caused by sulphate–reducing bacterial (SRB) colonization of HDGS surfaces, monitored within defined duration. The biocorrosion mechanism of the metal surface is elucidated by means of electrochemical assessments of associated liquid/metal interfacial phenomena evolved within the bacterial culture period and by monitoring the extent of surface pitting caused by associated biological activities of absorbed SRB cells. The rate of biocorrosion accompanying bacterial metabolic activities for test and control systems are further quantified by weight loss technique in the presence of a benzothiazole biocidal (MBT) additive capable of inhibiting biofilm growth at anaerobic conditions. MBT doped within the SRB-inoculated culture medium inhibited both SRB cellular growth and HDGS pitting, by forming passive antibiotic films on the metal surface. Since sustainable development is an important aspect of modern material designs and construction economics, this work provides a biofilm engineering background to safe monitoring of HDGS products."
SCIENCEDIRECT,Journal Article,2017,Quasi dimensional numerical investigation of syngas fuelled engine operation: MBT operation and parametric sensitivity analysis,"Shivapuji AM,Dasappa S","Non-regular fuel, Engine simulation, Quasi-dimensional model, Williams-Klimov criterion, Turbulent combustion, Syngas",18,"The formulation, validation and application of a thermodynamic quasi dimensional SI engine simulation model for syngas fuelled operation is reported. The QD approach establishes the dependence of turbulent combustion on mixture thermo-physical properties and fluid domain average turbulent parameters, eliminating the need for domain discretization (unlike in multi-dimensional models). Turbulent combustion is formulated along the Eddy Entrainment Laminar Burn-up concept (Williams-Klimov criterion) with non-linear dependence of mixture burn rate on local laminar flame speed and turbulent intensity. Simulations are reported for syngas fuelled operation of a six cylinder engine and compared with experimental pressure and heat release traces. Maximum brake torque stoichiometric operation pressure and heat release simulation traces evolve closely with corresponding experimental traces. The simulation peak pressure and IMEP deviations remain within 5% and 2% of experimental traces respectively while the position of peak pressure overlaps within ±0.5deg. Parametric sensitivity analysis for load, mixture quality and ignition timing are also addressed. Overall, the simulation results are in accordance within 5% of experimental results as long as the parametric variations are within the regimes of tuning of empirical correlations. In general, the versatility and robustness of quasi dimensional approach to simulate non-regular bio-derived alternative fuels is established."
SCIENCEDIRECT,Journal Article,2019,Model-based test suite generation for graph transformation system using model simulation and search-based techniques,"Kalaee A,Rafe V","Model-based testing, Search-based testing, Graph transformation specification, Data-flow coverage",29,"Context Test generation by model checking is a useful technique in model-based testing that allows automatic generation of test cases from models by utilizing the counter-examples/witnesses produced through a model checker. However, generating redundant test cases and state space explosion problem are two major obstacles to transfer this technique into industrial practice. Objective An idea to cope with these challenges consists in an intelligent model checking for exploring only a portion of the state space according to the test objectives. Motivated by this idea, we propose an approach that exploits meta-heuristic algorithms to adapt a model checker when used for integration testing of systems formally specified by graph transformations. Method This method is not based on model checking algorithms, but rather uses the modeling and simulation features of the underlying model checker. In the proposed approach, a population of test suites that each of which is a set of paths on the state space, is evolved towards satisfying the all def-use test objectives. Consequently, a test suite with high coverage is generated. Results To assess the efficiency of our approach, it is implemented in GROOVE, an open source toolset for designing and model checking graph transformation systems. Empirical results based on some case studies, confirm a significant improvement in terms of coverage, speed and memory usage, in comparison with the state of the art techniques. Conclusion Our analysis reveals that intelligent model checking can appropriately address the challenges of traditional model-checking-assisted testing. We further conclude that graph transformation specification is an efficient modeling solution to behavioral testing and graph transformation tools have a great potential for developing a model-based testing tool."
SCIENCEDIRECT,Journal Article,2023,Model-based security testing in IoT systems: A Rapid Review,"Lonetti F,Bertolino A,Di Giandomenico F","Internet of Things, Model-based testing, Security testing",107326,"Context: Security testing is a challenging and effort-demanding task in IoT scenarios. The heterogeneous devices expose different vulnerabilities that can influence the methods and cost of security testing. Model-based security testing techniques support the systematic generation of test cases for the assessment of security requirements by leveraging the specifications of the IoT system model and of the attack templates. Objective: This paper aims to review the adoption of model-based security testing in the context of IoT, and then provides the first systematic and up-to-date comprehensive classification and analysis of research studies in this topic. Method: We conducted a systematic literature review analyzing 803 publications and finally selecting 17 primary studies, which satisfied our inclusion criteria and were classified according to a set of relevant analysis dimensions. Results: We report the state-of-the-art about the used formalisms, the test techniques, the objectives, the target applications and domains; we also identify the targeted security attacks, and discuss the challenges, gaps and future research directions. Conclusion: Our review represents the first attempt to systematically analyze and classify existing studies on model-based security testing for IoT. According to the results, model-based security testing has been applied in core IoT domains. Models complexity and the need of modeling evolving scenarios that include heterogeneous open software and hardware components remain the most important shortcomings. Our study shows that model-based security testing of IoT applications is a promising research direction. The principal future research directions deal with: extending the existing modeling formalisms in order to capture all peculiarities and constraints of complex and large scale IoT networks; the definition of context-aware and dynamic evolution modeling approaches of IoT entities; and the combination of model-based testing techniques with other security test strategies such as penetration testing or learning techniques for model inference."
WILLEY,Journal Article,2019,MBT in agile/lightweight processes: a process-centred review,"Taromirad M,Ramsin R","program testing, Web services, software engineering, development process, MBT artefacts, MBT activities, integration criteria, agile/lightweight processes, appropriate MBT process, AD processes, agile processes, process-centred review, process-driven view, process-related aspects, practical MBT approach, agile development, effective MBT approach",11,"This study presents a process-driven view on the use of model-based testing (MBT) in agile/lightweight processes. It argues that process-related aspects of MBT and agile processes should be explicitly considered in any practical MBT approach intended for use in agile development (AD). It demonstrates that an effective MBT approach for lightweight processes has to specify how MBT activities are integrated into a development process, how and when MBT artefacts are generated in relation to other development artefacts, and who would carry out MBT activities. Accordingly, a set of integration criteria is introduced for complete incorporation of MBT into agile/lightweight processes. The integration criteria demonstrate the specific characteristics of an appropriate MBT process for AD processes, and help identify the benefits and shortcomings of existing methods on the use of MBT in such processes. Evaluation of existing works based on the proposed integration criteria shows that they have all focused on minimal modelling, and only one method has considered the ‘evolution’ of test models and the ‘reuse’ of test cases, whereas ‘evolution’ and ‘reuse’ are essential characteristics of agile processes, which have to be addressed in any MBT approach intended for such processes."
WILLEY,Book Chapter,2016,Process aspects of MBT,,"Certified Tester - Foundation Level syllabus, end-to-end testing, fundamental test process, MBT-specific activities, model-based testing, regression testing, software development lifecycles",24,"Summary This chapter covers the learning objectives of syllabus “Model-based testing (MBT) activities and artifacts in the fundamental test process” and “Integrating MBT into the software development lifecycles”. It illustrates the fundamental test process as defined in the Certified Tester - Foundation Level (CTFL) syllabus. The chapter presents typical MBT-specific activities in a testing workflow. The major output of the test planning activities is a documented test plan. The major difference lies in the modeling activity and the steps required to obtain executable tests from the MBT model. If the MBT approach fits the test objectives, that is, if the appropriate modeling language, the appropriate level of abstraction, and the appropriate tools are selected, MBT provides the same benefits for both lifecycle categories. To illustrate the manifold applications of MBT, the chapter presents two additional test types in more details: regression testing and end-to-end testing."
WILLEY,Book Chapter,2017,Systematic mapping study on MBT: tools and models,"Bernardino M,Rodrigues EM,Zorzo AF,Marchezan L","software engineering, program testing, systematic mapping, model-based testing, MBT process, software modelling, software development",15,"Every year several contributions to the model-based testing (MBT) field are published. Therefore, to follow the evolution and trends of several tools and models available is difficult. Moreover, since the variety of models and tools that became available in recent years, choosing an approach to support the MBT process is a challenging activity. The main objective of this study is to provide an overview on MBT tools and models used by those tools. Furthermore, the authors' study can help academic researchers and companies to understand the topics involving MBT. Therefore, a systematic mapping study was conducted in which 1197 distinct papers were evaluated. At the end, 87 primary studies were selected to be analysed in a quantitative and qualitative way. As a result, they classified the tools and models that are currently used to support MBT. Moreover, they identified 70 MBT tools, as well as different domains in which MBT is already applied to. Therefore, there are some evidence that MBT continues to be a broad and ‘alive’ research field since every year a significant number of papers presenting different kinds of contributions are published."
WILLEY,Book Chapter,2016,On transforming model-based tests into code: A systematic literature review,"Ferrari FC,Durelli VH,Andler SF,Offutt J,Saadatmand M,Müllner N","model-based testing, test coverage criteria, test case generation, test case transformation, systematic literature review",1860,"Summary Model-based test design is increasingly being applied in practice and studied in research. Model-based testing (MBT) exploits abstract models of the software behaviour to generate abstract tests, which are then transformed into concrete tests ready to run on the code. Given that abstract tests are designed to cover models but are run on code (after transformation), the effectiveness of MBT is dependent on whether model coverage also ensures coverage of key functional code. In this article, we investigate how MBT approaches generate tests from model specifications and how the coverage of tests designed strictly based on the model translates to code coverage. We used snowballing to conduct a systematic literature review. We started with three primary studies, which we refer to as the initial seeds. At the end of our search iterations, we analysed 30 studies that helped answer our research questions. More specifically, this article characterizes how test sets generated at the model level are mapped and applied to the source code level, discusses how tests are generated from the model specifications, analyses how the test coverage of models relates to the test coverage of the code when the same test set is executed and identifies the technologies and software development tasks that are on focus in the selected studies. Finally, we identify common characteristics and limitations that impact the research and practice of MBT: (i) some studies did not fully describe how tools transform abstract tests into concrete tests, (ii) some studies overlooked the computational cost of model-based approaches and (iii) some studies found evidence that bears out a robust correlation between decision coverage at the model level and branch coverage at the code level. We also noted that most primary studies omitted essential details about the experiments."
WILLEY,Book Chapter,2014,Automatic test case generation from Simulink/Stateflow models using model checking,"Mohalik S,Gadkari AA,Yeolekar A,Shashidhar KC,Ramesh S","model-based testing, automatic test generation, model checking, model translation, test coverage, Simulink/Stateflow",26,"SUMMARYModel-based test generation techniques based on random input generation and guided simulation do not satisfy the demands of high test coverage and completeness guarantees as required by safety-critical applications. Recently, test generation techniques based on model checking have been reported to bridge this gap. To evaluate the effectiveness of these techniques, an in-house tool suite, AutoMOTGen, has been developed for Simulink/Stateflow and applied on real-life case studies at General Motors. This paper outlines the test generation methodology of AutoMOTGen and gives a comparative study with a commercial, primarily random input-based, test generation tool on the same set of examples. The results indicate that in terms of coverage, model checking-based techniques complement the random input-based techniques. In addition, they provide proofs for unreachability that can aid in debugging the models. Therefore, it is recommended that model checking-based tools be utilized to complement and enhance the effectiveness of model-based testing methods in safety-critical systems engineering. Copyright © 2013 John Wiley & Sons, Ltd."
WILLEY,Journal Article,2014,A random testing approach using pushdown automata,"Dreyfus A,Héam PC,Kouchnarenko O,Masson C","uniform random test data generation, automated software testing, pushdown automata-based testing",28,"SUMMARY Developing efficient and automatic testing techniques is one of the major challenges faced by the software validation community. Recent work by A. Denise et al. shows how to draw traces uniformly at random for testing large systems modelled by finite automata. Because finite automata are strong abstractions of systems, many test cases generated following this approach may be unconcretizable, that is, they do not correspond to any concrete execution of the system under test. In this paper, this problem is tackled by extending the approach to pushdown systems that can encode either a stack data structure or the call stack. The method is based on context-free grammars and related algorithms, and relies on combinatorial techniques to guarantee the uniformity of generated traces. In addition, the combination of coverage criteria with random testing is investigated to benefit from both approaches for evaluating the quality of the test suites. The application of the random approach is illustrated within both structural and model-based testing contexts. Copyright © 2014 John Wiley & Sons, Ltd."
WILLEY,Book Chapter,2020,Design and validation of a C++ code generator from Abstract State Machines specifications,"Bonfanti S,Gargantini A,Mashkoor A","abstract state machine, automatic code generation, C++, model-driven engineering, transformation validation, unit tests generation",2205,"Abstract According to best practices of model-driven engineering, the implementation of a system should be obtained from its model through a systematic model-to-code transformation. We present in this paper a methodology supported by the Asm2C++ tool, which allows the users to generate C++ code from abstract state machine models. Thanks to Asm2C++, the implementation is generated in a seamless manner with an assurance of potential bug freeness of the generated code. Following the same approach, model-based testing suggests deriving also (unit) tests from abstract models. We extend the Asm2C++ tool such that it can automatically produce unit tests for the generated code. Abstract test sequences, either generated randomly or through model checking, are translated to concrete C++ unit tests using the Boost library. In a similar manner, also, scenarios are generated in a behavior-driven development (BDD) approach. To guarantee the correctness of the transformation process, we define a mechanism to test the correctness of the model-to-code transformation with respect to two main criteria: syntactical correctness and semantic correctness, which is based on the definition of conformance between the specification and the code. Using this approach, we have devised a process able to test the generated code by reusing unit tests. The process has been used to validate our model-to-code transformations."
WILLEY,Journal Article,2021,Testing of adaptive and context-aware systems: approaches and challenges,"Siqueira BR,Ferrari FC,Souza KE,Camargo VV,de Lemos R","software testing, adaptive systems, context-aware systems, systematic literature review, systematic mapping study",1772,"Summary Adaptive systems (ASs) and context-aware systems (CASs) are able to evaluate their own behaviour and to adapt it when the system fails to accomplish its goals or when better functionality or performance is possible. Ensuring the reliability of ASs and CASs is demanding because failures might have undesirable consequences. Testing ASs and CASs effectively is not trivial because of the inherent characteristics of these systems. The literature lacks a comprehensive review that provides a broad picture of the area; current reviews are outdated and incomplete. The objectives of this study are characterizing the state of the art in AS and CAS testing and discussing approaches, challenges, observed trends, and research limitations and directions. We performed a systematic literature review (SLR) and a thematic analysis of studies, reporting up-to-date, refined and extended results when compared with existing reviews. Based on 102 selected studies, we (i) characterized testing approaches by grouping techniques for ASs and CASs; (ii) updated and refined a characterization of testing challenges for ASs and CASs; and (iii) analysed and discussed research trends and implications for AS and CAS testing. There are recurring research concerns regarding AS and CAS testing. Examples are the generation of test cases and built-in tests. Moreover, we also identified recurring testing challenges such as context monitoring and runtime decisions. Moreover, there are some trends such as model-based testing and hybrid techniques and some little investigated issues like uncertainty and prediction of changes. All in all, our results may provide guidance for developers and researchers with respect to the practice and the future research on AS and CAS testing."
